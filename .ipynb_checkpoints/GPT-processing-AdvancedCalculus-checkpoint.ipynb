{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78c11609-2a8b-404a-81e5-db456fca9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb932f10-b19f-49a9-b883-3a14d4058e6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing section 0\n",
      "-s->\\section*{SOLVED PROBLEMS} 24\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 36\n",
      "processing section 1\n",
      "-s->\\section*{SOLVED PROBLEMS} 12\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 22\n",
      "processing section 2\n",
      "-s->\\section*{SOLVED PROBLEMS} 21\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 28\n",
      "processing section 3\n",
      "-s->\\section*{SOLVED PROBLEMS} 18\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 27\n",
      "processing section 4\n",
      "-s->\\section*{SOLVED PROBLEMS} 23\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 33\n",
      "processing section 5\n",
      "-s->\\section*{SOLVED PROBLEMS} 22\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 36\n",
      "processing section 6\n",
      "-s->\\section*{SOLVED PROBLEMS} 21\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 32\n",
      "processing section 7\n",
      "-s->\\section*{SOLVED PROBLEMS} 9\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 20\n",
      "processing section 8\n",
      "-s->\\section*{SOLVED PROBLEMS} 7\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 13\n",
      "processing section 9\n",
      "-s->\\section*{SOLVED PROBLEMS} 12\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 20\n",
      "processing section 10\n",
      "-s->\\section*{SOLVED PROBLEMS} 18\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 33\n",
      "processing section 11\n",
      "-s->\\section*{SOLVED PROBLEMS} 23\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 32\n",
      "processing section 12\n",
      "-s->\\section*{SOLVED PROBLEMS} 13\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 22\n",
      "processing section 13\n",
      "-s->\\section*{SOLVED PROBLEMS} 5\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 10\n",
      "processing section 14\n",
      "-s->\\section*{SOLVED PROBLEMS} 6\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 12\n",
      "-s->\\section*{SOLVED PROBLEMS} 33\n",
      "15\n",
      "'section*{CHAPTER 1}\\n'\n",
      "'section*{CHAPTER 2}\\n'\n",
      "'section*{CHAPTER 3}\\n'\n",
      "'section*{CHAPTER 4}\\n'\n",
      "'section*{CHAPTER 5}\\n'\n",
      "'section*{CHAPTER 6}\\n'\n",
      "'section*{CHAPTER 7}\\n'\n",
      "'section*{CHAPTER 8}\\n'\n",
      "'section*{CHAPTER 9}\\n'\n",
      "'section*{CHAPTER 10}'\n",
      "'section*{CHAPTER 11}'\n",
      "'section*{CHAPTER 12}'\n",
      "'section*{CHAPTER 13}'\n",
      "'section*{CHAPTER 14}'\n",
      "'section*{CHAPTER 15}'\n"
     ]
    }
   ],
   "source": [
    "def get_structured_contents(book_url, file_contents):\n",
    "    contents = []\n",
    "    if book_url == \"books/Schaum's Outlines - Tensor Calculus/2024_04_03_41f90be4f896e21f0dc9g/2024_04_03_41f90be4f896e21f0dc9g.tex\":\n",
    "        sections = re.split(r'(?=\\\\section..Chapter)', file_contents)\n",
    "        contents = []\n",
    "        for section in sections:\n",
    "            print(section.split('\\n', 1)[0],len(section))\n",
    "            section_parts = {}\n",
    "            section_parts[\"all\"]=section.split('\\n', 1)\n",
    "            \n",
    "            subsections = re.split(r'(?=\\\\section)', section)\n",
    "            for subsection in subsections:\n",
    "                if \"solved problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                    print(\"-->\"+subsection.split('\\n', 1)[0])\n",
    "                if \"supplementary problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                    print(\"-->\"+subsection.split('\\n', 1)[0])\n",
    "                    \n",
    "            # Splitting the section into three parts\n",
    "            parts = section.split(\"Solved Problems\", 1)\n",
    "            part_one = parts[0]\n",
    "            part_two_and_three = parts[1] if len(parts) > 1 else \"\"\n",
    "            \n",
    "            parts = part_two_and_three.split(\"Supplementary Problems\", 1)\n",
    "            part_two = \"Solved Problems\" + parts[0] if part_two_and_three else \"\"\n",
    "            part_three_and_four = \"Supplementary Problems\" + parts[1] if len(parts) > 1 else \"\"\n",
    "    \n",
    "            #extract answers to supplementary problems\n",
    "            parts = part_three_and_four.split(\"Answers to Supplementary Problems\", 1)\n",
    "            part_three = \"Supplementary Problems\" + parts[0] if part_two_and_three else \"\"\n",
    "            part_four = \"Answers to Supplementary Problems\" + parts[1] if len(parts) > 1 else \"\"\n",
    "    \n",
    "            # Optionally, print or process the parts\n",
    "            print(\"lesson:\", len(part_one), \"solved problems:\", len(part_two), \"supplementary:\", len(part_three), \", total\", len(part_one)+len(part_two)+ len(part_three))\n",
    "            \n",
    "            section_parts[\"lesson\"]=part_one\n",
    "            section_parts[\"solved_problems\"]=part_two\n",
    "            section_parts[\"supplementary_problems\"]=part_three\n",
    "            section_parts[\"answers_to_supplementary_problems\"]=part_four\n",
    "        \n",
    "            if (len(part_one)>0 and len(part_two)>0):\n",
    "                contents.append(section_parts)\n",
    "            else:\n",
    "                print(\"dropped a section from further analysis\")\n",
    "                \n",
    "    elif book_url == \"books/Schaum's Outlines - Linear Algebra,Fourth Edition/2024_04_03_de2bde501961f6000cc6g/2024_04_03_de2bde501961f6000cc6g.tex\":\n",
    "        contents = []\n",
    "        sections = re.split(r'(?=section.*.Introduction)', file_contents)\n",
    "        for i, section in enumerate(sections):\n",
    "            if i<len(sections)-1:\n",
    "                #print('\\n'.join(section.split('\\n')[-3:]),\"(length:\",len(section),\")\")\n",
    "                #make these last three lines before the Indtroduction part of the next chapter\n",
    "                sections[i+1] = '\\n'.join(section.split('\\n')[-3:])+sections[i+1]\n",
    "            #and remove them from the last\n",
    "            sections[i] = '\\n'.join(section.split('\\n')[:-3])\n",
    "        \n",
    "        for i, section in enumerate(sections[1:]):#skip the stuff before chapter 1\n",
    "            section_parts = {}\n",
    "            section_parts[\"all\"]=section\n",
    "            subsections = re.split(r'(?=\\\\section)', section)\n",
    "            print(\"processing section\",i)\n",
    "            for j, subsection in enumerate(subsections):\n",
    "                if \"solved problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                    print(\"-s->\"+subsection.split('\\n', 1)[0], j)\n",
    "                    section_parts[\"lesson\"] = \"\\n\".join(subsections[0:j])\n",
    "                    end_of_lesson = j\n",
    "                if \"supplementary problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                    if \"answers to supplementary problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                        print(\"-p->\"+subsection.split('\\n', 1)[0],j)\n",
    "                        section_parts[\"supplementary_problems\"] = \"\\n\".join(subsections[end_of_solved_problems:j])\n",
    "                        section_parts[\"answers_to_supplementary_problems\"] = \"\\n\".join(subsections[j:])\n",
    "                    else:\n",
    "                        print(\"-a->\"+subsection.split('\\n', 1)[0],j)\n",
    "                        section_parts[\"solved_problems\"] = \"\\n\".join(subsections[end_of_lesson:j])\n",
    "                        end_of_solved_problems = j\n",
    "            if \"lesson\" in section_parts and \"supplementary_problems\" in section_parts and \"answers_to_supplementary_problems\" in section_parts:\n",
    "                contents.append(section_parts)\n",
    "            else:\n",
    "                print(\"dropped a section from further analysis\")\n",
    "\n",
    "    elif book_url == \"books/SCHAUM's Outlines - Advanced Calculus, 3rd Edition_2010/2024_04_03_ffb6ac533fe0a53b3ceeg/2024_04_03_ffb6ac533fe0a53b3ceeg.tex\":\n",
    "        contents = []\n",
    "        sections = re.split(r'(?=section.*.CHAPTER)', file_contents)\n",
    "       \n",
    "        for i, section in enumerate(sections[1:]):#skip the stuff before chapter 1\n",
    "            section_parts = {}\n",
    "            section_parts[\"all\"]=section\n",
    "            subsections = re.split(r'(?=\\\\section)', section)\n",
    "            print(\"processing section\",i)\n",
    "            for j, subsection in enumerate(subsections):\n",
    "                if \"solved problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                    print(\"-s->\"+subsection.split('\\n', 1)[0], j)\n",
    "                    section_parts[\"lesson\"] = \"\\n\".join(subsections[0:j])\n",
    "                    end_of_lesson = j\n",
    "                if \"supplementary problems\" in subsection.split('\\n', 1)[0].lower():\n",
    "                    print(\"-a->\"+subsection.split('\\n', 1)[0],j)\n",
    "                    section_parts[\"solved_problems\"] = \"\\n\".join(subsections[end_of_lesson:j])\n",
    "                    section_parts[\"supplementary_problems\"] = \"\\n\".join(subsections[j:])\n",
    "\n",
    "            if \"lesson\" in section_parts and \"supplementary_problems\" in section_parts:\n",
    "                contents.append(section_parts)\n",
    "            else:\n",
    "                print(\"dropped a section from further analysis\")\n",
    "\n",
    "    return contents\n",
    "\n",
    "book_url = \"books/SCHAUM's Outlines - Advanced Calculus, 3rd Edition_2010/2024_04_03_ffb6ac533fe0a53b3ceeg/2024_04_03_ffb6ac533fe0a53b3ceeg.tex\"\n",
    "with open(book_url, 'r') as file:\n",
    "    # Read the contents of the file into a string\n",
    "    file_contents = file.read()\n",
    "\n",
    "contents = get_structured_contents(book_url, file_contents)\n",
    "\n",
    "print(len(contents))\n",
    "for chapter in contents:\n",
    "    print(repr(chapter[\"all\"][:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38516fe5-9dad-4f3d-bff8-39a73fc10847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books/Schaum's Outlines - Linear Algebra,Fourth Edition/2024_04_03_de2bde501961f6000cc6g/2024_04_03_de2bde501961f6000cc6g.tex\n",
      "processing section 0\n",
      "-s->\\section*{SOLVED PROBLEMS} 21\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 27\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 34\n",
      "processing section 1\n",
      "-s->\\section*{SOLVED PROBLEMS} 18\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 29\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 35\n",
      "processing section 2\n",
      "-s->\\section*{SOLVED PROBLEMS} 42\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 51\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 59\n",
      "processing section 3\n",
      "-s->\\section*{SOLVED PROBLEMS} 28\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 41\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 51\n",
      "processing section 4\n",
      "-s->\\section*{SOLVED PROBLEMS} 20\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 27\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 34\n",
      "processing section 5\n",
      "-s->\\section*{SOLVED PROBLEMS} 8\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 14\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 21\n",
      "processing section 6\n",
      "-s->\\section*{SOLVED PROBLEMS} 23\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 31\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 39\n",
      "processing section 7\n",
      "-s->\\section*{SOLVED PROBLEMS} 13\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 20\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 28\n",
      "processing section 8\n",
      "-s->\\section*{SOLVED PROBLEMS} 16\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 22\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 27\n",
      "processing section 9\n",
      "-s->\\section*{SOLVED PROBLEMS} 3\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 10\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 19\n",
      "processing section 10\n",
      "-s->\\section*{SOLVED PROBLEMS} 3\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 7\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 12\n",
      "processing section 11\n",
      "-s->\\section*{SOLVED PROBLEMS} 9\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 15\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 21\n",
      "processing section 12\n",
      "-s->\\section*{SOLVED PROBLEMS} 7\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 13\n",
      "-p->\\section*{ANSWERS TO SUPPLEMENTARY PROBLEMS} 21\n",
      "processing section 13\n",
      "dropped a section from further analysis\n",
      "processing section 14\n",
      "dropped a section from further analysis\n",
      "processing section 15\n",
      "dropped a section from further analysis\n",
      "books/SCHAUM's Outlines - Advanced Calculus, 3rd Edition_2010/2024_04_03_ffb6ac533fe0a53b3ceeg/2024_04_03_ffb6ac533fe0a53b3ceeg.tex\n",
      "processing section 0\n",
      "-s->\\section*{SOLVED PROBLEMS} 24\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 34\n",
      "-s->\\section*{SOLVED PROBLEMS} 63\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 77\n",
      "-s->\\section*{SOLVED PROBLEMS} 107\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 118\n",
      "-s->\\section*{SOLVED PROBLEMS} 136\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 147\n",
      "-s->\\section*{SOLVED PROBLEMS} 164\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 170\n",
      "-s->\\section*{SOLVED PROBLEMS} 189\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 197\n",
      "-s->\\section*{SOLVED PROBLEMS} 223\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 238\n",
      "-s->\\section*{SOLVED PROBLEMS} 273\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 282\n",
      "-s->\\section*{SOLVED PROBLEMS} 302\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 311\n",
      "-s->\\section*{SOLVED PROBLEMS} 322\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 327\n",
      "-s->\\section*{SOLVED PROBLEMS} 337\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 343\n",
      "-s->\\section*{SOLVED PROBLEMS} 364\n",
      "books/Schaum's Outlines - Tensor Calculus/2024_04_03_41f90be4f896e21f0dc9g/2024_04_03_41f90be4f896e21f0dc9g.tex\n",
      "\\documentclass[10pt]{article} 386\n",
      "lesson: 386 solved problems: 0 supplementary: 0 , total 386\n",
      "dropped a section from further analysis\n",
      "\\section*{Chapter 1} 19218\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 8913 solved problems: 8080 supplementary: 2247 , total 19240\n",
      "\\section*{Chapter 2} 46088\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 18735 solved problems: 22706 supplementary: 4669 , total 46110\n",
      "\\section*{Chapter 3} 64587\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 30932 solved problems: 29896 supplementary: 3781 , total 64609\n",
      "\\section*{Chapter 4} 28058\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 11872 solved problems: 14301 supplementary: 1907 , total 28080\n",
      "\\section*{Chapter 5} 46129\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 19967 solved problems: 22209 supplementary: 3975 , total 46151\n",
      "\\section*{Chapter 6} 49218\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 22268 solved problems: 22400 supplementary: 4572 , total 49240\n",
      "\\section*{Chapter 7} 54408\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 7641 solved problems: 42821 supplementary: 3968 , total 54430\n",
      "\\section*{Chapter 8} 45043\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 19338 solved problems: 20745 supplementary: 4982 , total 45065\n",
      "\\section*{Chapter 9} 42707\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 20990 solved problems: 19771 supplementary: 1968 , total 42729\n",
      "\\section*{Chapter 10} 80197\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 33342 solved problems: 41807 supplementary: 5070 , total 80219\n",
      "\\section*{Chapter 11} 32983\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 17080 solved problems: 14262 supplementary: 1663 , total 33005\n",
      "\\section*{Chapter 12} 76938\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "lesson: 30474 solved problems: 39909 supplementary: 6577 , total 76960\n",
      "\\section*{Chapter 13} 113804\n",
      "-->\\section*{Solved Problems}\n",
      "-->\\section*{Supplementary Problems}\n",
      "-->\\section*{Answers to Supplementary Problems}\n",
      "lesson: 42369 solved problems: 37296 supplementary: 5332 , total 84997\n",
      "books/Differential quation/2024_04_03_5bb5b4275a64cb9887d1g/2024_04_03_5bb5b4275a64cb9887d1g.tex\n",
      "books/Schaum's_Outlines_-_Discrete_Mathematics,_3rd_Ed._by_Seymour_Lipschutz/2024_04_03_e2bc10318661343af903g/2024_04_03_e2bc10318661343af903g.tex\n",
      "books/Schaum's Outlines - Calculus, 5th Edition/2024_04_03_1accc0f8242883d76c43g/2024_04_03_1accc0f8242883d76c43g.tex\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk('books'):\n",
    "    for file in files:\n",
    "        if file.endswith('.tex'):\n",
    "            book_url = os.path.join(root, file)\n",
    "            # Now you have the path of a .tex file, you can do something with it\n",
    "            print(book_url)\n",
    "\n",
    "            with open(book_url, 'r') as file:\n",
    "                # Read the contents of the file into a string\n",
    "                file_contents = file.read()\n",
    "            \n",
    "            contents = get_structured_contents(book_url, file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a052841f-c7d3-4e7e-9fed-6db3a1597b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing section 0\n",
      "-s->\\section*{SOLVED PROBLEMS} 24\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 36\n",
      "processing section 1\n",
      "-s->\\section*{SOLVED PROBLEMS} 12\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 22\n",
      "processing section 2\n",
      "-s->\\section*{SOLVED PROBLEMS} 21\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 28\n",
      "processing section 3\n",
      "-s->\\section*{SOLVED PROBLEMS} 18\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 27\n",
      "processing section 4\n",
      "-s->\\section*{SOLVED PROBLEMS} 23\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 33\n",
      "processing section 5\n",
      "-s->\\section*{SOLVED PROBLEMS} 22\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 36\n",
      "processing section 6\n",
      "-s->\\section*{SOLVED PROBLEMS} 21\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 32\n",
      "processing section 7\n",
      "-s->\\section*{SOLVED PROBLEMS} 9\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 20\n",
      "processing section 8\n",
      "-s->\\section*{SOLVED PROBLEMS} 7\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 13\n",
      "processing section 9\n",
      "-s->\\section*{SOLVED PROBLEMS} 12\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 20\n",
      "processing section 10\n",
      "-s->\\section*{SOLVED PROBLEMS} 18\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 33\n",
      "processing section 11\n",
      "-s->\\section*{SOLVED PROBLEMS} 23\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 32\n",
      "processing section 12\n",
      "-s->\\section*{SOLVED PROBLEMS} 13\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 22\n",
      "processing section 13\n",
      "-s->\\section*{SOLVED PROBLEMS} 5\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 10\n",
      "processing section 14\n",
      "-s->\\section*{SOLVED PROBLEMS} 6\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 12\n",
      "-s->\\section*{SOLVED PROBLEMS} 33\n"
     ]
    }
   ],
   "source": [
    "book_url = \"books/SCHAUM's Outlines - Advanced Calculus, 3rd Edition_2010/2024_04_03_ffb6ac533fe0a53b3ceeg/2024_04_03_ffb6ac533fe0a53b3ceeg.tex\"\n",
    "with open(book_url, 'r') as file:\n",
    "    # Read the contents of the file into a string\n",
    "    file_contents = file.read()\n",
    "\n",
    "contents = get_structured_contents(book_url, file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "618aac3c-a98c-438d-91b3-be0b7504c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n",
      "present in chapter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\\\section*{SOLVED PROBLEMS}\\n\\n\\\\section*{Operations with numbers}\\n',\n",
       " '1.1. If $x=4, y=15, z=-3, p=\\\\frac{2}{3}, q=-\\\\frac{1}{6}$, and $r=$\\\\\\\\\\n(c) $p(q r), \\\\quad$ (d) $(p q) r$, (e) $x(p+q)$.\\\\\\\\\\n(a) $x+(y+z)=4+[15+(-3)]=4+12=16$\\\\\\\\\\n(b) $(x+y)+z=(4+15)+(-3)=19-3=16$\\n\\nThe fact that $(a)$ and $(b)$ are equal illustrates the associative law of addition.\\n\\n(c) $p(q r)=\\\\frac{2}{3}\\\\left\\\\{\\\\left(-\\\\frac{1}{6}\\\\right)\\\\left(\\\\frac{3}{4}\\\\right)\\\\right\\\\}=\\\\left(\\\\frac{2}{3}\\\\right)\\\\left(-\\\\frac{3}{24}\\\\right)=\\\\left(\\\\frac{2}{3}\\\\right)\\\\left(-\\\\frac{1}{8}\\\\right)=-\\\\frac{2}{24}=-\\\\frac{1}{12}$\\n\\n(d) $(p q) r=\\\\left\\\\{\\\\left(\\\\frac{2}{3}\\\\right)\\\\left(-\\\\frac{1}{6}\\\\right)\\\\right\\\\}\\\\left(\\\\frac{3}{4}\\\\right)=\\\\left(-\\\\frac{2}{18}\\\\right)\\\\left(\\\\frac{3}{4}\\\\right)=\\\\left(-\\\\frac{1}{9}\\\\right)\\\\left(\\\\frac{3}{4}\\\\right)=-\\\\frac{3}{36}=-\\\\frac{1}{12}$\\n\\nThe fact that $(c)$ and $(d)$ are equal illustrates the associative law of multiplication.\\n\\n(e) $x(p+q)=4\\\\left(\\\\frac{2}{3}-\\\\frac{1}{6}\\\\right)=4\\\\left(\\\\frac{4}{6}-\\\\frac{1}{6}\\\\right)=4\\\\left(\\\\frac{3}{6}\\\\right)=\\\\frac{12}{6}=2$\\n\\nAnother method: $x(p+q)=x p+x q=(4)\\\\left(\\\\frac{2}{3}\\\\right)+(4)\\\\left(-\\\\frac{1}{6}\\\\right)=\\\\frac{8}{3}-\\\\frac{4}{6}=\\\\frac{8}{3}-\\\\frac{2}{3}=\\\\frac{6}{3}=2$ using the dis-\\\\\\\\\\ntributive law.\\n',\n",
       " '\\n1.2. Explain why we do not consider (a) $\\\\frac{0}{0}$ and (b) $\\\\frac{1}{0}$ as numbers.\\n\\n(a) If we define $a / b$ as that number (if it exists) such that $b x=a$, then $0 / 0$ is that number $x$ such that $0 x=0$. However, this is true for all numbers. Since there is no unique number which $0 / 0$ can represent, we consider it undefined.\\n\\n(b) As in (a), if we define $1 / 0$ as that number $x$ (if it exists) such that $0 x=1$, we conclude that there is no such number.\\n\\nBecause of these facts we must look upon division by zero as meaningless.\\n',\n",
       " '\\n1.3. Simplify $\\\\frac{x^{2}-5 x+6}{x^{2}-2 x-3}$.\\n\\n$\\\\frac{x^{2}-5 x+6}{x^{2}-2 x-3}=\\\\frac{(x-3)(x-2)}{(x-3)(x+1)}=\\\\frac{x-2}{x+1}$ provided that the cancelled factor $(x-3)$ is not zero; i.e., $x \\\\neq 3$. For $x=3$, the given fraction is undefined.\\n\\n\\n\\\\section*{Rational and irrational numbers}\\n',\n",
       " '1.4. Prove that the square of any odd integer is odd.\\n\\nAny odd integer has the form $2 m+1$. Since $(2 m+1)^{2}=4 m^{2}+4 m+1$ is 1 more than the even integer $4 m^{2}$ $+4 m=2\\\\left(2 m^{2}+2 m\\\\right)$, the result follows.\\n',\n",
       " '\\n1.5. Prove that there is no rational number whose square is 2 .\\n\\nLet $p$ / $q$ be a rational number whose square is 2 , where we assume that $p / q$ is in lowest terms; i.e., $p$ and $q$ have no common integer factors except $\\\\pm 1$ (we sometimes call such integers relatively prime).\\n\\nThen $(p / q)^{2}=2, p^{2}=2 q^{2}$ and $p^{2}$ is even. From Problem 1.4, $p$ is even, since if $p$ were odd, $p^{2}$ would be odd. Thus, $p=2 m$.\\n\\nSubstituting $p=2 m$ in $p^{2}=2 q^{2}$ yields $q^{2}=2 m^{2}$, so that $q^{2}$ is even and $q$ is even.\\n\\nThus, $p$ and $q$ have the common factor 2, contradicting the original assumption that they had no common factors other than $\\\\pm 1$. By virtue of this contradiction there can be no rational number whose square is 2 .\\n',\n",
       " '\\n1.6. Show how to find rational numbers whose squares can be arbitrarily close to 2 .\\n\\nWe restrict ourselves to positive rational numbers. Since $(1)^{2}=1$ and $(2)^{2}=4$, we are led to choose rational numbers between 1 and 2, e.g., 1.1, 1.2, 1.3, . ., 1.9.\\n\\nSince $(1.4)^{2}=1.96$ and $(1.5)^{2}=2.25$, we consider rational numbers between 1.4 and 1.5, e.g., 1.41, $1.42, ., 1.49$.\\n\\nContinuing in this manner we can obtain closer and closer rational approximations; e.g., $(1.414213562)^{2}$ is less than 2, while $(1.414213563)^{2}$ is greater than 2 .\\n',\n",
       " '\\n1.7. Given the equation $a_{0} x^{n}+a_{1} x^{n-1}+\\\\cdots+a_{n}=0$, where $a_{0}, a_{1}, \\\\ldots a_{n}$ are integers and $a_{0}$ and $a_{n} \\\\neq 0$, show that if the equation is to have a rational root $p / q$, then $p$ must divide $a_{n}$ and $q$ must divide $a_{0}$ exactly.\\n\\nSince $p / q$ is a root we have, on substituting in the given equation and multiplying by $q^{n}$, the result is\\n\\n\\n\\\\begin{equation*}\\na_{0} p^{n}+a_{1} p^{n-1} q+a_{2} p^{n-2} q^{2}+\\\\cdots+a_{n-1} p q^{n-1}+a_{n} q^{n}=0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nor dividing by $p$,\\n\\n\\n\\\\begin{equation*}\\na_{0} p^{n-1}+a_{1} p^{n-2} q+\\\\cdots+a_{n-1} q^{n-1}=-\\\\frac{a_{n} q^{n}}{p} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSince the left side of Equation (2) is an integer, the right side must also be an integer. Then, since $p$ and $q$ are relatively prime, $p$ does not divide $q^{n}$ exactly and so must divide $a_{n}$.\\n\\nIn a similar manner, by transposing the first term of Equation (1) and dividing by $q$, we can show that $q$ must divide $a_{0}$.\\n',\n",
       " '\\n1.8. Prove that $\\\\sqrt{2}+\\\\sqrt{3}$ cannot be a rational number.\\n\\nIf $x=\\\\sqrt{2}+\\\\sqrt{3}$, then $x^{2}=5+2 \\\\sqrt{6}, x^{2}-5=2 \\\\sqrt{6}$, and, squaring, $x^{4}-10 x^{2}+1=0$. The only possible rational roots of this equation are $\\\\pm 1$ by Problem 1.7, and these do not satisfy the equation. It follows that $\\\\sqrt{2}+\\\\sqrt{3}$, which satisfies the equation, cannot be a rational number.\\n',\n",
       " '\\n1.9. Prove that between any two rational numbers there is another rational number.\\n\\nThe set of rational numbers is closed under the operations of addition and division (nonzero denominator). Therefore, $\\\\frac{a+b}{2}$ is rational. The next step is to guarantee that this value is between $a$ and $b$. To this purpose, assume $a<b$. (The proof would proceed similarly under the assumption $b<a$.) Then $2 a<a+b$; thus, $a<$ $\\\\frac{a+b}{2}$ and $a+b<2 b$; therefore, $\\\\frac{a+b}{2}<b$.\\n\\n\\n\\\\section*{Inequalities}\\n',\n",
       " '1.10. For what values of $x$ is $x+3(2-x) \\\\geqq 4-x$ ?\\n\\n$$\\nx+3(2-x) \\\\geqq 4-x \\\\text { when } x+6-3 x \\\\geqq 4-x, 6-2 x \\\\geqq 4-x, 6-4 \\\\geqq 2 x-x \\\\text {, and } 2 \\\\geqq x \\\\text {; i.e. } x \\\\leqq 2\\n$$\\n',\n",
       " '\\n1.11. For what values of $x$ is $x^{2}-3 x-2<10-2 x$ ?\\n\\nThe required inequality holds when $x^{2}-3 x-2-10+2 x<0, x^{2}-x-12<0$ or $(x-4)(x+3)<0$. This last inequality holds only in the following cases.\\n\\nCase 1: $\\\\quad x-4>0$ and $x+3<0$; i.e., $x>4$ and $x<-3$. This is impossible, since $x$ cannot be both greater than 4 and less than -3 .\\n\\nCase 2: $\\\\quad x-4<0$ and $x+3>0$; i.e., $x<4$ and $x>-3$. This is possible when $-3<x<4$. Thus, the inequality holds for the set of all $x$ such that $-3<x<4$.\\n',\n",
       " '\\n1.12. $\\\\quad$ If $a \\\\geqq 0$ and $b \\\\geqq 0$, prove that $\\\\frac{1}{2}(a+b) \\\\geqq \\\\sqrt{a b}$.\\n\\nThe statement is self-evident in the following cases: (1) $a=b$, and (2) either or both of $a$ and $b$ zero. For both $a$ and $b$ positive and $a \\\\neq b$. the proof is by contradiction.\\n\\nAssume to the contrary of the supposition that $\\\\frac{1}{2}(a+b)<\\\\sqrt{a b}$, then $\\\\frac{1}{4}\\\\left(a^{2}+2 a b+b^{2}\\\\right)<a b$.\\n\\nThat is, $a^{2}-2 a b+b^{2}=(a-b)^{2}<0$. Since the left member of this equation is a square, it cannot be less than zero, as is indicated. Having reached this contradiction, we may conclude that our assumption is incorrect and that the original assertion is true.\\n',\n",
       " \"\\n1.13. If $a_{1}, a_{2}, \\\\ldots, a_{n}$ and $b_{1}, b_{2} \\\\ldots b_{n}$ are any real numbers, prove Schwarz's inequality:\\n\\n$$\\n\\\\left(a_{1} b_{1}+a_{2} b_{2}+\\\\cdots+a_{n} b_{n}\\\\right)^{2} \\\\leqq\\\\left(a_{1}^{2}+a_{2}^{2}+\\\\cdots+a_{n}^{2}\\\\right)\\\\left(b_{1}^{2}+b_{2}^{2}+\\\\cdots+b_{2}^{2}\\\\right)\\n$$\\n\\nFor all real numbers $\\\\lambda$, we have\\n\\n$$\\n\\\\left(a_{1} \\\\lambda+b_{1}\\\\right)^{2}+\\\\left(a_{2} \\\\lambda+b_{2}\\\\right)^{2}+\\\\cdots+\\\\left(a_{n} \\\\lambda+b_{n}\\\\right)^{2} \\\\geqq 0\\n$$\\n\\nExpanding and collecting terms yields\\n\\n\\n\\\\begin{equation*}\\nA^{2} \\\\lambda^{2}+2 C \\\\lambda+B^{2} \\\\geqq 0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere\\n\\n\\n\\\\begin{equation*}\\nA^{2}=a_{1}^{2}+a_{2}^{2}+\\\\cdots+a_{n}^{2} . \\\\quad B^{2}=b_{1}^{2}+b_{2}^{2}+\\\\cdots+b_{n}^{2}, \\\\quad C=a_{1} b_{1}+a_{2} b_{2}+\\\\cdots+a_{n} b_{n} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nThe left member of Equation (1) is a quadratic form in $\\\\lambda$. Since it never is negative, its discriminant, $4 C^{2}$ $-4 A^{2} B^{2}$, cannot be positive. Thus,\\n\\n$$\\nC^{2}-A^{2} B^{2} \\\\leq 0 \\\\quad \\\\text { or } \\\\quad C^{2} \\\\leq A^{2} B^{2}\\n$$\\n\\nThis is the inequality that was to be proved.\\n\",\n",
       " '\\n1.14. Prove that $\\\\frac{1}{2}+\\\\frac{1}{4}+\\\\frac{1}{8}+\\\\cdots+\\\\frac{1}{2^{n-1}}<1$ for all positive integers $n>1$.\\n\\nLet\\n\\n$$\\nS_{n}=\\\\frac{1}{2}+\\\\frac{1}{4}+\\\\frac{1}{8}+\\\\cdots+\\\\frac{1}{2^{n-1}}\\n$$\\n\\nThen\\n\\n$$\\n\\\\frac{1}{2} S_{n}=\\\\frac{1}{4}+\\\\frac{1}{8}+\\\\cdots+\\\\frac{1}{2^{n-1}}+\\\\frac{1}{2^{n}}\\n$$\\n\\nSubtracting,\\n\\n$$\\n\\\\frac{1}{2} S_{n}=\\\\frac{1}{2}-\\\\frac{1}{2^{n}}\\n$$\\n\\nThus,\\n\\n$$\\nS_{n}=1-\\\\frac{1}{2^{n-1}}<1 \\\\text { for all } n\\n$$\\n\\n\\n\\\\section*{Exponents, roots, and logarithms}\\n',\n",
       " '1.15. Evaluate each of the following:\\n\\n(a) $\\\\frac{3^{4} \\\\cdot 3^{8}}{3^{14}}=\\\\frac{3^{4+8}}{3^{14}}=3^{4+8-14}=3^{-2}=\\\\frac{1}{3^{2}}=\\\\frac{1}{9}$\\n\\n(b) $\\\\sqrt{\\\\frac{\\\\left(5 \\\\cdot 10^{-6}\\\\right)\\\\left(4 \\\\cdot 10^{2}\\\\right)}{8 \\\\cdot 10^{5}}}=\\\\sqrt{\\\\frac{5 \\\\cdot 4}{8}: \\\\frac{10^{-6} \\\\cdot 10^{2}}{10^{5}}}=\\\\sqrt{2.5 \\\\cdot 10^{-9}}=\\\\sqrt{25 \\\\cdot 10^{-10}}=5 \\\\cdot 10^{-5}$ or 0.00005\\n\\n(c) $\\\\log _{2 / 3}\\\\left(\\\\frac{27}{8}\\\\right)=x$. Then $\\\\left(\\\\frac{2}{3}\\\\right)^{x}=\\\\frac{27}{8}=\\\\left(\\\\frac{3}{2}\\\\right)^{3}=\\\\left(\\\\frac{2}{3}\\\\right)^{-3}$ or $x=-3$\\n\\n(d) $\\\\left(\\\\log _{a} b\\\\right)\\\\left(\\\\log _{b} a\\\\right)=u$. Then $\\\\log _{a} b=x, \\\\log _{b} a=y$, assuming $a, b>0$ and $a, b \\\\neq 1$.\\n\\nThen $a^{x}=b, b^{y}=a$, and $u=x y$. Since $\\\\left(a^{x}\\\\right)^{y}=a^{x y}=b^{y}=a$, we have $a^{x y}=a^{1}$ or $x y=1$, the required value.\\n',\n",
       " '\\n1.16. If $M>0, N>0$, and $a>0$ but $a \\\\neq 1$, prove that $\\\\log _{a} \\\\frac{M}{N}=\\\\log _{a} M-\\\\log _{a} N$.\\n\\nLet $\\\\log _{a} M=x, \\\\log _{a} N=y . \\\\quad$ Then $a^{x}=M, a^{y}=N$ and so\\n\\n$$\\n\\\\frac{M}{N}=\\\\frac{a^{x}}{a^{y}}=a^{x-y} \\\\quad \\\\text { or } \\\\quad \\\\log _{a} \\\\frac{M}{N}=x-y=\\\\log _{a} M-\\\\log _{a} N\\n$$\\n\\n\\n\\\\section*{Countability}\\n',\n",
       " '1.17. Prove that the set of all rational numbers between 0 and 1 inclusive is countable.\\n\\nWrite all fractions with denominator 2 , then $3, \\\\ldots$, considering equivalent fractions such as $\\\\frac{1}{2}, \\\\frac{2}{4}$, $\\\\frac{3}{6}, \\\\ldots$ no more than once. Then the 1-1 correspondence with the natural numbers can be accomplished as follows:\\n\\n\\\\begin{center}\\n\\\\begin{tabular}{lcccccccccc}\\nRational numbers & 0 & 1 & $\\\\frac{1}{2}$ & $\\\\frac{1}{3}$ & $\\\\frac{2}{3}$ & $\\\\frac{1}{4}$ & $\\\\frac{3}{4}$ & $\\\\frac{1}{5}$ & $\\\\frac{2}{5}$ & $\\\\ldots$ \\\\\\\\\\n & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\uparrow$ & $\\\\downarrow$ &  \\\\\\\\\\n & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\\\\ldots$ \\\\\\\\\\n\\\\end{tabular}\\n\\\\end{center}\\n\\nThus, the set of all rational numbers between 0 and 1 inclusive is countable and has cardinal number $\\\\boldsymbol{\\\\aleph}_{0}$ (see Page 6).\\n',\n",
       " '\\n1.18. If $A$ and $B$ are two countable sets, prove that the set consisting of all elements from $A$ or $B$ (or both) is also countable.\\n\\nSince $A$ is countable, there is a 1-1 correspondence between elements of $A$ and the natural numbers so that we can denote these elements by $a_{1}, a_{2}, a_{3}, \\\\ldots$\\n\\nSimilarly, we can denote the elements of $B$ by $b_{1}, b_{2}, b_{3}, \\\\ldots$\\n\\nCase 1: Suppose elements of $A$ are all distinct from elements of $B$. Then the set consisting of elements from\\n\\n\\\\begin{center}\\n\\\\begin{tabular}{|c|c|c|c|c|c|}\\n\\\\hline\\nor $B$ &  &  & $a_{2}$ & ${ }_{2} b_{2}$ & ${ }_{2} a_{3}$ \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}\\n\\\\end{center}\\n\\n$A$ or $B$ is countable, since we can establish the following 1-1 correspondence:\\n\\nCase 2: If some elements of $A$ and $B$ are the same, we count them only once, as in Problem 1.17. Then the set of elements belonging to $A$ or $B$ (or both) is countable.\\n\\nThe set consisting of all elements which belong to $A$ or $B$ (or both) is often called the union of $A$ and $B$, denoted by $A \\\\cup B$ or $A+B$.\\n\\nThe set consisting of all elements which are contained in both $A$ and $B$ is called the intersection of $A$ and $B$, denoted by $A \\\\cap B$ or $A B$. If $A$ and $B$ are countable, so is $A \\\\cap B$.\\n\\nThe set consisting of all elements in $A$ but not in $B$ is written $A-B$. If we let $[B$ be the set of elements which are not in $B$, we can also write $A-B=A \\\\bar{B}$. If $A$ and $B$ are countable, so is $A-B$.\\n',\n",
       " '\\n1.19. Prove that the set of all positive rational numbers is countable.\\n\\nConsider all rational numbers $x>1$. With each such rational number we can associate one and only one rational number $1 / x$ in $(0,1)$; i.e., there is a one-to-one correspondence between all rational numbers $>1$ and all rational numbers in $(0,1)$. Since these last are countable by Problem 1.17, it follows that the set of all rational numbers $>1$ is also countable.\\n\\nFrom Problem 1.18 it then follows that the set consisting of all positive rational numbers is countable, since this is composed of the two countable sets of rationals between 0 and 1 and those greater than or equal to 1 .\\n\\nFrom this we can show that the set of all rational numbers is countable (see Problem 1.59).\\n',\n",
       " \"\\n1.20. Prove that the set of all real numbers in $[0,1]$ is noncountable.\\n\\nEvery real number in $[0,1]$ has a decimal expansion.$a_{1} a_{2} a_{3} \\\\ldots$ where $a_{1}, a_{2}, \\\\ldots$ are any of the digits 0 , $1,2, \\\\ldots, 9$.\\n\\nWe assume that numbers whose decimal expansions terminate such as 0.7324 are written $0.73240000 \\\\ldots$ and that this is the same as $0.73239999 \\\\ldots$\\n\\nIf all real numbers in $[0,1]$ are countable we can place them in 1-1 correspondence with the natural numbers as in the following list:\\n\\n$$\\n\\\\begin{aligned}\\n& 1 \\\\leftrightarrow 0 . a_{11} a_{12} a_{13} a_{14} \\\\ldots \\\\\\\\\\n& 2 \\\\leftrightarrow 0 . a_{21} a_{22} a_{23} a_{24} \\\\ldots \\\\\\\\\\n& 3 \\\\leftrightarrow 0 . a_{31} a_{32} a_{33} a_{34} \\\\ldots\\n\\\\end{aligned}\\n$$\\n\\nWe now form a number\\n\\n$$\\n0 . b_{1} b_{2} b_{3} b_{4} \\\\ldots\\n$$\\n\\nwhere $b_{1} \\\\neq a_{11}, b_{2} \\\\neq a_{22}, b \\\\neq a_{33}, b_{4} \\\\neq a_{44}, \\\\ldots$ and where all $b$ 's beyond some position are not all 9's.\\n\\nThis number, which is in [0.1], is different from all numbers in the preceding list and is thus not in the list, contradicting the assumption that all numbers in $[0,1]$ were included.\\n\\nBecause of this contradiction, it follows that the real numbers in $[0,1]$ cannot be placed in 1-1 correspondence with the natural numbers; i.e., the set of real numbers in $[0,1]$ is noncountable.\\n\\n\\n\\\\section*{Limit points, bounds, Bolzano-Weierstrass theorem}\\n\",\n",
       " '1.21. (a) Prove that the infinite set of numbers $1, \\\\frac{1}{2}, \\\\frac{1}{3}, \\\\frac{1}{4}, \\\\ldots$ is bounded. (b) Determine the least upper bound (l.u.b.) and greatest lower bound (g.l.b.) of the set. (c) Prove that 0 is a limit point of the set. (d) Is the set a closed set? (e) How does this set illustrate the Bolzano-Weierstrass theorem?\\n\\n(a) Since all members of the set are less than 2 and greater than -1 (for example), the set is bounded; 2 is an upper bound; -1 is a lower bound.\\n\\nWe can find smaller upper bounds (e.g., 3/2) and larger lower bounds (e.g., $-\\\\frac{1}{2}$ ).\\\\\\\\\\n(b) Since no member of the set is greater than 1 and since there is at least one member of the set (namely, 1) which exceeds $1-\\\\varepsilon$ for every positive number $\\\\varepsilon$, we see that 1 is the l.u.b. of the set.\\n\\nSince no member of the set is less than 0 and since there is at least one member of the set which is less than $0+\\\\varepsilon$ for every positive $\\\\varepsilon$ (we can always choose for this purpose the number $1 / n$, where $n$ is a positive integer greater than $1 / \\\\varepsilon$ ), we see that 0 is the g.1.b. of the set.\\n\\n(c) Let $x$ be any member of the set. Since we can always find a number $x$ such that $0<|x|<\\\\delta$ for any positive number $\\\\delta$ (e.g., we can always pick $x$ to be the number $1 / n$, where $n$ is a positive integer greater than $1 / \\\\delta$ ), we see that 0 is a limit point of the set. To put this another way, we see that any deleted $\\\\delta$ neighborhood of 0 always includes members of the set, no matter how small we take $\\\\delta>0$.\\n\\n(d) The set is not a closed set, since the limit point 0 does not belong to the given set.\\n\\n(e) Since the set is bounded and infinite, it must, by the Bolzano-Weierstrass theorem, have at least one limit point. We have found this to be the case, so that the theorem is illustrated.\\n\\n\\n\\\\section*{Algebraic numbers}\\n',\n",
       " '1.22. Prove that $\\\\sqrt[3]{2}+\\\\sqrt{3}$ is an algebraic number.\\n\\nLet $x=\\\\sqrt[3]{2}+\\\\sqrt{3}$. Then $x-\\\\sqrt{3}=\\\\sqrt[3]{2}$. Cubing both sides and simplifying, we find $x^{3}+9 x-2=3 \\\\sqrt{3}$ $\\\\left(x^{2}+1\\\\right)$. Then, squaring both sides and simplifying, we find $x^{6}-9 x^{4}-4 x^{3}+27 x^{2}+36 x-23=0$.\\n\\nSince this is a polynomial equation with integral coefficients, it follows that $\\\\sqrt[3]{2}+\\\\sqrt{3}$, which is a solution, is an algebraic number.\\n',\n",
       " '\\n1.23. Prove that the set of all algebraic numbers is a countable set.\\n\\nAlgebraic numbers are solutions to polynomial equations of the form $a_{0} x^{n}+\\\\mathrm{a}, x^{n-1}+\\\\cdots+a_{n}=0$ where $a_{0}, a_{1}, \\\\ldots, a_{n}$ are integers.\\n\\nLet $P=\\\\left|a_{0}\\\\right|+\\\\left|a_{1}\\\\right|+\\\\cdots+\\\\left|a_{n}\\\\right|+n$. For any given value of $P$ there are only a finite number of possible polynomial equations and thus only a finite number of possible algebraic numbers.\\n\\nWrite all algebraic numbers corresponding to $P=1,2,3,4, \\\\ldots$, avoiding repetitions. Thus, all algebraic numbers can be placed into 1-1 correspondence with the natural numbers and so are countable.\\n\\n\\n\\\\section*{Complex numbers}\\n',\n",
       " '1.24. Perform the indicated operations:\\n\\n(a) $(4-2 i)+(-6+5 i)=4-2 i-6+5 i=4-6+(-2+5) i=-2+3 i$\\n\\n(b) $(-7+3 i)-(2-4 i)=-7+3 i-2+4 i=-9+7 i$\\n\\n(c) $(3-2 i)(1+3 i)=3(1+3 i)-2 i(1+3 i)=3+9 i-2 i-6 i^{2}=3+9 i-2 i+6=9+7 i$\\n\\n(d) $\\\\frac{-5+5 i}{4-3 i}=\\\\frac{-5+5 i}{4-3 i} \\\\cdot \\\\frac{4+3 i}{4+3 i}=\\\\frac{(-5+5 i)(4+3 i)}{16-9 i^{2}}=\\\\frac{-20-15 i+20 i+15 i^{2}}{16+9}$ $=\\\\frac{-35+5 i}{25}=\\\\frac{5(-7+i)}{25}=\\\\frac{-7}{5}+\\\\frac{1}{5} i$\\n\\n(e) $\\\\frac{i+i^{2}+i^{3}+i^{4}+i^{5}}{1+i}=\\\\frac{i-1+\\\\left(i^{2}\\\\right)(i)+\\\\left(i^{2}\\\\right)^{2}+\\\\left(i^{2}\\\\right)^{2} i}{1+i}=\\\\frac{i-1-i+1+i}{1+i}$\\n\\n$=\\\\frac{i}{1+i} \\\\cdot \\\\frac{1-i}{1-i}=\\\\frac{i-i^{2}}{1-i^{2}}=\\\\frac{i+1}{2}=\\\\frac{1}{2}+\\\\frac{1}{2} i$\\n\\n(f) $|3-4 i||4+3 i|=\\\\sqrt{(3)^{2}+(-4)^{2}} \\\\sqrt{(4)^{2}+(3)^{2}}=(5)(5)=25$\\\\\\\\\\n(g) $\\\\left|\\\\frac{1}{1+3 i}-\\\\frac{1}{1-3 i}\\\\right|=\\\\left|\\\\frac{1-3 i}{1-9 i^{2}}-\\\\frac{1+3 i}{1-9 i^{2}}\\\\right|=\\\\left|\\\\frac{-6 i}{10}\\\\right|=\\\\sqrt{(0)^{2}+\\\\left(-\\\\frac{6}{10}\\\\right)^{2}}=\\\\frac{3}{5}$\\n',\n",
       " '\\n1.25. If $z_{1}$ and $z_{2}$ are two complex numbers, prove that $\\\\left|z_{1} z_{2}\\\\right|=\\\\left|z_{1}\\\\right|\\\\left|z_{2}\\\\right|$.\\n\\nLet $z_{1}=x_{1}+i y_{1}, z_{2}=x_{2}+i y_{2}$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\left|\\\\mathrm{z}_{1} z_{2}\\\\right| & =\\\\left|\\\\left(x_{1}+i y_{1}\\\\right)\\\\left(x_{2}+i y_{2}\\\\right)\\\\right|=\\\\left|x_{1} x_{2}-y_{1} y_{2}+i\\\\left(x_{1} y_{2}+x_{2} y_{1}\\\\right)\\\\right| \\\\\\\\\\n& =\\\\sqrt{\\\\left(x_{1} x_{2}-y_{1} y_{2}\\\\right)^{2}+\\\\left(x_{1} y_{2}+x_{2} y_{1}\\\\right)^{2}}=\\\\sqrt{x_{1}^{2} x_{2}^{2}+y_{1}^{2} y_{2}^{2}+x_{1}^{2} y_{2}^{2}+x_{2}^{2} y_{1}^{2}} \\\\\\\\\\n& =\\\\sqrt{\\\\left(x_{1}^{2}+y_{1}^{2}\\\\right)\\\\left(x_{2}^{2}+y_{2}^{2}\\\\right)}=\\\\sqrt{x_{1}^{2}+y^{2}} \\\\sqrt{x_{2}^{2}+y_{2}^{2}}=\\\\left|x_{1}+i y_{1}\\\\right|\\\\left|x_{2}+i y_{2}\\\\right|=\\\\left|z_{1}\\\\right|\\\\left|z_{2}\\\\right| .\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n1.26. Solve $x^{3}-2 x-4=0$.\\n\\nThe possible rational roots using Problem 1.7 are $\\\\pm 1, \\\\pm 2$, and $\\\\pm 4$. By trial, we find $x=2$ is a root. Then the given equation can be written $(x-2)\\\\left(x^{2}+2 x+2\\\\right)=0$. The solutions to the quadratic equation $a x^{2}+b x+c=0$ are $x=\\\\frac{-b \\\\pm \\\\sqrt{b^{2}-4 a c}}{2 a}$ For $a=1, b=2$, and $c=2$, this gives $x=\\\\frac{-2 \\\\pm \\\\sqrt{4-8}}{2}=$ $\\\\frac{-2 \\\\pm \\\\sqrt{-4}}{2}=\\\\frac{-2 \\\\pm 2 i}{2}=-1 \\\\pm i$.\\n\\nThe set of solutions is $2,-1+i,-1-i$.\\n\\n\\n\\\\section*{Polar form of complex numbers}\\n',\n",
       " '1.27. Express in polar form $(a) 3+3 i,(b)-1+\\\\sqrt{3} i,(c)-1$, and $(d)-2-2 \\\\sqrt{3} i$. See Figure 1.4.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-026(3)}\\n\\\\end{center}\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-026(1)}\\n\\\\end{center}\\n\\n(b)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-026}\\n\\\\end{center}\\n\\n(c)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-026(2)}\\n\\\\end{center}\\n\\n(d)\\n\\nFigure 1.4\\n\\n(a) Amplitude $\\\\phi=45^{\\\\circ}=\\\\pi / 4$ radians. Modulus $\\\\rho=\\\\sqrt{3^{2}+3^{2}}=3 \\\\sqrt{2}$.\\n\\nThen $3+3 i=\\\\rho(\\\\cos \\\\phi+i \\\\sin \\\\phi)=3 \\\\sqrt{2}(\\\\cos \\\\pi / 4+i \\\\sin \\\\pi / 4)=3 \\\\sqrt{2}$ $\\\\operatorname{cis} \\\\pi / 4=3 \\\\sqrt{2} e^{\\\\pi / 4}$\\n\\n(b) Amplitude $\\\\phi=120^{\\\\circ}=2 \\\\pi / 3$ radians. Modulus\\n\\n$\\\\rho=\\\\sqrt{(-1)^{2}+(\\\\sqrt{3})^{2}}=\\\\sqrt{4}=2$. Then $-1+3 \\\\sqrt{3} i=2(\\\\cos 2 \\\\pi / 3+$ $i \\\\sin 2 \\\\pi / 3)=2$ cis $2 \\\\pi / 3=2 e^{2 \\\\pi i / 3}$.\\n\\n(c) Amplitude $\\\\phi=180^{\\\\circ}=\\\\pi$ radians. Modulus $\\\\rho=\\\\sqrt{(-1)^{2}+(0)^{2}}=1$. Then $-1=1(\\\\cos \\\\pi+i \\\\sin \\\\pi)=\\\\operatorname{cis} \\\\pi=e^{\\\\pi \\\\mathrm{i}}$.\\n\\n(d) Amplitude $\\\\phi=240^{\\\\circ}=4 \\\\pi / 3$ radians. Modulus $\\\\rho=\\\\sqrt{(-2)^{2}+(-2 \\\\sqrt{3})^{2}}=4$. Then $-2-2 \\\\sqrt{3}=$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-026(4)}\\n\\\\end{center}\\n\\nFigure 1.5 $4(\\\\cos 4 \\\\pi / 3+i \\\\sin 4 \\\\pi / 3)=4 \\\\operatorname{cis} 4 \\\\pi / 3=4 e^{4 \\\\pi i / 3}$.\\n',\n",
       " \"\\n1.28. Evaluate $(a)(-1+\\\\sqrt{3} i)^{10}$ and $(b)(-1+i)^{1 / 3}$.\\n\\n(a) By Problem 1.27(b) and De Moivre's theorem.\\n\\n$$\\n\\\\begin{aligned}\\n(-1+\\\\sqrt{3} i)^{10} & =[2(\\\\cos 2 \\\\pi / 3+i \\\\sin 2 \\\\pi / 3)]^{10}=2^{10}(\\\\cos 20 \\\\pi / 3+i \\\\sin 20 \\\\pi / 3) \\\\\\\\\\n& =1024[\\\\cos (2 \\\\pi / 3+6 \\\\pi)+i \\\\sin (2 \\\\pi / 3+6 \\\\pi)]=1024(\\\\cos 2 \\\\pi / 3+i \\\\sin 2 \\\\pi / 3) \\\\\\\\\\n& =1024\\\\left(-\\\\frac{1}{2}+\\\\frac{1}{2} \\\\sqrt{3} i\\\\right)=-512+512 \\\\sqrt{3} i\\n\\\\end{aligned}\\n$$\\n\\n(b) $-1+i=\\\\sqrt{2}\\\\left(\\\\cos 135^{\\\\circ}+i \\\\sin 135^{\\\\circ}\\\\right)=\\\\sqrt{2}\\\\left[\\\\cos \\\\left(135^{\\\\circ}+k \\\\cdot 360^{\\\\circ}\\\\right)+i \\\\sin \\\\left(135^{\\\\circ}+k \\\\cdot 360^{\\\\circ}\\\\right)\\\\right]$. Then\\n\\n$$\\n(-1+i)^{1 / 3}=(\\\\sqrt{2})^{1 / 3}\\\\left[\\\\cos \\\\left(\\\\frac{135^{\\\\circ}+k \\\\cdot 360^{\\\\circ}}{3}\\\\right)+i \\\\sin \\\\left(\\\\frac{135^{\\\\circ}+k \\\\cdot 360^{\\\\circ}}{3}\\\\right)\\\\right]\\n$$\\n\\nThe results for $k=0,1,2$ are\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\sqrt[6]{2}\\\\left(\\\\cos 45^{\\\\circ}+i \\\\sin 45^{\\\\circ}\\\\right) \\\\\\\\\\n& \\\\sqrt[6]{2}\\\\left(\\\\cos 165^{\\\\circ}+i \\\\sin 165^{\\\\circ}\\\\right) \\\\\\\\\\n& \\\\sqrt[6]{2}\\\\left(\\\\cos 285^{\\\\circ}+i \\\\sin 285^{\\\\circ}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nThe results for $k=3,4,5,6,7, \\\\ldots$ give repetitions of these. These complex roots are represented geometrically in the complex plane by points $P_{1}, P_{2}, P_{3}$ on the circle of Figure 1.5.\\n\\n\\n\\\\section*{Mathematical induction}\\n\",\n",
       " '1.29. Prove that $1^{2}+2^{2}+3^{3}+4^{2}+\\\\cdots+n^{2}=\\\\frac{1}{6} n(n+1)(2 n+1)$.\\n\\nThe statement is true for $n=1$, since $1^{2}=\\\\frac{1}{6}(1)(1+1)(2 \\\\cdot 1+1)=1$.\\n\\nAssume the statement is true for $n=k$. Then\\n\\nAdding $(k+1)^{2}$ to both sides.\\n\\n$$\\n1^{2}+2^{2}+3^{2}+\\\\cdots+k^{2}=\\\\frac{1}{6} k(k+1)(2 k+1)\\n$$\\n\\n$$\\n\\\\begin{aligned}\\n1^{2}+2^{2}+3^{2}+\\\\cdots+k^{2}+(k+1)^{2} & =\\\\frac{1}{6} k(k+1)(2 k+1)+(k+1)^{2}=(k+1)\\\\left[\\\\frac{1}{6} k(2 k+1)+k+1\\\\right] \\\\\\\\\\n& =\\\\frac{1}{6}(k+1)\\\\left(2 k^{2}+7 k+6\\\\right)=\\\\frac{1}{6}(k+1)(k+2)(2 k+3)\\n\\\\end{aligned}\\n$$\\n\\nwhich shows that the statement is true for $n=k+1$ if it is true for $n=k$. But since it is true for $n=1$, it follows that it is true for $n=1+1=2$ and for $n=2+1=3, \\\\ldots$; i.e., it is true for all positive integers $n$.\\n',\n",
       " '\\n1.30. Prove that $x^{n}-y^{n}$ has $x-y$ as a factor for all positive integers $n$.\\n\\nThe statement is true for $n=1$, since $x^{1}-y^{1}=x-y$.\\n\\nAssume the statement is true for $n=k$; i.e., assume that $x^{k}-y^{k}$ has $x-y$ as a factor. Consider\\n\\n$$\\n\\\\begin{aligned}\\nx^{k+1}-y^{k+1} & =x^{k+1}-x^{k} y+x^{k} y-y^{k+1} \\\\\\\\\\n& =x^{k}(x-y)+y\\\\left(x^{k}-y^{k}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nThe first term on the right has $x-y$ as a factor, and the second term on the right also has $x-y$ as a factor because of the previous assumption.\\n\\nThus, $x^{k+1}-y^{k+1}$ has $x-y$ as a factor if $x^{k}-y^{k}$ does.\\n\\nThen, since $x^{1}-y^{1}$ has $x-y$ as factor, it follows that $x^{2}-y^{2}$ has $x-y$ as a factor, $x^{3}-y^{3}$ has $x-y$ as a factor, etc.\\n',\n",
       " \"\\n1.31. Prove Bernoulli's inequality $(1+x)^{n}>1+n x$ for $n=2,3, \\\\ldots$ if $x>-1, x \\\\neq 0$.\\n\\nThe statement is true for $n=2$, since $(1+x)^{2}=1+2 x+x^{2}>1+2 x$.\\n\\nAssume the statement is true for $n=k$; i.e., $(1+x)^{k}>1+k x$.\\n\\nMultiply both sides by $1+x$ (which is positive, since $x>-1$ ). Then we have\\n\\n$$\\n(1+x)^{k+1}>(1+x)(1+k x)=1+(k+1) x+k x^{2}>1+(k+1) x\\n$$\\n\\nThus, the statement is true for $n=k+1$ if it is true for $n=k$.\\n\\nBut since the statement is true for $n=2$, it must be true for $n=2+1=3 \\\\ldots$ and is thus true for all integers greater than or equal to 2 .\\n\\nNote that the result is not true for $n=1$. However, the modified result $(1+x)^{n} \\\\geq 1+n x$ is true for $n=1,2,3, \\\\ldots$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n\",\n",
       " \"1.32. Prove that every positive integer $P$ can be expressed uniquely in the form $P=a_{0} 2^{n}+a_{1} 2^{n-1}+a_{2} 2^{n-2}+\\\\cdots+$ $a_{n}$ where the $a$ 's are 0 's or 1 's.\\n\\nDividing $P$ by 2 , we have $P / 2=a_{0} 2^{n-1}+a_{1} 2^{n-2}+\\\\cdots+a_{n-1}+a_{n} / 2$.\\n\\nThen $a_{n}$ is the remainder, 0 or 1 , obtained when $P$ is divided by 2 and is unique.\\n\\nLet $P_{1}$ be the integer part of $P / 2$. Then $P_{1}=a_{0} 2^{n-1}+a_{1} 2^{n-2}+\\\\cdots+a_{n-1}$.\\n\\nDividing $P_{1}$ by 2 , we see that $a_{n-1}$ is the remainder, 0 or 1 , obtained when $P_{1}$ is divided by 2 and is unique\\n\\nBy continuing in this manner, all the $a$ 's can be determined as 0's or 1's and are unique.\\n\",\n",
       " '\\n1.33. Express the number 23 in the form of Problem 1.32.\\n\\nThe determination of the coefficient can be arranged as follows:\\\\\\\\\\n2) $\\\\underline{23}$\\\\\\\\\\n2) $11 \\\\quad$ Remainder 1\\\\\\\\\\n2) $5 \\\\quad$ Remainder 1\\\\\\\\\\n2) $2 \\\\quad$ Remainder 1\\\\\\\\\\n2) $1 \\\\quad$ Remainder 0\\n\\n$0 \\\\quad$ Remainder 1\\n\\nThe coefficients are 10111 . Check: $23=1 \\\\cdot 2^{4}+0 \\\\cdot 2^{3}+1 \\\\cdot 2^{2}+1 \\\\cdot 2+1$.\\n\\nThe number 10111 is said to represent 23 in the scale of two or binary scale.\\n',\n",
       " '\\n1.34. Dedekind defined a cut, section, or partition in the rational number system as a separation of all rational numbers into two classes or sets called $L$ (the left-hand class) and $R$ (the right-hand class) having the following properties:\\n\\nI. The classes are non-empty (i.e. at least one number belongs to each class).\\n\\nII. Every rational number is in one class or the other.\\n\\nIII. Every number in $L$ is less than every number in $R$.\\n\\nProve each of the following statements:\\n\\n(a) There cannot be a largest number in $L$ and a smallest number in $R$.\\n\\n(b) It is possible for $L$ to have a largest number and for $R$ to have no smallest number. What type of number does the cut define in this case?\\\\\\\\\\n(c) It is possible for $L$ to have no largest number and for $R$ to have a smallest number. What type of number does the cut define in this case?\\n\\n(d) It is possible for $L$ to have no largest number and for $R$ to have no smallest number. What type of number does the cut define in this case?\\n\\n(a) Let $a$ be the largest rational number in $L$ and $b$ the smallest rational number in $R$. Then either $a=b$ or $a<b$.\\n\\nWe cannot have $a=b$, since, by definition of the cut, every number in $L$ is less than every number in $R$.\\n\\nWe cannot have $a<b$, since, by Problem 1.9, $\\\\frac{1}{2}(a+b)$ is a rational number which would be greater than $a$ (and so would have to be in $R$ ) but less than $b$ (and so would have to be in $L$ ), and, by definition, a rational number cannot belong to both $L$ and $R$.\\n\\n(b) As an indication of the possibility, let $L$ contain the number $\\\\frac{2}{3}$ and all rational numbers less than $\\\\frac{2}{3}$, while $R$, contains all rational numbers greater than $\\\\frac{2}{3}$. In this case the cut defines the rational number $\\\\frac{2}{3}$. A similar argument replacing $\\\\frac{2}{3}$ by any other rational number shows that in such case the cut defines a ra-\\\\\\\\\\ntional number.\\n\\n(c) As an indication of the possibility, let $L$ contain all rational numbers less than $\\\\frac{2}{3}$, while $R$ contains all rational numbers greater than $\\\\frac{2}{3}$. This cut also defines the rational number $\\\\frac{2}{3}$. A similar argument shows that this cut always defines a rational number.\\n\\n(d) As an indication of the possibility, let $L$ consist of all negative rational numbers and all positive rational numbers whose squares are less than 2 , while $R$ consists of all positive numbers whose squares are greater than 2. We can show that if $a$ is any number of the $L$ class, there is always a larger number of the $L$ class, while if $b$ is any number of the $R$ class, there is always a smaller number of the $R$ class (see Problem 1.106). A cut of this type defines an irrational number.\\n\\nFrom $(b),(c)$, and $(d)$, it follows that every cut in the rational number system, called a Dedekind cut, defines either a rational or an irrational number. By use of Dedekind cuts we can define operations (addition, multiplication, etc.) with irrational numbers.\\n\\n',\n",
       " '2.1. Write the first five terms of each of the following sequences.\\n\\n(a) $\\\\left\\\\{\\\\frac{2 n-1}{3 n+2}\\\\right\\\\}$\\n\\n(b) $\\\\left\\\\{\\\\frac{1-(-1)^{n}}{n^{3}}\\\\right\\\\}$\\n\\n(c) $\\\\left\\\\{\\\\frac{(-1)^{n-1}}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots 2 n}\\\\right\\\\}$\\n\\n(d) $\\\\left\\\\{\\\\frac{1}{2}+\\\\frac{1}{4}+\\\\frac{1}{8}+\\\\cdots+\\\\frac{1}{2^{n}}\\\\right\\\\}$\\n\\n(e) $\\\\left\\\\{\\\\frac{(-1)^{n-1} x^{2 n-1}}{(2 n-1) !}\\\\right\\\\}$\\n\\n(a) $\\\\frac{1}{5}, \\\\frac{3}{8}, \\\\frac{5}{11}, \\\\frac{7}{14}, \\\\frac{9}{17}$\\n\\n(b) $\\\\frac{2}{1^{3}}, 0, \\\\frac{2}{3^{3}}, 0, \\\\frac{2}{5^{3}}$\\n\\n(c) $1 \\\\frac{1}{2}, \\\\frac{-1}{2 \\\\cdot 4}, \\\\frac{1}{2 \\\\cdot 4 \\\\cdot 6}, \\\\frac{-1}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdot 8}, \\\\frac{1}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdot 8 \\\\cdot 10}$\\n\\n(d) $\\\\frac{1}{2}, \\\\frac{1}{2}+\\\\frac{1}{4}, \\\\frac{1}{2}+\\\\frac{1}{4}+\\\\frac{1}{8}, \\\\frac{1}{2}+\\\\frac{1}{4}+\\\\frac{1}{8}+\\\\frac{1}{16}, \\\\frac{1}{2}+\\\\frac{1}{4}+\\\\frac{1}{8}+\\\\frac{1}{16}+\\\\frac{1}{32}$\\n\\n(e) $\\\\frac{x}{1 !}, \\\\frac{-x^{3}}{3 !}, \\\\frac{x^{5}}{5 !}, \\\\frac{-x^{7}}{7 !}, \\\\frac{x^{9}}{9 !}$\\n\\nNote that $n !=1 \\\\cdot 2 \\\\cdot 3 \\\\cdot 4 \\\\ldots n$. Thus, $1 !=1,3 !=1 \\\\cdot 2 \\\\cdot 3=6,5 !=1 \\\\cdot 2 \\\\cdot 3 \\\\cdot 4 \\\\cdot 5=120$, etc. We define $0 !=1$.\\n',\n",
       " '\\n2.2. Two students were asked to write an $n$th term for the sequence $1,16,81,256, \\\\ldots$ and to write the 5 th term of the sequence. One student gave the $n$th term as $u_{n}=n^{4}$. The other student, who did not recognize this simple law of formation, wrote $u_{n}=10 n^{3}-35 n^{2}+50 n-24$. Which student gave the correct 5 th term?\\n\\nIf $u_{n}=n^{4}$, then $u_{1}=1^{4}=1, u_{2}=2^{4}=16, u_{3}=3^{4}=81$, and $u_{4}=4^{4}=256$, which agrees with the first four terms of the sequence. Hence, the first student gave the 5 th term as $u_{5}=5^{4}=625$.\\n\\nIf $u_{n}=10 n^{3}-35 n^{2}+50 n-24$, then $u_{1}=1, u_{2}=16, u_{3}=81$, and $u_{4}=256$, which also agrees with the first four terms given. Hence, the second student gave the 5 th term as $u_{5}=601$.\\n\\nBoth students were correct. Merely giving a finite number of terms of a sequence does not define a unique $n$th term. In fact, an infinite number of $n$th terms is possible.\\n\\n\\n\\\\section*{Limit of a sequence}\\n',\n",
       " '2.3. A sequence has its $n$th term given by $u_{n}=\\\\frac{3 n-1}{4 n+5}$. (a) Write the 1 st, 5th, 10th, 100th, 1000th, 10,000th and 100,000 th, terms of the sequence in decimal form. Make a guess as to the limit of this sequence as $n \\\\rightarrow \\\\infty$.\\n\\n(b) Using the definition of limit, verify that the guess in $(a)$ is actually correct.\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-040}\\n\\\\end{center}\\n\\nA good guess is that the limit is $.75000 \\\\ldots=\\\\frac{3}{4}$. Note that it is only for large enough values of $n$ that a possible limit may become apparent.\\n\\n(b) We must show that for any given $\\\\epsilon>0$ (no matter how small) there is a number $N$ (depending on $\\\\epsilon$ ) such that $\\\\left|u_{n}-\\\\frac{3}{4}\\\\right|<\\\\epsilon$ for all $n>N$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\text { Now } & {\\\\left[\\\\frac{3 n-1}{4 n+5}-\\\\frac{3}{4}\\\\right]=\\\\left[\\\\frac{-19}{4(4 n+5)}\\\\right]<\\\\varepsilon \\\\quad \\\\text { when } \\\\frac{19}{4(4 n+5)}<\\\\varepsilon \\\\text { or } } \\\\\\\\\\n& \\\\frac{4(4 n+5)}{19}>\\\\frac{1}{\\\\varepsilon}, \\\\quad 4 n+5>\\\\frac{19}{4 \\\\varepsilon}, \\\\quad n>\\\\frac{1}{4}\\\\left(\\\\frac{19}{4 \\\\varepsilon}-5\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nChoosing $N=\\\\frac{1}{4}(19 / 4 \\\\epsilon-5)$, we see that $\\\\left|u_{n}-\\\\frac{3}{4}\\\\right|<\\\\epsilon$ for all $n>N$, so that $\\\\lim _{n \\\\rightarrow \\\\infty}=\\\\frac{3}{4}$ and the proof is complete.\\n\\nNote that if $\\\\epsilon=.001$ (for example), $N=\\\\frac{1}{4}(19000 / 4-5)=1186 \\\\frac{1}{4}$. This means that all terms of the sequence beyond the 1186th term differ from 3/4 in absolute value by less than .001 .\\n',\n",
       " '\\n2.4. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{c}{n^{p}}=0$ where $c \\\\neq 0$ and $p>0$ are constants (independent of $n$ ).\\n\\nWe must show that for any $\\\\epsilon>0$ there is a number $N$ such that $\\\\left|c / n^{p}-0\\\\right|<\\\\epsilon$ for all $n>N$.\\n\\nNow $\\\\left|\\\\frac{c}{n^{p}}\\\\right|<\\\\epsilon$ when $\\\\frac{|c|}{n^{p}}<\\\\epsilon$; i.e., $n^{p}>\\\\frac{|c|}{\\\\varepsilon}$ or $n>\\\\left(\\\\frac{|c|}{\\\\varepsilon}\\\\right)^{1 / p}$. Choosing $N=\\\\left(\\\\frac{|c|}{\\\\varepsilon}\\\\right)^{1 / p}$ (depending on $\\\\epsilon$ ), we see that $\\\\left|c / n^{p}\\\\right|<\\\\epsilon$ for all $n>N$, proving that $\\\\lim \\\\left(c / n^{p}\\\\right)=0$.\\n',\n",
       " '\\n2.5. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1+2 \\\\cdot 10^{n}}{5+3 \\\\cdot 10^{n}}=\\\\frac{2}{3}$.\\n\\nWe must show that for any $\\\\epsilon>0$ there is a number $N$ such that $\\\\left|\\\\frac{1+2 \\\\cdot 10^{n}}{5+3 \\\\cdot 10^{n}}-\\\\frac{2}{3}\\\\right|<\\\\varepsilon$ for all $n>N$.\\n\\nNow $\\\\left|\\\\frac{1+2 \\\\cdot 10^{n}}{5+3 \\\\cdot 10^{n}}-\\\\frac{2}{3}\\\\right|=\\\\left|\\\\frac{-7}{3\\\\left(5+3 \\\\cdot 10^{n}\\\\right)}\\\\right|<\\\\varepsilon$ when $\\\\frac{7}{3\\\\left(5+3 \\\\cdot 10^{n}\\\\right)}<\\\\varepsilon$; i.e., when $\\\\frac{3}{7}\\\\left(5+3 \\\\cdot 10^{n}\\\\right)>1 / \\\\varepsilon$,\\n\\n$3 \\\\cdot 10^{n}>7 / 3 \\\\epsilon-5,10^{n}>\\\\frac{1}{8}(7 / 3 \\\\epsilon-5)$ or $n>\\\\log _{10}\\\\left\\\\{\\\\frac{1}{3}(7 / 3 \\\\epsilon-5)\\\\right\\\\}=N$, proving the existence of $N$ and thus establishing the required result.\\n\\nNote that the value of $N$ is real only if $7 / 3 \\\\epsilon-5>0$; i.e., $0<\\\\epsilon<7 / 15$. If $\\\\epsilon \\\\geqq 7 / 15$, we see that\\n\\n$\\\\left|\\\\frac{1+2 \\\\cdot 10^{n}}{5+3 \\\\cdot 10^{n}}-\\\\frac{2}{3}\\\\right|<\\\\varepsilon$ for all $n>0$\\n',\n",
       " '\\n2.6. Explain exactly what is meant by the statements (a) $\\\\lim _{n \\\\rightarrow \\\\infty} 3^{2 n-1}=\\\\infty$ and (b) $\\\\lim _{n \\\\rightarrow \\\\infty}(1-2 n)=-\\\\infty$.\\n\\n(a) If for each positive number $M$ we can find a positive number $N$ (depending on $M$ ) such that $a_{n}>M$ for all $n>N$, then we write $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=\\\\infty$.\\n\\nIn this case, $3^{2 n-1}>M$ when $(2 n-1) \\\\log 3>\\\\log M$; i.e., $n>\\\\frac{1}{2}\\\\left(\\\\frac{\\\\log M}{\\\\log 3}+1\\\\right)=N$.\\\\\\\\\\n(b) If for each positive number $M$ we can find a positive number $N$ (depending on $M$ ) such that $a_{n}<-M$ for all $n>N$, then we write $\\\\lim =-\\\\infty$.\\n\\nIn this case, $1-2 n<-M$ when $2 n-1>M$ or $n>\\\\frac{1}{2}(M+1)=N$.\\n\\nIt should be emphasized that the use of the notations $\\\\infty$ and $-\\\\infty$ for limits does not in any way imply convergence of the given sequences, since $\\\\infty$ and $-\\\\infty$ are not numbers. Instead, these are notations used to describe that the sequences diverge in specific ways.\\n',\n",
       " \"\\n2.7. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} x^{n}=0$ if $|x|<1$.\\n\\nMethod 1: We can restrict ourselves to $x \\\\neq 0$, since if $x=0$, the result is clearly true. Given $\\\\epsilon>0$, we must show that there exists $N$ such that $\\\\left|x^{n}\\\\right|<\\\\epsilon$ for $n>N$. Now $\\\\left|x^{n}\\\\right|=|x|^{n}<\\\\epsilon$ when $n \\\\log _{10}|x|<\\\\log _{10} \\\\epsilon$. Dividing by $\\\\log _{10}|x|$, which is negative, yields $n>\\\\frac{\\\\log _{10} \\\\varepsilon}{\\\\log _{10}|x|}=N$, proving the required result.\\n\\nMethod 2: Let $|x|=1 /(1+p)$, where $p>0$. By Bernoulli's inequality (Problem 1.31), we have $\\\\left|x^{n}\\\\right|=$ $|x|^{n}=1 /(1+p)^{n}<1 /(1+n p)<\\\\epsilon$ for all $n>N$. Thus, $\\\\lim _{n \\\\rightarrow \\\\infty} x^{n}=0$.\\n\\n\\n\\\\section*{Theorems on limits of sequences}\\n\",\n",
       " '2.8. Prove that if $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}$ exists, it must be unique.\\n\\nWe must show that if $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=l_{1}$ and $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=l_{2}$, then $l_{1}=l_{2}$.\\n\\nBy hypothesis, given any $\\\\epsilon>0$ we can find $N$ such that\\n\\n$$\\n\\\\left|u_{n}-l_{1}\\\\right|<\\\\frac{1}{2} \\\\varepsilon \\\\text { when } n>N, \\\\quad\\\\left|u_{n}-l_{2}\\\\right|<\\\\frac{1}{2} \\\\varepsilon \\\\text { when } n>N\\n$$\\n\\nThen\\n\\n$$\\n\\\\left|l_{1}-l_{2}\\\\right|=\\\\left|l_{1}-u_{n}+u_{n}-l_{2}\\\\right| \\\\leqq\\\\left|l_{1}-u_{n}\\\\right|+\\\\left|u_{n}-l_{2}\\\\right|<\\\\frac{1}{2} \\\\varepsilon+\\\\frac{1}{2} \\\\varepsilon=\\\\varepsilon\\n$$\\n\\ni.e., $\\\\left|l_{1}-l_{2}\\\\right|$ is less than any positive $\\\\epsilon$ (however small) and so must be zero. Thus, $l_{1}=l_{2}$.\\n',\n",
       " '\\n2.9. If $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=A$ and $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B$, prove that $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(a_{n}+b_{n}\\\\right)=A+B$.\\n\\nWe must show that for any $\\\\epsilon>0$, we can find $N>0$ such that $\\\\left|\\\\left(a_{n}+b_{n}\\\\right)-(A+B)\\\\right|<\\\\epsilon$ for all $n>N$. From absolute value property 2 , Page 4 , we have\\n\\n\\n\\\\begin{equation*}\\n\\\\left|\\\\left(a_{n}+b_{n}\\\\right)-(A+B)\\\\right|=\\\\left|\\\\left(a_{n}-A\\\\right)+\\\\left(b_{n}-B\\\\right)\\\\right| \\\\leqq\\\\left|a_{n}-A\\\\right|+\\\\left|b_{n}-B\\\\right| \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nBy hypothesis, given $\\\\epsilon>0$ we can find $N_{1}$ and $N_{2}$ such that\\n\\n\\\\[\\n\\\\begin{array}{ll}\\n\\\\left|a_{n}-A\\\\right|<\\\\frac{1}{2} \\\\varepsilon & \\\\text { for all } n>N_{1} \\\\\\\\\\n\\\\left|b_{n}-B\\\\right|<\\\\frac{1}{2} \\\\varepsilon & \\\\text { for all } n>N_{2} \\\\tag{3}\\n\\\\end{array}\\n\\\\]\\n\\nThen from Equations (1), (2), and (3),\\n\\n$$\\n\\\\left|\\\\left(a_{n}+b_{n}\\\\right)-(A+B)\\\\right|<\\\\frac{1}{2} \\\\varepsilon+\\\\frac{1}{2} \\\\varepsilon=\\\\varepsilon \\\\quad \\\\text { for all } n>N\\n$$\\n\\nwhere $N$ is chosen as the larger of $N_{1}$ and $N_{2}$. Thus, the required result follows.\\n',\n",
       " '\\n2.10. Prove that a convergent sequence is bounded. Now\\n\\nGiven $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=A$, we must show that there exists a positive number $P$ such that $\\\\left|a_{n}\\\\right|<P$ for all $n$.\\n\\n$$\\n\\\\left|a_{n}\\\\right|=\\\\left|a_{n}-A+A\\\\right| \\\\leqq\\\\left|a_{n}-A\\\\right|+|A|\\n$$\\n\\nBut by hypothesis we can find $N$ such that $\\\\left|a_{n}-A\\\\right|<\\\\epsilon$ for all $n>N$, i.e.,\\n\\n$$\\n\\\\left|a_{n}\\\\right|<\\\\epsilon+|A| \\\\quad \\\\text { for all } n>N\\n$$\\n\\n$\\\\epsilon+|A|$.\\n\\nIt follows that $\\\\left|a_{n}\\\\right|<P$ for all $n$ if we choose $P$ as the largest one of the numbers $a_{1}, a_{2}, \\\\ldots, a_{N}$,\\n',\n",
       " '\\n2.11. If $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B \\\\neq 0$, prove there exists a number $N$ such that $\\\\left|b_{n}\\\\right|>\\\\frac{1}{2}|B|$ for all $n>N$.\\n\\nSince $B=B-b_{n}+b_{n}$, we have:\\n\\n\\n\\\\begin{equation*}\\n|B| \\\\leqq\\\\left|B-b_{n}\\\\right|+\\\\left|b_{n}\\\\right| \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nNow we can choose $N$ so that $\\\\left|B-b_{n}\\\\right|=\\\\left|b_{n}-B\\\\right|<\\\\frac{1}{2}|B|$ for all $n>N$, since $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B$ by hypothesis.\\n\\nHence, from Equation (1), $|B|<\\\\frac{1}{2}|B|+\\\\left|b_{n}\\\\right|$ or $\\\\left|b_{n}\\\\right|>\\\\frac{1}{2}|B|$ for all $n>N$.\\n',\n",
       " '\\n2.12. If $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=A$ and $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B$, prove that $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n} b_{n}=A B$.\\n\\nUsing Problem 2.10, we have\\n\\n\\n\\\\begin{align*}\\n\\\\left|a_{n} b_{n}-A B\\\\right|=\\\\left|a_{n}\\\\left(b_{n}-B\\\\right)+B\\\\left(a_{n}-A\\\\right)\\\\right| & \\\\leqq\\\\left|a_{n}\\\\right|\\\\left|b_{n}-B\\\\right|+|B|\\\\left|a_{n}-A\\\\right| \\\\\\\\\\n& \\\\leqq P\\\\left|b_{n}-B\\\\right|+(|B|+1)\\\\left|a_{n}-A\\\\right| \\\\tag{1}\\n\\\\end{align*}\\n\\n\\nBut since $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=A$ and $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B$, given any $\\\\epsilon>0$ we can find $N_{1}$ and $N_{2}$ such that\\n\\n$$\\n\\\\left|b_{n}-B\\\\right|<\\\\frac{\\\\varepsilon}{2 P} \\\\text { for all } n>N_{1} \\\\quad\\\\left|a_{n}-A\\\\right|<\\\\frac{\\\\varepsilon}{2(|B|+1)} \\\\text { for all } n>N_{2}\\n$$\\n\\nHence, from Equation (1), $\\\\left|a_{n} b_{n}-A B\\\\right|<\\\\frac{1}{2} \\\\epsilon+\\\\frac{1}{2} \\\\epsilon=\\\\epsilon$ for all $n>N$, where $N$ is the larger of $N_{1}$ and $N_{2}$.\\\\\\\\\\nThus, the result is proved.\\n',\n",
       " '\\n2.13. If $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=A$ and $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B \\\\neq 0$, prove (a) $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{b_{n}}=\\\\frac{1}{B}$, (b) $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{a_{n}}{b_{n}}=\\\\frac{A}{B}$.\\n\\n(a) We must show that for any given $\\\\epsilon>0$, we can find $N$ such that\\n\\n\\n\\\\begin{equation*}\\n\\\\left|\\\\frac{1}{b_{n}}-\\\\frac{1}{B}\\\\right|=\\\\frac{\\\\left|B-b_{n}\\\\right|}{|B|\\\\left|b_{n}\\\\right|}<\\\\varepsilon \\\\quad \\\\text { for all } n>N \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nBy hypothesis, given any $\\\\epsilon>0$, we can find $N_{1}$, such that $\\\\left|b_{n}-B\\\\right|<\\\\frac{1}{2} B^{2} \\\\epsilon$ for all $n>N_{1}$. 2.11).\\n\\nAlso, since $\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=B \\\\neq 0$, we can find $N_{2}$ such that $\\\\left|b_{n}\\\\right|>\\\\frac{1}{2}|B|$ for all $n>N_{2}$ (see Problem\\n\\nThen if $N$ is the larger of $N_{1}$ and $N_{2}$, we can write Equation (1) as\\n\\n$$\\n\\\\left|\\\\frac{1}{b_{n}}-\\\\frac{1}{B}\\\\right|=\\\\frac{\\\\left|b_{n}-B\\\\right|}{|B|\\\\left|b_{n}\\\\right|}<\\\\frac{\\\\frac{1}{2} B^{2} \\\\varepsilon}{|B| \\\\cdot \\\\frac{1}{2}|B|}=\\\\varepsilon \\\\quad \\\\text { for all } n>N\\n$$\\n\\nand the proof is complete.\\n\\n(b) From (a) and Problem 2.12, we have\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{a_{n}}{b_{n}}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(a_{n} \\\\cdot \\\\frac{1}{\\\\mathrm{~b}_{n}}\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty} a_{n} \\\\cdot \\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{b_{n}}=A \\\\cdot \\\\frac{1}{B}=\\\\frac{A}{B}\\n$$\\n\\nThis can also be proved directly (see Problem 2.41).\\n',\n",
       " '\\n2.14. Evaluate each of the following, using theorems on limits.\\n\\n(a) $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{3 n^{2}-5 n}{5 n^{2}+2 n-6}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{3-5 / n}{5+2 / n-6 / n^{2}}=\\\\frac{3+0}{5+0+0}=\\\\frac{3}{5}$\\n\\n(b) $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{n(n+2)}{n+1}-\\\\frac{n^{3}}{n^{2}+1}\\\\right\\\\}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{n^{3}+n^{2}+2 n}{(n+1)\\\\left(n^{2}+1\\\\right)}\\\\right\\\\}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{1+1 / n+2 / n^{2}}{(1+1 / n)\\\\left(1+1 / n^{2}\\\\right)}\\\\right\\\\}$\\n\\n$$\\n=\\\\frac{1+0+0}{(1+0) \\\\cdot(1+0)}=1\\n$$\\n\\n(c) $\\\\lim _{n \\\\rightarrow \\\\infty}(\\\\sqrt{n+1}-\\\\sqrt{n})=\\\\lim _{n \\\\rightarrow \\\\infty}(\\\\sqrt{n+1}-\\\\sqrt{n}) \\\\frac{\\\\sqrt{n+1}+\\\\sqrt{n}}{\\\\sqrt{n+1}+\\\\sqrt{n}}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{\\\\sqrt{n+1}+\\\\sqrt{n}}=0$\\n\\n(d) $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{3 n^{2}+4 n}{2 n-1}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{3=4 / n}{2 / n-1 / n^{2}}$\\n\\nSince the limits of the numerator and the denominator are 3 and 0 , respectively, the limit does not exist.\\n\\nSince $\\\\frac{3 n^{2}+4 n}{2 n-1}>\\\\frac{3 n^{2}}{2 n}=\\\\frac{3 n}{2}$ can be made larger than any positive number $M$ by choosing $n>N$, we can write, if desired, $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{3 n^{2}+4 n}{2 n-1}=\\\\infty$.\\n\\n(e) $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(\\\\frac{2 n-3}{2 n+7}\\\\right)^{4}=\\\\left(\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2-3 / n}{3+7 / n}\\\\right)^{4}=\\\\left(\\\\frac{2}{3}\\\\right)^{4}=\\\\frac{16}{18}$\\n\\n(f) $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2 n^{5}-4 n^{2}}{3 n^{7}+n^{3}-10}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2 / n^{2}-4 / n^{5}}{3+1 / n^{4}-10 / n^{7}}=\\\\frac{0}{3}=0$\\n\\n(g) $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1+2 \\\\cdot 10^{n}}{5+3 \\\\cdot 10^{n}}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{10^{-n}+2}{5 \\\\cdot 10^{-n}+3}=\\\\frac{2}{3} \\\\quad$ (Compare with Problem 2.5.)\\n\\n\\n\\\\section*{Bounded monotonic sequences}\\n',\n",
       " '2.15. Prove that the sequence with $n$th $u_{n}=\\\\frac{2 n-7}{3 n+2}$ (a) is monotonic increasing, (b) is bounded above, (c) is bounded below, (d) is bounded, (e) has a limit.\\n\\n(a) $\\\\left\\\\{u_{n}\\\\right\\\\}$ is monotonic increasing if $u_{n+1} \\\\geq u_{n}, n=1,2,3, \\\\ldots$ Now\\n\\n$$\\n\\\\frac{2(n+1)-7}{3(n+1)+2} \\\\geqq \\\\frac{2 n-7}{3 n+2} \\\\text { if and only if } \\\\frac{2 n-5}{2 n+5} \\\\geqq \\\\frac{2 n-7}{3 n+2}\\n$$\\n\\nor $(2 n-5)(3 n+2) \\\\geq(2 n-7)(3 n+5), 6 n^{2}-11 n-10 \\\\geq 6 n^{2}-11 n-35$, i.e., $-10 \\\\geq-35$, which is true. Thus, by reversal of steps in the inequalities, we see that $\\\\left\\\\{u_{n}\\\\right\\\\}$ is monotonic increasing. Actually, since $-10>-35$, the sequence is strictly increasing.\\n\\n(b) By writing some terms of the sequence, we may guess that an upper bound is 2 (for example). To prove this we must show that $u_{n} \\\\leq 2$. If $(2 n-7) /(3 n+2) \\\\leq 2$, then $2 n-7 \\\\leq 6 n+4$ or $-4 n<11$, which is true. Reversal of steps proves that 2 is an upper bound.\\n\\n(c) Since this particular sequence is monotonic increasing, the first term -1 is a lower bound; i.e., $u_{n} \\\\geqq-1$, $n=1,2,3, \\\\ldots$ Any number less than -1 is also a lower bound.\\n\\n(d) Since the sequence has an upper and a lower bound, it is bounded. Thus, for example, we can write $\\\\left|u_{n}\\\\right| \\\\leqq 2$ for all $n$.\\n\\n(e) Since every bounded monotonic (increasing or decreasing) sequence has a limit, the given sequence has a limit. In fact, $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2 n-7}{3 n+2}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2-7 / n}{3+2 / n}=\\\\frac{2}{3}$.\\n',\n",
       " '\\n2.16. A sequence $\\\\left\\\\{u_{n}\\\\right\\\\}$ is defined by the recursion formula $u_{n+1} \\\\sqrt{3 u_{n}}, u_{1}=1$. (a) Prove that $\\\\lim u_{n}$ exists. (b) Find the limit in (a).\\n\\n(a) The terms of the sequence are $u_{1}=1, u_{2}=\\\\sqrt{3 u_{1}}=3^{1 / 2}, u_{3}=\\\\sqrt{3 u_{2}}=3^{1 / 2+1 / 4}, \\\\ldots$.\\n\\nThe $n$th term is given by $u_{n}=3^{1 / 2+1 / 4+\\\\cdots+1 / 2 n-1}$, as can be proved by mathematical induction (Chapter 1 ).\\n\\nClearly, $u_{n+1} \\\\geqq u_{n}$. Then the sequence is monotonic increasing.\\n\\nBy Problem 1.14, $u_{n} \\\\leq 3^{1}=3$, i.e., $u_{n}$ is bounded above. Hence, $u_{n}$ is bounded (since a lower bound is zero).\\n\\nThus, a limit exists, since the sequence is bounded and monotonic increasing.\\n\\n(b) Let $x=$ required limit. Since $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n+1}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sqrt{3 u_{n}}$, we have $x=\\\\sqrt{3 x}$ and $x=3$. (The other possibility, $x=0$, is excluded, since $u_{n} \\\\geqq 1$.)\\n\\nAnother method: $\\\\lim _{n \\\\rightarrow \\\\infty} 3^{1 / 2+1 / 4+\\\\cdots+1 / 2^{n-1}}=\\\\lim _{n \\\\rightarrow \\\\infty} 3^{1-1 / 2^{n}}=3 \\\\lim _{n \\\\rightarrow \\\\infty}^{\\\\left(1-1 / 2^{n}\\\\right)}=3^{1}=3$\\n',\n",
       " '\\n2.17. Verify the validity of the entries in the following table.\\n\\n\\\\begin{center}\\n\\\\begin{tabular}{lllll}\\n\\\\hline\\nSEQUENCE & BOUNDED & \\\\begin{tabular}{l}\\nMONOTONIC \\\\\\\\\\nINCREASING \\\\\\\\\\n\\\\end{tabular} & \\\\begin{tabular}{l}\\nMONOTONIC \\\\\\\\\\nDECREASING \\\\\\\\\\n\\\\end{tabular} & \\\\begin{tabular}{l}\\nLIMIT \\\\\\\\\\nEXISTS \\\\\\\\\\n\\\\end{tabular} \\\\\\\\\\n\\\\hline\\n$2,1.9,1.8,1.7, \\\\ldots, 2-(n-1) / 10 \\\\ldots$ & No & No & Yes & No \\\\\\\\\\n$1,-1,1,-1, \\\\ldots,(-1)^{n-1}, \\\\ldots$ & Yes & No & No & No \\\\\\\\\\n$\\\\frac{1}{2},-\\\\frac{1}{3}, \\\\frac{1}{4},-\\\\frac{1}{5}, \\\\ldots,(-1)^{n-1} /(n+1), \\\\ldots$ & Yes & No & No & Yes $(0)$ \\\\\\\\\\n$.6, .66, .666, \\\\ldots, \\\\frac{2}{3}\\\\left(1-1 / 10^{n}\\\\right), \\\\ldots$ & Yes & Yes & No & Yes $\\\\left(\\\\frac{2}{3}\\\\right)$ \\\\\\\\\\n$-1,+2,-3,+4,-5, \\\\ldots,(-1)^{n} n, \\\\ldots$ & No & No & No & No \\\\\\\\\\n\\\\end{tabular}\\n\\\\end{center}\\n',\n",
       " '\\n2.18. Prove that the sequence with the $n$th term $u_{n}=\\\\left(1+\\\\frac{1}{n}\\\\right)^{n}$ is monotonic, increasing, and bounded, and thus a limit exists. The limit is denoted by the symbol $e$.\\n\\nNote: $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{n}\\\\right)^{n}=e$, where $e \\\\cong 2.71828 \\\\cdots$ was introduced in the eighteenth century by Leonhart Euler as the base for a system of logarithms in order to simplify certain differentiation and integration formulas.\\n\\nBy the binomial theorem, if $n$ is a positive integer (see Problem 1.95),\\n\\n$$\\n(1+x)^{n}=1+n x+\\\\frac{n(n-1)}{2 !} x^{2}+\\\\frac{n(n-1)(n-2)}{3 !} x^{2}+\\\\cdots+\\\\frac{n(n-1) \\\\cdots(n-n+1)}{n !} x^{n}\\n$$\\n\\nLetting $x=1 / n$,\\n\\n$$\\n\\\\begin{aligned}\\nu^{n}=\\\\left(1+\\\\frac{1}{n}\\\\right)^{n}= & 1+n \\\\frac{1}{n}+\\\\frac{n(n-1)}{2 !} \\\\frac{1}{n^{2}}+\\\\cdots+\\\\frac{n(n-1) \\\\cdots(n-n+1)}{n !} \\\\frac{1}{n^{n}} \\\\\\\\\\n= & 1+1+\\\\frac{1}{2 !}\\\\left(1-\\\\frac{1}{n}\\\\right)+\\\\frac{1}{3 !}\\\\left(1-\\\\frac{1}{n}\\\\right)\\\\left(1-\\\\frac{2}{n}\\\\right) \\\\\\\\\\n& +\\\\cdots+\\\\frac{1}{n !}\\\\left(1-\\\\frac{1}{n}\\\\right)\\\\left(1-\\\\frac{2}{n}\\\\right) \\\\cdots\\\\left(1-\\\\frac{n-1}{n}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nSince each term beyond the first two terms in the last expression is an increasing function of $n$, it follows that the sequence $u_{n}$ is a monotonic increasing sequence.\\n\\nIt is also clear that\\n\\n$$\\n\\\\left(1+\\\\frac{1}{n}\\\\right)^{n}<1+1+\\\\frac{1}{2 !}+\\\\frac{1}{3 !}+\\\\ldots+\\\\frac{1}{n !}<1+1+\\\\frac{1}{2}+\\\\frac{1}{2^{2}}+\\\\cdots+\\\\frac{1}{2^{n-1}}<3\\n$$\\n\\nby Problem 1.14.\\n\\nThus, $u_{n}$ is bounded and monotonic increasing, and so has a limit which we denote by $e$. The value of $e=$ 2.71828 . .\\n',\n",
       " '\\n2.19. Prove that $\\\\lim _{x \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{x}\\\\right)^{x}=e$, where $x \\\\rightarrow \\\\infty$ in any manner whatsoever (i.e., not necessarily along the positive integers, as in Problem 2.18).\\n\\nIf $n=$ largest integer $\\\\leqq x$, then $n \\\\leqq x \\\\leqq n+1$ and $\\\\left(1+\\\\frac{1}{n+1}\\\\right)^{n} \\\\leqq\\\\left(1+\\\\frac{1}{x}\\\\right)^{x} \\\\leqq\\\\left(1+\\\\frac{1}{n}\\\\right)^{n+1}$. Since $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{n+1}\\\\right)^{n}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{n+1}\\\\right)^{n+1} /\\\\left(1+\\\\frac{1}{n+1}\\\\right)=e$ and $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{n}\\\\right)^{n+1}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{n}\\\\right)^{n}\\\\left(1+\\\\frac{1}{n}\\\\right)=e$, it follows that $\\\\lim _{x \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{x}\\\\right)^{x}=e$.\\n\\n\\n\\\\section*{Least upper bound, greatest lower bound, limit superior, limit inferior}\\n',\n",
       " \"2.20. Find the (a) l.u.b., (b) g.l.b., (c) $\\\\lim \\\\sup (\\\\overline{\\\\lim })$, and (d) $\\\\lim \\\\inf (\\\\underline{\\\\lim })$ for the sequence $2,-2,1,-1,1,-1,1$, $-1, \\\\ldots$.\\n\\n(a) 1.u.b. $=2$, since all terms are less than equal to 2 , while at least one term (the 1 st) is greater than $2-\\\\epsilon$ for any $\\\\epsilon>0$.\\n\\n(b) g.1.b. $=-2$, since all terms are greater than or equal to -2 , while at least one term (the 2 nd) is less than $-2+\\\\epsilon$ for any $\\\\epsilon>0$.\\n\\n(c) $\\\\lim$ sup or $\\\\overline{\\\\lim }=1$, since infinitely many terms of the sequence are greater than $1-\\\\epsilon$ for any $\\\\epsilon>0$ (namely, all 1's in the sequence), while only a finite number of terms are greater than $1+\\\\epsilon$ for any $\\\\epsilon>0$ (namely, the 1st term).\\n\\n(d) $\\\\lim \\\\inf$ or $\\\\underline{\\\\lim }=-1$, since infinitely many terms of the sequence are less than $-1+\\\\epsilon$ for any $\\\\epsilon>0$ (namely, all -1 's in the sequence), while only a finite number of terms are less than $-1-\\\\epsilon$ for any $\\\\epsilon>0$ (namely, the 2nd term).\\n\",\n",
       " '\\n2.21. Find the (a) l.u.b., (b) g.l.b., (c) $\\\\lim \\\\sup (\\\\overline{\\\\lim }$ ), and (d) $\\\\lim \\\\inf (\\\\underline{\\\\lim })$ for the sequences in Problem 2.17.\\n\\nThe results are shown in the following table.\\n\\n\\\\begin{center}\\n\\\\begin{tabular}{lllll}\\n\\\\hline\\nSEQUENCE & l.u.b. & g.l.b. & lim sup or lim & lim inf or lim \\\\\\\\\\n\\\\hline\\n$2,1.9,1.8,1.7, \\\\ldots, 2-(n-1) / 10 \\\\ldots$ & 2 & none & $-\\\\infty$ & $-\\\\infty$ \\\\\\\\\\n$1,-1,1,-1, \\\\ldots,(-1)^{n-1}, \\\\ldots$ & 1 & -1 & 1 & -1 \\\\\\\\\\n$\\\\frac{1}{2},-\\\\frac{1}{3}, \\\\frac{1}{4}-\\\\frac{1}{5}, \\\\ldots,(-1)^{n-1} /(n+1), \\\\ldots$ & $\\\\frac{1}{2}$ & $-\\\\frac{1}{3}$ & 0 & 0 \\\\\\\\\\n$.6, .66, .666, \\\\ldots, \\\\frac{2}{3}\\\\left(1-1 / 10^{n}\\\\right), \\\\ldots$ & $\\\\frac{2}{3}$ & 6 & $\\\\frac{2}{3}$ & $\\\\frac{2}{3}$ \\\\\\\\\\n$-1,+2,-3,+4,-5, \\\\ldots,(-1)^{n} n, \\\\ldots$ & none & none & $+\\\\infty$ & $-\\\\infty$ \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}\\n\\\\end{center}\\n\\n\\n\\\\section*{Nested intervals}\\n',\n",
       " '2.22. Prove that to every set of nested intervals $\\\\left[a_{n}, b_{n}\\\\right], n=1,2,3, \\\\ldots$ there corresponds one and only one real number.\\n\\nBy definition of nested intervals, $a_{n+1} \\\\geqq a_{n}, b_{n+1}$, $b_{n} n=1,2,3, \\\\ldots$ and $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(a_{n}-b_{n}\\\\right)=0$.\\n\\nThen $a_{1} \\\\leqq a_{n} \\\\leqq b_{n} \\\\leqq b_{1}$, and the sequences $\\\\left\\\\{a_{n}\\\\right\\\\}$ and $\\\\left\\\\{b_{n}\\\\right\\\\}$ are bounded and, respectively, monotonic increasing and decreasing sequences and so converge to $a$ and $b$.\\n\\nTo show that $a=b$ and thus prove the required result, we note that\\n\\n\\n\\\\begin{gather*}\\nb-a=\\\\left(b-b_{n}\\\\right)+\\\\left(b_{n}-a_{n}\\\\right)+\\\\left(a_{n}-a\\\\right)  \\\\tag{1}\\\\\\\\\\n|b-a| \\\\leqq\\\\left|b-b_{n}\\\\right|+\\\\left|b_{n}-a_{n}\\\\right|+\\\\left|a_{n}-a\\\\right| \\\\tag{2}\\n\\\\end{gather*}\\n\\n\\nNow, given any $\\\\epsilon>0$, we can find $N$ such that for all $n>N$\\n\\n\\n\\\\begin{equation*}\\n\\\\left|b-b_{n}\\\\right|<\\\\epsilon / 3,\\\\left|b_{n}-a\\\\right|<\\\\epsilon / 3 \\\\text {, } \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nso that from Equation (2), $|b-a|<\\\\epsilon$. Since $\\\\epsilon$ is any positive number, we must have $b-a=0$ or $a=b$.\\n',\n",
       " \"\\n2.23. Prove the Bolzano-Weierstrass theorem (see Page 7).\\n\\nSuppose the given bounded infinite set is contained in the finite interval $[a, b]$. Divide this interval into two equal intervals. Then at least one of these, denoted by $\\\\left[a_{1}, b_{1}\\\\right]$, contains infinitely many points. Dividing $\\\\left[a_{1}, b_{1}\\\\right]$ into two equal intervals, we obtain another interval-say, $\\\\left[a_{2}, b_{2}\\\\right]$-containing infinitely many points. Continuing this process, we obtain a set of intervals $\\\\left[a_{n}, b_{n}\\\\right], n=1,2,3, \\\\ldots$, each interval contained in the preceding one and such that\\n\\n$$\\nb_{1}-a_{1}=(b-a) / 2, b_{2}-a_{2}=\\\\left(b_{1}-a_{1}\\\\right) / 2=(b-a) / 2^{2}, \\\\ldots, b_{n}-a_{n}=(b-a) / 2^{n}\\n$$\\n\\nfrom which we see that $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(b_{n}-a_{n}\\\\right)=0$.\\n\\nThis set of nested intervals, by Problem 2.22, corresponds to a real number which represents a limit point and so proves the theorem.\\n\\n\\n\\\\section*{Cauchy's convergence criterion}\\n\",\n",
       " \"2.24. Prove Cauchy's convergence criterion as stated on Page 27.\\n\\nNecessity. Suppose the sequence $\\\\left\\\\{u_{n}\\\\right\\\\}$ converges to $l$. Then, given any $\\\\epsilon>0$, we can find $N$ such that\\n\\n$$\\n\\\\left|u_{p}-l\\\\right|<\\\\epsilon / 2 \\\\text { for all } p>N \\\\text { and }\\\\left|u_{q}-l\\\\right|<\\\\epsilon / 2 \\\\text { for all } q>N\\n$$\\n\\nThen, for both $p>N$ and $q>N$, we have\\n\\n$$\\n\\\\left|u_{p}-u_{q}\\\\right|=\\\\left|\\\\left(u_{p}-l\\\\right)+\\\\left(l-u_{q}\\\\right)\\\\right| \\\\leqq\\\\left|u_{p}-l\\\\right|+\\\\left|l-u_{q}\\\\right|<\\\\epsilon / 2+\\\\epsilon / 2=\\\\epsilon\\n$$\\n\\nSufficiency. Suppose $\\\\left|u_{p}-u_{q}\\\\right|<\\\\epsilon$ for all $p, q>N$ and any $\\\\epsilon>0$. Then all the numbers $u_{N}, u_{N+1}, \\\\ldots$ lie in a finite interval; i.e., the set is bounded and infinite. Hence, by the Bolzano-Weierstrass theorem there is at least one limit point—say, $a$.\\n\\nIf $a$ is the only limit point, we have the desired proof and $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=a$.\\n\\nSuppose there are two distinct limit points—say, $a$ and $b$ - and suppose $b>a$ (see Figure 2.1). By definition of limit points, we have\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\left|u_{p}-a\\\\right|<(b-a) / 3 \\\\text { for infinitely many values of } p \\\\\\\\\\n& \\\\left|u_{q}-b\\\\right|<(b-a) / 3 \\\\text { for infinitely many values of } q\\n\\\\end{aligned}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-046}\\n\\\\end{center}\\n\\nFigure 2.1\\n\\nThen, since $b-a=\\\\left(b-u_{q}\\\\right)+\\\\left(u_{q}-u_{p}\\\\right)+\\\\left(u_{p}-a\\\\right)$, we have\\n\\n\\n\\\\begin{equation*}\\n|b-a|=b-a \\\\leqq\\\\left|b-u_{q}\\\\right|+\\\\left|u_{p}-u_{q}\\\\right|+\\\\left|u_{p}-a\\\\right| \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nUsing Equations (1) and (2) in (3), we see that $\\\\left|u_{p}-u_{q}\\\\right|>(b-a) / 3$ for infinitely many values of $p$ and $q$, thus contradicting the hypothesis that $\\\\left|u_{p}-u_{q}\\\\right|<\\\\epsilon$ for $p, q>N$ and any $\\\\epsilon>0$. Hence, there is only one limit point and the theorem is proved.\\n\\n\\n\\\\section*{Infinite series}\\n\",\n",
       " '2.25. Prove that the infinite series (sometimes called the geometric series)\\n\\n$$\\na+a r+a r^{2}+\\\\cdots=\\\\sum_{n=1}^{\\\\infty} a r^{n-1}\\n$$\\n\\n(a) converges to $a /(1-r)$ if $|r|<1$, and (b) diverges if $|r| \\\\geqq 1$.\\n\\nLet\\n\\n$$\\nS_{n}=a+a r+a r^{2}+\\\\cdots+a r^{n-1}\\n$$\\n\\nThen\\n\\n$$\\nr S_{n}=a r+a r^{2}+\\\\cdots+a r^{n-1}+a r^{n}\\n$$\\n\\nSubtract\\n\\n$$\\n\\\\begin{array}{rlr}\\n(1-r) S_{n} & =a & -a r^{n} \\\\\\\\\\ns_{n} & =\\\\frac{a\\\\left(1-r^{n}\\\\right)}{1-r}\\n\\\\end{array}\\n$$\\n\\nor\\n\\n(a) If $|r|<1, \\\\lim _{n \\\\rightarrow \\\\infty} S_{n}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{a\\\\left(1-r^{n}\\\\right)}{1-r}=\\\\frac{a}{1-r}$ by Problem 2.7.\\n\\n(b) If $|r|>1, \\\\lim _{n \\\\rightarrow \\\\infty} S_{n}$ does not exist (see Problem 2.44).\\n',\n",
       " '\\n2.26. Prove that if a series converges, its $n$th term must necessarily approach zero.\\n\\nSince $S_{n}=u_{1}+u_{2}+\\\\cdots+u_{n}$ and $S_{n-1}=u_{1}+u_{2}+\\\\cdots+u_{n-1}$, we have $u_{n}=S_{n}-S_{n-1}$.\\n\\nIf the series converges to $S$, then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(S_{n}-S_{n-1}\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}-\\\\lim _{n \\\\rightarrow \\\\infty} S_{n-1}=S-S=0\\n$$\\n',\n",
       " \"\\n2.27. Prove that the series $1-1+1-1+1-1+\\\\cdots=\\\\sum_{n=1}^{\\\\infty}(-1)^{n-1}$ diverges. Method 1: $\\\\quad \\\\lim _{n \\\\rightarrow \\\\infty}(-1)^{n} \\\\neq 0$; in fact, it doesn't exist. Then by Problem 2.26, the series cannot converge; i.e.,\\\\\\\\\\nit diverges.\\n\\nMethod 2: The sequence of partial sums is $1,1-1,1-1+1,1-1+1-1$, . .; i.e., 1, $0,1,0,1,0$, $1, \\\\ldots$ Since this sequence has no limit, the series diverges.\\n\\n\\n\\\\section*{Miscellaneous problems}\\n\",\n",
       " '2.28. If $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=l$, prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{u_{1}+u_{2}+\\\\cdots+u_{n}}{n}=l$.\\n\\nLet $u_{n}=v_{n}+l$. We must show that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{v_{1}+v_{2}+\\\\cdots+v_{n}}{n}=0$ if $\\\\lim _{n \\\\rightarrow \\\\infty} v_{n}=0$. Now\\n\\n$$\\n\\\\frac{v_{1}+v_{2}+\\\\cdots+v_{n}}{n}=\\\\frac{v_{1}+v_{2}+\\\\cdots+v_{p}}{n}+\\\\frac{v_{p+1}+v_{p+2}+\\\\cdots v_{n}}{n}\\n$$\\n\\nso that\\n\\n\\n\\\\begin{equation*}\\n\\\\left|\\\\frac{v_{1}+v_{2}+\\\\cdots+v_{n}}{n}\\\\right| \\\\leqq \\\\frac{\\\\left|v_{1}+v_{2}+\\\\cdots+v_{p}\\\\right|}{n}+\\\\frac{\\\\left|v_{P+1}\\\\right|+\\\\left|v_{P+2}\\\\right|+\\\\cdots+\\\\left|v_{n}\\\\right|}{n} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSince $\\\\lim _{n \\\\rightarrow \\\\infty} v_{n}=0$, we can choose $P$ so that $\\\\left|v_{n}\\\\right|<\\\\epsilon / 2$ for $n>P$. Then\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\left|v_{P+1}\\\\right|+\\\\left|v_{P+2}\\\\right|+\\\\cdots+\\\\left|v_{n}\\\\right|}{n}<\\\\frac{\\\\varepsilon / 2+\\\\varepsilon / 2+\\\\cdots+\\\\varepsilon / 2}{n}=\\\\frac{(n-P) \\\\varepsilon / 2}{n}<\\\\frac{\\\\varepsilon}{2} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nAfter choosing $P$, we can choose $N$ so that for $n>N>P$,\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\left|v_{1}+v_{2}+\\\\cdots+v_{P}\\\\right|}{n}<\\\\frac{\\\\varepsilon}{2} \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nThen, using Equations (2) and (3), (1) becomes\\n\\n$$\\n\\\\left|\\\\frac{v_{1}+v_{2}+\\\\cdots+v_{n}}{n}\\\\right|<\\\\frac{\\\\varepsilon}{2}+\\\\frac{\\\\varepsilon}{2}=\\\\varepsilon \\\\quad \\\\text { for } n>N\\n$$\\n\\nthus proving the required result.\\n',\n",
       " '\\n2.29. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+n+n^{2}\\\\right)^{1 / n}=1$.\\n\\nLet $\\\\left(1+n+n^{2}\\\\right)^{1 / n}=1+u_{n}$, where $u_{n} \\\\geqq 0$. Now, by the binomial theorem,\\n\\n$$\\n1+n+n^{2}=\\\\left(1+u_{n}\\\\right)^{n}=1+n u_{n}+\\\\frac{n(n-1)}{2 !} u_{n}^{2}+\\\\frac{n(n-1)(n-2)}{3 !} u_{n}^{3}+\\\\cdots+u_{n}^{n}\\n$$\\n\\nThen $1+n+n^{2}>1+\\\\frac{n(n-1)(n-2)}{3 !} u_{n}^{3}$ or $0<u_{n}^{3}<\\\\frac{6\\\\left(n^{2}+n\\\\right)}{n(n-1)(n-2)}$. Hence, $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}^{3}=0$ and\\n\\n$\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=0$. Thus, $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+n+n^{2}\\\\right)^{1 / n}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+u_{n}\\\\right)=1$.\\n',\n",
       " '\\n2.30. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{a^{n}}{n !}=0$ for all constants $a$.\\n\\nThe result follows if we can prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{|a|^{n}}{n !}=0$ (see Problem 2.38). We can assume $a \\\\neq 0$.\\n\\nLet $u_{n}=\\\\frac{|a|^{n}}{n !}$. Then $\\\\frac{u_{n}}{u_{n-1}}=\\\\frac{|a|}{n}$. If $n$ is large enough—say, $n>2|a|$-and if we call $N=[2|a|+1]$, i.e., the greatest integer $\\\\leqq 2|a|+1$, then\\n\\n$$\\n\\\\frac{u_{N+1}}{u_{N}}<\\\\frac{1}{2}, \\\\frac{u_{N+2}}{u_{N+1}}<\\\\frac{1}{2}, \\\\ldots, \\\\frac{u_{n}}{u_{n-1}}<\\\\frac{1}{2}\\n$$\\n\\nMultiplying these inequalities yields $\\\\frac{u_{n}}{u_{N}}<\\\\left(\\\\frac{1}{2}\\\\right)^{n-N}$ or $u_{n}<\\\\left(\\\\frac{1}{2}\\\\right)^{n-N} u_{N}$. Since $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(\\\\frac{1}{2}\\\\right)^{n-N}=0$ (using\\n\\n',\n",
       " '3.1. Let $f(x)=(x-2)(8-x)$ for $2 \\\\leq x \\\\leq 8$. (a) Find $f(6)$ and $f(-1)$. (b) What is the domain of definition of $f(x)$ ? (c) Find $f(1-2 t)$ and give the domain of definition. (d) Find $f[f(3)], f[f(5)]$. (e) Graph $f(x)$.\\n\\n(a) $f(6)=(6-2)(8-6)=4 \\\\cdot 2=8$\\n\\n$f(-1)$ is not defined since $f(x)$ is defined only for $2 \\\\leqq x \\\\leqq 8$.\\n\\n(b) The set of all $x$ such that $2 \\\\leqq x \\\\leqq 8$.\\n\\n(c) $f(1-2 t)=\\\\{(1-2 t)-2\\\\}\\\\{8-(1-2 t)\\\\}=-(1+2 t)(7+2 t)$ where $t$ is such that $2 \\\\leqq 1-2 t \\\\leqq 8$; i.e., $-7 / 2 \\\\leq t \\\\leq-1 / 2$.\\n\\n(d) $f(3)=(3-2)(8-3)=5, f[f(3)]=f(5)=(5-2)(8-5)=9$. $f(5)=9$ so that $f[f(5)]=f(9)$ is not defined.\\n\\n(e) The following table shows $f(x)$ for various values of $x$.\\n\\n\\\\begin{center}\\n\\\\begin{tabular}{llllllllll}\\n$x$ & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 2.5 & 7.5 \\\\\\\\\\n$f(x)$ & 0 & 5 & 8 & 9 & 8 & 5 & 0 & 2.75 & 2.75 \\\\\\\\\\n\\\\end{tabular}\\n\\\\end{center}\\n\\nPlot points $(2,0),(3,5),(4,8),(5,9),(6,8),(7,5),(8,0)$, $(2.5,2.75),(7.5,2.75)$. These points are only a few of the infinitely many points on the required graph shown in the adjoining Figure 3.5. This set of points defines a curve which is part of a parabola.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-064}\\n\\\\end{center}\\n\\nFigure 3.5\\n',\n",
       " '\\n3.2. Let $g(x)=(x-2)(8-x)$ for $2<x<8$. (a) Discuss the difference between the graph of $g(x)$ and that of $f(x)$ in Problem 3.1. (b) What are the 1.u.b. and g.1.b. of $g(x)$ ? (c) Does $g(x)$ attain its 1.u.b. and g.l.b. for any value of $x$ in the domain of definition? (d) Answer parts (b) and (c) for the function $f(x)$ of Problem 3.1.\\n\\n(a) The graph of $g(x)$ is the same as that in Problem 3.1 except that the two points $(2,0)$ and 8,0 ) are missing, since $g(x)$ is not defined at $x=2$ and $x=8$.\\n\\n(b) The 1.u.b. of $g(x)$ is 9. The g.l.b. of $g(x)$ is 0 .\\n\\n(c) The l.u.b. of $g(x)$ is attained for the value of $x=5$. The g.l.b. of $g(x)$ is not attained, since there is no value of $x$ in the domain of definition such that $g(x)=0$.\\n\\n(d) As in (b), the l.u.b. of $f(x)$ is 9 and the g.l.b. of $f(x)$ is 0 . The l.u.b. of $f(x)$ is attained for the value $x=5$ and the g.l.b. of $f(x)$ is attained at $x=2$ and $x=8$.\\n\\nNote that a function, such as $f(x)$, which is continuous in a closed interval attains its l.u.b. and g.l.b. at some point of the interval. However, a function, such as $g(x)$, which is not continuous in a closed interval need not attain its 1.u.b. and g.1.b. See Problem 3.34.\\n',\n",
       " '\\n3.3. Let\\n\\n$$\\nf(x)= \\\\begin{cases}1, & \\\\text { if } x \\\\text { is a rational number } \\\\\\\\ 0, & \\\\text { if } x \\\\text { is an irrational number }\\\\end{cases}\\n$$\\n\\n(a) Find $f\\\\left(\\\\frac{2}{3}\\\\right), f(-5), f(1.41423), f(\\\\sqrt{2})$. (b) Construct a graph of $f(x)$ and explain why it is misleading by\\\\\\\\\\nitself.\\n\\n(a) $f\\\\left(\\\\frac{2}{3}\\\\right) \\\\quad=1$ since $\\\\frac{2}{3}$ is a rational number\\n\\n$f(-5) \\\\quad=1$ since -5 is a rational number\\n\\n$f(1.41423)=1$ since 1.41423 is a rational number\\n\\n$f(\\\\sqrt{2}) \\\\quad=0$ since $\\\\sqrt{2}$ is an irrational number\\n\\n(b) The graph is shown in Figure 3.6. Because the sets of both rational numbers and irrational numbers are dense, the visual impression is that there are two images corresponding to each domain value. In actuality, each domain value has only one corresponding range value.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-065(1)}\\n\\\\end{center}\\n\\nFigure 3.6\\n',\n",
       " '\\n3.4. Referring to Problem 3.1: (a) Draw the graph with axes interchanged, thus illustrating the two possible choices available for definition of $f^{-1}$. (b) Solve for $x$ in terms of $y$ to determine the equations describing the two branches, and then interchange the variables.\\n\\n(a) The graph of $y=f(x)$ is shown in Figure 3.5 of Problem 3.1(a). By interchanging the axes (and the variables), we obtain the graphical form of Figure 3.7. This figure illustrates that there are two values of $y$ corresponding to each value of $x$, and, hence, two branches. Either may be employed to define $f^{-1}$.\\n\\n(b) We have $y=(x-2)(8-x)$ or $x^{2}-10 x+16+y=0$. The solution of this quadratic equation is\\n\\n$$\\nx=5 \\\\pm \\\\sqrt{9-y}\\n$$\\n\\nAfter interchanging variables\\n\\n$$\\ny=5 \\\\pm \\\\sqrt{9-x}\\n$$\\n\\nIn Figure 3.7, $A P$ represents $y=5+\\\\sqrt{9-x}$, and $B P$ designates $y=5-\\\\sqrt{9-x}$. Either branch may represent $f^{-1}$.\\n\\nNote: The point at which the two branches meet is called a branch point.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-065}\\n\\\\end{center}\\n\\nFigure 3.7\\n',\n",
       " '\\n3.5. (a) Prove that $g(x)=5+\\\\sqrt{9-x}$ is strictly decreasing in $0 \\\\leqq x \\\\leqq 9$. (b) Is it monotonic decreasing in this interval? (c) Does $g(x)$ have a single-valued inverse?\\n\\n(a) $g(x)$ is strictly decreasing if $g\\\\left(x_{1}\\\\right)>g\\\\left(x_{2}\\\\right)$ whenever $x_{1}<x_{2}$. If $x_{1}<x_{2}$, the $9-x_{1}>9-x_{2}, \\\\sqrt{9-x_{1}}>$ $\\\\sqrt{9-x_{2}}$, and $5+\\\\sqrt{9-x_{1}}>5+\\\\sqrt{9-x_{2}}$, showing that $g(x)$ is strictly decreasing.\\n\\n(b) Yes, any strictly decreasing function is also monotonic decreasing, since if $g\\\\left(x_{1}\\\\right)>g\\\\left(x_{2}\\\\right)$ it is also true that $g\\\\left(x_{1}\\\\right) \\\\geq g\\\\left(x_{2}\\\\right)$. However, if $g(x)$ is monotonic decreasing, it is not necessarily strictly decreasing.\\n\\n(c) If $y=5+\\\\sqrt{9-x}$, then $y-5=\\\\sqrt{9-x}$ or, squaring, $x=-16+10 y-y^{2}=(y-2)(8-y)$ and $x$ is a single-valued function of $y$; i.e., the inverse function is single-valued.\\n\\nIn general, any strictly decreasing (or increasing) function has a single-valued inverse (see Theorem 6, Page 52).\\n\\nThe results of this problem can be interpreted graphically using Figure 3.7.\\n',\n",
       " '\\n3.6. Construct graphs for the following functions:\\n\\n$$\\n\\\\text { (a) } f(x)= \\\\begin{cases}x \\\\sin 1 / x, & x>0 \\\\\\\\ 0, & x=0\\\\end{cases}\\n$$\\n\\n$$\\n\\\\text { (b) } f(x)=[x]=\\\\text { greatest integer } \\\\leqq x\\n$$\\n\\n(a) The required graph is shown in Figure 3.8. Since $|x \\\\sin 1 / x| \\\\leqq|x|$, the graph is included between $y=$ $x$ and $y=-x$. Note that $f(x)=0$ when $\\\\sin 1 / x=0$ or $1 / x=, m \\\\pi, m=1,2,3,4, \\\\ldots$, i.e., where $x=1 / \\\\pi, 1 / 2 \\\\pi$, $1 / 3 \\\\pi, \\\\ldots$ The curve oscillates infinitely often between $x=1 / \\\\pi$ and $x=0$.\\n\\n(b) The required graph is shown in Figure 3.9. If $1 \\\\leqq x<2$, then $[x]=1$. Thus, $[1.8]=1,[\\\\sqrt{2}]=1$, $[1.99999]=1$. However, [2] = 2. Similarly, for $2 \\\\leqq x<3,[x]=2$, etc. Thus, there are jumps at the integers.\\n\\nThe function is sometimes called the staircase function or step function.\\n',\n",
       " '\\n3.7. (a) Construct the graph of $f(x)=\\\\tan x$. (b) Construct the graph of some of the infinite number of branches available for a definition of $\\\\tan ^{-1} x$. (c) Show graphically why the relationship of $x$ to $y$ is multivalued. (d) Indicate possible principal values for $\\\\tan ^{-1} x$. (e) Using your choice, evaluate $\\\\tan ^{-1}(-1)$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-066(1)}\\n\\\\end{center}\\n\\nFigure 3.8\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-066}\\n\\\\end{center}\\n\\nFigure 3.9\\n\\n(a) The graph of $f(x)=\\\\tan x$ appears in Figure 3.10.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-066(2)}\\n\\\\end{center}\\n\\nFigure 3.10\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-066(3)}\\n\\\\end{center}\\n\\nFigure 3.11\\n\\n(b) The required graph is obtained by interchanging the $x$ and $y$ axes in the graph of (a). The result, with axes oriented as usual, appears in Figure 3.11.\\n\\n(c) In Figure 3.11, any vertical line meets the graph in infinitely many points. Thus, the relation of $y$ to $x$ is multivalued and infinitely many branches are available for the purpose of defining $\\\\tan ^{-1} x$.\\n\\n(d) To define $\\\\tan ^{-1} x$ as a single-valued function, it is clear from the graph that we can do so only by restricting its value to any of the following: $-\\\\pi / 2<\\\\tan ^{-1} x<\\\\pi / 2, \\\\pi / 2<\\\\tan ^{-1} x<3 \\\\pi / 2$, etc. We agree to take the first as defining the principal value.\\n\\nNote that no matter which branch is used to define $\\\\tan ^{-1} x$, the resulting function is strictly increasing.\\n\\n(e) $\\\\tan ^{-1}(-1)=-\\\\pi / 4$ is the only value lying between $-\\\\pi / 2$ and $\\\\pi / 2$; i.e., it is the principal value according to our choice in $(d)$.\\n',\n",
       " '\\n3.8. Show that $f(x)=\\\\frac{\\\\sqrt{x}+1}{x+1}, x \\\\neq-1$, describes an irrational algebraic function.\\n\\nIf $y=\\\\frac{\\\\sqrt{x}+1}{x+1}$, then $(x+1) y-1=\\\\sqrt{x}$ or, squaring, $(x+1)^{2} y^{2}-2(x+1) y+1-x=0$, a polynomial equation in $y$ whose coefficients are polynomials in $x$. Thus, $f(x)$ is an algebraic function. However, it is not the quotient of two polynomials, so that it is an irrational algebraic function.\\n',\n",
       " '\\n3.9. If $f(x)=\\\\cosh x=\\\\frac{1}{2}\\\\left(e^{x}+e^{-x}\\\\right)$, prove that we can choose, as the principal value of the inverse function,\\n\\n$\\\\cosh ^{-1} x=\\\\ln \\\\left(x+\\\\sqrt{x^{2}-1}\\\\right), x \\\\geqq 1$.\\n\\nIf $y=\\\\frac{1}{2}\\\\left(e^{x}+e^{-x}\\\\right), e^{2 x}-2 y e^{x}+1=0$. Then, using the quadratic formula, $e^{x}=\\\\frac{2 y \\\\pm \\\\sqrt{4 y^{2}-4}}{2}=y \\\\pm \\\\sqrt{y^{2}-1}$.\\n\\nThus, $x=\\\\ln \\\\left(y \\\\pm \\\\sqrt{y^{2}-1}\\\\right)$.\\n\\nSince $y-\\\\sqrt{y^{2}-1}=\\\\left(y-\\\\sqrt{\\\\left.y^{2}-1\\\\right)}\\\\left(\\\\frac{y+\\\\sqrt{y^{2}-1}}{y+\\\\sqrt{y^{2}-1}}\\\\right)=\\\\frac{1}{y+\\\\sqrt{y^{2}-1}}\\\\right.$ we can also write $x= \\\\pm \\\\ln \\\\left(y+\\\\sqrt{y^{2}-1}\\\\right)$ or $\\\\cosh ^{-1} y= \\\\pm \\\\ln \\\\left(y+\\\\sqrt{y^{2}-1}\\\\right)$.\\n\\nChoosing the + sign as defining the principal value and replacing $y$ by $x$, we have $\\\\cosh ^{-1} x=\\\\ln (x+$ $\\\\sqrt{y^{2}-1}$ ). The choice $x \\\\geqq 1$ is made so that the inverse function is real.\\n\\n\\n\\\\section*{Limits}\\n',\n",
       " '3.10. If (a) $f(x)=x^{2}$ and (b) $f(x)=\\\\left\\\\{\\\\begin{array}{ll}x^{2}, & x \\\\neq 2 \\\\\\\\ 0, & x=2\\\\end{array}\\\\right.$, prove that $\\\\lim _{x \\\\rightarrow 2} f(x)=4$.\\n\\n(a) We must show that, given any $\\\\epsilon>0$, we can find $\\\\delta>0$ (depending on $\\\\epsilon$ in general) such that $\\\\left|x^{2}-4\\\\right|<\\\\epsilon$ when $0<|x-2|<\\\\delta$.\\n\\nChoose $\\\\delta \\\\leqq 1$ so that $0<|x-2|<1$ or $1<x<3, x \\\\neq 2$. Then $\\\\left|x^{2}-4\\\\right|=|(x-2)(x+2)|=|x-2|$ $|x+2|<\\\\delta|x+2|<5 \\\\delta$.\\n\\nTake $\\\\delta$ as 1 or $\\\\epsilon / 5$, whichever is smaller. Then we have $\\\\left|x^{2}-4\\\\right|<\\\\epsilon$ whenever $0<|x-2|<\\\\delta$, and the required result is proved.\\n\\nIt is of interest to consider some numerical values. If, for example, we wish to make $\\\\left|x^{2}-4\\\\right|<.05$, we can choose $\\\\delta=\\\\epsilon / 5=.05 / 5=.01$. To see that this is actually the case, note that if $0<|x-2|<.01$, then $1.99<x<2.01(x \\\\neq 2)$, and so $3.9601<x^{2}<4.0401,-.0399<x^{2}-4<.0401$, and certainly $\\\\left|x^{2}-4\\\\right|$ $<.05\\\\left(x^{2} \\\\neq 4\\\\right)$. The fact that these inequalities also happen to hold at $x=2$ is merely coincidental.\\n\\nIf we wish to make $\\\\left|x^{2}-4\\\\right|<6$, we can choose $\\\\delta=1$, and this will be satisfied.\\n\\n(b) There is no difference between the proof for this case and the proof in (a), since in both cases we exclude $x=2$.\\n',\n",
       " '\\n3.11. Prove that $\\\\lim _{x \\\\rightarrow 1} \\\\frac{2 x^{4}-6 x^{3}+x^{2}+3}{x-1}=-8$.\\n\\nWe must show that for any $\\\\epsilon>0$ we can find $\\\\delta>0$ such that $\\\\left|\\\\frac{2 x^{4}-6 x^{3}+x^{2}+3}{x-1}-(-8)\\\\right|<\\\\varepsilon$ when $0<$ $|x-1|<\\\\delta$. Since $x \\\\neq 1$, we can write $\\\\frac{2 x^{4}-6 x^{3}+x^{2}+3}{x-1}=\\\\frac{\\\\left(2 x^{3}-4 x^{2}-3 x-3\\\\right)(x-1)}{x-1}=2 x^{3}-4 x^{2}-3 x-3$ on cancelling the common factor $x-1 \\\\neq 0$.\\n\\nThen we must show that for any $\\\\varepsilon>0$, we can find $\\\\delta>0$ such that $\\\\left|2 x^{3}-4 x^{2}-3 x+5\\\\right|<\\\\epsilon$ when $0<$ $|x-1|<\\\\delta$. Choosing $\\\\delta \\\\leqq 1$, we have $0<x<2, x \\\\neq 1$.\\n\\nNow $\\\\left|2 x^{3}-4 x^{2}-3 x+5\\\\right|=|x-1|\\\\left|2 x^{2}-2 x-5\\\\right|<\\\\delta\\\\left|2 x^{2}-2 x-5\\\\right|<\\\\delta\\\\left(\\\\left|2 x^{2}\\\\right|+|2 x|+5\\\\right)<(8+4+5)$ $\\\\delta=17 \\\\delta$. Taking $\\\\delta$ as the smaller of 1 and $\\\\epsilon / 17$, the required result follows.\\n',\n",
       " '\\n3.12. Let\\n\\n$$\\nf(x)=\\\\left\\\\{\\\\begin{array}{ll}\\n\\\\frac{|x-3|}{x-3}, & x \\\\neq x \\\\\\\\\\n0, & x=3\\n\\\\end{array} .\\\\right.\\n$$\\n\\n(a) Graph the function. (b) Find $\\\\lim _{x f(x)}$. (c) Find $\\\\lim _{x \\\\rightarrow 3+} f(x)$. (d) Find $\\\\lim _{x \\\\rightarrow 3} f(x)$.\\n\\n(a) For $x>3, \\\\frac{|x-3|}{x-3}=\\\\frac{x-3}{x-3}=1$.\\n\\nFor $x>3, \\\\frac{|x-3|}{x-3}=\\\\frac{-(x-3)}{x-3}=1$.\\n\\nThen the graph, shown in Figure 3.12, consists of the lines $y=1, x>3 ; y=-1, x<3$; and the point $(3,0)$.\\n\\n(b) As $x \\\\rightarrow 3$ from the right, $f(x) \\\\rightarrow 1$; i.e., $\\\\lim _{x \\\\rightarrow 3+} f(x)=1$, as seems clear from the graph. To prove this we must show that given any $\\\\epsilon>0$, we can find $\\\\delta>0$ such that $|f(x)-1|<\\\\epsilon$ whenever $0<x-1<\\\\delta$.\\n\\nNow, since $x>1, f(x)=1$ and so the proof consists in the triviality that $|1-1|<\\\\epsilon$ whenever $0<x-1<\\\\delta$.\\n\\n(c) As $x \\\\rightarrow 3$ from the left, $f(x) \\\\rightarrow-1$; i.e., $\\\\lim _{x \\\\rightarrow 3-} f(x)=-1$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-068}\\n\\\\end{center}\\n\\nFigure 3.12 A proof can be formulated as in $(b)$.\\n\\n(d) Since $\\\\lim _{x \\\\rightarrow 3+} f(x) \\\\neq \\\\lim _{x \\\\rightarrow 3-} f(x), \\\\neq \\\\lim _{x \\\\rightarrow 3-} f(x)$ does not exist.\\n',\n",
       " '\\n3.13. Prove that $\\\\lim _{x \\\\rightarrow 0} x \\\\sin 1 / x=0$.\\n\\nWe must show that given any $\\\\epsilon>0$, we can find $\\\\delta>0$ such that $|x \\\\sin 1 / x-0|<\\\\epsilon$ when $0<|x-0|$ $<\\\\delta$.\\n\\nIf $0<|x|<\\\\delta$, then $|x \\\\sin 1 / x|=|x||\\\\sin 1 / x| \\\\leqq|x|<\\\\delta$, since $|\\\\sin 1 / x| \\\\leqq 1$ for all $x \\\\neq 0$.\\n\\nMaking the choice $\\\\delta=\\\\epsilon$, we see that $|x \\\\sin 1 / x|<\\\\epsilon$ when $0<|x|<\\\\delta$, completing the proof.\\n',\n",
       " '\\n3.14. Evaluate $\\\\lim _{x \\\\rightarrow 0+} \\\\frac{2}{1+e^{-1 / x}}$.\\n\\nAs $x \\\\rightarrow 0+$ we suspect that $1 / x$ increases indefinitely, $e^{1 / x}$ increases indefinitely, $e^{-1 / x}$ approaches 0 , and $1+e^{-1 / x}$ approaches 1 ; thus, the required limit is 2 .\\n\\nTo prove this conjecture we must show that, given $\\\\epsilon>0$, we can find $\\\\delta>0$ such that\\n\\n$$\\n\\\\left|\\\\frac{2}{1+e^{-1 / x}}-2\\\\right|<\\\\varepsilon \\\\text { when } 0<x<\\\\delta\\n$$\\n\\nNow\\n\\n$$\\n\\\\left|\\\\frac{2}{1+e^{-1 / x}}-2\\\\right|=\\\\left|\\\\frac{2-2-2 e^{-1 / x}}{1+e^{-1 / x}}\\\\right|=\\\\frac{2}{e^{1 / x}+1}\\n$$\\n\\nSince the function on the right is smaller than 1 for all $x>0$, any $\\\\delta>0$ will work when $e \\\\geq 1$. If $0<\\\\varepsilon<1$, then $\\\\frac{2}{e^{1 / x}+1}<\\\\varepsilon$ when $\\\\frac{e^{1 / x}+1}{2}>\\\\frac{1}{\\\\varepsilon}, e^{1 / x}>\\\\frac{2}{\\\\varepsilon}-1, \\\\frac{1}{x}>\\\\operatorname{In}\\\\left(\\\\frac{2}{\\\\varepsilon}-1\\\\right)$; or $0<x<\\\\frac{1}{\\\\ln (2 / \\\\varepsilon-1)}=\\\\delta$.\\n',\n",
       " '\\n3.15. Explain exactly what is meant by the statement $\\\\lim _{x \\\\rightarrow 1} \\\\frac{1}{(x-1)^{4}}=\\\\infty$ and prove the validity of this statement.\\n\\nThe statement means that for each positive number $M$, we can find a positive number $\\\\delta$ (depending on $M$ in general) such that\\n\\n$$\\n\\\\frac{1}{(x-1)^{4}}>4 \\\\quad \\\\text { when } \\\\quad 0<|x-1|<\\\\delta\\n$$\\n\\nTo prove this, note that $\\\\frac{1}{(x-1)^{4}}>M$ when $0<(x-1)^{4}<\\\\frac{1}{M}$ or $0<|x-1|<\\\\frac{1}{\\\\sqrt[4]{M}}$.\\n\\nChoosing $\\\\delta=1 / \\\\sqrt[4]{M}$, the required results follows.\\n',\n",
       " '\\n3.16. Present a geometric proof that $\\\\lim _{\\\\theta \\\\rightarrow 0} \\\\frac{\\\\sin \\\\theta}{\\\\theta}=1$.\\n\\nConstruct a circle with center at $O$ and radius $O A=O D=1$, as in Figure 3.13. Choose point $B$ on $O A$ extended and point $C$ on $O D$ so that lines $B D$ and $A C$ are perpendicular to $O D$.\\n\\nIt is geometrically evident that\\n\\nArea of triangle $O A C<$ Area of sector $O A D<$ Area of triangle $O B D$\\n\\nthat is,\\n\\nDividing by $\\\\frac{1}{2} \\\\sin \\\\theta$,\\n\\n$$\\n\\\\frac{1}{2} \\\\sin \\\\theta \\\\cos \\\\theta<\\\\frac{1}{2} \\\\theta<\\\\frac{1}{2} \\\\tan \\\\theta\\n$$\\n\\n$$\\n\\\\cos \\\\theta<\\\\frac{\\\\theta}{\\\\sin \\\\theta}<\\\\frac{1}{\\\\cos \\\\theta}\\n$$\\n\\nor\\n\\n$$\\n\\\\cos \\\\theta<\\\\frac{\\\\sin \\\\theta}{\\\\theta}<\\\\frac{1}{\\\\cos \\\\theta}\\n$$\\n\\nAs $\\\\theta \\\\rightarrow 0, \\\\cos \\\\theta \\\\rightarrow 1$, and it follows that $\\\\lim _{\\\\theta \\\\rightarrow 0} \\\\frac{\\\\sin \\\\theta}{\\\\theta}=1$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-069}\\n\\\\end{center}\\n\\nFigure 3.13\\n\\n\\n\\\\section*{Theorems on limits}\\n',\n",
       " '3.17. If $\\\\lim _{x \\\\rightarrow x_{0}} f(x)$ exists, prove that it must be unique.\\n\\nWe must show that if $\\\\lim _{x \\\\rightarrow x_{0}} f(x)=l_{1}$ and $\\\\lim _{x \\\\rightarrow x_{0}} f(x)=l_{2}$, then $l_{1}=l_{2}$.\\n\\nBy hypothesis, given any $\\\\epsilon>0$ we can find $\\\\delta>0$ such that\\n\\n$$\\n\\\\begin{array}{lll}\\n\\\\left|f(x)-l_{1}\\\\right|<\\\\epsilon / 2 & \\\\text { when } & 0<\\\\left|x-x_{0}\\\\right|<\\\\delta \\\\\\\\\\n\\\\left|f(x)-l_{2}\\\\right|<\\\\epsilon / 2 & \\\\text { when } & 0<\\\\left|x-x_{0}\\\\right|<\\\\delta\\n\\\\end{array}\\n$$\\n\\nThen by the absolute value property 2 on Page 4 ,\\n\\n$$\\n\\\\left|l_{1}-l_{2}\\\\right|=\\\\left|l_{1}-f(x)+f(x)-l_{2}\\\\right| \\\\leqq\\\\left|l_{1}-f(x)\\\\right|+\\\\left|f(x)-l_{2}\\\\right|<\\\\epsilon / 2+\\\\epsilon / 2=\\\\epsilon\\n$$\\n\\ni.e., $\\\\left|l_{1}-l_{2}\\\\right|$ is less than any positive number $\\\\epsilon$ (however small) and so must be zero. Thus, $l_{1}=l_{2}$.\\n',\n",
       " '\\n3.18. If $\\\\lim _{x \\\\rightarrow x_{0}} g(x)=B \\\\neq 0$, prove that there exists $\\\\delta>0$ such that\\n\\n$$\\n|g(x)|>\\\\frac{1}{2}|B| \\\\quad \\\\text { for } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta\\n$$\\n\\nSince $\\\\lim _{x \\\\rightarrow x_{0}} g(x)=B$, we can find $\\\\delta>0$ such that $|g(x)-B|<\\\\frac{1}{2}|B|$ for $0<\\\\left|x-x_{0}\\\\right|<\\\\delta$.\\n\\nWriting $B=B-g(x)+g(x)$, we have\\n\\n$$\\n|B| \\\\leqq|B-g(x)|+|g(x)|<\\\\frac{1}{2}|B|+|g(x)|\\n$$\\n\\ni.e., $|B|<\\\\frac{1}{2}|B|+|g(x)|$, from which $|g(x)|>\\\\frac{1}{2}|B|$.\\n',\n",
       " '\\n3.19. Given $\\\\lim _{x \\\\rightarrow x_{0}} f(x)=A$ and $\\\\lim _{x \\\\rightarrow x_{0}} g(x)=B$, prove (a) $\\\\lim _{x \\\\rightarrow x_{0}}[f(x)+g(x)]=A+B$, (b) $\\\\lim _{x \\\\rightarrow x_{0}} f(x) g(x)=A B$,\\n\\n(c) $\\\\lim _{x \\\\rightarrow x_{0}} \\\\frac{1}{g(x)}=\\\\frac{1}{B}$ if $B \\\\neq 0$, and (d) $\\\\lim _{x \\\\rightarrow x_{0}} \\\\frac{f(x)}{g(x)}=\\\\frac{A}{B}$ if $B \\\\neq 0$.\\n\\n(a) We must show that for any $\\\\epsilon>0$ we can find $\\\\delta>0$ such that\\n\\n$$\\n|[f(x)+g(x)]-(A+B)|<\\\\varepsilon \\\\quad \\\\text { when } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta\\n$$\\n\\nUsing absolute value property 2 , Page 4 , we have\\n\\n\\n\\\\begin{equation*}\\n|[f(x)+g(x)]-(A+B)|=|[f(x)-A]+[g(x)-B]| \\\\leqq|f(x)-A|+|g(x)-B| \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nBy hypothesis, given $\\\\epsilon>0$ we can find $\\\\delta_{1}>0$ and $\\\\delta_{2}>0$ such that\\n\\n\\\\[\\n\\\\begin{array}{lll}\\n|f(x)-A|<\\\\epsilon / 2 & \\\\text { when } & 0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{1} \\\\\\\\\\n|g(x)-B|<\\\\epsilon / 2 & \\\\text { when } & 0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{2} \\\\tag{3}\\n\\\\end{array}\\n\\\\]\\n\\nThen, from Equations (1), (2), and (3),\\n\\n$$\\n|[f(x)+g(x)]-(A+B)|<\\\\epsilon / 2+\\\\epsilon / 2=\\\\epsilon \\\\quad \\\\text { when } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta\\n$$\\n\\nwhere $\\\\delta$ is chosen as the smaller of $\\\\delta_{1}$ and $\\\\delta_{2}$.\\n\\n(b) We have\\n\\n\\n\\\\begin{align*}\\n|f(x) g(x)-A B| & =|f(x)[g(x)-B]+B[f(x)-A]|  \\\\tag{4}\\\\\\\\\\n& \\\\leqq|f(x)||g(x)-B|+|B||f(x)-A| \\\\\\\\\\n& \\\\leqq|f(x)||g(x)-B|+(|B|+1)|f(x)-A|\\n\\\\end{align*}\\n\\n\\nSince $\\\\lim _{x \\\\rightarrow x_{0}} f(x)=A$, we can find $\\\\delta_{1}$ such that $|f(x)-A|<1$ for $0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{1}$, i.e., $A-1<f(x)<A$ +1 , so that $f(x)$ is bounded, i.e., $|f(x)|<P$ where $P$ is a positive constant.\\n\\nSince $\\\\lim _{x \\\\rightarrow x_{0}} g(x)=B$, given $\\\\epsilon>0$, we can find $\\\\delta_{2}>0$ such that $|g(x)-B|<\\\\epsilon / 2 P$ for $0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{2}$.\\n\\nSince $\\\\lim _{x \\\\rightarrow x_{0}} f(x)=A$, given $\\\\epsilon>0$, we can find $\\\\delta_{3}>0$ such that $|f(x)-A|<\\\\frac{\\\\varepsilon}{2(|B|+1)}$ for $0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{2}$.\\n\\nUsing these in Equation (4), we have\\n\\n$$\\n|f(x) g(x)-A B|<P \\\\cdot \\\\frac{\\\\varepsilon}{2 P}+(|B|+1) \\\\cdot \\\\frac{\\\\varepsilon}{2(|B|+1)}=\\\\varepsilon\\n$$\\n\\nfor $0<\\\\left|x-x_{0}\\\\right|<\\\\delta$, where $\\\\delta$ is the smaller of $\\\\delta_{1}, \\\\delta_{1}, \\\\delta_{2}, \\\\delta_{3}$, and the proof is complete.\\n\\n(c) We must show that for any $\\\\epsilon>0$ we can find $\\\\delta>0$ such that\\n\\n\\n\\\\begin{equation*}\\n\\\\left|\\\\frac{1}{g(x)}-\\\\frac{1}{B}\\\\right|=\\\\frac{|g(x)-B|}{|B||g(x)|}<\\\\varepsilon \\\\quad \\\\text { when } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nBy hypothesis, given $\\\\epsilon>0$, we can find $\\\\delta_{1}>0$ such that\\n\\n$$\\n|g(x)-B|<\\\\frac{1}{2} B^{2} \\\\epsilon \\\\quad \\\\text { when } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{1}\\n$$\\n\\nBy Problem 3.18, since $\\\\lim _{x \\\\rightarrow 0} g(x)=B \\\\neq 0$, we can find $\\\\delta_{2}>0$ such that\\n\\n$$\\n|g(x)|>\\\\frac{1}{2}|B| \\\\quad \\\\text { when } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta_{2}\\n$$\\n\\nThen, if $\\\\delta$ is the smaller of $\\\\delta_{1}$ and $\\\\delta_{2}$, we can write\\n\\n$$\\n\\\\left|\\\\frac{1}{g(x)}-\\\\frac{1}{B}\\\\right|=\\\\frac{|g(x)-B|}{|B||g(x)|}<\\\\frac{\\\\frac{1}{2} B^{2} \\\\varepsilon}{|B| \\\\cdot \\\\frac{1}{2}|B|}=\\\\varepsilon \\\\quad \\\\text { whenever } \\\\quad 0<\\\\left|x-x_{0}\\\\right|<\\\\delta\\n$$\\n\\nand the required result is proved.\\n\\n(d) From parts $(b)$ and $(c)$,\\n\\n$$\\n\\\\lim _{x \\\\rightarrow x_{0}} \\\\frac{f(x)}{g(x)}=\\\\lim _{x \\\\rightarrow x_{0}} f(x) \\\\cdot \\\\frac{1}{g(x)}=\\\\lim _{x \\\\rightarrow x_{0}} f(x) \\\\cdot \\\\lim _{x \\\\rightarrow x_{0}} \\\\frac{1}{g(x)}=A \\\\cdot \\\\frac{1}{B}=\\\\frac{A}{B}\\n$$\\n\\nThis can also be proved directly (see Problem 3.69).\\n\\nThese results can also be proved in the cases $x \\\\rightarrow x_{0}+, x \\\\rightarrow x_{0}-, x \\\\rightarrow \\\\infty, x \\\\rightarrow-\\\\infty$.\\n\\nNote: In the proof of $(a)$ we have used the results $|f(x)-A|<\\\\epsilon / 2$ and $|g(x)-B|<\\\\epsilon / 2$, so that the final result would come out to be $|f(x)+g(x)-(A+B)|<\\\\epsilon$. Of course, the proof would be just as valid if we had used $2 \\\\epsilon$ (or any other positive multiple of $\\\\epsilon$ ) in place of $\\\\epsilon$. A similar remark holds for the proofs of $(b),(c)$, and $(d)$.\\n',\n",
       " '\\n3.20. Evaluate each of the following, using theorems on limits.\\n\\n(a) $\\\\lim _{x \\\\rightarrow 2}\\\\left(x^{2}-6 x+4\\\\right) \\\\quad=\\\\lim _{x \\\\rightarrow 2} x^{2}+\\\\lim _{x \\\\rightarrow 2}(-6 x)+\\\\lim _{x \\\\rightarrow 2} 4$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left(\\\\lim _{x \\\\rightarrow 2} x\\\\right)\\\\left(\\\\lim _{x \\\\rightarrow 2} x\\\\right)+\\\\left(\\\\lim _{x \\\\rightarrow 2}-6\\\\right)\\\\left(\\\\lim _{x \\\\rightarrow 2} x\\\\right)+\\\\lim _{x \\\\rightarrow 2} 4 \\\\\\\\\\n& =(2)(2)+(-6)(2)+4=-4\\n\\\\end{aligned}\\n$$\\n\\nIn practice, the intermediate steps are omitted.\\n\\n(b) $\\\\lim _{x \\\\rightarrow-1} \\\\frac{(x+3)(2 x-1)}{x^{2}+3 x-2}=\\\\frac{\\\\lim _{x \\\\rightarrow-1}(x+3) \\\\lim _{x \\\\rightarrow-1}(2 x-1)}{\\\\lim _{x \\\\rightarrow-1}\\\\left(x^{2}+3 x-2\\\\right)}=\\\\frac{2 \\\\cdot(-3)}{-4}=\\\\frac{3}{2}$\\n\\n(c) $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{2 x^{4}-3 x^{2}+1}{6 x^{4}+x^{3}-3 x}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{2-\\\\frac{3}{x^{2}}+\\\\frac{1}{x^{4}}}{6+\\\\frac{1}{x}-\\\\frac{3}{x^{3}}}$\\n\\n$$\\n=\\\\frac{\\\\lim _{x \\\\rightarrow \\\\infty} 2+\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{-3}{2}+\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{1}{x^{4}}}{\\\\lim _{x \\\\rightarrow \\\\infty} 6+\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{1}{x}+\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{-3}{x^{3}}}=\\\\frac{2}{6}=\\\\frac{1}{3}\\n$$\\n\\nby Problem 3.19.\\n\\n(d) $\\\\begin{aligned} \\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\sqrt{4+h}-2}{h} & =\\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\sqrt{4+h}-2}{h} \\\\cdot \\\\frac{\\\\sqrt{4+h}+2}{\\\\sqrt{4+h}+2} \\\\\\\\ & =\\\\lim _{h \\\\rightarrow 0} \\\\frac{4+h-4}{h(\\\\sqrt{4+h}+2}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{1}{\\\\sqrt{4+h}+2}=\\\\frac{1}{2+2}=\\\\frac{1}{4}\\\\end{aligned}$\\n\\n(e) $\\\\lim _{x \\\\rightarrow 0+} \\\\frac{\\\\sin x}{\\\\sqrt{x}}=\\\\lim _{x \\\\rightarrow 0+} \\\\frac{\\\\sin x}{x} \\\\cdot \\\\sqrt{x}=\\\\lim _{x \\\\rightarrow 0-} \\\\frac{\\\\sin x}{x} \\\\cdot \\\\lim _{x \\\\rightarrow 0+} \\\\sqrt{x}=1 \\\\cdot 0=0$.\\n\\nNote that in (c), (d), and (e) if we use the theorems on limits indiscriminately we obtain the so-called indeterminate forms $\\\\infty / \\\\infty$ and $0 / 0$. To avoid such predicaments, note that in each case the form of the limit is suitably modified. For other methods of evaluating limits, see Chapter 4.\\n\\n\\n\\\\section*{Continuity}\\n(Assume that values at which continuity is to be demonstrated are interior domain values unless otherwise stated.)\\n',\n",
       " '\\n3.21. Prove that $f(x)=x^{2}$ is continuous at $x=2$.\\n\\nMethod 1: By Problem 3.10, $\\\\lim _{x \\\\rightarrow 2} f(x)=f(2)=4$ and so $f(x)$ is continuous at $x=2$.\\n\\nMethod 2: We must show that, given any $\\\\epsilon>0$, we can find $\\\\delta>0$ (depending on $\\\\epsilon$ ) such that $|f(x)-f(2)|$ $=\\\\left|x^{2}-4\\\\right|<\\\\epsilon$ when $|x-2|<\\\\delta$. The proof patterns are given in Problem 3.10.\\n',\n",
       " '\\n3.22. (a) Prove that $f(x)=\\\\left\\\\{\\\\begin{array}{ll}x \\\\sin 1 / x, & x \\\\neq 0 \\\\\\\\ 5, & x=0\\\\end{array}\\\\right.$ is not continuous at $x=0$. (b) Can we redefine $f(0)$ so that $f(x)$ is continuous at $x=0$ ?\\n\\n(a) From Problem 3.13, $\\\\lim _{x \\\\rightarrow 0} f(x)=0$. But this limit is not equal to $f(0)=5$, so $f(x)$ is discontinuous at $x=0$.\\n\\n(b) By redefining $f(x)$ so that $f(0)=0$, the function becomes continuous. Because the function can be made continuous at a point simply by redefining the function at the point, we call the point a removable discontinuity.\\n',\n",
       " '\\n3.23. Is the function $f(x)=\\\\frac{2 x^{4}-6 x^{3}+x^{2}+3}{x-1}$ continuous at $x=1$ ?\\n\\n$f(1)$ does not exist, so $f(x)$ is not continuous at $x=1$. By redefining $f(x)$ so that $f(1)=\\\\lim _{x \\\\rightarrow 1} f(x)=-8$ (see Problem 3.11), it becomes continuous at $x=1$; i.e., $x=1$ is a removable discontinuity.\\n',\n",
       " '\\n3.24. $\\\\quad$ Prove that if $f(x)$ and $g(x)$ are continuous at $x=x_{0}$, so also are (a) $f(x),+g(x)$, (b) $f(x) g(x)$, and (c) $\\\\frac{f(x)}{g(x)}$ if $f\\\\left(x_{0}\\\\right) \\\\neq 0$.\\n\\nThese results follow at once from the proofs given in Problem 3.19 by taking $A=f\\\\left(x_{0}\\\\right)$ and $B=g\\\\left(x_{0}\\\\right)$ and rewriting $0<\\\\left|x-x_{0}\\\\right|<\\\\delta$ as $\\\\left|x-x_{0}\\\\right|<\\\\delta$, i.e., including $x=x_{0}$.\\n',\n",
       " '\\n3.25. Prove that $f(x)=x$ is continuous at any point $x=x_{0}$.\\n\\nWe must show that, given any $\\\\epsilon>0$, we can find $\\\\delta>0$ such that $\\\\left|f(x)-f\\\\left(x_{0}\\\\right)\\\\right|=\\\\left|x-x_{0}\\\\right|<\\\\epsilon$ when $\\\\left|x-x_{0}\\\\right|<\\\\delta$. By choosing $\\\\delta=\\\\epsilon$, the result follows at once.\\n',\n",
       " '\\n3.26. Prove that $f(x)=2 x^{3}+x$ is continuous at any point $x=x_{0}$.\\n\\nSince $x$ is continuous at any point $x=x_{0}$ (Problem 3.25), so also is $x \\\\cdot x=x^{2}, x^{2} \\\\cdot x=x^{3}, 2 x^{3}$, and, finally, $2 x^{3}+x$, using the theorem (Problem 3.24) that sums and products of continuous functions are continuous.\\n',\n",
       " '\\n3.27. Prove that if $f(x)=\\\\sqrt{x-5}$ for $5 \\\\leqq x \\\\leqq 9$, then $f(x)$ is continuous in this interval.\\n\\nIf $x_{0}$ is any point such that $5<x_{0}<9$, then $\\\\lim _{x \\\\rightarrow x_{0}} f(x)=\\\\lim _{x \\\\rightarrow x_{0}} \\\\sqrt{x-5}=\\\\sqrt{x_{0}-5}=f\\\\left(x_{0}\\\\right)$. Also, $\\\\lim _{x \\\\rightarrow 5+} \\\\sqrt{x-5}=0=f(5)$ and $\\\\lim _{x \\\\rightarrow 9-} \\\\sqrt{x-5}=2 f(9)$. Thus the result follows.\\n\\nHere we have used the result that $\\\\lim _{x \\\\rightarrow x_{0}} \\\\sqrt{f(x)}=\\\\sqrt{\\\\lim _{x \\\\rightarrow x_{0}} f(x)}=\\\\sqrt{f\\\\left(x_{0}\\\\right)}$ if $f(x)$ is continuous at $x_{0}$. An $\\\\epsilon, \\\\delta$ proof, directly from the definition, can also be employed.\\n',\n",
       " '\\n3.28. For what values of $x$ in the domain of definition is each of the following functions continuous?\\n\\n(a) $f(x)=\\\\frac{1}{x^{2}-1}$\\n\\n(b) $f(x)=\\\\frac{1+\\\\cos x}{3+\\\\sin x}$\\n\\n(c) $f(x)=\\\\frac{1}{\\\\sqrt[4]{10+4}}$\\n\\n(d) $f(x)=10^{-1 /(x-3) 2}$\\n\\n(e) $f(x)= \\\\begin{cases}10^{-1(x-3)^{2}}, & x \\\\neq 3 \\\\\\\\ 0, & x=3\\\\end{cases}$\\n\\n(f) $f(x)=\\\\frac{x-|x|}{x}$\\n\\n(g) $f(x)= \\\\begin{cases}\\\\frac{x-|x|}{x}, & x<0 \\\\\\\\ 2, & x=0\\\\end{cases}$\\n\\n(h) $f(x)=x \\\\csc x=\\\\frac{x}{\\\\sin x}$.\\n\\n(i) $f(x)=x \\\\csc x, f(0)=1$.\\n\\n(a) All $x$ except $\\\\cdot x= \\\\pm 1$ (where the denominator is zero)\\n\\n(b) All $x$\\n\\n(c) All $x>-10$\\n\\n(d) All $x \\\\neq 3$ (see Problem 3.55)\\n\\n(e) All $x$, since $\\\\lim _{x \\\\rightarrow 3} f(x)=f(3)$\\n\\n(f) If $x>0, f(x)=\\\\frac{x-x}{x}=0$. If $x<0, f(x)=\\\\frac{x+x}{x}=2$. At $x=0, f(x)$ is undefined. Then $f(x)$ is continuous for all $x$ except $x=0$.\\n\\n(g) As in $(f), f(x)$ is continuous for $x<0$. Then, since\\n\\n$$\\n\\\\lim _{x \\\\rightarrow 0-} \\\\frac{x-|x|}{x}=\\\\lim _{x \\\\rightarrow 0-} \\\\frac{x+x}{x}=\\\\lim _{x \\\\rightarrow 0-} 2=2=f(0)\\n$$\\n\\nit follows that $f(x)$ is continuous (from the left) at $x=0$.\\n\\nThus, $f(x)$ is continuous for all $x \\\\leqq 0$, i.e., everywhere in its domain of definition.\\\\\\\\\\n(h) All $x$ except $0, \\\\pm \\\\pi, \\\\pm 2 \\\\pi, \\\\pm 3 \\\\pi, \\\\ldots$\\n\\n(i) Since $\\\\lim _{x \\\\rightarrow 0} x \\\\csc x=\\\\lim _{x \\\\rightarrow 0} \\\\frac{x}{\\\\sin x}=1=f(0)$, we see that $f(x)$ is continuous for all $x$ except $\\\\pm \\\\pi, \\\\pm 2 \\\\pi$, $\\\\pm 3 \\\\pi, \\\\ldots$ [compare $(h)]$.\\n\\n\\n\\\\section*{Uniform continuity}\\n',\n",
       " '3.29. Prove that $f(x)=x^{2}$ is uniformly continuous in $0<x<1$.\\n\\nMethod 1: Using definition.\\n\\nWe must show that, given any $\\\\epsilon>0$, we can find $\\\\delta>0$ such that $\\\\left|x^{2}-x_{0}^{2}\\\\right|<\\\\epsilon$ when $\\\\left|x-x_{0}\\\\right|<\\\\delta$, where $\\\\delta$ depends only on $\\\\epsilon$ and not on $x_{0}$ where $0<x_{0}<1$.\\n\\nIf $x$ and $x_{0}$ are any points in $0<x<1$, then\\n\\n$$\\n\\\\left|x^{2}-x_{0}^{2}\\\\right|=\\\\left|x+x_{0}\\\\right|\\\\left|x-x_{0}\\\\right|<2\\\\left|x-x_{0}\\\\right|\\n$$\\n\\nThus, if $\\\\left|x-x_{0}\\\\right|<\\\\delta$, it follows that $\\\\left|x^{2}-x^{2}{ }_{0}\\\\right|<2 \\\\delta$. Choosing $\\\\delta=\\\\epsilon / 2$, we see that $\\\\left|x^{2}-x_{0}^{2}\\\\right|<\\\\epsilon$ when $\\\\left|x-x_{0}\\\\right|$ $<\\\\delta$, where $\\\\delta$ depends only on $\\\\epsilon$ and not on $x_{0}$ Hence, $f(x)=x^{2}$ is uniformly continuous in $0<x<1$.\\n\\nThis can be used to prove that $f(x)=x^{2}$ is uniformly continuous in $0 \\\\leqq x \\\\leqq 1$.\\n\\nMethod 2: The function $f(x)=x^{2}$ is continuous in the closed interval $0 \\\\leqq x \\\\leqq 1$. Hence, by the theorem on Page 48, it is uniformly continuous in $0 \\\\leqq x \\\\leqq 1$ and thus in $0<x<1$.\\n',\n",
       " '\\n3.30. Prove that $f(x)=1 / x$ is not uniformly continuous in $0<x<1$.\\n\\nMethod 1: Suppose $f(x)$ is uniformly continuous in the given interval. Then, for any $\\\\epsilon>0$ we should be able to find $\\\\delta$, say, between 0 and 1 , such that $\\\\left|f(x)-f\\\\left(x_{0}\\\\right)\\\\right|<\\\\epsilon$ when $\\\\left|x-x_{0}\\\\right|<\\\\delta$ for all $x$ and $x_{0}$ in the interval.\\n\\nLet $x=\\\\delta$ and $x_{0}=\\\\frac{\\\\delta}{1+\\\\varepsilon}$. Then $\\\\left|x-x_{0}\\\\right|=\\\\left|\\\\delta-\\\\frac{\\\\delta}{1+\\\\varepsilon}\\\\right|=\\\\frac{\\\\varepsilon}{1+\\\\varepsilon} \\\\delta<\\\\delta$.\\n\\nHowever, $\\\\left|\\\\frac{1}{x}-\\\\frac{1}{x_{0}}\\\\right|=\\\\left|\\\\frac{1}{\\\\delta}-\\\\frac{1+\\\\varepsilon}{\\\\delta}\\\\right|=\\\\frac{\\\\varepsilon}{\\\\delta}>\\\\varepsilon \\\\quad($ since $0<\\\\delta<1)$.\\n\\nThus, we have a contradiction, and it follows that $f(x)=1 / x$ cannot be uniformly continuous in $0<x<1$.\\n\\nMethod 2: Let $x_{0}$ and $x_{0}+\\\\delta$ be any two points in $(0,1)$. Then,\\n\\n$$\\n\\\\left\\\\lvert\\\\, f\\\\left(x_{0}\\\\right)-f\\\\left(\\\\left.x_{0}+\\\\delta|=| \\\\frac{1}{x_{0}}-\\\\frac{1}{x_{0}+\\\\delta} \\\\right\\\\rvert\\\\,=\\\\frac{\\\\delta}{x_{0}\\\\left(x_{0}+\\\\delta\\\\right)}\\\\right.\\\\right.\\n$$\\n\\ncan be made larger than any positive number by choosing $x_{0}$ sufficiently close to 0 . Hence, the function cannot be uniformly continuous.\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '3.31. If $y=f(x)$ is continuous at $x=x_{0}$, and $z=g(y)$ is continuous at $y=y_{0}$ where $y_{0}=f\\\\left(x_{0}\\\\right)$, prove that $z=g\\\\{f(x)\\\\}$ is continuous at $x=x_{0}$.\\n\\nLet $h(x)=g\\\\{f(x)\\\\}$. Since, by hypothesis, $f(x)$ and $g(y)$ are continuous at $x_{0}$ and $y_{0}$, respectively, we have\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\lim _{x \\\\rightarrow x_{0}} f(x)=f\\\\left(\\\\lim _{x \\\\rightarrow x_{0}} x\\\\right)=f\\\\left(x_{0}\\\\right) \\\\\\\\\\n& \\\\lim _{y \\\\rightarrow y_{0}} g(y)=g\\\\left(\\\\lim _{y \\\\rightarrow y_{0}} y\\\\right)=g\\\\left(y_{0}\\\\right)=g\\\\left\\\\{f\\\\left(x_{0}\\\\right)\\\\right\\\\}\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n$$\\n\\\\lim _{x \\\\rightarrow x_{0}} h(x)=\\\\lim _{x \\\\rightarrow x_{0}} g\\\\{f(x)\\\\}=g\\\\left\\\\{\\\\lim _{x \\\\rightarrow x_{0}} f(x)\\\\right\\\\}=g\\\\left\\\\{f\\\\left(x_{0}\\\\right)\\\\right\\\\}=h\\\\left(x_{0}\\\\right)\\n$$\\n\\nwhich proves that $h(x)=g\\\\{f(x)\\\\}$ is continuous at $x=x_{0}$.\\n',\n",
       " '\\n3.32. Prove Theorem 8, Page 52.\\n\\nSuppose that $f(a)<0$ and $f(b)>0$. Since $f(x)$ is continuous, there must be an interval $(a, a+h), h>0$, for which $f(x)<0$. The set of points $(a, a+h)$ has an upper bound and so has a least upper bound, which we call $c$. Then $f(c) \\\\leq 0$. Now we cannot have $f(c)<0$, because if $f(c)$ were negative we would be able to find an interval about $c$ (including values greater than $c$ ) for which $f(x)<0$; but since $c$ is the least upper bound, this is impossible, and so we must have $f(c)=0$ as required.\\n\\nIf $f(a)>0$ and $f(b)<0$, a similar argument can be used.\\n',\n",
       " '\\n3.33. (a) Given $f(x)=2 x^{3}-3 x^{2}+7 x-10$, evaluate $f(1)$ and $f(2)$. (b) Prove that $f(x)=0$ for some real number $x$ such that $1<x<2$. (c) Show how to calculate the value of $x$ in (b).\\n\\n(a) $f(1)=2(1)^{3}-3(1)^{2}+7(1)-10=-4, f(2)=2(2)^{3}-3(2)^{2}+7(2)-10=8$.\\n\\n(b) If $f(x)$ is continuous in $a \\\\leq x \\\\leq b$ and if $f(a)$ and $f(b)$ have opposite signs, then there is a value of $x$ between $a$ and $b$ such that $f(\\\\bar{x})=\\\\overline{0}$ (Problem 3.32).\\n\\nTo apply this theorem, we need only realize that the given polynomial is continuous in $1 \\\\leqq x \\\\leqq 2$, since we have already shown in $(a)$ that $f(1)<0$ and $f(2)>0$. Thus, there exists a number $c$ between 1 and 2 such that $f(c)=0$.\\n\\n(c) $f(1.5)=2(1.5)^{3}-3(1.5)^{2}+7(1.5)-10=0.5$. Then, applying the theorem of $(b)$ again, we see that the required root lies between 1 and 1.5 and is \"most likely\" closer to 1.5 than to 1 , since $f(1.5)=$ 0.5 has a value closer to 0 than $f(1)=-4$ (this is not always a valid conclusion but is worth pursuing in practice).\\n\\nThus, we consider $x=1.4$. Since $f(1.4)=2(1.4)^{3}-3(1.4)^{2}+7(1.4)-10=-0.592$, we conclude that there is a root between 1.4 and 1.5 which is most likely closer to 1.5 than to 1.4.\\n\\nContinuing in this manner, we find that the root is 1.46 to 2 decimal places.\\n',\n",
       " '\\n3.34. Prove Theorem 10, Page 52 .\\n\\nGiven any $\\\\epsilon>0$, we can find $x$ such that $M-f(x)<\\\\epsilon$ by definition of the 1.u.b. $M$.\\n\\nThen $\\\\frac{1}{M-f(x)}>\\\\frac{1}{\\\\varepsilon}$, so that $\\\\frac{1}{M-f(x)}$ is not bounded and, hence, cannot be continuous in view of Theorem 4, Page 52. However, if we suppose that $f(x) \\\\neq M$, then, since $M-f(x)$ is continuous, by hypothesis we must have $\\\\frac{1}{M-f(x)}$ also continuous. In view of this contradiction, we must have $f(x)=M$ for at least one value of $x$ in the interval.\\n\\nSimilarly, we can show that there exists an $x$ in the interval such that $f(x)=m$ (Problem 3.93).\\n\\n',\n",
       " '4.1. (a) Let $f(x)=\\\\frac{3+x}{3-x}, x \\\\neq 3$. Evaluate $f^{\\\\prime}(2)$ from the definition.\\n\\n$$\\nf^{\\\\prime}(2)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(2+h)-f(2)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{1}{h}\\\\left(\\\\frac{5+h}{1-h}-5\\\\right)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{1}{h} \\\\cdot \\\\frac{6 h}{1-h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{6}{1-h}=6\\n$$\\n\\nNote: By using rules of differentiation we find\\n\\n$$\\nf^{\\\\prime}(x)=\\\\frac{(3-x) \\\\frac{d}{d x}(3+x)-(3+x) \\\\frac{d}{d x}(3-x)}{(3-x)^{2}}=\\\\frac{(3-x)(1)-(3+x)(-1)}{(3-x)^{2}}=\\\\frac{6}{(3-x)^{2}}\\n$$\\n\\nat all points $x$ where the derivative exists. Putting $x=2$, we find $f^{\\\\prime}(2)=6$. Although such rules are often useful, one must be careful not to apply them indiscriminately (see Problem 4.5).\\n\\n(b) Let $f(x)=\\\\sqrt{2 x-1}$. Evaluate $f^{\\\\prime}(5)$ from the definition.\\n\\n$$\\n\\\\begin{aligned}\\nf^{\\\\prime}(5) & =\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(5+h)-f(5)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\sqrt{9+2 h}-3}{h} \\\\\\\\\\n& =\\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\sqrt{9+2 h}-3}{h} \\\\cdot \\\\frac{\\\\sqrt{9+2 h}+3}{\\\\sqrt{9+2 h}+3}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{9+2 h-9}{h(\\\\sqrt{9+2 h}+3}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{2}{\\\\sqrt{9+2 h}+3}=\\\\frac{1}{3}\\n\\\\end{aligned}\\n$$\\n\\nBy using rules of differentiation we find $f^{\\\\prime}(x)=\\\\frac{d}{d x}(2 x-1)^{1 / 2}=\\\\frac{1}{2}(2 x-1)^{-1 / 2} \\\\frac{d}{d x}(2 x-1)=$ $(2 x-1)^{-1 / 2}$. Then $f^{\\\\prime}(5)=9^{-1 / 2}=\\\\frac{1}{3}$.\\n',\n",
       " '\\n4.2. (a) Show directly from definition that the derivative of $f(x)=x^{3}$ is $3 x^{2}$.\\n\\n(b) Show from definition that $\\\\left.\\\\frac{d}{d x} \\\\sqrt{x}\\\\right)=\\\\frac{1}{2 \\\\sqrt{x}}$.\\n\\n(a) $\\\\frac{f(x+h)-f(x)}{h}=\\\\frac{1}{h}\\\\left[(x+h)^{3}-x^{3}\\\\right]$\\n\\n$$\\n\\\\left.=\\\\frac{1}{h}\\\\left[x^{3}+3 x^{2} h+3 x h^{2}+h^{2}\\\\right]-x^{3}\\\\right]=3 x^{2}+3 x h+h^{2}\\n$$\\n\\nThen\\n\\n$$\\nf^{\\\\prime}(x)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(x+h)-f(x)}{h}=3 x^{2}\\n$$\\n\\n(b) $\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(x+h)-f(x)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\sqrt{x+h}-\\\\sqrt{x}}{h}$\\n\\nThe result follows by multiplying numerator and denominator by $\\\\sqrt{x+h}-\\\\sqrt{x}$ and then letting $h \\\\rightarrow 0$.\\n',\n",
       " '\\n4.3. If $f(x)$ has a derivative at $x=x_{0}$, prove that $f(x)$ must be continuous at $x=x_{0}$.\\n\\n$$\\nf\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)=\\\\frac{f\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)}{h} \\\\cdot h, \\\\quad h \\\\neq 0\\n$$\\n\\nThen\\n\\n$$\\n\\\\lim _{h \\\\rightarrow 0} f\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)}{h} \\\\cdot \\\\lim _{h \\\\rightarrow 0} h=f^{\\\\prime}\\\\left(x_{0}\\\\right) \\\\cdot 0=0\\n$$\\n\\nsince $f^{\\\\prime}\\\\left(x_{0}\\\\right)$ exists by hypothesis. Thus,\\n\\n$$\\n\\\\lim _{h \\\\rightarrow 0} f\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)=0 \\\\quad \\\\text { or } \\\\quad \\\\lim _{h \\\\rightarrow 0} f\\\\left(x_{0}+h\\\\right)=f\\\\left(x_{0}\\\\right)\\n$$\\n\\nshowing that $f(x)$ is continuous at $x=x_{0}$.\\n',\n",
       " '\\n4.4. Let $f(x)=\\\\left\\\\{\\\\begin{array}{ll}x \\\\sin 1 / x, & x \\\\neq 0 \\\\\\\\ 0, & x=0\\\\end{array}\\\\right.$.\\n\\n(a) Is $f(x)$ continuous at $x=0$ ? (b) Does $f(x)$ have a derivative at $x=0$ ?\\n\\n(a) By Problem 3.22(b), $f(x)$ is continuous at $x=0$.\\n\\n(b) $f^{\\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(0+h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{h \\\\sin 1 / h-0}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\sin \\\\frac{1}{h}$\\n\\nwhich does not exist.\\n\\nThis example shows that even though a function is continuous at a point, it need not have a derivative at the point; i.e., the converse of the theorem in Problem 4.3 is not necessarily true.\\n\\nIt is possible to construct a function which is continuous at every point of an interval but has a derivative nowhere.\\n',\n",
       " '\\n4.5. Let $f(x)=\\\\left\\\\{\\\\begin{array}{ll}x^{2} \\\\sin 1 / x, & x \\\\neq 0 \\\\\\\\ 0, & x=0\\\\end{array}\\\\right.$.\\n\\n(a) Is $f(x)$ differentiable at $x=0$ ? (b) Is $f^{\\\\prime}(x)$ continuous at $x=0$ ?\\n\\n(a) $\\\\quad f^{\\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{h^{2} \\\\sin 1 / h-0}{h}=\\\\lim _{h \\\\rightarrow 0} h \\\\sin \\\\frac{1}{h}=0$\\n\\nby Problem 3.13. Then $f(x)$ has a derivative (is differentiable) at $x=0$ and its value is 0 .\\n\\n(b) From elementary calculus differentiation rules, if $x \\\\neq 0$,\\n\\n$$\\n\\\\begin{aligned}\\nf^{\\\\prime}(x) & =\\\\frac{d}{d x}\\\\left(x^{2} \\\\sin \\\\frac{1}{x}\\\\right)=x^{2} \\\\frac{d}{d x}\\\\left(\\\\sin \\\\frac{1}{x}\\\\right)+\\\\left(\\\\sin \\\\frac{1}{x}\\\\right) \\\\frac{d}{d x}\\\\left(x^{2}\\\\right) \\\\\\\\\\n& =x^{2}\\\\left(\\\\cos \\\\frac{1}{x}\\\\right)\\\\left(-\\\\frac{1}{x^{2}}\\\\right)+\\\\left(\\\\sin \\\\frac{1}{x}\\\\right)(2 x)=-\\\\cos \\\\frac{1}{x}+2 x \\\\sin \\\\frac{1}{x}\\n\\\\end{aligned}\\n$$\\n\\nSince $\\\\lim _{x \\\\rightarrow 0} f^{\\\\prime}(x)=\\\\lim _{x \\\\rightarrow 0}\\\\left(-\\\\cos \\\\frac{1}{x}+2 x \\\\sin \\\\frac{1}{x}\\\\right)$ does not exist (because $\\\\lim _{x \\\\rightarrow 0} \\\\cos 1 / x$ does not exist). $f^{\\\\prime}(x)$ cannot be continuous at $x=0$ in spite of the fact that $f^{\\\\prime}(0)$ exists.\\n\\nThis shows that we cannot calculate $f^{\\\\prime}(0)$ in this case by simply calculating $f^{\\\\prime}(x)$ and and putting $x=0$, as is frequently supposed in elementary calculus. It is only when the derivative of a function is continuous at a point that this procedure gives the right answer. This happens to be true for most functions arising in elementary calculus.\\n',\n",
       " '\\n4.6. Present an \" $\\\\epsilon, \\\\delta$ \" definition of the derivative of $f(x)$ at $x=x_{0}$.\\n\\n$f(x)$ has a derivative $f^{\\\\prime}\\\\left(x_{0}\\\\right)$ at $x=x_{0}$ if, given any $\\\\epsilon>0$, we can find $\\\\delta>0$ such that\\n\\n$$\\n\\\\left|\\\\frac{f\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)}{h}-f^{\\\\prime}\\\\left(x_{0}\\\\right)\\\\right|<\\\\varepsilon \\\\quad \\\\text { when } \\\\quad 0<|h|<\\\\delta\\n$$\\n\\n\\n\\\\section*{Right- and left-hand derivatives}\\n',\n",
       " '4.7. Let $f(x)=|x|$. (a) Calculate the right-hand derivatives of $f(x)$ at $x=0$. (b) Calculate the left-hand derivative of $f(x)$ at $x=0$. (c) Does $f(x)$ have a derivative at $x=0$ ? (d) Illustrate the conclusions in (a), (b), and (c) from a graph.\\n\\n(a) $f_{+}^{\\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{f(h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{|h|-0}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{h}{h}=1$\\n\\nsince $|h|=-h$ for $h>0$.\\n\\n(b) $f_{-}^{\\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0-} \\\\frac{f(h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0-} \\\\frac{|h|-0}{h}=\\\\lim _{h \\\\rightarrow 0-} \\\\frac{-h}{h}=-1$\\n\\nsince $|h|=-h$ for $h<0$.\\n\\n(c) No. The derivative at 0 does not exist if the right- and lefthand derivatives are unequal.\\n\\n(d) The required graph is shown in Figure 4.8. Note that the slopes of the lines $y=x$ and $y=-x$ are 1 and -1 , respectively, representing the right- and left-hand derivatives at $x=0$. However, the derivative at $x=0$ does not exist.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-094}\\n\\\\end{center}\\n\\nFigure 4.8\\n',\n",
       " '\\n4.8. Prove that $f(x)=x^{2}$ is differentiable in $0 \\\\leqq x \\\\leqq 1$.\\n\\nLet $x_{0}$ be any value such that $0<x_{0}<1$. Then\\n\\n$$\\nf^{\\\\prime}\\\\left(x_{0}\\\\right)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f\\\\left(x_{0}+h\\\\right)-f\\\\left(x_{0}\\\\right)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\left(x_{0}+h\\\\right)^{2}-x_{0}^{2}}{h}=\\\\lim _{h \\\\rightarrow 0}\\\\left(2 x_{0}+h\\\\right)=2 x_{0}\\n$$\\n\\nAt the endpoint $x=0$,\\n\\n$$\\nf_{+}^{\\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{f(0+h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{h^{2}-0}{h}=\\\\lim _{h \\\\rightarrow 0+} h=0\\n$$\\n\\nAt the end point $x=1$,\\n\\n$$\\nf_{-}^{\\\\prime}(1)=\\\\lim _{h \\\\rightarrow 0-} \\\\frac{f(1+h)-f(1)}{h}=\\\\lim _{h \\\\rightarrow 0-} \\\\frac{(1+h)^{2}-1}{h}=\\\\lim _{h \\\\rightarrow 0-}(2+h)=2\\n$$\\n\\nThen $f(x)$ is differentiable in $0 \\\\leqq x \\\\leqq 1$. We may write $f^{\\\\prime}(x)=2 x$ for any $x$ in this interval. It is customary to write $f_{+}^{\\\\prime}(0)=f^{\\\\prime}(0)$ and $f_{-}^{\\\\prime}(1)=f^{\\\\prime}(1)$ in this case.\\n',\n",
       " '\\n4.9. Find an equation for the tangent line to $y=x^{2}$ at the point where (a) $x=1 / 3$ and (b) $x=1$.\\n\\n(a) From Problem 4.8. $f^{\\\\prime}\\\\left(x_{0}\\\\right)=2 x_{0}$ so that $f^{\\\\prime}(1 / 3)=2 / 3$. Then the equation of the tangent line is\\n\\n$$\\ny-f\\\\left(x_{0}\\\\right)=f\\\\left(x_{0}\\\\right)\\\\left(x-x_{0}\\\\right) \\\\quad \\\\text { or } \\\\quad y-\\\\frac{1}{9}=\\\\frac{2}{3}\\\\left(x-\\\\frac{1}{3}\\\\right) \\\\text {. i.e., } \\\\mathrm{y}=\\\\frac{2}{3} x-\\\\frac{1}{9}\\n$$\\n\\n(b) As in part $(a), y-f(1)=f^{\\\\prime}(1)(x-1)$ or $y-1=2(x-1)$, i.e., $y=2 x-1$.\\n\\n\\n\\\\section*{Differentials}\\n',\n",
       " '4.10. If $y=f(x)=x^{3}-6 x$, find (a) $\\\\Delta y$, (b) $d y$, and (c) $\\\\Delta y-d y$.\\n\\n(a) $\\\\Delta y=f(x+\\\\Delta x)-f(x)=\\\\left\\\\{(x+\\\\Delta x)^{3}-6(x+\\\\Delta x)\\\\right\\\\}-\\\\left\\\\{x^{3}-6 x\\\\right\\\\}$\\n\\n$$\\n\\\\begin{aligned}\\n& =x^{3}+3 x^{2} \\\\Delta x+3 x(\\\\Delta x)^{2}+(\\\\Delta x)^{3}-6 x-6 \\\\Delta x-x^{3}+6 x \\\\\\\\\\n& =\\\\left(3 x^{2}-6\\\\right) \\\\Delta x+3 x(\\\\Delta x)^{2}+(\\\\Delta x)^{3}\\n\\\\end{aligned}\\n$$\\n\\n(b) $d y=$ principal part of $\\\\Delta y=\\\\left(3 x^{2}-6\\\\right) \\\\Delta x=\\\\left(3 x^{2}-6\\\\right) d x$, since by definition $\\\\Delta x=d x$.\\n\\nNote that $f^{\\\\prime}(x)=3 x^{2}-6$ and $d y=\\\\left(3 x^{2}-6\\\\right) d x$, i.e.; $d y / d x=3 x^{2}-6$. It must be emphasized that $d y$ and $d x$ are not necessarily small.\\n\\n(c) From (a) and (b), $\\\\Delta y-d y=3 x(\\\\Delta x)^{2}+(\\\\Delta x)^{3}=\\\\epsilon \\\\Delta x$, where $\\\\epsilon=3 x \\\\Delta x+(\\\\Delta x)^{2}$.\\n\\nNote that $\\\\epsilon \\\\rightarrow 0$ as $\\\\Delta x \\\\rightarrow 0$; i.e., $\\\\frac{\\\\Delta y-d y}{\\\\Delta x} \\\\rightarrow 0$ as $\\\\Delta x \\\\rightarrow 0$. Hence, $\\\\Delta y-d y$ is an infinitesimal of higher order than $\\\\Delta x$ (see Problem 4.83).\\n\\nIn case $\\\\Delta x$ is small, $d y$ and $\\\\Delta y$ are approximately equal.\\n',\n",
       " '\\n4.11. Evaluate $\\\\sqrt[3]{25}$ approximately by use of differentials.\\n\\nIf $\\\\Delta x$ is small, $\\\\Delta y=f(x+\\\\Delta x)-f(x)=f^{\\\\prime}(x) \\\\Delta x$ approximately.\\n\\nLet $f(x)=\\\\sqrt[3]{x}$. Then $\\\\sqrt[3]{x+\\\\Delta x}-\\\\sqrt[3]{x} \\\\approx \\\\frac{1}{3} x^{-2 / 3} \\\\Delta x$ (where $\\\\approx$ denotes approximately equal to).\\n\\nIf $x=27$ and $\\\\Delta x=-2$, we have\\n\\n$$\\n\\\\sqrt[3]{27-2}-\\\\sqrt[3]{27} \\\\approx \\\\frac{1}{3}(27)^{-2 / 3}(-2), \\\\quad \\\\text { i.e., } \\\\sqrt[3]{25}-3 \\\\approx-2 / 27\\n$$\\n\\nThen $\\\\sqrt[3]{25} \\\\approx 3-2 / 27$ or 2.926 .\\n\\nIt is interesting to observe that $(2.926)^{3}=25.05$, so the approximation is fairly good.\\n\\n\\n\\\\section*{Differentiation rules: differentiation of elementary functions}\\n',\n",
       " '4.12. Prove the formula $\\\\frac{d}{d x}\\\\{f(x) g(x)\\\\}=f(x) \\\\frac{d}{d x} g(x)+g(x) \\\\frac{d}{d x} f(x)$, assuming $f$ and $g$ are differentiable. By definition,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{d}{d x}\\\\{f(x) g(x)\\\\} & =\\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{f(x+\\\\Delta x) g(x+\\\\Delta x)-f(x) g(x)}{\\\\Delta x} \\\\\\\\\\n& =\\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{f(x+\\\\Delta x)\\\\{g(x+\\\\Delta x)-g(x)\\\\}+g(x)\\\\{f(x+\\\\Delta x)-f(x)\\\\}}{\\\\Delta x} \\\\\\\\\\n& =\\\\lim _{\\\\Delta x \\\\rightarrow 0} f(x+\\\\Delta x)\\\\left\\\\{\\\\frac{g(x+\\\\Delta x)-g(x)}{\\\\Delta x}\\\\right\\\\}+\\\\lim _{\\\\Delta x \\\\rightarrow 0} g(x)\\\\left\\\\{\\\\frac{f(x+\\\\Delta x)-f(x)}{\\\\Delta x}\\\\right\\\\} \\\\\\\\\\n& =f(x) \\\\frac{d}{d x} g(x)+g(x) \\\\frac{d}{d x} f(x)\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Another method:}\\nLet $u=f(x), v=g(x)$. Then $\\\\Delta u=f(x+\\\\Delta x)-f(x)$ and $\\\\Delta v=g(x+\\\\Delta x)-g(x)$; i.e., $f(x+\\\\Delta x)=u+\\\\Delta u$, $g(x+\\\\Delta x)=v+\\\\Delta v$. Thus,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{d}{d x} u v & =\\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{(u+\\\\Delta u)(v+\\\\Delta v)-w}{\\\\Delta x}=\\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{u \\\\Delta v+v \\\\Delta u+\\\\Delta u \\\\Delta v}{\\\\Delta x} \\\\\\\\\\n& =\\\\lim _{\\\\Delta x \\\\rightarrow 0}\\\\left(u \\\\frac{\\\\Delta v}{\\\\Delta x}+v \\\\frac{\\\\Delta u}{\\\\Delta x}+\\\\frac{\\\\Delta u}{\\\\Delta x} \\\\Delta v\\\\right)=u \\\\frac{d v}{d x}+v \\\\frac{d u}{d x}\\n\\\\end{aligned}\\n$$\\n\\nwhere it is noted that $\\\\Delta v \\\\rightarrow 0$ as $\\\\Delta x \\\\rightarrow 0$, since $v$ is supposed differentiable and thus continuous.\\n',\n",
       " '\\n4.13. If $y=f(u)$ where $u=g(x)$, prove that $\\\\frac{d y}{d x}=\\\\frac{d y}{d u} \\\\cdot \\\\frac{d u}{d x}$, assuming that $f$ and $g$ are differentiable.\\n\\nLet $x$ be given an increment $\\\\Delta x \\\\neq 0$. Then, as a consequence, $u$ and $y$ take on increments $\\\\Delta u$ and $\\\\Delta y$, respectively, where\\n\\n\\n\\\\begin{equation*}\\n\\\\Delta y=f(u+\\\\Delta u)-f(u), \\\\quad \\\\Delta u=g(x+\\\\Delta x)-g(x) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nNote that as $\\\\Delta x \\\\rightarrow 0, \\\\Delta y \\\\rightarrow 0$ and $\\\\Delta u \\\\rightarrow 0$.\\n\\nIf $\\\\Delta u \\\\neq 0$, let us write $\\\\in=\\\\frac{\\\\Delta y}{\\\\Delta u}-\\\\frac{d y}{d u}$ so that $\\\\epsilon \\\\rightarrow 0$ as $\\\\Delta u \\\\rightarrow 0$ and\\n\\n\\n\\\\begin{equation*}\\n\\\\Delta y=\\\\frac{d y}{d u} \\\\Delta u+\\\\in \\\\Delta u \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nIf $\\\\Delta u=0$ for values of $\\\\Delta x$, then Equation (1) shows that $\\\\Delta y=0$ for these values of $\\\\Delta x$. For such cases, we define $\\\\epsilon=0$.\\n\\nIt follows that in both cases. $\\\\Delta u \\\\neq 0$ or $\\\\Delta u=0$, Equation (2) holds. Dividing Equation (2) by $\\\\Delta x \\\\neq 0$ and taking the limit as $\\\\Delta x \\\\rightarrow 0$, we have\\n\\n\\n\\\\begin{align*}\\n\\\\frac{d y}{d x} & =\\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{\\\\Delta y}{\\\\Delta x}=\\\\lim _{\\\\Delta x \\\\rightarrow 0}\\\\left(\\\\frac{d y}{d u} \\\\frac{\\\\Delta u}{\\\\Delta x}+\\\\in \\\\frac{\\\\Delta u}{\\\\Delta x}\\\\right)=\\\\frac{d y}{d u} \\\\cdot \\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{\\\\Delta u}{\\\\Delta x}+\\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\in \\\\cdot \\\\lim _{\\\\Delta x \\\\rightarrow 0} \\\\frac{\\\\Delta u}{\\\\Delta x}  \\\\tag{3}\\\\\\\\\\n& =\\\\frac{d y}{d u} \\\\frac{d u}{d x}+0 \\\\cdot \\\\frac{d u}{d x} \\\\frac{d y}{d u} \\\\cdot \\\\frac{d u}{d x}\\n\\\\end{align*}\\n',\n",
       " '\\n\\n4.14. Given $\\\\frac{d}{d x}(\\\\sin x)=\\\\cos x$ and $\\\\frac{d}{d x}(\\\\cos x)=-\\\\sin x$, derive the following formulas:\\\\\\\\\\n(a) $\\\\frac{d}{d x}(\\\\tan x)=\\\\sec ^{2} x$\\\\\\\\\\n(b) $\\\\frac{d}{d x}\\\\left(\\\\sin ^{-1} x\\\\right)=\\\\frac{1}{\\\\sqrt{1-x^{2}}}$\\\\\\\\\\n(a) $\\\\frac{d}{d x}(\\\\tan x)=\\\\frac{d}{d x}\\\\left(\\\\frac{\\\\sin x}{\\\\cos x}\\\\right)=\\\\frac{\\\\cos x \\\\frac{d}{d x}(\\\\sin x)-\\\\sin x \\\\frac{d}{d x}}{\\\\cos ^{2} x}$\\n\\n$$\\n=\\\\frac{(\\\\cos x)(\\\\cos x)-(\\\\sin x)(-\\\\sin x)}{\\\\cos ^{2} x}=\\\\frac{1}{\\\\cos ^{2} x}={ }^{2} x\\n$$\\n\\n(b) If $y=\\\\sin ^{-1} x$, then $x=\\\\sin y$. Taking the derivative with respect to $x$,\\n\\n$$\\n1=\\\\cos y \\\\frac{d y}{d x} \\\\quad \\\\text { or } \\\\quad \\\\frac{d y}{d x}=\\\\frac{1}{\\\\cos y}=\\\\frac{1}{\\\\sqrt{1-\\\\sin ^{2} y}}=\\\\frac{1}{\\\\sqrt{1-x^{2}}}\\n$$\\n\\nWe have supposed here that the principal value $-\\\\pi / 2 \\\\leqq \\\\sin ^{-1} x \\\\leqq \\\\pi / 2$ is chosen so that $\\\\cos y$ is positive, thus accounting for our writing $\\\\cos y=\\\\sqrt{1-\\\\sin ^{2} y}$ rather than $\\\\cos y= \\\\pm \\\\sqrt{1-\\\\sin ^{2} y}$.\\n',\n",
       " '\\n4.15. Derive the formula $\\\\frac{d}{d x}\\\\left(\\\\log _{a} u\\\\right)=\\\\frac{\\\\log _{a} e}{u} \\\\frac{d u}{d x}(a>0, a \\\\neq 1)$, where $u$ is a differentiable function of $x$.\\n\\nConsider $y=f(u)=\\\\log _{a} u$. By definition,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{d y}{d u} & =\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{f(u+\\\\Delta u)-f(u)}{\\\\Delta u}=\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{\\\\log _{a}(u+\\\\Delta u)-\\\\log _{a} u}{\\\\Delta u} \\\\\\\\\\n& =\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{1}{\\\\Delta u} \\\\log _{a}\\\\left(\\\\frac{u+\\\\Delta u}{u}\\\\right)=\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{1}{u} \\\\log _{a}\\\\left(1+\\\\frac{\\\\Delta u}{u}\\\\right)^{u / \\\\Delta u}\\n\\\\end{aligned}\\n$$\\n\\nSince the logarithm is a continuous function, this can be written\\n\\n$$\\n\\\\frac{1}{u} \\\\log _{a}\\\\left\\\\{\\\\lim _{\\\\Delta u \\\\rightarrow 0}\\\\left(1+\\\\frac{\\\\Delta u}{u}\\\\right)^{u / \\\\Delta u}\\\\right\\\\}=\\\\frac{1}{u} \\\\log _{a} e\\n$$\\n\\nby Problem 2.19, with $x=u / \\\\Delta u$.\\n\\nThen by Problem 4.13, $\\\\frac{d}{d x}\\\\left(\\\\log _{a} u\\\\right)=\\\\frac{\\\\log _{a} e}{u} \\\\frac{d u}{d x}$.\\n',\n",
       " '\\n4.16. Calculate $d y / d x$ if (a) $x y^{3}-3 x^{2}=x y+5$ and (b) $e^{x y}+y \\\\ln x=\\\\cos 2 x$.\\n\\n(a) Differentiate with respect to $x$, considering $y$ as a function of $x$. (We sometimes say that $y$ is an implicit function of $x$, since we cannot solve explicitly for $y$ in terms of $x$.) Then\\n\\n$\\\\frac{d}{d x}(x y)^{2}-\\\\frac{d}{d x}\\\\left(3 x^{2}\\\\right)=\\\\frac{d}{d x}(x y)+\\\\frac{d}{d x}(5) \\\\quad$ or $\\\\quad(x)\\\\left(3 y^{2} y^{\\\\prime}\\\\right)+\\\\left(y^{3}\\\\right)(1)-6 x=(x)\\\\left(y^{\\\\prime}\\\\right)+(y)(1)+0$\\n\\nwhere $y^{\\\\prime}=d y / d x$. Solving,\\n\\n$$\\ny^{\\\\prime}=\\\\left(6 x-y^{3}+y\\\\right) /\\\\left(3 x y^{2}-x\\\\right)\\n$$\\n\\n(b) $\\\\frac{d}{d x}\\\\left(e^{x y}\\\\right)+\\\\frac{d}{d x}(u \\\\operatorname{In})=\\\\frac{d}{d x}(\\\\cos 2 x) . \\\\quad e^{x y}\\\\left(x y^{\\\\prime}+y\\\\right)+\\\\frac{y}{x}+(\\\\operatorname{In} x) y^{\\\\prime}=-2 \\\\sin 2 x$.\\n\\nSolving,\\n\\n$$\\ny^{\\\\prime}=-\\\\frac{2 x \\\\sin 2 x+x y e^{x y}+y}{x^{2} e^{x y}+x \\\\operatorname{In} x}\\n$$\\n',\n",
       " '\\n4.17. If $y=\\\\cosh \\\\left(x^{2}-3 x+1\\\\right)$, find (a) $d y / d x$ and (b) $d^{2} y / d x^{2}$.\\n\\n(a) Let $y=\\\\cosh u$, where $u=x^{2}-3 x+1$. Then $d y / d x=\\\\sinh u, d u / d x=2 x-3$, and\\n\\n$$\\n\\\\frac{d y}{d x}=\\\\frac{d y}{d u} \\\\cdot \\\\frac{d u}{d x}=(\\\\sinh u)(2 x-3)=(2 x-3) \\\\sinh \\\\left(x^{2}-3 x+1\\\\right)\\n$$\\n\\n(b) $\\\\frac{d^{2} y}{d x^{2}}=\\\\frac{d}{d x}\\\\left(\\\\frac{d y}{d x}\\\\right)=\\\\frac{d}{d x}\\\\left(\\\\sinh u \\\\frac{d u}{d x}\\\\right)=\\\\sinh u \\\\frac{d^{2} u}{d x^{2}}+\\\\cosh u\\\\left(\\\\frac{d u}{d x}\\\\right)^{2}$\\n\\n$$\\n=(\\\\sinh u)(2)+(\\\\cosh u)(2 x-3)^{2}=2 \\\\sinh \\\\left(x^{2}-3 x+1\\\\right)+(2 x-3)^{2} \\\\cosh \\\\left(x^{2}-3 x+1\\\\right)\\n$$\\n',\n",
       " '\\n4.18. If $x^{2} y+y^{3}=2$, find (a) $y^{\\\\prime}$ and (b) $y^{\\\\prime \\\\prime}$ at the point $(1,1)$.\\n\\n(a) Differentiating with respect to $x, x^{2} y^{\\\\prime}+2 x y+3 y^{2} y^{\\\\prime}=0$ and\\n\\n$$\\ny^{\\\\prime}=\\\\frac{-2 x y}{x^{2}+3 x y^{2}}=-\\\\frac{1}{2} \\\\text { at }(1,1)\\n$$\\n\\n(b) $y^{\\\\prime \\\\prime}=\\\\frac{d}{d x}\\\\left(y^{\\\\prime}\\\\right)=\\\\frac{d}{d x}\\\\left(\\\\frac{-2 x y}{x^{2}+3 y^{2}}\\\\right)=-\\\\frac{\\\\left(x^{2}+3 y^{2}\\\\right)\\\\left(2 x y^{\\\\prime}+2 y\\\\right)-(2 x y)\\\\left(2 x+6 y y^{\\\\prime}\\\\right)}{\\\\left(x^{2}+3 y^{2}\\\\right)^{2}}$\\n\\nSubstituting $x=1, y=1$, and $y^{\\\\prime}=-\\\\frac{1}{2}$, we find $y^{\\\\prime \\\\prime}=-\\\\frac{3}{8}$.\\n\\n\\n\\\\section*{Mean value theorems}\\n',\n",
       " \"4.19. Prove Rolle's theorem.\\n\\nCase 1: $f(x) \\\\equiv 0$ in $[a, b]$. Then $f^{\\\\prime}(x)=0$ for all $x$ in $(a, b)$.\\n\\nCase 2: $f(x) \\\\not \\\\equiv 0$ in $[a, b]$. Since $f(x)$ is continuous, there are points at which $f(x)$ attains its maximum and minimum values, denoted by $M$ and $m$, respectively (see Problem 3.34).\\n\\nSince $f(x) \\\\not \\\\equiv 0$, at least one of the values $M, m$ is not zero. Suppose, for example, $M \\\\not \\\\equiv 0$ and that $f(\\\\xi)=$ $M$ (see Figure 4.9). For this case, $f(\\\\xi+h) \\\\leqq f(\\\\xi)$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-098}\\n\\\\end{center}\\n\\nFigure 4.9\\n\\nIf $h>0$, then $\\\\frac{f(\\\\xi+h)-f(\\\\xi)}{h} \\\\leqq 0$ and\\n\\n\\n\\\\begin{equation*}\\n\\\\lim _{h \\\\rightarrow 0+} \\\\frac{f(\\\\xi+h)-f(\\\\xi)}{h} \\\\leqq 0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf $h<0$, then $\\\\frac{f(\\\\xi+h)-f(\\\\xi)}{h} \\\\geqq 0$ and\\n\\n\\n\\\\begin{equation*}\\n\\\\lim _{h \\\\rightarrow 0-} \\\\frac{f(\\\\xi+h)-f(\\\\xi)}{h} \\\\geq 0 \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nBut, by hypothesis, $f(x)$ has a derivative at all points in $(a, b)$. Then the right-hand derivative (1) must be equal to the left-hand derivative (2). This can happen only if they are both equal to zero, in which case $f^{\\\\prime}(\\\\xi)=0$ as required.\\n\\nA similar argument can be used in case $M=0$ and $m \\\\neq 0$.\\n\",\n",
       " \"\\n4.20. Prove the mean value theorem.\\n\\nDefine $F(x)=f(x)-f(a)-(x-a) \\\\frac{f(b)-f(a)}{b-a}$.\\\\\\\\\\nThen $f(a)=0$ and $f(b)=0$.\\n\\nAlso, if $f(x)$ satisfies the conditions on continuity and differentiability specified in Rolle's theorem, then $F(x)$ satisfies them also.\\n\\nThen, applying Rolle's theorem to the function $F(x)$, we obtain\\n\\n$$\\nF^{\\\\prime}(\\\\xi)=f^{\\\\prime}(\\\\xi)-\\\\frac{f(b)-f(a)}{b-a}=0, \\\\quad a<\\\\xi<b \\\\quad \\\\text { or } \\\\quad f^{\\\\prime}(\\\\xi)=\\\\frac{f(b)-f(a)}{b-a}, \\\\quad a<\\\\xi<b\\n$$\\n\",\n",
       " '\\n4.21. Verify the mean value theorem for $f(x)=2 x^{2}-7 x+10, a=2, b=5$.\\n\\n$f(2)=4, f(5)=25, f^{\\\\prime}(\\\\xi)=4 \\\\xi-7$. Then the mean value theorem states that $4 \\\\xi-7=(25-4) /(5-2)$ or $\\\\xi=$ 3.5. Since $2<\\\\xi<5$, the theorem is verified.\\n',\n",
       " '\\n4.22. If $f^{\\\\prime}(x)=0$ at all points of the interval $(a, b)$, prove that $f(x)$ must be a constant in the interval.\\n\\nLet $x_{1}<x_{2}$ be any two different points in $(a, b)$. By the mean value theorem for $x_{1}<\\\\xi<x_{2}$,\\n\\n$$\\n\\\\frac{f\\\\left(x^{2}\\\\right)-f\\\\left(x_{1}\\\\right)}{x^{2}-x^{2}}=f^{\\\\prime}(\\\\xi)=0\\n$$\\n\\nThus $f\\\\left(x_{1}\\\\right)=f\\\\left(x_{2}\\\\right)=$ constant. From this it follows that if two functions have the same derivative at all points of $(a, b)$, the functions can differ only by a constant.\\n',\n",
       " '\\n4.23. If $f^{\\\\prime}(x)>0$ at all points of the interval $(a, b)$, prove that $f(x)$ is strictly increasing.\\n\\nLet $x_{1}<x_{2}$ be any two different points in $(a, b)$. By the mean value theorem for $x_{1}<\\\\xi<x_{2}$,\\n\\n$$\\n\\\\frac{f\\\\left(x_{2}\\\\right)-f\\\\left(x_{1}\\\\right)}{x_{2}-x_{1}}=f^{\\\\prime}(\\\\xi)>0\\n$$\\n\\nThen $f\\\\left(x_{2}\\\\right)>f\\\\left(x_{1}\\\\right)$ for $x_{2}>x_{1}$, and so $f(x)$ is strictly increasing.\\n',\n",
       " '\\n4.24.\\n\\n(a) Pr ove that $\\\\frac{b-a}{1+b^{2}}<\\\\tan ^{-1} b-\\\\tan ^{-1} a<\\\\frac{b-a}{1+a^{2}}$ if $a<b$.\\n\\n(b) Show that $\\\\frac{\\\\pi}{4}+\\\\frac{3}{25}<\\\\tan ^{-1} \\\\frac{4}{3}<\\\\frac{\\\\pi}{4}+\\\\frac{1}{6}$.\\n\\n(a) Let $f(x)=\\\\tan ^{-1} x$. Since $f^{\\\\prime}(x)=1 /\\\\left(1+x^{2}\\\\right)$ and $f^{\\\\prime}(\\\\xi)=1 /\\\\left(1+\\\\xi^{2}\\\\right)$, we have by the mean value theorem\\n\\n$$\\n\\\\frac{\\\\tan ^{-1} b-\\\\tan ^{-1} a}{b-a}=\\\\frac{1}{1+\\\\xi^{2}} \\\\quad a<\\\\xi<b\\n$$\\n\\nSince $\\\\xi>a, 1 /\\\\left(1+\\\\xi^{2}\\\\right)<1 /\\\\left(1+a^{2}\\\\right)$. Since $\\\\xi<b, 1 /\\\\left(1+\\\\xi^{2}\\\\right)>1 /\\\\left(1+b^{2}\\\\right)$. Then\\n\\n$$\\n\\\\frac{1}{1+b^{2}}<\\\\frac{\\\\tan ^{-1} b-\\\\tan ^{-1} a}{b-a}<\\\\frac{1}{1+a^{2}}\\n$$\\n\\nand the required result follows on multiplying by $b-a$.\\n\\n(b) Let $b=4 / 3$ and $a=1$ in the result of (a). Then, since $\\\\tan ^{+} 1=\\\\pi / 4$, we have\\n\\n$$\\n\\\\frac{3}{25}<\\\\tan ^{-1} \\\\frac{4}{3}-\\\\tan ^{-1} 1<\\\\frac{1}{6} \\\\quad \\\\text { or } \\\\quad \\\\frac{\\\\pi}{4}+\\\\frac{3}{25}<\\\\tan ^{-1} \\\\frac{4}{3}<\\\\frac{\\\\pi}{4}+\\\\frac{1}{6}\\n$$\\n',\n",
       " \"\\n4.25. Prove Cauchy's generalized mean value theorem.\\n\\nConsider $G(x)=f(x)-f(a)-\\\\alpha\\\\{g(x)-g(a)\\\\}$, where $\\\\alpha$ is a constant. Then $G(x)$ satisfies the conditions of Rolle's theorem, provided $f(x)$ and $g(x)$ satisfy the continuity and differentiability conditions of Rolle's theorem and if $G(a)=G(b)=0$. Both latter conditions are satisfied if the constant $\\\\alpha=\\\\frac{f(b)-f(a)}{g(b)-g(a)}$.\\n\\nApplying Rolle's theorem, $G^{\\\\prime}(\\\\xi)=0$ for $a<\\\\xi<b$, we have\\n\\n$$\\nf^{\\\\prime}(\\\\xi)-a g^{\\\\prime}(\\\\xi)=0 \\\\quad \\\\text { or } \\\\quad \\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(\\\\xi)}=\\\\frac{f(b)-f(a)}{g(b)-g(a)}, \\\\quad a<\\\\xi<b\\n$$\\n\\nas required.\\n\\n\\n\\\\section*{L'Hospital's rule}\\n\",\n",
       " '4.26. Prove L\\'Hospital\\'s rule for the case of the \"indeterminate forms\" (a) $0 / 0$ and (b) $\\\\infty / \\\\infty$.\\n\\n(a) We shall suppose that $f(x)$ and $g(x)$ are differentiable in $a<x<b$ and $f\\\\left(x_{0}\\\\right)=0, g\\\\left(x_{0}\\\\right)=0$, where $a<x_{0}<b$.\\n\\nBy Cauchy\\'s generalized mean value theorem (Problem 4.25),\\n\\n$$\\n\\\\frac{f(x)}{g(x)}=\\\\frac{f(x)-f\\\\left(x_{0}\\\\right)}{g(x)-g\\\\left(x_{0}\\\\right)}=\\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(\\\\xi)} \\\\quad x_{0}<\\\\xi<x\\n$$\\n\\nThen\\n\\n$$\\n\\\\lim _{x \\\\rightarrow x_{0}+} \\\\frac{f(x)}{g(x)}=\\\\lim _{x \\\\rightarrow x_{0}+} \\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(\\\\xi)}=\\\\lim _{x \\\\rightarrow x_{0}+} \\\\frac{f^{\\\\prime}(x)}{g^{\\\\prime}(x)}=L\\n$$\\n\\nsince as $x \\\\rightarrow x_{0}+, \\\\xi \\\\rightarrow x_{0}+$.\\n\\nModification of this procedure can be used to establish the result if $x \\\\rightarrow x_{0}-, x \\\\rightarrow x_{0}, x \\\\rightarrow \\\\infty$, or $x \\\\rightarrow-\\\\infty$.\\n\\n(b) We suppose that $f(x)$ and $g(x)$ are differentiable in $a<x<b$, and $\\\\lim _{x \\\\rightarrow x_{0}+} f(x)=\\\\infty, \\\\lim _{x \\\\rightarrow x_{0}+} g(x)=\\\\infty$ where\\\\\\\\\\n$a<x_{0}<b$.\\n\\nAssume $x_{1}$ is such that $a<x_{0}<x<x_{1}<b$. By Cauchy\\'s generalized mean value theorem,\\n\\n$$\\n\\\\frac{f(x)-f\\\\left(x_{1}\\\\right)}{g(x)-g\\\\left(x_{1}\\\\right)}=\\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(\\\\xi)} \\\\quad x<\\\\xi<x_{1}\\n$$\\n\\nHence,\\n\\n$$\\n\\\\frac{f(x)-f\\\\left(x_{1}\\\\right)}{g(x)-g\\\\left(x_{1}\\\\right)}=\\\\frac{f(x)}{g(x)} \\\\cdot \\\\frac{1-f\\\\left(x_{1}\\\\right) / f(x)}{1-g\\\\left(x_{1}\\\\right) / g(x)}=\\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(\\\\xi)}\\n$$\\n\\nfrom which we see that\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{f(x)}{g(x)}=\\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(\\\\xi)} \\\\cdot \\\\frac{1-g\\\\left(x_{1}\\\\right) / g(x)}{1-f\\\\left(x_{1}\\\\right) / f(x)} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nLet us now suppose that $\\\\lim _{x \\\\rightarrow x_{0}+} \\\\frac{f^{\\\\prime}(x)}{g^{\\\\prime}(x)}=L$ and write Equation (1) as\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{f(x)}{g(x)}=\\\\left(\\\\frac{f^{\\\\prime}(\\\\xi)}{g^{\\\\prime}(x)}-L\\\\right)\\\\left(\\\\frac{1-g\\\\left(x_{1}\\\\right) / g(x)}{1-f\\\\left(x_{1}\\\\right) / f(x)}\\\\right)+L\\\\left(\\\\frac{1-g\\\\left(x_{1}\\\\right) / g(x)}{1-f\\\\left(x_{1}\\\\right) / f(x)}\\\\right) \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nWe can choose $x_{1}$ so close to $x_{0}$ that $\\\\left|f^{\\\\prime}(\\\\xi) / g^{\\\\prime}(\\\\xi)-L\\\\right|<\\\\epsilon$. Keeping $x_{1}$ fixed, we see that\\n\\n$$\\n\\\\lim _{x \\\\rightarrow x_{0}+}\\\\left(\\\\frac{1-g\\\\left(x_{1}\\\\right) / g(x)}{1-f\\\\left(x_{1}\\\\right) / f(x)}\\\\right)=1 \\\\text { since } 1 \\\\lim _{x \\\\rightarrow x_{0}+} f(x)_{1}=\\\\infty \\\\text { and } \\\\lim _{x \\\\rightarrow x_{0}+} g(x)=\\\\infty\\n$$\\n\\nThen taking the limit as $x \\\\rightarrow x_{0}+$ on both sides of (2), we see that, as required,\\n\\n$$\\n\\\\lim _{x \\\\rightarrow x_{0}+} \\\\frac{f(x)}{g(x)}=L=\\\\lim _{x \\\\rightarrow x_{0}+} \\\\frac{f^{\\\\prime}(x)}{g^{\\\\prime}(x)}\\n$$\\n\\nAppropriate modifications of this procedure establish the result if $x \\\\rightarrow x_{0}-, x \\\\rightarrow x_{0}, x \\\\rightarrow \\\\infty$, or $x \\\\rightarrow-\\\\infty$.\\n',\n",
       " '\\n4.27. Evaluate (a) $\\\\lim _{x \\\\rightarrow 0} \\\\frac{e^{2 x}-1}{x}$ and (b) $\\\\lim _{x \\\\rightarrow 1} \\\\frac{1+\\\\cos \\\\pi x}{x^{2}-2 x+1}$.\\n\\nAll of these have the \"indeterminate form\" $0 / 0$\\n\\n(a) $\\\\lim _{x \\\\rightarrow 0} \\\\frac{e^{2 x}-1}{x}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{2 e^{2 x}}{1}=2$\\n\\n(b) $\\\\lim _{x \\\\rightarrow 1} \\\\frac{1+\\\\cos \\\\pi x}{x^{2}-2 x+1}=\\\\lim _{x \\\\rightarrow 1} \\\\frac{-\\\\pi \\\\sin \\\\pi x}{2 x-2}=\\\\lim _{x \\\\rightarrow 1} \\\\frac{-\\\\pi^{2}+\\\\cos \\\\pi x}{2}=\\\\frac{\\\\pi^{2}}{2}$\\n\\nNote: Here L\\'Hospital\\'s rule is applied twice, since the first application again yields the \"indeterminate form\" $0 / 0$ and the conditions for L\\'Hospital\\'s rule are satisfied once more.\\n',\n",
       " '\\n4.28. Evaluate (a) $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{3 x^{2}-x+5}{5 x^{2}-6 x-3}$ and (b) $\\\\lim _{x \\\\rightarrow \\\\infty} x^{2} e^{-x}$.\\n\\nAll of these have or can be arranged to have the \"indeterminate form\" $\\\\infty / \\\\infty$.\\n\\n(a) $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{3 x^{2}-x+5}{5 x^{2}-6 x-3}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{6 x-1}{10 x+6}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{6}{10}=\\\\frac{3}{5}$\\n\\n(b) $\\\\lim _{x \\\\rightarrow \\\\infty} x^{2} e^{-x}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{x^{2}}{e^{x}}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{2 x}{e^{x}}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{2}{e^{x}}=0$\\n',\n",
       " '\\n4.29. Evaluate $\\\\lim _{x \\\\rightarrow 0+} x^{2} \\\\ln x$.\\n\\n$$\\n\\\\lim _{x \\\\rightarrow 0+} x^{2} \\\\operatorname{In} x=\\\\lim _{x \\\\rightarrow 0+} \\\\frac{\\\\operatorname{In} x}{1 / x^{2}}=\\\\lim _{x \\\\rightarrow 0+} \\\\frac{1 / x}{-2 / x^{3}} \\\\lim _{x \\\\rightarrow 0+} \\\\frac{-x^{2}}{2}=0\\n$$\\n\\nThe given limit has the \"indeterminate form\" $0 \\\\cdot \\\\infty$. In the second step the form is altered so as to give the indeterminate form $\\\\infty / \\\\infty$, and L\\'Hospital\\'s rule is then applied.\\n',\n",
       " '\\n4.30. Find $\\\\lim _{x \\\\rightarrow 0}(\\\\cos x)^{1 / x^{2}}$.\\n\\nSince $\\\\lim _{x \\\\rightarrow 0} \\\\cos x=1$ and $\\\\lim _{x \\\\rightarrow 0} 1 / x^{2}=\\\\infty$, the limit takes the \"indeterminate form\" 1 .\\n\\nLet $F(x)=(\\\\cos x)^{1 / x 2}$. Then $\\\\ln F(x)=(\\\\ln \\\\cos x) / x^{2}$, to which L\\'Hospital\\'s rule can be applied. We have\\n\\n$$\\n\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\operatorname{In} \\\\cos x}{x^{2}}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{(-\\\\sin x) /(\\\\cos x)}{2 x}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{-\\\\sin x}{2 x \\\\cos x}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{-\\\\cos x}{-2 x \\\\sin x+2 \\\\cos x}=-\\\\frac{1}{2} .\\n$$\\n\\nThus, $\\\\lim _{x \\\\rightarrow 0} \\\\ln F(x)=-\\\\frac{1}{2}$. But since the logarithm is a continuous function, $\\\\lim _{x \\\\rightarrow 0} \\\\ln F(x)=\\\\ln \\\\left(\\\\lim _{x \\\\rightarrow 0} F(x)\\\\right)$.\\\\\\\\\\nThen\\n\\n$$\\n\\\\ln \\\\left(\\\\lim _{x \\\\rightarrow 0} F(x)\\\\right)=-\\\\frac{1}{2} \\\\quad \\\\text { or } \\\\quad \\\\lim _{x \\\\rightarrow 0} F(x)=\\\\lim _{x \\\\rightarrow 0}(\\\\cos x)^{1 / x^{2}}=e^{-1 / 2}\\n$$\\n',\n",
       " \"\\n4.31. If $F(x)=\\\\left(e^{3 x}-5 x\\\\right)^{1 / x}$, find $(a) \\\\lim _{x \\\\rightarrow 0} F(x)$ and $(b) \\\\lim _{x \\\\rightarrow 0} F(x)$.\\n\\nThe respective indeterminate forms in $(a)$ and $(b)$ are $\\\\infty^{0}$ and $1^{\\\\infty}$.\\n\\nLet $G(x)=\\\\ln F(x)=\\\\frac{\\\\left(\\\\ln \\\\left(e^{3 x}-5 x\\\\right)\\\\right.}{x}$. Then $\\\\lim _{x \\\\rightarrow \\\\infty} G(x)$ and $\\\\lim _{x \\\\rightarrow 0} G(x)$ assume the indeterminate forms $\\\\infty / \\\\infty$ and $0 / 0$, respectively, and L'Hospital's rule applies. We have\\n\\n(a) $\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\ln \\\\left(e^{3 x}-5 x\\\\right)}{x}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{3 e^{3 x}-5}{e^{3 x}-5 x}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{9 e^{3 x}}{3 e^{3 x}-5}=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{27 e^{3 x}}{9 e^{3 x}}=3$\\n\\nThen, as in Problem 4.30, $\\\\lim _{x \\\\rightarrow \\\\infty}\\\\left(e^{3 x}-5 x\\\\right)^{1 / x}=e^{3}$.\\n\\n(b) $\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\ln \\\\left(e^{3 x}-5 x\\\\right)}{x}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{3 e^{3 x}-5}{e^{3 x}-5 x}=-2$\\n\",\n",
       " '\\n4.32. Suppose the equation of motion of a particle is $x=\\\\sin \\\\left(c_{1} t+c_{2}\\\\right)$, where $c_{1}$ and $c_{2}$ are constants (simple harmonic motion). (a) Show that the acceleration of the particle is proportional to its distance from the origin. (b) If $c_{1}=1, c_{2}=\\\\pi$, and $t \\\\geq 0$, determine the velocity and acceleration at the endpoints and at the midpoint of the motion.\\n\\n(a) $\\\\frac{d x}{d t} c_{1} \\\\cos \\\\left(c_{1} t+c_{2}\\\\right), \\\\frac{d^{2} x}{d t^{2}}=c_{1}^{2} \\\\sin \\\\left(c_{1} t+c_{2}\\\\right)=-c_{1}^{2} x$\\n\\nThis relation demonstrates the proportionality of acceleration and distance.\\n\\n(b) The motion starts at 0 and moves to -1 . Then it oscillates between this value and 1 . The absolute value of the velocity is zero at the endpoints, and that of the acceleration is maximum there. The particle coasts through the origin (zero acceleration), while the absolute value of the velocity is maximum there.\\n',\n",
       " \"\\n4.33. Use Newton's method to determine $\\\\sqrt{3}$ to three decimal points of accuracy.\\n\\n$\\\\sqrt{3}$ is a solution of $x^{2}-3=0$, which lies between 1 and 2. Consider $f(x)=x^{2}-3$, then $f^{\\\\prime}(x)=2 x$. The graph of $f$ crosses the $x$ axis between 1 and 2. Let $x_{0}=2$. Then $f\\\\left(x_{0}\\\\right)=1$ and $f^{\\\\prime}\\\\left(x_{0}\\\\right)=1.75$. According to the Newton formula, $x_{1}=x_{0}-\\\\frac{f\\\\left(x_{0}\\\\right)}{f^{\\\\prime}\\\\left(x_{0}\\\\right)}=2-.25=1.75$.\\n\\nThen $x_{2}=x_{1}-\\\\frac{f\\\\left(x_{1}\\\\right)}{f^{\\\\prime}\\\\left(x_{1}\\\\right)}=1.732$. To verify the three-decimal-point accuracy, note that $(1.732)^{2}=2.9998$ and $(1.7333)^{2}=3.0033$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n\",\n",
       " '4.34. If $x=g(t)$ and $y=f(t)$ are twice differentiable, find (a) $d y / d x$ and (b) $d^{2} y / d x^{2}$.\\n\\n(a) Letting primes denote derivatives with respect to $t$, we have\\n\\n$$\\n\\\\frac{d y}{d x}=\\\\frac{d y / d t}{d x / d t}=\\\\frac{f^{\\\\prime}(t)}{g^{\\\\prime}(t)} \\\\text { if } g^{\\\\prime}(t) \\\\neq 0\\n$$\\n\\n(b) $\\\\frac{d^{2} y}{d x^{2}}=\\\\frac{d}{d x}\\\\left(\\\\frac{d y}{d x}\\\\right)=\\\\frac{d}{d x}\\\\left(\\\\frac{f^{\\\\prime}(t)}{g^{\\\\prime}(t)}\\\\right) \\\\frac{\\\\frac{d}{d t}\\\\left(\\\\frac{f^{\\\\prime}(t)}{g^{\\\\prime}(t)}\\\\right)}{d x / d t}=\\\\frac{\\\\frac{d}{d t}\\\\left(\\\\frac{f^{\\\\prime}(t)}{g^{\\\\prime}(t)}\\\\right)}{g^{\\\\prime}(t)}$\\n\\n$$\\n=\\\\frac{1}{g^{\\\\prime}(t)}\\\\left\\\\{\\\\frac{g^{\\\\prime}(t) f^{\\\\prime \\\\prime}(t)-f^{\\\\prime}(t) g^{\\\\prime \\\\prime}(t)}{\\\\left[g^{\\\\prime}(t)\\\\right]^{2}}\\\\right\\\\}=\\\\frac{g^{\\\\prime}(t) f^{n}(t)-f^{\\\\prime}(t) g^{n}(t)}{\\\\left[g^{\\\\prime}(t)\\\\right]^{3}} \\\\text { if } g^{\\\\prime}(t) \\\\neq 0\\n$$\\n',\n",
       " \"\\n4.35. Let $f(x)=\\\\left\\\\{\\\\begin{array}{ll}e^{-1 / x 2}, & x \\\\neq 0 \\\\\\\\ 0, & x \\\\neq 0\\\\end{array}\\\\right.$. Prove that (a) $f^{\\\\prime}(0)=0$ and (b) $f^{\\\\prime \\\\prime}(0)=0$.\\n\\n(a) $\\\\quad f_{+}^{\\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{f(h)-f(0)}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{e^{-1 / h^{2}}-0}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{e^{-1 / h^{2}}}{h}$\\n\\nIf $h=1 / u$, using L'Hospital's rule this limit equals\\n\\n$$\\n\\\\lim _{u \\\\rightarrow \\\\infty} u e^{-u^{2}}=\\\\lim _{u \\\\rightarrow \\\\infty} u / e^{u^{2}}=\\\\lim _{u \\\\rightarrow \\\\infty} 1 / 2 u e^{u^{2}}=0\\n$$\\n\\nSimilarly, replacing $h \\\\rightarrow 0+$ by $h \\\\rightarrow 0-$ and $u \\\\rightarrow \\\\infty$ by $u \\\\rightarrow-\\\\infty$, we find $f_{-}^{\\\\prime}(0)=0$. Thus, $f_{+}^{\\\\prime}(0)=f_{-}^{\\\\prime}(0)=0$, and $\\\\operatorname{so} f^{\\\\prime}(0)=0$.\\n\\n(b) $f_{+}^{\\\\prime \\\\prime}(0)=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{f^{\\\\prime}(h)-f^{\\\\prime}(0)}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{e^{-1 / h^{2}} \\\\cdot 2 h^{-3}-0}{h}=\\\\lim _{h \\\\rightarrow 0+} \\\\frac{2 e^{-1 / h^{2}}}{h}=\\\\lim _{u \\\\rightarrow \\\\infty} \\\\frac{2 u^{4}}{e^{u^{2}}}=0$\\n\\nby successive applications of L'Hospital's rule.\\n\\nSimilarly, $f_{-}^{\\\\prime \\\\prime}(0)=0$ and so $f^{\\\\prime \\\\prime}(0)=0$.\\n\\nIn general, $f^{(n)}(0)=0$ for $n=1,2,3, \\\\ldots$\\n\",\n",
       " '\\n4.36. Find the length of the longest ladder which can be carried around the corner of a corridor whose dimensions are indicated in Figure 4.10, if it is assumed that the ladder is carried parallel to the floor.\\n\\nThe length of the longest ladder is the same as the shortest straight-line segment $A B$ (Figure 4.10), which touches both outer walls and the corner formed by the inner walls.\\n\\nAs seen from Figure 4.10, the length of the ladder $A B$ is $L=a$ sec $\\\\theta+b \\\\csc \\\\theta$.\\n\\n$L$ is a minimum when $d L / d \\\\theta=a \\\\sec \\\\theta \\\\tan \\\\theta-b \\\\csc \\\\theta \\\\cot \\\\theta=0 ;$\\n\\ni.e., $a \\\\sin ^{3} \\\\theta=b \\\\cos ^{3} \\\\theta$ or $\\\\tan \\\\theta=\\\\sqrt[3]{b / a}$. Then $\\\\sec \\\\theta=\\\\frac{\\\\sqrt{a^{2 / 3}+b^{2 / 3}}}{a^{1 / 3}}$ and $\\\\cos \\\\theta=\\\\frac{\\\\sqrt{a^{2 / 3}+b^{2 / 3}}}{b^{1 / 3}}$ so that $L=a \\\\sec \\\\theta+b \\\\csc \\\\theta=\\\\left(a^{2 / 3}+b^{2 / 3}\\\\right)^{3 / 2}$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-102}\\n\\\\end{center}\\n\\nFigure 4.10\\n\\nAlthough it is geometrically evident that this gives the minimum length, we can prove this analytically by showing that $d^{2} L / d \\\\theta^{2}$ for $\\\\theta=\\\\tan ^{-1} \\\\sqrt[3]{b / a}$ is positive (see Problem 4.78).\\n\\n',\n",
       " '5.1. If $f(x)$ is continuous in $[a, b]$, prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{b-a}{n} \\\\sum_{k=1}^{n} f\\\\left(a+\\\\frac{k(b-a)}{n}\\\\right)=\\\\int_{a}^{b} f(x) d x$.\\n\\nSince $f(x)$ is continuous, the limit exists independent of the mode of subdivision (see Problem 5.31). Choose the subdivision of $[a, b]$ into $n$ equal parts of equal length $\\\\Delta x=(b-a) / n$ see Figure 5.1. Let $\\\\xi_{k}=a+$ $k(b-a) / n, k=1,2, \\\\ldots, n$. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sum_{k=1}^{n} f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{b-a}{n} \\\\sum_{k=1}^{n} f\\\\left(a+\\\\frac{k(b-a)}{n}\\\\right)=\\\\int_{a}^{b} f(x) d x\\n$$\\n',\n",
       " '\\n5.2. Express $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n} \\\\sum_{k=1}^{n} f\\\\left(\\\\frac{k}{n}\\\\right)$ as a definite integral.\\n\\nLet $a=0, b=1$ in Problem 5.1. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n} \\\\sum_{k=1}^{n} f\\\\left(\\\\frac{k}{n}\\\\right)=\\\\int_{0}^{1} f(x) d x\\n$$\\n',\n",
       " '\\n5.3. (a) Express $\\\\int_{0}^{1} x^{2} d x$ as a limit of a sum, and use the result to evaluate the given definite integral. (b) Interpret the result geometrically.\\n\\n(a) If $f(x)=x^{2}$, then $f(k / n)=(k / n)^{2}=k^{2} / n^{2}$. Thus, by Problem 5.2,\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n} \\\\sum_{k=1}^{n} \\\\frac{k^{2}}{n^{2}}=\\\\int_{0}^{1} x^{2} d x\\n$$\\n\\nThis can be written, using Problem 1.29,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{1} x^{2} d x & =\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n}\\\\left(\\\\frac{1^{2}}{n^{2}}+\\\\frac{2^{2}}{n^{2}}+\\\\cdots+\\\\frac{n^{2}}{n^{2}}\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1^{2}+2^{2}+\\\\cdots+n^{2}}{n^{3}} \\\\\\\\\\n& =\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{n(n+1)(2 n+1)}{6 n^{3}} \\\\\\\\\\n& =\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{(1+1 / n)(2+1 / n)}{6}=\\\\frac{1}{3}\\n\\\\end{aligned}\\n$$\\n\\nwhich is the required limit.\\n\\nNote: By using the fundamental theorem of the calculus, we observe that $\\\\int_{0}^{1} x^{2} d x=\\\\left.\\\\left(x^{3} / 3\\\\right)\\\\right|_{0} ^{1}=1^{3} / 3-0^{3} / 3$ $=1 / 3$.\\n\\n(b) The area bounded by the curve $y=x^{2}$, the $x$ axis, and the line $x=1$ is equal to $\\\\frac{1}{3}$.\\n',\n",
       " '\\n5.4. Evaluate $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{1}{n+1}+\\\\frac{1}{n+2}+\\\\cdots+\\\\frac{1}{n+n}\\\\right\\\\}$.\\n\\nThe required limit can be written\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n}\\\\left\\\\{\\\\frac{1}{1+1 / n}+\\\\frac{1}{1+2 / n}+\\\\cdots+\\\\frac{1}{1+n / n}\\\\right\\\\}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n} \\\\sum_{k=1}^{n} \\\\frac{1}{1+k / n}=\\\\int_{0}^{1} \\\\frac{d x}{1+x}=\\\\ln |1+x|_{0}^{1}=\\\\ln 2\\n$$\\n\\nusing Problem 5.2 and the fundamental theorem of the calculus.\\n',\n",
       " '\\n5.5. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n}\\\\left\\\\{\\\\sin \\\\frac{t}{n}+\\\\sin \\\\frac{2 t}{n}+\\\\cdots+\\\\sin \\\\frac{(n-1) t}{n}\\\\right\\\\}=\\\\frac{1-\\\\cos t}{t}$.\\n\\nLet $a=0, b=t, f(x)=\\\\sin x$ in Problem 1. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n} \\\\sum_{k=1}^{n} \\\\sin \\\\frac{k t}{n}=\\\\int_{0}^{t} \\\\sin x d x=1-\\\\cos t\\n$$\\n\\nand so\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n} \\\\sum_{k=1}^{n-1} \\\\sin \\\\frac{k t}{n}=\\\\frac{1-\\\\cos t}{t}\\n$$\\n\\nusing the fact that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{\\\\sin t}{n}=0$.\\n\\n\\n\\\\section*{Measure zero}\\n',\n",
       " '5.6. Prove that a countable point set has measure zero.\\n\\nLet the point set be denoted by $x_{1}, x_{2}, x_{3}, x_{4}, \\\\ldots$ and suppose that intervals of lengths less than $\\\\varepsilon / 2, \\\\varepsilon / 4$, $\\\\varepsilon / 8, \\\\varepsilon / 16, \\\\ldots$, respectively, enclose the points, where $\\\\varepsilon$ is any positive number. Then the sum of the lengths of the intervals is less than $\\\\varepsilon / 2+\\\\varepsilon / 4+\\\\varepsilon / 8+\\\\ldots=\\\\varepsilon$ [let $a=\\\\varepsilon / 2$ and $r=1 / 2$ in Problem 2.25(a)], showing that the set has measure zero.\\n\\n\\n\\\\section*{Properties of definite integrals}\\n',\n",
       " '5.7. Prove that $\\\\left|\\\\int_{a}^{b} f(x) d x\\\\right| \\\\leqq \\\\int_{a}^{b}|f(x)| d x$ if $a<b$.\\n\\nBy absolute value property 2, on Page 4,\\n\\n$$\\n\\\\left|\\\\sum_{k=1}^{n} f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k}\\\\right| \\\\leqq \\\\sum_{k=1}^{n}\\\\left|f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k}\\\\right|=\\\\sum_{k=1}^{n}\\\\left|f\\\\left(\\\\xi_{k}\\\\right)\\\\right| \\\\Delta x_{k}\\n$$\\n\\nTaking the limit as $n \\\\rightarrow \\\\infty$ and each $\\\\Delta x_{k} \\\\rightarrow 0$, we have the required result.\\n',\n",
       " '\\n5.8. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{0}^{2 \\\\pi} \\\\frac{\\\\sin n x}{x^{2}+n^{2}} d x=0$.\\n\\n$$\\n\\\\left|\\\\int_{0}^{2 \\\\pi} \\\\frac{\\\\sin n x}{x^{2}+n^{2}} d x\\\\right| \\\\leqq \\\\int_{0}^{2 \\\\pi}\\\\left|\\\\frac{\\\\sin n x}{x^{2}+n^{2}}\\\\right| d x \\\\leqq \\\\int_{0}^{2 \\\\pi} \\\\frac{d x}{n^{2}}=\\\\frac{2 \\\\pi}{n^{2}}\\n$$\\n\\nThen $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\int_{0}^{2 \\\\pi} \\\\frac{\\\\sin n x}{x^{2}+n^{2}} d x\\\\right|=0$, and so the required result follows.\\n\\n\\n\\\\section*{Mean value theorems for integrals}\\n',\n",
       " '5.9. Given the right triangle pictured in Figure 5.6: (a) Find the average value of $h$. (b) At what point does this average value occur? (c) Determine the average value of $f(x)=\\\\sin ^{-1} x, 0 \\\\leqq x \\\\leqq \\\\frac{1}{2}$. (Use integration by parts.) (d) Determine the average value of $f(x)=\\\\cos ^{2} x, 0 \\\\leqq x \\\\leqq \\\\frac{\\\\pi}{2}$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-121}\\n\\\\end{center}\\n\\nFigure 5.6\\n\\n(a) $h(x)=\\\\frac{H}{B} x$. According to the mean value theorem for integrals, the average value of the function $h$ on the interval $[0, B]$ is\\n\\n$$\\nA=\\\\frac{1}{B} \\\\int_{0}^{B} \\\\frac{H}{B} x d x=\\\\frac{H}{2}\\n$$\\n\\n(b) The point $\\\\xi$, at which the average value of $h$ occurs, may be obtained by equating $f(\\\\xi)$ with that average value, i.e., $\\\\frac{H}{B} \\\\xi=\\\\frac{H}{2}$. Thus, $\\\\xi=\\\\frac{B}{2}$.\\n\\n\\n\\\\section*{Fundamental theorem of the calculus}\\n',\n",
       " '5.10. If $F(x)=\\\\int_{a}^{x} f(t) d t$ where $f(x)$ is continuous in $[a, b]$, prove that $F^{\\\\prime}(x)=f(x)$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{F(x+h)-F(x)}{h} & =\\\\frac{1}{h}\\\\left\\\\{\\\\int_{a}^{x+h} f(t) d t-\\\\int_{a}^{x} f(t) d t\\\\right\\\\} \\\\\\\\\\n& =\\\\frac{1}{h} \\\\int_{x}^{x+h} f(t) d t=f(\\\\xi) \\\\quad \\\\xi \\\\text { between } x \\\\text { and } x+h\\n\\\\end{aligned}\\n$$\\n\\nby the first mean value theorem for integrals (Page 99).\\n\\nThen if $x$ is any point interior to $[a, b]$,\\n\\n$$\\nF^{\\\\prime}(x)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{F(x+h)-F(x)}{h}=\\\\lim _{h \\\\rightarrow 0} f(\\\\xi)=f(x)\\n$$\\n\\nsince $f$ is continuous.\\n\\nIf $x=a$ or $x=b$, we use right-or left-hand limits, respectively, and the result holds in these cases as well.\\n',\n",
       " '\\n5.11. Prove the fundamental theorem of the calculus, Part 2 (Page 101).\\n\\nBy Problem 5.10, if $F(x)$ is any function whose derivative is $f(x)$, we can write\\n\\n$$\\nF(x)=\\\\int_{a}^{x} f(t) d t+c\\n$$\\n\\nwhere $c$ is any constant (see the last line of Problem 4.22).\\n\\nSince $F(a)=c$, it follows that $F(x)=\\\\int_{a}^{b} f(t) d t+F(a)$ or $\\\\int_{a}^{b} f(t) d t=F(b)-F(a)$\\n',\n",
       " '\\n5.12. If $f(x)$ is continuous in $[a, b]$, prove that $F(x)=\\\\int_{a}^{b} f(t) d t$ is continuous in $[a, b]$.\\n\\nIf $x$ is any point interior to $[a, b]$, then, as in Problem 5.10,\\n\\n$$\\n\\\\lim _{h \\\\rightarrow 0} F(x+h)-F(x)=\\\\lim _{h \\\\rightarrow 0} h f(\\\\xi)=0\\n$$\\n\\nand $F(x)$ is continuous.\\n\\nIf $x=a$ and $x=b$, we use right- and left-hand limits, respectively, to show that $F(x)$ is continuous at $x=a$ and $x=b$.\\n\\nAnother Method: By Problems 5.10 and 4.3, it follows that $F^{\\\\prime}(x)$ exists, and so $F(x)$ must be continuous.\\n\\n\\n\\\\section*{Change of variables and special methods of integration}\\n',\n",
       " '5.13. Prove the result in Equation (7), Page 102, for changing the variable of integration.\\n\\nLet $F(x)=\\\\int_{a}^{x} f(x) d x$ and $G(t)=\\\\int_{a}^{x} f\\\\{g(t)\\\\} g^{\\\\prime}(t) d t$, where $x=g(t)$\\n\\nThen $d F=f(x) d x, d G=f\\\\{g(t)\\\\} g^{\\\\prime}(t) d t$.\\n\\nSince $d x=g^{\\\\prime}(t) d t$, it follows that $f(x) d x=f\\\\{g(t)\\\\} g^{\\\\prime}(t) d t$ so that $d F(x)=d G(t)$, from which $F(x)=G(t)+c$.\\n\\nNow, when $x=a, t=\\\\alpha$ or $F(a)=G(\\\\alpha)+c$. But $F(a)=G(\\\\alpha)=0$, so that $c=0$. Hence, $F(x)=G(t)$. Since $x=b$ when $t=\\\\beta$, we have\\n\\n$$\\n\\\\int_{a}^{b} f(x) d x=\\\\int_{\\\\alpha}^{\\\\beta} f\\\\{g(t)\\\\} g^{\\\\prime}(t) d t\\n$$\\n\\nas required.\\n',\n",
       " '\\n5.14. Evaluate:\\\\\\\\\\n(a) $\\\\int(x+2) \\\\sin \\\\left(x^{2}+4 x-6\\\\right) d x$\\\\\\\\\\n(c) $\\\\int_{-1}^{1} \\\\frac{d x}{\\\\sqrt{(x+2)(3-x)}}$\\\\\\\\\\n(e) $\\\\int_{0}^{1 / \\\\sqrt{2}} \\\\frac{x \\\\sin ^{-1} x^{2}}{\\\\sqrt{1-x^{4}}} d x$\\\\\\\\\\n(b) $\\\\int \\\\frac{\\\\cot (\\\\ln x)}{x} d x$\\\\\\\\\\n(d) $\\\\int 2^{-x} \\\\tanh 2^{1-x} d x$\\\\\\\\\\n(f) $\\\\int \\\\frac{x d x}{\\\\sqrt{x^{2}+x+1}}$\\n\\n(a) Method 1: Let $x^{2}+4 x-6=u$. Then $(2 x+4) d x=d u,(x+2) d x=\\\\frac{1}{2} d u$, and the integral becomes $\\\\frac{1}{2} \\\\int \\\\sin u d u=-\\\\frac{1}{2} \\\\cos u+c=-\\\\frac{1}{2} \\\\cos \\\\left(x^{2}+4 x-6\\\\right)+c$.\\n\\nMethod 2:\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int(x+2) \\\\sin \\\\left(x^{2}+4 x-6\\\\right) d x & =\\\\frac{1}{2} \\\\int \\\\sin \\\\left(x^{2}+4 x-6\\\\right) d\\\\left(x^{2}+4 x-6\\\\right) \\\\\\\\\\n& =-\\\\frac{1}{2} \\\\cos \\\\left(x^{2}+4 x-6\\\\right)+c\\n\\\\end{aligned}\\n$$\\n\\n(b) Let $\\\\ln x=u$. Then $(d x) / x=d u$ and the integral becomes $\\\\int \\\\cot u d u=\\\\ln |\\\\sin u|+c=\\\\ln |\\\\sin (\\\\ln x)|+c$.\\n\\n(c) Method 1:\\n\\n$$\\n\\\\int \\\\frac{d x}{\\\\sqrt{(x+2)(3-x)}}=\\\\int \\\\frac{d x}{\\\\sqrt{6+x-x^{2}}}=\\\\int \\\\frac{d x}{\\\\sqrt{6+\\\\left(x^{2}-x\\\\right)}}=\\\\int \\\\frac{d x}{\\\\sqrt{25 / 4-\\\\left(x-\\\\frac{1}{2}\\\\right)^{2}}} .\\n$$\\n\\nLetting $x-\\\\frac{1}{2}=u$, this becomes $\\\\int \\\\frac{d u}{\\\\sqrt{25 / 4-u^{2}}}=\\\\sin ^{-1} \\\\frac{u}{5 / 2}+c=\\\\sin ^{-1}\\\\left(\\\\frac{2 x-1}{5}\\\\right)+c$\\n\\nThen\\n\\n$\\\\int_{-1}^{1} \\\\frac{d x}{\\\\sqrt{(x+2)(3-x)}}=\\\\left.\\\\sin ^{-1}\\\\left(\\\\frac{2 x-1}{5}\\\\right)\\\\right|_{-1} ^{1}=\\\\sin ^{-1}\\\\left(\\\\frac{1}{5}\\\\right)-\\\\sin ^{-1}\\\\left(-\\\\frac{3}{5}\\\\right)=\\\\sin ^{-1} .2+\\\\sin ^{-1} .6$\\n\\nMethod 2: Let $x-\\\\frac{1}{2}=u$ as in Method 1. Now, when $x=-1, u=-\\\\frac{3}{2}$, and when $x=1, u=\\\\frac{1}{2}$. Thus, by Formula 25, Page 102,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{-1}^{1} \\\\frac{d x}{\\\\sqrt{(x+2)(3-x)}} & =\\\\int_{-1}^{1} \\\\frac{d x}{\\\\sqrt{25 / 4-\\\\left(x-\\\\frac{1}{2}\\\\right)^{2}}}=\\\\int_{-3 / 2}^{1 / 2} \\\\frac{d u}{\\\\sqrt{25 / 4-u^{2}}}=\\\\left.\\\\sin ^{-1} \\\\frac{u}{5 / 2}\\\\right|_{-3 / 2} ^{1 / 2} \\\\\\\\\\n& =\\\\sin ^{1} .2+\\\\sin ^{-1} .6\\n\\\\end{aligned}\\n$$\\n\\n(d) Let $2^{1-x}=u$. Then $-2^{1-x}(\\\\ln 2) d x=d u$ and $2^{-x} d x=-\\\\frac{d u}{2 \\\\ln 2}$, so that the integral becomes\\n\\n$$\\n\\\\frac{1}{-2 \\\\ln 2} \\\\int \\\\tanh u d u=-\\\\frac{1}{2 \\\\ln 2} \\\\ln \\\\cosh 2^{1-x}+c\\n$$\\n\\n(e) Let $\\\\sin ^{-1} x^{2}=u$. Then $d u=\\\\frac{1}{\\\\sqrt{1-\\\\left(x^{2}\\\\right)^{2}}} 2 x d x=\\\\frac{2 x d x}{\\\\sqrt{1-x^{4}}}$ and the integral becomes\\n\\n$$\\n\\\\frac{1}{2} \\\\int u d u=\\\\frac{1}{4} u^{2}+c=\\\\frac{1}{4}\\\\left(\\\\sin ^{-1} x^{2}\\\\right)^{2}+c\\n$$\\n\\nThus,\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\int_{0}^{1 / \\\\sqrt{2}} \\\\frac{x \\\\sin ^{-1} x^{2}}{\\\\sqrt{1-x^{4}}} d x=\\\\left.\\\\frac{1}{4}\\\\left(\\\\sin ^{-1} x^{2}\\\\right)^{2}\\\\right|_{0} ^{1 / \\\\sqrt{2}}=\\\\frac{1}{4}\\\\left(\\\\sin ^{-1} \\\\frac{1}{2}\\\\right)^{2} \\\\frac{\\\\pi^{2}}{144} . \\\\\\\\\\n& \\\\text { (f) } \\\\int \\\\frac{x d x}{\\\\sqrt{x^{2}+x+1}}=\\\\frac{1}{2} \\\\int \\\\frac{2 x+1-1}{\\\\sqrt{x^{2}+x+1}} d x=\\\\frac{1}{2} \\\\int \\\\frac{2 x+1}{\\\\sqrt{x^{2}+x+1}} d x-\\\\frac{1}{2} \\\\frac{d x}{\\\\sqrt{x^{2}+x+1}} \\\\\\\\\\n& =\\\\frac{1}{2} \\\\int\\\\left(x^{2}+x+1\\\\right)^{-1 / 2} d\\\\left(x^{2}+x+1\\\\right)-\\\\frac{1}{2} \\\\int \\\\frac{d x}{\\\\sqrt{\\\\left(x+\\\\frac{1}{2}\\\\right)^{2}+\\\\frac{3}{4}}} \\\\\\\\\\n& =\\\\sqrt{x^{2}+x+1}-\\\\frac{1}{2} \\\\ln \\\\left|x+\\\\frac{1}{2}+\\\\sqrt{\\\\left(x+\\\\frac{1}{2}\\\\right)^{2}+\\\\frac{3}{4}}\\\\right|+c\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n5.15. Show that $\\\\int_{1}^{2} \\\\frac{d x}{\\\\left(x^{2}-2 x+4\\\\right)^{3 / 2}}=\\\\frac{1}{6}$.\\n\\nWrite the integral as $\\\\int_{1}^{2} \\\\frac{d x}{\\\\left[(x-1)^{2}+3\\\\right]^{3 / 2}}$. Let $x-1=\\\\sqrt{3}$ tan $u, d x=\\\\sqrt{3} \\\\sec ^{2} u d u$. When $x=1, u=$ $\\\\tan ^{-1} 0=0$; when $x=2, u=\\\\tan ^{-1} 1 / \\\\sqrt{3}=\\\\pi / 6$. Then the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\pi / 6} \\\\frac{\\\\sqrt{3} \\\\sec ^{2} u d u}{\\\\left[3+3 \\\\tan ^{2} u\\\\right]^{3 / 2}}=\\\\int_{0}^{\\\\pi / 6} \\\\frac{\\\\sqrt{3} \\\\sec ^{2} u d u}{\\\\left[3 \\\\sec ^{2} u\\\\right]^{3 / 2}}=\\\\frac{1}{3} \\\\int_{0}^{\\\\pi / 6} \\\\cos u d u=\\\\left.\\\\frac{1}{3} \\\\sin u\\\\right|_{0} ^{\\\\pi / 6}=\\\\frac{1}{6}\\n$$\\n',\n",
       " '\\n5.16. Determine $\\\\int_{e}^{e^{2}} \\\\frac{d x}{x(\\\\ln x)^{3}}$.\\n\\nLet $\\\\ln x=y,(d x) / x=d y$. When $x=e, y=1$; when $x=e^{2}, y=2$. Then the integral becomes\\n\\n$$\\n\\\\int_{1}^{2} \\\\frac{d y}{y^{3}}=\\\\left.\\\\frac{y^{-2}}{-2}\\\\right|_{1} ^{2}=\\\\frac{3}{8}\\n$$\\n',\n",
       " '\\n5.17. Find $\\\\int x^{n} \\\\ln x d x$ if (a) $n \\\\neq-1$ and if (b) $n=-1$.\\n\\n(a) Use integration by parts, letting $u=\\\\ln x, d v=x^{n} d x$, so that $d u=(d x) / x, v=x^{n+1} /(n+1)$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int x^{n} \\\\ln x d x & =\\\\int u d v=w-\\\\int v d u=\\\\frac{x^{n+1}}{n+1} \\\\ln x-\\\\int \\\\frac{x^{n+1}}{n+1} \\\\cdot \\\\frac{d x}{x} \\\\\\\\\\n& =\\\\frac{x^{n+1}}{n+1} \\\\ln x-\\\\frac{x^{n+1}}{(n+1)^{2}}+c\\n\\\\end{aligned}\\n$$\\n\\n(b) $\\\\int x^{-1} \\\\ln x d x=\\\\int \\\\ln x d(\\\\ln x)=\\\\frac{1}{2}(\\\\ln x)^{2}+c$.\\n',\n",
       " '\\n5.18. Find $\\\\int 3^{\\\\sqrt{2 x+1}} d x$.\\n\\nLet $\\\\sqrt{2 x+1}=y, 2 x+1=y^{2}$. Then $d x=y d y$ and the integral becomes $\\\\int 3^{y} \\\\cdot y d y$.\\n\\nIntegrate by parts, letting $u=y, d v=3^{y} d y$; then $d u=d y, v=3^{y} /(\\\\ln 3)$, and we have\\n\\n$$\\n\\\\int 3^{y} \\\\cdot y d y=\\\\int u d v=w-\\\\int v d u=\\\\frac{y \\\\cdot 3^{y}}{\\\\ln 3}-\\\\int \\\\frac{3^{y}}{\\\\ln 3} d y=\\\\frac{y \\\\cdot 3^{y}}{\\\\ln 3}-\\\\frac{3^{y}}{(\\\\ln 3)^{2}}+c\\n$$\\n',\n",
       " '\\n5.19. Find $\\\\int_{0}^{1} x \\\\ln (x+3) d x$.\\n\\nLet $u=\\\\ln (x+3), d v=x d x$. Then $d u=\\\\frac{d x}{x+3}, v=\\\\frac{x^{2}}{2}$. Hence, on integrating by parts,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int x \\\\ln (x+3) d x & =\\\\frac{x^{2}}{2} \\\\ln (x+3)-\\\\frac{1}{2} \\\\int \\\\frac{x^{2} d x}{x+3}=\\\\frac{x^{2}}{2} \\\\ln (x+3)-\\\\frac{1}{2} \\\\int\\\\left(x-3+\\\\frac{9}{x+3}\\\\right) d x \\\\\\\\\\n& =\\\\frac{x^{2}}{2} \\\\ln (x+3)-\\\\frac{1}{2}\\\\left\\\\{\\\\frac{x^{2}}{2}-3 x+9 \\\\ln (x+3)\\\\right\\\\}+c\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n$$\\n\\\\int_{0}^{1} x \\\\ln (x+3) d x=\\\\frac{5}{4}-4 \\\\ln 4+\\\\frac{9}{2} \\\\ln 3\\n$$\\n',\n",
       " '\\n5.20. Determine $\\\\int \\\\frac{6-x}{(x-3)(2 x+5)} d x$.\\n\\nUse the method of partial fractions. Let $\\\\frac{6-x}{(x-3)(2 x+5)}=\\\\frac{A}{x-3}+\\\\frac{B}{2 x+5}$.\\n\\nMethod 1: To determine the constants $A$ and $B$, multiply both sides by $(x-3)(2 x+5)$ to obtain\\n\\n\\n\\\\begin{equation*}\\n6-x=A(2 x+5)+B(x-3) \\\\text { or } 6-x=5 A-3 B+(2 A+B) x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSince this is an identity, $5 A-3 B=6,2 A+B=-1$ and $A=3 / 11, B=-17 / 11$. Then\\n\\n$$\\n\\\\int \\\\frac{6-x}{(x-3)(2 x+5)} d x=\\\\int \\\\frac{3 / 11}{x-3} d x+\\\\int \\\\frac{-17 / 11}{2 x+5} d x=\\\\frac{3}{11} \\\\ln |x-3|-\\\\frac{17}{22} \\\\ln |2 x+5|+c\\n$$\\n\\nMethod 2: Substitute suitable values for $x$ in the identity (1). For example, letting $x=3$ and $x=-5 / 2$ in (1), we find at once $A=3 / 11, B=-17 / 11$.\\n',\n",
       " '\\n5.21. Evaluate $\\\\int \\\\frac{d x}{5+3 \\\\cos x}$ by using the substitution $\\\\tan x / 2=u$.\\n\\nFrom Figure 5.7 we see that\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-125}\\n\\\\end{center}\\n\\nFigure 5.7\\n\\nThen\\n\\n$$\\n\\\\cos x=\\\\cos ^{2} x / 2-\\\\sin ^{2} x / 2=\\\\frac{1-u^{2}}{1+u^{2}}\\n$$\\n\\nAlso\\n\\n$$\\nd u=\\\\frac{1}{2} \\\\sec ^{2} x / 2 d x \\\\quad \\\\text { or } \\\\quad d x=2 \\\\cos ^{2} x / 2 d u=\\\\frac{2 d u}{1+u^{2}}\\n$$\\n\\nThus, the integral becomes\\n\\n$$\\n\\\\int \\\\frac{d u}{u^{2}+4}=\\\\frac{1}{2} \\\\tan ^{-1} u / 2+c=\\\\frac{1}{2} \\\\tan ^{-1}\\\\left(\\\\frac{1}{2} \\\\tan x / 2\\\\right)+c .\\n$$\\n',\n",
       " '\\n5.22. Evaluate $\\\\int_{0}^{\\\\pi} \\\\frac{x \\\\sin x}{1+\\\\cos ^{2} x} d x$.\\n\\nLet $x=\\\\pi-y$. Then\\n\\n$$\\n\\\\begin{aligned}\\nI & =\\\\int_{0}^{\\\\pi} \\\\frac{x \\\\sin x}{1+\\\\cos ^{2} x} d x=\\\\int_{0}^{\\\\pi} \\\\frac{(\\\\pi-y) \\\\sin y}{1+\\\\cos ^{2} y} d y=\\\\pi \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin y}{1+\\\\cos ^{2} y} d y-\\\\int_{0}^{\\\\pi} \\\\frac{y \\\\sin y}{1+\\\\cos ^{2} y} d y \\\\\\\\\\n& =-\\\\pi \\\\int_{0}^{\\\\pi} \\\\frac{d(\\\\cos y)}{1+\\\\cos ^{2} y}-I=-\\\\left.\\\\pi \\\\tan ^{-1}(\\\\cos y)\\\\right|_{0} ^{\\\\pi}=-I=\\\\pi^{2} / 2-I\\n\\\\end{aligned}\\n$$\\n\\ni.e., $I=\\\\pi^{2} / 2-I$ or $I=\\\\pi^{2} / 4$.\\n',\n",
       " '\\n5.23. Prove that $\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sqrt{\\\\sin x}}{\\\\sqrt{\\\\sin x}+\\\\sqrt{\\\\cos x}} d x=\\\\frac{\\\\pi}{4}$.\\n\\nLetting $x=\\\\pi / 2-y$, we have\\n\\n$$\\nI=\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sqrt{\\\\sin x}}{\\\\sqrt{\\\\sin x}+\\\\sqrt{\\\\cos x}} d x=\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sqrt{\\\\cos y}}{\\\\sqrt{\\\\cos y}+\\\\sqrt{\\\\sin y}} d y=\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sqrt{\\\\cos x}}{\\\\sqrt{\\\\cos x}+\\\\sqrt{\\\\sin x}} d x\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nI+I \\\\int_{0}^{\\\\pi / 2} & =\\\\frac{\\\\sqrt{\\\\sin x}}{\\\\sqrt{\\\\sin x}+\\\\sqrt{\\\\cos x}} d x+\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sqrt{\\\\cos x}}{\\\\sqrt{\\\\cos x}+\\\\sqrt{\\\\sin x}} d x \\\\\\\\\\n& =\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sqrt{\\\\sin x}+\\\\sqrt{\\\\cos x}}{\\\\sqrt{\\\\sin x}+\\\\sqrt{\\\\cos x}} d x=\\\\int_{0}^{\\\\pi / 2}=\\\\frac{\\\\pi}{2}\\n\\\\end{aligned}\\n$$\\n\\nfrom which $2 I=\\\\pi / 2$ and $I=\\\\pi / 4$.\\n\\nThe same method can be used to prove that for all real values of $m$,\\n\\n$$\\n\\\\int_{0}^{\\\\pi / 2} \\\\frac{\\\\sin ^{m} x}{\\\\sin ^{m} x+\\\\cos ^{m} x} d x=\\\\frac{\\\\pi}{4}\\n$$\\n\\n(see Problem 5.89).\\n\\nNote: This problem and Problem 5.22 show that some definite integrals can be evaluated without first finding the corresponding indefinite integrals.\\n\\n\\n\\\\section*{Numerical methods for evaluating definite integrals}\\n',\n",
       " \"5.24. Evaluate $\\\\int_{0}^{1} \\\\frac{d x}{1+x^{2}}$ approximately, using (a) the trapezodial rule, and (b) Simpson's rule, where the interval $[0,1]$ is divided into $n=4$ equal parts.\\n\\nLet $f(x)=1 /\\\\left(1+x^{2}\\\\right)$. Using the notation on Page 104 , we find $\\\\Delta x=(b-a) / n=(1-0) / 4=0.25$. Then, keeping four decimal places, we have $y_{0}=f(0)=1.0000, y_{1}=f(0.25)=0.9412, y_{2}=f(0.50)=0.8000, y_{3}=$ $f(0.75)=0.6400$, and $y_{4}=f(1)=0.50000$.\\n\\n(a) The trapezoidal rule gives\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{\\\\Delta x}{2}\\\\left\\\\{y_{0}+2 y_{1}+2 y_{2}+2 y_{3}+y_{4}\\\\right\\\\} & =\\\\frac{0.25}{2}\\\\{1.0000+2(0.9412)+2(0.8000)+2(0.6400)+0.500\\\\} \\\\\\\\\\n& =0.7828\\n\\\\end{aligned}\\n$$\\n\\n(b) Simpson's rule gives\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{\\\\Delta x}{3}\\\\left\\\\{y_{0}+4 y_{1}+2 y_{2}+4 y_{3}+y_{4}\\\\right\\\\} & =\\\\frac{0.25}{2}\\\\{1.0000+4(0.9412)+2(0.8000)+4(0.6400)+0.500\\\\} \\\\\\\\\\n& =0.7854\\n\\\\end{aligned}\\n$$\\n\\nThe true value is $\\\\pi / 4 \\\\approx 0.7854$.\\n\\n\\n\\\\section*{Applications (area, arc length, volume, moment of inertia)}\\n\",\n",
       " '5.25. Find (a) the area and (b) the moment of inertia about the $y$ axis of the region in the $x y$ plane bounded by $y=$ $4-x^{2}$ and the $x$ axis.\\n\\n(a) Subdivide the region into rectangles as in Figure 5.1. A typical rectangle is shown in Figure 5.8. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\text { Required area } & =\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sum_{k=1}^{n} f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k} \\\\\\\\\\n& =\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sum_{k=1}^{n}\\\\left(4-\\\\xi_{k}^{2}\\\\right) \\\\Delta x_{k} \\\\\\\\\\n& =\\\\int_{-2}^{2}\\\\left(4-x^{2}\\\\right) d x=\\\\frac{32}{3}\\n\\\\end{aligned}\\n$$\\n\\n(b) Assuming unit density, the moment of inertia about the $y$ axis of the typical rectangle shown in Figure 5.8 is $\\\\xi_{k}^{2} f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k}$. Then\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-126}\\n\\\\end{center}\\n\\nFigure 5.8\\n\\nRequired moment of inertia $=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sum_{k=1}^{n} \\\\xi_{k}^{2} f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sum_{k=1}^{n} \\\\xi_{k}^{2}\\\\left(4-\\\\xi_{k}^{2}\\\\right) \\\\Delta x_{k}$\\n\\n$$\\n=\\\\int_{-2}^{2} x^{2}\\\\left(4-x^{2}\\\\right) d x=\\\\frac{128}{15}\\n$$\\n',\n",
       " '\\n5.26. Find the length of arc of the parabola $y=x^{2}$ from $x=0$ to $x=1$.\\n\\nRequired arc length $=\\\\int_{0}^{1} \\\\sqrt{1+(d y / d x)^{2}} d x=\\\\int_{0}^{1} \\\\sqrt{1+(2 x)^{2} d x}$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\int_{0}^{1} \\\\sqrt{1+4 x^{2}} d x=\\\\frac{1}{2} \\\\int_{0}^{2} \\\\sqrt{1+u^{2}} d u \\\\\\\\\\n& =\\\\left.\\\\frac{1}{2}\\\\left\\\\{\\\\frac{1}{2} u \\\\sqrt{1+u^{2}}+\\\\frac{1}{2} \\\\ln \\\\left(u+\\\\sqrt{1+u^{2}}\\\\right)\\\\right\\\\}\\\\right|_{0} ^{2}=\\\\frac{1}{2} \\\\sqrt{5}+\\\\frac{1}{4} \\\\ln (2+\\\\sqrt{5})\\n\\\\end{aligned}\\n$$\\n',\n",
       " \"\\n5.27. (a) (Disk method.) Find the volume generated by revolving the region of Problem 5.25 about the $x$ axis.\\n\\n$$\\n\\\\text { Required volume }=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sum_{k=1}^{n} \\\\pi y_{k}^{2} \\\\Delta x_{k}=\\\\pi \\\\int_{-2}^{2}\\\\left(4-x^{2}\\\\right)^{2} d x=512 \\\\pi / 15 .\\n$$\\n\\n(b) (Disk method.) Find the volume of the frustrum of a paraboloid obtained by revolving $f(x)=\\\\sqrt{k x}$, $0<a \\\\leqq x \\\\leqq b$ about the $x$ axis.\\n\\n$$\\nV=\\\\pi \\\\int_{a}^{b} k x d x=\\\\frac{\\\\pi k}{2}\\\\left(b^{2}-a^{2}\\\\right)\\n$$\\n\\n(c) (Shell method.) Find the volume obtained by orbiting the region of (b) about the $y$ axis. Compare this volume with that obtained in (b).\\n\\n$$\\nV=2 \\\\pi \\\\int_{0}^{b} x(k x) d x=2 \\\\pi k b^{3} / 3\\n$$\\n\\nThe solids generated by the two regions are different, as are the volumes.\\n\\n\\n\\\\section*{Miscellaneous problems}\\nIf $f(x)$ and $g(x)$ are continuous in $[a, b]$, prove Schwarz's inequality for integrals:\\n\\n$$\\n\\\\left(\\\\int_{a}^{b} f(x) g(x) d x\\\\right)^{2} \\\\leqq \\\\int_{a}^{b}\\\\{f(x)\\\\}^{2} d x \\\\int_{a}^{b}\\\\{g(x)\\\\}^{2} d x\\n$$\\n\\nWe have\\n\\n$$\\n\\\\int_{a}^{b}\\\\{f(x)+\\\\lambda g(x)\\\\}^{2} d x=\\\\int_{a}^{b}\\\\{f(x)\\\\}^{2} d x+2 \\\\lambda \\\\int_{a}^{b} f(x) g(x) d x+\\\\lambda^{2} \\\\int_{a}^{b}\\\\{g(x)\\\\}^{2} d x \\\\geqq 0\\n$$\\n\\nfor all real values of $\\\\lambda$. Hence, using Equation (1) in Problem 1.13 with\\n\\n$$\\nA^{2}=\\\\int_{a}^{b}\\\\{g(x)\\\\}^{2} d x, \\\\quad B^{2}=\\\\int_{a}^{b}\\\\{f(x)\\\\}^{2} d x, \\\\quad C=\\\\int_{a}^{b} f(x) g(x) d x\\n$$\\n\\nwe find $C^{2} \\\\leqq A^{2} B^{2}$, which gives the required result.\\n\",\n",
       " '\\n5.29. Prove that $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} \\\\frac{d x}{x^{4}+4}=\\\\frac{\\\\pi}{8}$.\\n\\nWe have $x^{4}+4=x^{4}+4 x^{2}+4-4 x^{2}=\\\\left(x^{2}+2\\\\right)^{2}-(2 x)^{2}=\\\\left(x^{2}+2+2 x\\\\right)\\\\left(x^{2}+2-2 x\\\\right)$. According to the method of partial fractions, assume\\n\\n$$\\n\\\\frac{1}{x^{4}+4}=\\\\frac{A x+B}{x^{2}+2 x+2}+\\\\frac{C x+D}{x^{2}-2 x+2}\\n$$\\n\\nThen $1=(A+C) x^{3}+(B-2 A+2 C+D) x^{2}+(2 A-2 B+2 C+2 D) x+2 B+2 D$, so that $A+C=0, B-2 A$ $+2 C+D=0,2 A-2 B+2 C+2 D=0,2 B+2 D=1$. Solving simultaneously, $A=\\\\frac{1}{8}, \\\\quad B=\\\\frac{1}{4}, \\\\quad C=-\\\\frac{1}{8}, \\\\quad D=\\\\frac{1}{4}$.\\\\\\\\\\nThus,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int \\\\frac{d x}{x^{4}+4} & =\\\\frac{1}{8} \\\\int \\\\frac{x+2}{x^{2}+2 x+2} d x-\\\\frac{1}{8} \\\\int \\\\frac{x-2}{x^{2}-2 x+2} d x \\\\\\\\\\n& =\\\\frac{1}{8} \\\\int \\\\frac{x+1}{(x+1)^{2}+1} d x+\\\\frac{1}{8} \\\\int \\\\frac{d x}{(x+1)^{2}+1}-\\\\frac{1}{8} \\\\int \\\\frac{x-1}{(x-1)^{2}+1} d x+\\\\frac{1}{8} \\\\int \\\\frac{d x}{(x-1)^{2}+1} \\\\\\\\\\n& =\\\\frac{1}{16} \\\\ln \\\\left(x^{2}+2 x+2\\\\right)+\\\\frac{1}{8} \\\\tan ^{-1}(x+1)-\\\\frac{1}{16} \\\\ln \\\\left(x^{2}-2 x+2\\\\right)+\\\\frac{1}{8} \\\\tan ^{-1}(x-1)+C\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n$$\\n\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} \\\\frac{d x}{x^{4}+4}=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{1}{16} \\\\ln \\\\left(\\\\frac{M^{2}+2 M+2}{M^{2}-2 M+2}\\\\right)+\\\\frac{1}{8} \\\\tan ^{-1}(M+1)+\\\\frac{1}{8} \\\\tan ^{-1}(M-1)\\\\right\\\\}=\\\\frac{\\\\pi}{8}\\n$$\\n\\nWe denote this limit by $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{x^{4}+4}$, called an improper integral of the first kind. Such integrals are considered further in Chapter 12. See also Problem 5.74.\\n',\n",
       " \"\\n5.30. Evaluate $\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\int_{0}^{x} \\\\sin t^{3} d t}{x^{4}}$.\\n\\nThe conditions of L'Hospital's rule are satisfied, so that the required limit is\\n\\n$$\\n\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\frac{d}{d x} \\\\int_{0}^{x} \\\\sin t^{3} d t}{\\\\frac{d}{d x}\\\\left(x^{4}\\\\right)}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\sin x^{3}}{4 x^{3}}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{\\\\frac{d}{d x}\\\\left(\\\\sin x^{3}\\\\right)}{\\\\frac{d}{d x}\\\\left(4 x^{3}\\\\right)}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{3 x^{2} \\\\cos x^{3}}{12 x^{2}}=\\\\frac{1}{4}\\n$$\\n\",\n",
       " '\\n5.31. Prove that if $f(x)$ is continuous in $[a, b]$, then $\\\\int_{a}^{b} f(x) d x$ exists.\\n\\nLet $\\\\sigma=\\\\sum_{k=1}^{n} f\\\\left(\\\\xi_{k}\\\\right) \\\\Delta x_{k}$, using the notation of Page 99. Since $f(x)$ is continuous, we can find numbers $M_{k}$ and $m_{k}$, representing the l.u.b. and g.l.b. of $f(x)$ in the interval $\\\\left[x_{k-1}, x_{k}\\\\right]$, i.e., such that $m_{k} \\\\leqq f(x) \\\\leqq M_{k}$. We then have\\n\\n\\n\\\\begin{equation*}\\nm(b-a) \\\\leqq s=\\\\sum_{k=1}^{n} m_{k} \\\\Delta x_{k} \\\\leqq \\\\sigma \\\\leqq \\\\sum_{k=1}^{n} M_{k} \\\\Delta x_{k}=S \\\\leqq M_{k}(b-a) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere $m$ and $M$ are the g.l.b. and l.u.b. of $f(x)$ in $[a, b]$. The sums $s$ and $S$ are sometimes called the lower and upper sums, respectively.\\n\\nNow choose a second mode of subdivision of $[a, b]$ and consider the corresponding lower and upper sums denoted by $s^{\\\\prime}$ and $S^{\\\\prime}$ respectively. We have must\\n\\n\\n\\\\begin{equation*}\\ns^{\\\\prime} \\\\leqq S \\\\quad \\\\text { and } \\\\quad S^{\\\\prime} \\\\varepsilon S \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nTo prove this we choose a third mode of subdivision obtained by using the division points of both the first and second modes of subdivision and consider the corresponding lower and upper sums, denoted by $t$ and $T$, respectively. By Problem 5.84, we have\\n\\n\\n\\\\begin{equation*}\\ns \\\\leqq t \\\\leqq T \\\\leqq S^{\\\\prime} \\\\quad \\\\text { and } \\\\quad s^{\\\\prime} \\\\leqq t \\\\leqq T \\\\leqq S \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nwhich proves (2).\\n\\nFrom (2) it is also clear that as the number of subdivisions is increased, the upper sums are monotonic decreasing and the lower sums are monotonic increasing. Since, according to Equation (1), these sums are also bounded, it follows that they have limiting values, which we shall call $\\\\bar{s}$ and $\\\\underline{S}$, respectively. By By Problem $5.85, \\\\bar{s} \\\\leqq \\\\underline{S}$. In order to prove that the integral exists, we must show that $\\\\bar{s}=\\\\underline{S}$.\\n\\nSince $f(x)$ is continuous in the closed interval $[a, b]$, it is uniformly continuous. Then, given any $\\\\varepsilon>0$, we can take each $\\\\Delta x_{k}$ so small that $M_{k}-m_{k}<\\\\varepsilon /(b-a)$. It follows that\\n\\n\\n\\\\begin{equation*}\\nS-s=\\\\sum_{k=1}^{n}\\\\left(M_{k}-m_{k}\\\\right) \\\\Delta x_{k}<\\\\frac{\\\\varepsilon}{b-a} \\\\sum_{k=1}^{n} \\\\Delta x_{k}=\\\\varepsilon \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nNow $S-s=(S-\\\\underline{S})+(\\\\underline{S}-\\\\bar{S})+(\\\\bar{S}-s)$ and it follows that each term in parentheses is positive and so is less than $\\\\varepsilon$, by Equation (4). In particular, since $\\\\underline{S}-\\\\bar{S}$ is a definite number, it must be zero; i.e., $\\\\underline{S}=\\\\bar{S}$. Thus, the limits of the upper and lower sums are equal and the proof is complete.\\n\\n',\n",
       " '6.1. If $f(x, y)=x^{3}-2 x y+3 y^{2}$, find:\\\\\\\\\\n(a) $f\\\\left(\\\\frac{1}{x}, \\\\frac{2}{y}\\\\right)$;\\\\\\\\\\n(c) $\\\\frac{f(x, y+k)-f(x, y)}{k}, k \\\\neq 0$.\\n\\n(a) $f(-2,3)=(-2)^{3}-2(-2)(3)+3(3)^{2}=-8+12+27=31$\\n\\n(b) $f\\\\left(\\\\frac{1}{x}, \\\\frac{2}{y}\\\\right)=\\\\left(\\\\frac{1}{x}\\\\right)^{3}-2\\\\left(\\\\frac{1}{x}\\\\right)\\\\left(\\\\frac{2}{y}\\\\right)+3\\\\left(\\\\frac{2}{y}\\\\right)^{2}=\\\\frac{1}{x^{3}}-\\\\frac{4}{x y}+\\\\frac{12}{y^{2}}$\\n\\n(c) $\\\\frac{f(x, y+k)-f(x, y)}{k}=\\\\frac{1}{k}\\\\left\\\\{\\\\left[x^{3}-2 x(y+k)+3(y+k)^{2}\\\\right]-\\\\left[x^{3}-2 x y+3 y^{2}\\\\right]\\\\right\\\\}$\\n\\n$=\\\\frac{1}{k}\\\\left(x^{3}-2 x y-2 k x+3 y^{2}+6 k y+3 k^{2}-x^{2}+2 x y-3 y^{2}\\\\right)$\\n\\n$=\\\\frac{1}{k}\\\\left(-2 k x=6 k y+3 k^{2}\\\\right)=-2 x+6 y+3 k$.\\n',\n",
       " '\\n6.2. Give the domain of definition for which each of the following functions is defined and real, and indicate this domain graphically.\\n\\n(a) $f(x, y)=\\\\ln \\\\left\\\\{\\\\left(16-x^{2}-y^{2}\\\\right)\\\\left(x^{2}+y^{2}-4\\\\right)\\\\right\\\\}$\\n\\nThe function is defined and real for all points $(x, y)$ such that\\n\\n$$\\n\\\\left(16-x^{2}-y^{2}\\\\right)\\\\left(x^{2}+y^{2}-4\\\\right)>0, \\\\quad \\\\text { i.e., } 4<x^{2}+y^{2}<16\\n$$\\n\\nwhich is the required domain of definition. This point set consists of all points interior to the circle of radius 4 with center at the origin and exterior to the circle of radius 2 with center at the origin, as in Figure 6.5. The corresponding region, shown shaded in Figure 6.5, is an open region.\\n\\n(b) $f(x, y)=\\\\sqrt{6-(2 x+3 y)}$\\n\\nThe function is defined and real for all points $(x, y)$ such that $2 x+3 y \\\\leq 6$, which is the required domain of definition.\\n\\nThe corresponding (unbounded) region of the $x y$ plane is shown shaded in Figure 6.6.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-146(1)}\\n\\\\end{center}\\n\\nFigure 6.5\\n',\n",
       " '\\n6.3. Sketch and name the surface in three-dimensional space represented by each of the following. What are the traces on the coordinate planes?\\n\\n(a) $2 x+4 y+3 z=12$.\\n\\nTrace on $x y$ plane $(z=0)$ is the straight line $x+2 y=6, z=0$.\\n\\nTrace on $y z$ plane $(x=0)$ is the straight line $4 y+3 z=12, x=0$.\\n\\nTrace on $x z$ plane $(y=0)$ is the straight line $2 x+3 z=12, y=0$.\\n\\nThese are represented by $A B, B C$, and $A C$ in Figure 6.7.\\n\\nThe surface is a plane intersecting the $x, y$, and $z$ axes in the points $A(6,0,0), B(0,3,0)$, and $C(0,0,4)$. The lengths $\\\\overline{O A}=6, \\\\overline{O B}=3$, and $\\\\overline{O C}=4$ are called the $x, y$, and $z$ intercepts, respectively.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-146}\\n\\\\end{center}\\n\\nFigure 6.7\\n\\n(b) $\\\\frac{x^{2}}{a^{2}}+\\\\frac{y^{2}}{b^{2}}-\\\\frac{z^{2}}{c^{2}}=1$\\n\\nTrace on $x y$ plane $(z=0)$ is the ellipse $\\\\frac{x^{2}}{a^{2}}+\\\\frac{y^{2}}{b^{2}}=1, z=0$.\\n\\nTrace on $y z$ plane $(x=0)$ is the hyperbola $\\\\frac{y^{2}}{b^{2}}-\\\\frac{z^{2}}{c^{2}}=1, x=0$.\\n\\nTrace on $x z$ plane $(y=0)$ is the hyperbola $\\\\frac{x^{2}}{a^{2}}-\\\\frac{z^{2}}{c^{2}}=1, y=0$.\\n\\nTrace on any plane $z=p$ parallel to the $x y$ plane is the ellipse $\\\\frac{x^{2}}{a^{2}\\\\left(1+p^{2} / c^{2}\\\\right)}+\\\\frac{y^{2}}{b^{2}\\\\left(1+p^{2} / c^{2}\\\\right)}=1$.\\n\\nAs $|p|$ increases from zero, the elliptic cross section increases in size.\\n\\nThe surface is a hyperboloid of one sheet (see Figure 6.8).\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-146(2)}\\n\\\\end{center}\\n\\nFigure 6.8\\n\\n\\n\\\\section*{Limits and continuity}\\n',\n",
       " '6.4. Prove that $\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ y \\\\rightarrow 2}}\\\\left(x^{2}+2 y\\\\right)=5$.\\n\\nMethod 1, using definition of limit.\\n\\nWe must show that, given any $\\\\delta>0$, we can find $\\\\delta>0$ such that $\\\\left|x^{2}+2 y-5\\\\right|<\\\\delta$ when $0<|x-1|<\\\\delta$, $0<|y-2|<\\\\delta$.\\n\\nIf $0<|x-1|<\\\\delta$ and $0<|y-2|<\\\\delta$, then $1-\\\\delta x<1+<\\\\delta$ and $2-\\\\delta<y<2+\\\\delta$, excluding $x=1$, $y=2$.\\n\\nThus, $1-2 \\\\delta+\\\\delta^{2}<x^{2}<1+2 \\\\delta+\\\\delta^{2}$ and $4-2 \\\\delta<2 y<4+2 \\\\delta$. Adding\\n\\n$$\\n5-4 \\\\delta+\\\\delta^{2}<x^{2}+2 y<5+4 \\\\delta+\\\\delta^{2} \\\\text { or }-48+\\\\delta^{2}<x^{2}+2 y-5<4 \\\\delta+\\\\delta^{2}\\n$$\\n\\nNow, if $\\\\delta \\\\leq 1$, it certainly follows that $-5 \\\\delta<x^{2}+2 y-5<5 \\\\delta$; i.e., $\\\\left|x^{2}+2 y-5\\\\right|<5 \\\\delta$ whenever $0<|x-1|$ $<\\\\delta, 0<|y-2|<\\\\delta$. Then, choosing $5 \\\\delta=\\\\epsilon$, i.e., $\\\\delta=\\\\epsilon / 5$ (or $\\\\delta=1$, whichever is smaller), it follows that $\\\\left|x^{2}+2 y-5\\\\right|$ $<\\\\epsilon$ when $0<|x-1|<\\\\delta, 0<|y-2|<\\\\delta$; i.e., $\\\\lim _{x \\\\rightarrow 1}\\\\left(x^{2}+2 y\\\\right)=5$.\\n\\nMethod 2, using theorems on limits.\\n\\n$$\\ny \\\\rightarrow 2\\n$$\\n\\n$$\\n\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ x \\\\rightarrow 2}}\\\\left(x^{2}+2 y\\\\right)=\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ x \\\\rightarrow 2}} x^{2}+\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ x \\\\rightarrow 2}} 2 y=1+4=5\\n$$\\n',\n",
       " '\\n6.5. Prove that $f(x, y)=x^{2}+2 y$ is continuous at $(1,2)$.\\n\\nBy Problem 6.4, $\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ y \\\\rightarrow 2}} f(x, y)=5$. Also, $f(1,2)=1^{2}+2(2)=5$.\\n\\nThen $\\\\lim _{x \\\\rightarrow 1} f(x, y)=f(1,2)$ and the function is continuous at $(1,2)$.\\n\\nAlternatively, we can show, in much the same manner as in the first method of Problem 6.4, that given any $\\\\delta>0$ we can find $\\\\delta>0$ such that $|f(x, y)-f(1,2)|<\\\\delta$ when $|x-1|<\\\\delta,|y-2|<\\\\delta$.\\n',\n",
       " '\\n6.6. Determine whether $f(x, y)=\\\\left\\\\lvert\\\\, \\\\begin{array}{ll}x^{2}+2 y, & (x, y) \\\\neq(1,2) \\\\\\\\ 0, & (x, y)=(1,2)\\\\end{array}\\\\right.$ (a) has a limit as $x \\\\rightarrow 1$ and $y \\\\rightarrow 2$, and (b) is continuous at $(1,2)$.\\n\\n(a) By Problem 6.4, it follows that $\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ x \\\\rightarrow 2}} f(x, y)=5$, since the limit has nothing to do with the value at $(1,2)$.\\n\\n(b) Since $\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ x \\\\rightarrow 2}} f(x, y)=5$ and $f(1,2)=0$, it follows that $\\\\lim _{\\\\substack{x \\\\rightarrow 1 \\\\\\\\ y \\\\rightarrow 2}} f(x, y) \\\\neq f(1,2)$. Hence, the function is discontinuous at $(1,2)$.\\n',\n",
       " '\\n6.7. Investigate the continuity of $f(x, y)=\\\\left\\\\{\\\\begin{array}{ll}\\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}} & (x, y) \\\\neq(0,0) \\\\\\\\ 0 & (x, y)=(0,0)\\\\end{array}\\\\right.$. at $(0,0)$.\\n\\nLet $x \\\\rightarrow 0$ and $y \\\\rightarrow 0$ in such a way that $y=m x$ (a line in the $x y$ plane). Then, along this line,\\n\\n$$\\n\\\\lim _{\\\\substack{x \\\\rightarrow 0 \\\\\\\\ y \\\\rightarrow 0}} \\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{x^{2}-m^{2} x^{2}}{x^{2}+m^{2} x^{2}}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{x^{2}\\\\left(1-m^{2}\\\\right)}{x^{2}\\\\left(1+m^{2}\\\\right)}=\\\\frac{1-m^{2}}{1+m^{2}}\\n$$\\n\\nSince the limit of the function depends on the manner of approach to $(0,0)$ (i.e., the slope $m$ of the line), the function cannot be continuous at $(0,0)$.\\n\\n\\n\\\\section*{Another method:}\\nSince $\\\\lim _{x \\\\rightarrow 0}\\\\left\\\\{\\\\lim _{x \\\\rightarrow 0} \\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}}\\\\right\\\\}=\\\\lim _{x \\\\rightarrow 0} \\\\frac{y^{2}}{x^{2}}=1$ and $\\\\lim _{x \\\\rightarrow 0}\\\\left\\\\{\\\\lim _{x \\\\rightarrow 0} \\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}}\\\\right\\\\}=-1$ are not equal, $\\\\lim _{\\\\substack{x \\\\rightarrow 0 \\\\\\\\ y \\\\rightarrow 0}} f(x, y)$ cannot exist. Hence, $f(x, y)$ cannot be continuous at $(0,0)$.\\n\\n\\n\\\\section*{Partial derivatives}\\n',\n",
       " '6.8. If $f(x, y)=2 x^{2}-x y+y^{2}$, find (a) $\\\\partial f / \\\\partial x$ and (b) $\\\\partial f / \\\\partial y$ at $\\\\left(x_{0}, y_{0}\\\\right)$ directly from the definition.\\n\\n(a) $\\\\left.\\\\frac{\\\\partial f}{\\\\partial x}\\\\right|_{\\\\left(x_{0}, y_{0}\\\\right)}=f_{x}\\\\left(x_{0}, y_{0}\\\\right)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f\\\\left(x_{0}+h, y_{0}\\\\right)-f\\\\left(x_{0}, y_{0}\\\\right)}{h}$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\lim _{h \\\\rightarrow 0} \\\\frac{\\\\left[2\\\\left(x_{0}+h\\\\right)^{2}-\\\\left(x_{0}+h\\\\right) y_{0}+y_{0}^{2}\\\\right]=\\\\left[2 x_{0}^{2}-x_{0} y_{0}+y_{0}^{2}\\\\right]}{h} \\\\\\\\\\n& =\\\\lim _{h \\\\rightarrow 0} \\\\frac{4 h x_{0}+2 h^{2}-h y_{0}}{h}=\\\\lim _{h \\\\rightarrow 0}\\\\left(4 x_{0}+2 h-y_{0}\\\\right)=4 x_{0}-y_{0}\\n\\\\end{aligned}\\n$$\\n\\n(b) $\\\\left.\\\\frac{\\\\partial f}{\\\\partial y}\\\\right|_{\\\\left(x_{0}, y_{0}\\\\right)}=f_{y}\\\\left(x_{0}, y_{0}\\\\right)=\\\\lim _{k \\\\rightarrow 0} \\\\frac{f\\\\left(x_{0}, y_{0}+k\\\\right)-f\\\\left(x_{0}, y_{0}\\\\right)}{k}$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\lim _{k \\\\rightarrow 0} \\\\frac{\\\\left[2 x_{0}^{2}-x_{0}\\\\left(y_{0}+k\\\\right)+\\\\left(y_{0}+k\\\\right)^{2}\\\\right]-\\\\left[2 x_{0}^{2}-x_{0} y_{0}+y_{0}^{2}\\\\right]}{k} \\\\\\\\\\n& =\\\\lim _{k \\\\rightarrow 0} \\\\frac{-k x_{0}+2 k y_{0}+k^{2}}{k}=\\\\lim _{k \\\\rightarrow 0}\\\\left(-x_{0}+2 y_{0}+k\\\\right)=-x_{0}+2 y_{0}\\n\\\\end{aligned}\\n$$\\n\\nSince the limits exist for all points $\\\\left(x_{0}, y_{0}\\\\right)$, we can write $f_{x}(x, y)=f_{x}=4 x-y, f_{y}(x, y)=f_{y}=-x+2 y$, which are themselves functions of $x$ and $y$.\\n\\nNote that formally $f_{x}\\\\left(x_{0}, y_{0}\\\\right)$ is obtained from $f(x, y)$ by differentiating with respect to $x$, keeping $y$ constant and then putting $x=x_{0}, y=y_{0}$. Similarly, $f_{y}\\\\left(x_{0}, y_{0}\\\\right)$ is obtained by differentiating $f$ with respect to $y$, keeping $x$ constant. This procedure, while often lucrative in practice, need not always yield correct results (see Problem 6.9). It will work if the partial derivatives are continuous.\\n',\n",
       " '\\n6.9. Let $f(x, y)=\\\\left\\\\{\\\\begin{array}{ll}x y /\\\\left(x^{2}+y^{2}\\\\right) & (x, y) \\\\neq(0,0) \\\\\\\\ 0 & \\\\text { otherwise }\\\\end{array}\\\\right.$. Prove that (a) both $f_{x}(0,0)$ and $f_{y}(0,0)$ exist but that (b) $f(x, y)$ is discontinuous at $(0,0)$.\\n\\n(a)\\n\\n$$\\n\\\\begin{aligned}\\n& f_{x}(0,0)=\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(h, 0)-f(0,0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{0}{h}=0 \\\\\\\\\\n& f_{x}(0,0)=\\\\lim _{k \\\\rightarrow 0} \\\\frac{f(0,0)-f(0,0)}{k}=\\\\lim _{k \\\\rightarrow 0} \\\\frac{0}{k}=0\\n\\\\end{aligned}\\n$$\\n\\n(b) Let $(x, y) \\\\rightarrow(0,0)$ along the line $y=m x$ in the $x y$ plane. Then $\\\\lim _{\\\\substack{x \\\\rightarrow 0 \\\\\\\\ y \\\\rightarrow 0}} f(x, y)=\\\\lim _{x \\\\rightarrow 0} \\\\frac{m x^{2}}{x^{2}+m^{2} x^{2}}=\\\\frac{m}{1+m^{2}}$ so that the limit depends on $m$ and, hence, on the approach; therefore, it does not exist. Hence, $f(x, y)$ is not continuous at $(0,0)$.\\n\\nNote that unlike the situation for functions of one variable, the existence of the first partial derivatives at a point does not imply continuity at the point.\\n\\nNote also that if $(x, y) \\\\neq(0,0), f_{x}=\\\\frac{y^{2}-x^{2} y}{\\\\left(x^{2}+y^{2}\\\\right)^{2}}, f_{y}=\\\\frac{x^{3}-x y^{2}}{\\\\left(x^{2}+y^{2}\\\\right)^{2}}$ and $f_{x}(0,0), f_{y}(0,0)$ cannot be computed from them by merely letting $x=0$ and $y=0$. See the remark at the end of Problem 4.5(b).\\n',\n",
       " '\\n6.10. If $\\\\phi(x, y)=x^{3} y+e^{x y^{2}}$, find (a) $\\\\phi_{x}$, (b) $\\\\phi_{y \\\\phi x}$, (d) $\\\\phi_{y y}$, (e) $\\\\phi_{x y}$, and (f) $\\\\phi_{y x}$.\\n\\n(a) $\\\\phi_{x}=\\\\frac{\\\\partial \\\\phi}{\\\\partial x}=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x^{3} y+e^{x y^{2}}\\\\right)=3 x^{2} y+e^{x y^{2}} \\\\cdot y^{2}=3 x^{2} y+y^{2} e^{x y^{2}}$\\n\\n(b) $\\\\phi_{y}=\\\\frac{\\\\partial \\\\phi}{\\\\partial y}=\\\\frac{\\\\partial}{\\\\partial y}\\\\left(x^{3} y+e^{x y^{2}}\\\\right)=x^{3}+e^{x y^{2}} \\\\cdot 2 x y=x^{3}+2 x y e^{x y^{2}}$\\n\\n(c) $\\\\phi_{x x}=\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial x^{2}}=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\frac{\\\\partial \\\\phi}{\\\\partial x}\\\\right)=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(3 x^{2} y+y^{2} e^{x y^{2}}\\\\right)=6 x y+y^{2}\\\\left(e^{x y^{2}} \\\\cdot y^{2}\\\\right)=6 x y+y^{4} e^{x y^{2}}$\\\\\\\\\\n(d) $\\\\phi_{y y}=\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial y^{2}}=\\\\frac{\\\\partial}{\\\\partial y}\\\\left(x^{3}+2 x y e^{x y^{2}}\\\\right)=0+2 x y \\\\cdot \\\\frac{\\\\partial}{\\\\partial y}\\\\left(e^{x y^{2}}\\\\right)+e^{x y^{2}} \\\\frac{\\\\partial}{\\\\partial y}(2 x y)$\\n\\n$$\\n=2 x y \\\\cdot e^{x y^{2}} \\\\cdot 2 x y+e^{x y^{2}} \\\\cdot 2 x=x^{2} y^{2} e^{x y^{2}}+2 x e^{x y^{2}}\\n$$\\n\\n(e) $\\\\phi_{x y}=\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial y \\\\partial x}=\\\\frac{\\\\partial}{\\\\partial y}\\\\left(\\\\frac{\\\\partial \\\\phi}{\\\\partial x}\\\\right)=\\\\frac{\\\\partial}{\\\\partial y}\\\\left(3 x^{2} y+y^{2} e^{x y^{2}}\\\\right)=3 x^{2}+y^{2} \\\\cdot e^{x y^{2}} \\\\cdot 2 x y+e^{x y^{2}} \\\\cdot 2 y$\\n\\n$$\\n=3 x^{2}+2 x y^{3} e^{x y^{2}}+2 y e^{x y^{2}}\\n$$\\n\\n(f) $\\\\phi_{y x}=\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial x \\\\partial y}=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\frac{\\\\partial \\\\phi}{\\\\partial y}\\\\right)=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x^{3}+2 x y e^{x y^{2}}\\\\right)=3 x^{2}+y^{2} \\\\cdot e^{x y^{2}} \\\\cdot 2 x y+e^{x y^{2}} \\\\cdot 2 y$\\n\\n$$\\n=3 x^{2}+2 x y^{3} e^{x y^{2}}+2 y e^{x y^{2}}\\n$$\\n\\nNote that $\\\\phi_{x y}=\\\\phi_{y x}$ in this case. This is because the second partial derivatives exist and are continuous for all $(x, y)$ in a region $\\\\Re$. When this is not true, we may have $\\\\phi_{x y} \\\\neq \\\\phi_{y x}$ (see Problem 6.41, for example).\\n',\n",
       " \"\\n6.11. Show that $U(x, y, z)=\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{-1 / 2}$ satisfies Laplace's partial differential equation $\\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}}+\\\\frac{\\\\partial^{2} U}{\\\\partial y^{2}}+\\\\frac{\\\\partial^{2} U}{\\\\partial z^{2}}=0$.\\n\\nWe assume here that $(x, y, z) \\\\neq(0,0,0)$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{\\\\partial U}{\\\\partial x} & =-\\\\frac{1}{2}\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{-3 / 2} \\\\cdot 2 x=-x\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{-3 / 2} \\\\\\\\\\n\\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}} & =\\\\frac{\\\\partial}{\\\\partial x}\\\\left[-x\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{-3 / 2}\\\\right]=(-x)\\\\left[-\\\\frac{3}{2}\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{-5 / 2} \\\\cdot 2 x\\\\right]+\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{-3 / 2} \\\\cdot(-1) \\\\\\\\\\n& =\\\\frac{3 x^{2}}{\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{5 / 2}}-\\\\frac{\\\\left(x^{2}+y^{2}+z^{2}\\\\right)}{\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{5 / 2}}=\\\\frac{2 x^{2}-y^{2}-z^{2}}{\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{5 / 2}}\\n\\\\end{aligned}\\n$$\\n\\nSimilarly,\\n\\nAdding,\\n\\n$$\\n\\\\frac{\\\\partial^{2} U}{\\\\partial y^{2}}=\\\\frac{2 y^{2}-x^{2}-z^{2}}{\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{5 / 2}}, \\\\quad \\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}}=\\\\frac{2 z^{2}-x^{2}-y^{2}}{\\\\left(x^{2}+y^{2}+z^{2}\\\\right)^{5 / 2}}\\n$$\\n\\n$$\\n\\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}}+\\\\frac{\\\\partial^{2} U}{\\\\partial y^{2}}+\\\\frac{\\\\partial^{2} U}{\\\\partial z^{2}}=0\\n$$\\n\",\n",
       " '\\n6.12. If $z=x^{2} \\\\tan ^{-1} \\\\frac{y}{x}$, find $\\\\frac{\\\\partial^{2} z}{\\\\partial x \\\\partial y}$ at $(1,1)$.\\n\\n$$\\n\\\\begin{gathered}\\n\\\\frac{\\\\partial z}{\\\\partial y}=x^{2} \\\\cdot \\\\frac{1}{1+(y / x)^{2}} \\\\frac{\\\\partial}{\\\\partial y}\\\\left(\\\\frac{y}{x}\\\\right)=x^{2} \\\\cdot \\\\frac{x^{2}}{x^{2}+y^{2}} \\\\cdot \\\\frac{1}{x}=\\\\frac{x^{3}}{x^{2}+y^{2}} \\\\\\\\\\n\\\\frac{\\\\partial^{2} z}{\\\\partial x \\\\partial y}=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\frac{\\\\partial z}{\\\\partial y}\\\\right)=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\frac{x^{3}}{x^{2}+y^{2}}\\\\right)=\\\\frac{\\\\left(x^{2}+y^{2}\\\\right)\\\\left(3 x^{2}\\\\right)-\\\\left(x^{3}\\\\right)(2 x)}{\\\\left(x^{2}+y^{2}\\\\right)^{2}}=\\\\frac{2 \\\\cdot 3-1 \\\\cdot 2}{2^{2}}=1 \\\\text { at }(1,1)\\n\\\\end{gathered}\\n$$\\n\\nThe result can be written $z_{x y}(1,1)=1$.\\n\\nNote: In this calculation we are using the fact that $z_{x y}$ is continuous at $(1,1)$ (see the remark at the end of Problem 6.9).\\n',\n",
       " '\\n6.13. If $f(x, y)$ is defined in a region $\\\\Re$ and if $f_{x y}$ and $f_{y x}$ exist and are continuous at a point of $\\\\Re$, prove that $f_{x y}=f_{y x}$ at this point.\\n\\nLet $\\\\left(x_{0}, y_{0}\\\\right)$ be the point of $\\\\Re$. Consider\\n\\n$$\\nG=f\\\\left(x_{0}+h, y_{0}+k\\\\right)-f\\\\left(x_{0}, y_{0}+k\\\\right)-f\\\\left(x_{0}-h, y_{0}\\\\right)+f\\\\left(x_{0}, y_{0}\\\\right)\\n$$\\n\\nDefine\\n\\n\\n\\\\begin{align*}\\n& \\\\phi(x, y)=f(x+h, y)-f(x, y)  \\\\tag{1}\\\\\\\\\\n& \\\\psi(x, y)=f(x, y+k)-f(x, y) \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nThen\\n\\n\\n\\\\begin{align*}\\n& G=\\\\phi\\\\left(x_{0}, y_{0}+k\\\\right)-\\\\phi\\\\left(x_{0}, y_{0}\\\\right)  \\\\tag{3}\\\\\\\\\\n& G=\\\\psi\\\\left(x_{0}+h, y_{0}\\\\right)-\\\\psi\\\\left(x_{0}, y_{0}\\\\right) \\\\tag{4}\\n\\\\end{align*}\\n\\n\\nApplying the mean value theorem for functions of one variable (see Page 78) to Equations (3) and (4), we have\\n\\n\\n\\\\begin{gather*}\\nG=k \\\\phi_{y}\\\\left(x_{0}, y_{0}+\\\\theta_{1} k\\\\right)=k\\\\left\\\\{f_{y}\\\\left(x_{0}+h, y_{0}+\\\\theta_{1}-k\\\\right)-f_{y}\\\\left(x_{0}, y_{0}+\\\\theta_{1} k\\\\right)\\\\right\\\\} 0<\\\\theta_{1}<1  \\\\tag{5}\\\\\\\\\\nG=h \\\\psi_{x}\\\\left(x_{0},+\\\\theta_{2} h, y_{0}\\\\right)=h\\\\left\\\\{f_{x}\\\\left(x_{0}+\\\\theta_{2} h, y_{0}+k\\\\right)-f_{x}\\\\left(x_{0}+\\\\theta_{2} h, y_{0}\\\\right)\\\\right\\\\} 0<\\\\theta_{2}<1 \\\\tag{6}\\n\\\\end{gather*}\\n\\n\\nApplying the mean value theorem again to Equations (5) and (6), we have\\n\\n\\\\[\\n\\\\begin{array}{ll}\\nG=h k f_{y x}\\\\left(x_{0}+\\\\theta_{3} h, y_{0}+\\\\theta_{1} k\\\\right) & 0<\\\\theta_{1}<1,0<\\\\theta_{3}<1 \\\\\\\\\\nG=h k f_{x y}\\\\left(x_{0}+\\\\theta_{2} h, y_{0}+\\\\theta_{4} k\\\\right) & 0<\\\\theta_{2}<1,0<\\\\theta_{4}<1 \\\\tag{8}\\n\\\\end{array}\\n\\\\]\\n\\nFrom Equations (7) and (8) we have\\n\\n\\n\\\\begin{equation*}\\nf_{y x}\\\\left(x_{0}+\\\\theta_{3} h, y_{0}+\\\\theta_{1} k\\\\right)=f_{x y}\\\\left(x_{0}+\\\\theta_{2} h, y_{0}+\\\\theta_{4} k\\\\right) \\\\tag{9}\\n\\\\end{equation*}\\n\\n\\nLetting $h \\\\rightarrow 0$ and $k \\\\rightarrow 0$ in (9) we have, since $f_{x y}$ and $f_{y x}$ are assumed continuous at $\\\\left(x_{0}, y_{0}\\\\right)$,\\n\\n$$\\nf_{y x}\\\\left(x_{0}, y_{0}\\\\right)=f_{x y}\\\\left(d_{0}, y_{0}\\\\right)\\n$$\\n\\nas required. For an example where this fails to hold, see Problem 6.41.\\n\\n\\n\\\\section*{Differentials}\\n',\n",
       " '6.14. Let $f(x, y)$ have continuous first partial derivatives in a region $\\\\Re$ of the $x y$ plane. Prove that\\n\\n$$\\n\\\\Delta f=f(x+\\\\Delta x, y+\\\\Delta y)-f(x, y)=f_{x} \\\\Delta x+f_{y} \\\\Delta y+\\\\delta_{1} \\\\Delta x+\\\\delta_{2} \\\\Delta y\\n$$\\n\\nwhere $\\\\epsilon_{1}$ and $\\\\epsilon_{2}$ approach zero as $\\\\Delta x$ and $\\\\Delta y$ approach zero.\\n\\nApplying the mean value theorem for functions of one variable (see Page 78), we have\\n\\n\\n\\\\begin{gather*}\\n\\\\Delta f=\\\\{f(x+\\\\Delta x, y+\\\\Delta y)-f(x, y+\\\\Delta y)\\\\}+\\\\{f(x, y+\\\\Delta y)-f(x, y)\\\\}  \\\\tag{1}\\\\\\\\\\n=\\\\Delta x f_{x}\\\\left(x+\\\\theta_{1} \\\\Delta x, y+\\\\Delta y\\\\right)+\\\\Delta f_{y}\\\\left(x, y+\\\\theta_{2} \\\\Delta y\\\\right) \\\\quad 0<\\\\theta_{1}<1,0<\\\\theta_{2}<1\\n\\\\end{gather*}\\n\\n\\nSince, by hypothesis, $f_{x}$ and $f_{y}$ are continuous, it follows that\\n\\n$$\\n\\\\begin{gathered}\\nf_{x}\\\\left(x+\\\\theta_{1} \\\\Delta x, y+\\\\Delta y\\\\right)=f_{x}(x, y)+\\\\delta_{1}, \\\\quad f_{y}\\\\left(x, y+\\\\theta_{2} \\\\Delta y\\\\right)=f_{y}(x, y)+\\\\delta_{2} \\\\\\\\\\n\\\\text { where } \\\\delta_{1} \\\\rightarrow 0, \\\\delta_{2} \\\\rightarrow 0 \\\\text { as } \\\\Delta x \\\\rightarrow 0 \\\\text { and } \\\\Delta y \\\\rightarrow 0 .\\n\\\\end{gathered}\\n$$\\n\\nThus, $\\\\Delta f=f_{x} \\\\Delta x+f_{y} \\\\Delta y+\\\\delta_{1} \\\\Delta x+\\\\delta_{2} \\\\Delta y$ as required.\\n\\nDefining $\\\\Delta x=d x, \\\\Delta y=d y$, we have $\\\\Delta f=f_{x} d x+f_{y} d y+\\\\delta_{1} d x+\\\\delta_{2} d y$.\\n\\nWe call $d f=f_{x} d x+f_{y} d y$ the differential of $f$ (or $z$ ) or the principal part of $\\\\Delta f$ (or $\\\\Delta z$ ).\\n',\n",
       " '\\n6.15. If $z=f(x, y),=x^{2} y-3 y$, find (a) $\\\\Delta z$ and (b) $d z$. (c) Determine $\\\\Delta z$ and $d z$ if $x=4, y=3, \\\\Delta x=-0.01$, and $\\\\Delta y=$ 0.02 . (d) How might you determine $f(5.12,6.85)$ without direct computation?\\n\\n\\n\\\\section*{Solution:}\\n(a) $\\\\Delta z=f(x+\\\\Delta x, y)-f(x, y)$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left[(x+\\\\Delta x)^{2}(y+\\\\Delta y)-3(y+\\\\Delta y)\\\\right]-\\\\left\\\\{x^{2} y-3 y\\\\right\\\\} \\\\\\\\\\n& =\\\\underbrace{2 x y \\\\Delta x+\\\\left(x^{2}-3\\\\right) \\\\Delta y}_{(A)}+\\\\underbrace{(\\\\Delta x)^{2} y+2 x \\\\Delta x \\\\Delta y+(\\\\Delta x)^{2} \\\\Delta y}_{(B)}\\n\\\\end{aligned}\\n$$\\n\\nThe sum (A) is the principal part of $\\\\Delta z$ and is the differential of $z$, i.e., $d z$. Thus,\\n\\n(b) $d z=2 x y \\\\Delta x+\\\\left(x^{2}-3\\\\right) \\\\Delta y=2 x y d x+\\\\left(x^{2}-3\\\\right) d y$\\n\\nAnother method: $d z=\\\\frac{\\\\partial z}{\\\\partial x} d x+\\\\frac{\\\\partial z}{\\\\partial y} d y=2 x y d x+\\\\left(x^{2}-3\\\\right) d y$\\n\\n(c) $\\\\Delta z=f(x+\\\\Delta x, y+\\\\Delta y)-f(x, y)=f(4-0.01,3+0.02)-f(4,3)$\\n\\n$$\\n=\\\\left\\\\{(3.99)^{2}(3.02)-3(3.02)\\\\right\\\\}-\\\\left\\\\{(4)^{2}(3)-3(3)\\\\right\\\\}=0.018702\\n$$\\n\\n$d z=2 x y d x+\\\\left(x^{2}-3\\\\right) d y=2(4)(3)(-0.01)+\\\\left(4^{3}-3\\\\right)(0.02)=0.02$\\n\\nNote that in this case $\\\\Delta z$ and $d z$ are approximately equal: because $\\\\Delta x=d x$ and $\\\\Delta y=d y$ are sufficiently small.\\n\\n(d) We must find $f(x+\\\\Delta x, y+\\\\Delta y)$ when $x+\\\\Delta x=5.12$ and $y=\\\\Delta y=6.85$. We can accomplish this by choosing $x=5, \\\\Delta x=0.12, y=7, \\\\delta y=-0.15$. Since $\\\\Delta x$ and $\\\\Delta y$ are small, we use the fact that $f(x+\\\\Delta x, y+\\\\Delta y)$ $=f(x, y)+\\\\Delta z$ is approximately equal to $f(x, y)+d z$, i.e., $z+d z$.\\n\\nNow\\n\\n$$\\n\\\\begin{aligned}\\nz & =f(x, y)=f(5,7)=(5)^{2}(7)-3(7)=154 \\\\\\\\\\nd z & =2 x y d x+\\\\left(x^{2}-3\\\\right) d y=2(5)(7)(0.12)+\\\\left(5^{2}-3\\\\right)(-0.15)=5.1\\n\\\\end{aligned}\\n$$\\n\\nThen the required value is $154+5.1=159.1$ approximately. The value obtained by direct computation is 159.01864 .\\n',\n",
       " '\\n6.16. (a) Let $U=x^{2} e^{y / x}$. Find $d U$. (b) Show that $\\\\left(3 x^{2} y-2 y^{2}\\\\right) d x+\\\\left(x^{3}-4 x y+6 y^{2}\\\\right) d y$ can be written as an exact differential of a function $\\\\phi(x, y)$ and find this function.\\n\\n(a) Method 1:\\n\\nThen\\n\\n$$\\n\\\\frac{\\\\partial U}{\\\\partial x}=x^{2} e^{y / x}\\\\left(-\\\\frac{y}{x^{2}}\\\\right)+2 x e^{y / x}, \\\\quad \\\\frac{\\\\partial U}{\\\\partial y}=x^{2} e^{y / x}\\\\left(\\\\frac{1}{x}\\\\right)\\n$$\\n\\n\\n\\\\section*{Method 2:}\\n$$\\nd U=\\\\frac{\\\\partial U}{\\\\partial x} d x+\\\\frac{\\\\partial U}{\\\\partial y} d y=\\\\left(2 x e^{y / x}-y e^{y / x}\\\\right) d x+x e^{y / x} d y\\n$$\\n\\n$$\\n\\\\begin{aligned}\\nd U & =x^{2} d\\\\left(e^{y / x}\\\\right)+e^{y / x} d\\\\left(x^{2}\\\\right)=x^{2} e^{y / x} d(y / x)+2 x e^{y / x} d x \\\\\\\\\\n& =x^{2} e^{y / x}\\\\left(\\\\frac{x d y-y d x}{x^{2}}\\\\right)+2 x e^{y / x} d x=\\\\left(2 x e^{y / x}-y e^{y / x}\\\\right) d x+x e^{y / x} d y\\n\\\\end{aligned}\\n$$\\n\\n(b) Method 1:\\n\\nSuppose that\\n\\n$$\\n\\\\left(3 x^{2} y-2 y^{2}\\\\right) d x+\\\\left(x^{3}-4 x y+6 y^{2}\\\\right) d y=d \\\\phi=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} d x+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} d y\\n$$\\n\\nThen\\n\\n\\n\\\\begin{gather*}\\n\\\\frac{\\\\partial \\\\phi}{\\\\partial x}=3 x^{2} y-2 y^{2}  \\\\tag{1}\\\\\\\\\\n\\\\frac{\\\\partial \\\\phi}{\\\\partial y}=x^{3}-4 x y+6 y^{2} \\\\tag{2}\\n\\\\end{gather*}\\n\\n\\nFrom Equation (1), integrating with respect to $x$ keeping $y$ constant, we have\\n\\n$$\\n\\\\phi=x^{3} y=2 x y^{2}+f(y)\\n$$\\n\\nwhere $f(y)$ is the \"constant\" of integration. Substituting this into Equation (2) yields\\n\\n$$\\nx^{3}-4 x y+F^{\\\\prime}(y)=x^{3}-4 x y+6 y^{2}\\n$$\\n\\nfrom which $F^{\\\\prime}(y)=6 y^{2}$, i.e., $f(y)=2 y^{3}+c$.\\n\\nHence, the required function is $\\\\phi=x^{3} y-2 x y^{2}+2 y^{3}+c$, where $c$ is an arbitrary constant.\\n\\nNote that by Theorem 3, Page 130, the existence of such a function is guaranteed, since if $P=3 x^{2} y-2 y^{2}$ and $Q=x^{3}-4 x y+6 y^{2}$, then $\\\\partial P / \\\\partial y=3 x^{2}-4 y=\\\\partial Q / \\\\partial x$ identically. If $\\\\partial P / \\\\partial y \\\\neq \\\\partial Q / \\\\partial x$, this function would not exist and the given expression would not be an exact differential.\\n\\n\\n\\\\section*{Method 2:}\\n$$\\n\\\\begin{aligned}\\n\\\\left(3 x^{2} y-2 y^{2}\\\\right) d x+\\\\left(x^{3}-4 x y+6 y^{2}\\\\right) d y & =\\\\left(3 x^{2} y d x+x^{3} d y\\\\right)-\\\\left(2 y^{2} d x+4 x y d y\\\\right)+6 y^{2} d y \\\\\\\\\\n& =d\\\\left(x^{3} y\\\\right)-d\\\\left(2 x y^{2}\\\\right)+d\\\\left(2 y^{3}\\\\right)=d\\\\left(x^{3} y-2 x y^{2}+2 y^{3}\\\\right) \\\\\\\\\\n& =d\\\\left(x^{3} y-2 x y^{2}+2 y^{3}+c\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nThen the required function is $x^{3} y-2 x y^{2}+2 y^{3}+c$.\\n\\nThis method, called the grouping method, is based on our ability to recognize exact differential combinations and is less than Method 1. Naturally, before attempting to apply any method, we should determine whether the given expression is an exact differential by using Theorem 3, Page 130. See Theorem 4, Page 130.\\n\\n\\n\\\\section*{Differentiation of composite functions}\\n',\n",
       " '6.17. Let $z=f(x, y)$ and $x=\\\\phi(t), y=\\\\psi(t)$ where $f, \\\\phi, \\\\psi$ are assumed differentiable. Prove\\n\\n$$\\n\\\\frac{d z}{d t}=\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{d x}{d t}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{\\\\partial y}{d t}\\n$$\\n\\nUsing the results of Problem 6.14, we have\\n\\n$$\\n\\\\frac{d z}{d t}=\\\\lim _{\\\\Delta t \\\\rightarrow 0} \\\\frac{\\\\Delta z}{\\\\Delta t}=\\\\lim _{\\\\Delta t \\\\rightarrow 0}\\\\left\\\\{\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{\\\\Delta x}{\\\\Delta t}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{\\\\Delta y}{\\\\Delta t}+\\\\varepsilon_{1} \\\\frac{\\\\Delta x}{\\\\Delta t}+\\\\varepsilon_{2} \\\\frac{\\\\Delta y}{\\\\Delta t}\\\\right\\\\}=\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{d x}{d t}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{d y}{d t}\\n$$\\n\\nsince, as $\\\\Delta t \\\\rightarrow 0$, we have $\\\\Delta x \\\\rightarrow 0, \\\\Delta y \\\\rightarrow 0, \\\\varepsilon_{1} \\\\rightarrow 0, \\\\frac{\\\\Delta x}{\\\\Delta t} \\\\rightarrow \\\\frac{d x}{d t}, \\\\frac{\\\\Delta y}{\\\\Delta t} \\\\rightarrow \\\\frac{d y}{d t}$.\\n',\n",
       " '\\n6.18. If $z=e^{x y^{2}}, x=t \\\\cos t, y=t \\\\sin t$, compute $d z / d t$ at $t=\\\\pi / 2$.\\n\\n$$\\n\\\\frac{d z}{d t}=\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{d x}{d t}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{d y}{d t}=\\\\left(y^{2} e^{x y^{2}}\\\\right)(-t \\\\sin t+\\\\cos t)+\\\\left(2 x y e^{x y^{2}}\\\\right)(t \\\\cos t+\\\\sin t)\\n$$\\n\\n$$\\n\\\\text { At } t=\\\\pi / 2, x=0, y=\\\\pi / 2 \\\\text {. Then }\\\\left.\\\\frac{d z}{d t}\\\\right|_{t=\\\\pi / 2}=\\\\left(\\\\pi^{2} / 4\\\\right)(-\\\\pi / 2)+(0)(1)=-\\\\pi^{3} / 8 \\\\text {. }\\n$$\\n\\nAnother method: Substitute $x$ and $y$ to obtain $z=e^{t 3} \\\\sin ^{2} t \\\\cos t$ and then differentiate.\\n',\n",
       " '\\n6.19. If $z=f(x, y)$ where $x=\\\\phi(u, v)$ and $y=\\\\psi(u, v)$, prove the following:\\n\\n$$\\n\\\\begin{array}{ll}\\n\\\\text { (a) } \\\\frac{\\\\partial z}{\\\\partial u}=\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial u}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial u} & \\\\text { (b) } \\\\frac{\\\\partial z}{\\\\partial v}=\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial v}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial v}\\n\\\\end{array}\\n$$\\n\\n(a) From Problem 6.14, assuming the differentiability of $f, \\\\phi, \\\\psi$, we have\\n\\n$$\\n\\\\frac{\\\\partial z}{\\\\partial u}=\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{\\\\Delta z}{\\\\Delta u}=\\\\lim _{\\\\Delta u \\\\rightarrow 0}\\\\left\\\\{\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{\\\\Delta x}{\\\\Delta u}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{\\\\Delta y}{\\\\Delta u}+\\\\varepsilon_{1} \\\\frac{\\\\Delta x}{\\\\Delta u}+\\\\varepsilon_{2} \\\\frac{\\\\Delta y}{\\\\Delta u}\\\\right\\\\}=\\\\frac{\\\\partial z}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial u}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial u}\\n$$\\n\\n(b) The result is proved as in (a) by replacing $\\\\Delta u$ by $\\\\Delta v$ and letting $\\\\Delta v \\\\rightarrow 0$.\\n',\n",
       " '\\n6.20. Prove that $d z=\\\\frac{\\\\partial z}{\\\\partial x} d x+\\\\frac{\\\\partial z}{\\\\partial y} d y$ even if $x$ and $y$ are dependent variables.\\n\\nSuppose $x$ and $y$ depend on three variables $u, v, w$, for example. Then\\n\\n\\n\\\\begin{align*}\\nd x & =x_{u} d u+x_{v} d v+x_{w} d w  \\\\tag{1}\\\\\\\\\\nd y & =y_{u} d u+y_{v} d v+y_{w} d w \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nThus,\\n\\n$z_{x} d x+z_{y} d y=\\\\left(z_{x} x_{u}+z_{y} y_{u}\\\\right) d u+\\\\left(z_{x} x_{v}+z_{y y v}\\\\right) d v+\\\\left(z_{x} x_{w}+z_{y} y_{w}\\\\right) d w=z_{u} d u+z_{v} d v+z_{w}=d z$ using obvious generalizations from Problem 6.19.\\n',\n",
       " '\\n6.21. If $T=x^{3}-x y+y^{3}, x=\\\\rho \\\\cos \\\\phi$, and $y=\\\\rho \\\\sin \\\\phi$, find (a) $\\\\partial T / \\\\partial \\\\rho, \\\\partial T / \\\\partial \\\\rho$ and (b) $\\\\partial T / \\\\partial \\\\phi$.\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\frac{\\\\partial T}{\\\\partial \\\\rho}=\\\\frac{\\\\partial T}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial \\\\rho}+\\\\frac{\\\\partial T}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial \\\\rho}=\\\\left(3 x^{2}-y\\\\right)(\\\\cos \\\\phi)+\\\\left(3 y^{2}-x\\\\right)(\\\\sin \\\\phi) \\\\\\\\\\n& \\\\frac{\\\\partial T}{\\\\partial \\\\phi}=\\\\frac{\\\\partial T}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial \\\\phi}+\\\\frac{\\\\partial T}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial \\\\phi}=\\\\left(3 x^{2}-y\\\\right)(-\\\\rho \\\\sin \\\\phi)+\\\\left(3 y^{2}-x\\\\right)(\\\\rho \\\\cos \\\\phi)\\n\\\\end{aligned}\\n$$\\n\\nThis may also be worked by direct substitution of $x$ and $y$ in $T$.\\n',\n",
       " '\\n6.22. If $U=z \\\\sin y / x$ where $x=3 r^{2}+2 s, y=4 r-2 s^{3}$, and $z=2 r^{2}-3 s^{2}$, find (a) $\\\\partial U / \\\\partial r$ and (b) $\\\\partial U / \\\\partial s$.\\n\\n(a) $\\\\frac{\\\\partial U}{\\\\partial r}=\\\\frac{\\\\partial U}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial r}+\\\\frac{\\\\partial U}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial r}+\\\\frac{\\\\partial U}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial r}$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left\\\\{\\\\left(z \\\\cos \\\\frac{y}{x}\\\\right)\\\\left(-\\\\frac{y}{x^{2}}\\\\right)\\\\right\\\\}(6 r)+\\\\left\\\\{\\\\left(z \\\\cos \\\\frac{y}{x}\\\\right)\\\\left(\\\\frac{1}{x}\\\\right)\\\\right\\\\}(4)+\\\\left(\\\\sin \\\\frac{y}{x}\\\\right)(4 r) \\\\\\\\\\n& =-\\\\frac{6 r y z}{x^{2}} \\\\cos \\\\frac{y}{x}+\\\\frac{4 z}{x} \\\\cos \\\\frac{y}{x}+4 r \\\\sin \\\\frac{y}{x}\\n\\\\end{aligned}\\n$$\\n\\n(b) $\\\\frac{\\\\partial U}{\\\\partial s}=\\\\frac{\\\\partial U}{\\\\partial x} \\\\frac{\\\\partial x}{\\\\partial s}+\\\\frac{\\\\partial U}{\\\\partial y} \\\\frac{\\\\partial y}{\\\\partial s}+\\\\frac{\\\\partial U}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial s}$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left\\\\{\\\\left(z \\\\cos \\\\frac{y}{x}\\\\right)\\\\left(-\\\\frac{y}{x^{2}}\\\\right)\\\\right\\\\}(2)+\\\\left\\\\{\\\\left(z \\\\cos \\\\frac{y}{x}\\\\right)\\\\left(\\\\frac{1}{x}\\\\right)\\\\right\\\\}\\\\left(-6 s^{2}\\\\right)+\\\\left(\\\\sin \\\\frac{y}{x}\\\\right)(-6 s) \\\\\\\\\\n& =-\\\\frac{2 y z}{x^{2}} \\\\cos \\\\frac{y}{x}-\\\\frac{6 s^{2} z}{x} \\\\cos \\\\frac{y}{x}-6 s \\\\sin \\\\frac{y}{x}\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n6.23. If $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$, shown that $\\\\left(\\\\frac{\\\\partial V}{\\\\partial x}\\\\right)^{2}+\\\\left(\\\\frac{\\\\partial V}{\\\\partial y}\\\\right)^{2}=\\\\left(\\\\frac{\\\\partial V}{\\\\partial \\\\rho}\\\\right)^{2}+\\\\frac{1}{\\\\rho^{2}}\\\\left(\\\\frac{\\\\partial V}{\\\\partial \\\\phi}\\\\right)^{2}$.\\n\\nUsing the subscript notation for partial derivatives, we have\\n\\n\\n\\\\begin{align*}\\n& V_{\\\\rho}=V_{x} x_{\\\\rho}+V_{y} y_{\\\\rho}=V_{x} \\\\cos \\\\phi+V_{y} \\\\sin \\\\phi  \\\\tag{1}\\\\\\\\\\n& V_{\\\\phi}=V_{x} x_{\\\\phi}+V_{y} y_{\\\\phi}=V_{x}(-\\\\rho \\\\sin \\\\phi)+V_{y}(\\\\rho \\\\cos \\\\phi) \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nDividing both sides of Equation (2) by $\\\\rho$, we have\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{1}{\\\\rho} V_{\\\\phi}=-V_{x} \\\\sin \\\\phi+V_{y} \\\\cos \\\\phi \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nThen from Equations (1) and (3), we have\\n\\n$$\\nV_{\\\\rho}^{2}+\\\\frac{1}{\\\\rho^{2}} V_{\\\\phi}^{2}=\\\\left(V_{x} \\\\cos \\\\phi+V_{y} \\\\sin \\\\phi\\\\right)^{2}+\\\\left(-V_{x} \\\\sin \\\\phi+V_{y} \\\\cos \\\\phi\\\\right)^{2}=V_{x}^{2}+V_{y}^{2}\\n$$\\n',\n",
       " '\\n6.24. Show that $z=f\\\\left(x^{2} y\\\\right)$, where $f$ is differentiable, satisfies $x(\\\\partial z / \\\\partial x)=2 y(\\\\partial z / \\\\partial y)$.\\n\\nLet $x^{2} y=u$. Then $z=f(u)$. Thus,\\n\\n$$\\n\\\\frac{\\\\partial z}{\\\\partial x}=\\\\frac{\\\\partial z}{\\\\partial u} \\\\frac{\\\\partial u}{\\\\partial x}=f^{\\\\prime}(u) \\\\cdot 2 x y, \\\\quad \\\\frac{\\\\partial z}{\\\\partial y}=\\\\frac{\\\\partial z}{\\\\partial u} \\\\frac{\\\\partial u}{\\\\partial y}=f^{\\\\prime}(u) \\\\cdot x^{2}\\n$$\\n\\nThen\\n\\n$$\\nx \\\\frac{\\\\partial z}{\\\\partial x}=f^{\\\\prime}(u) \\\\cdot 2 x^{2} y, \\\\quad 2 y \\\\frac{\\\\partial z}{\\\\partial y}=f^{\\\\prime}(u) \\\\cdot 2 x^{2} y \\\\text { and so } x \\\\frac{\\\\partial z}{\\\\partial x}=2 y \\\\frac{\\\\partial z}{\\\\partial y}\\n$$\\n\\nAnother method: We have $d z=f^{\\\\prime}\\\\left(x^{2} y\\\\right) d\\\\left(x^{2} y\\\\right)=f^{\\\\prime}\\\\left(x^{2} y\\\\right)\\\\left(2 x y d x+x^{2} d y\\\\right)$.\\n\\nAlso,\\n\\n$$\\nd z=\\\\frac{\\\\partial z}{\\\\partial x} d x+\\\\frac{\\\\partial z}{\\\\partial y} d y\\n$$\\n\\nThen\\n\\n$$\\n\\\\frac{\\\\partial z}{\\\\partial x}=2 x y f^{\\\\prime}\\\\left(x^{2} y\\\\right) . \\\\quad \\\\frac{\\\\partial z}{\\\\partial y}=x^{3} f^{\\\\prime}\\\\left(x^{2} y\\\\right)\\n$$\\n\\nElimination of $f^{\\\\prime}\\\\left(x^{2} y\\\\right)$ yields $x \\\\frac{\\\\partial z}{\\\\partial x}=2 y \\\\frac{\\\\partial z}{\\\\partial y}$.\\n',\n",
       " '\\n6.25. If for all values of the parameter $\\\\lambda$ and for some constant $p, F(\\\\lambda x, \\\\lambda y)=\\\\lambda^{p} F(x, y)$ identically, where $F$ is assumed differentiable, prove that $x(\\\\partial F / \\\\partial x)+y(\\\\partial F / \\\\partial y)=p F$.\\n\\nLet $\\\\lambda x=u, \\\\lambda y=v$. Then\\n\\n\\n\\\\begin{equation*}\\nF(u, v)=\\\\lambda^{p} F(x, y) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nThe derivative with respect to $\\\\lambda$ of the left side of Equation (1) is\\n\\n$$\\n\\\\frac{\\\\partial F}{\\\\partial \\\\lambda}=\\\\frac{\\\\partial F}{\\\\partial u} \\\\frac{\\\\partial u}{\\\\partial \\\\lambda}+\\\\frac{\\\\partial F}{\\\\partial v} \\\\frac{d v}{\\\\partial \\\\lambda}=\\\\frac{\\\\partial F}{\\\\partial u} x+\\\\frac{\\\\partial F}{\\\\partial v} y\\n$$\\n\\nThe derivative with respect to $\\\\lambda$ of the right side of Equation (1) is $p \\\\lambda^{p-1} F$. Then\\n\\n\\n\\\\begin{equation*}\\nx \\\\frac{\\\\partial F}{\\\\partial u}+y \\\\frac{\\\\partial F}{\\\\partial v}=p \\\\lambda^{p-1} F \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nLetting $\\\\lambda=1$ in Equation (2), so that $u=x, v=y$, we have $x(\\\\partial F / \\\\partial x)+y(\\\\partial F / \\\\partial y)=p F$.\\n',\n",
       " '\\n6.26. If $F(x, y)=x^{4} y^{2} \\\\sin ^{-1} y / x$, show that $x(\\\\partial F / \\\\partial x)+y(\\\\partial F / \\\\partial y)=6 F$.\\n\\nSince $F(\\\\lambda x, \\\\lambda y)=(\\\\lambda x)^{4}(\\\\lambda y)^{2} \\\\sin ^{-1} \\\\lambda y / \\\\lambda x=\\\\lambda^{6} x^{4} y^{2} \\\\sin ^{-1} y / x=\\\\lambda^{6} F(x, y)$, the result follows from Problem 6.25 with $p=6$. It can, of course, also be shown by direct differentiation.\\n',\n",
       " '\\n6.27. Prove that $Y=f(x+a t)+g(x-a t)$ satisfies $\\\\partial^{2} Y / \\\\partial t^{2}=a^{2}\\\\left(\\\\partial^{2} Y / \\\\partial x^{2}\\\\right)$, where $f$ and $g$ are assumed to be at least twice differentiable and $a$ is any constant.\\n\\nLet $u=x+a t, v=x-a t$ so that $Y=f(u)+g(v) . \\\\quad$ Then if $f^{\\\\prime}(u) \\\\equiv d f / d u, g^{\\\\prime}(v) \\\\equiv d g / d v$,\\n\\n$\\\\frac{\\\\partial Y}{\\\\partial t}=\\\\frac{\\\\partial Y}{\\\\partial u} \\\\frac{\\\\partial u}{\\\\partial t}+\\\\frac{\\\\partial Y}{\\\\partial v} \\\\frac{\\\\partial v}{\\\\partial t}=a f^{\\\\prime}(u)-a g^{\\\\prime}(v), \\\\quad \\\\frac{\\\\partial Y}{\\\\partial x}=\\\\frac{\\\\partial Y}{\\\\partial x} \\\\frac{\\\\partial u}{\\\\partial x}+\\\\frac{\\\\partial Y}{\\\\partial v} \\\\frac{\\\\partial v}{\\\\partial x}=f^{\\\\prime}(u)+g^{\\\\prime}(v)$\\n\\nBy further differentiation, using the notation $f^{\\\\prime \\\\prime}(u) \\\\equiv d^{2} f / d u^{2}, g^{\\\\prime \\\\prime}(v) \\\\equiv d^{2} g / d v^{2}$, we have\\n\\n\\n\\\\begin{align*}\\n\\\\frac{\\\\partial^{2} Y}{\\\\partial t^{2}} & =\\\\frac{\\\\partial Y_{t}}{\\\\partial t}=\\\\frac{\\\\partial Y_{t}}{\\\\partial u} \\\\frac{\\\\partial u}{\\\\partial t}+\\\\frac{\\\\partial Y_{t}}{\\\\partial v} \\\\frac{\\\\partial v}{\\\\partial t}=\\\\frac{\\\\partial}{\\\\partial u}\\\\left\\\\{a f^{\\\\prime}(u)-a g^{\\\\prime}(v)\\\\right\\\\}(a)+\\\\frac{\\\\partial}{\\\\partial v}\\\\left\\\\{a f^{\\\\prime}(u)-a g^{\\\\prime}(v)\\\\right\\\\}(-a)  \\\\tag{1}\\\\\\\\\\n& =a^{2} f^{\\\\prime \\\\prime}(u)+a^{2} g^{\\\\prime \\\\prime}(v) \\\\\\\\\\n\\\\frac{\\\\partial^{2} Y}{\\\\partial x^{2}}= & \\\\left.\\\\frac{\\\\partial Y_{x}}{\\\\partial x}=\\\\frac{\\\\partial Y_{x}}{\\\\partial u} \\\\frac{\\\\partial u}{\\\\partial x}+\\\\frac{\\\\partial Y_{x}}{\\\\partial v} \\\\frac{\\\\partial v}{\\\\partial x}=\\\\frac{\\\\partial}{\\\\partial u}\\\\left\\\\{f^{\\\\prime}(u)+g^{\\\\prime}(v)\\\\right\\\\}+\\\\frac{\\\\partial}{\\\\partial v}\\\\left\\\\{f^{\\\\prime}(u)+g^{\\\\prime}\\\\right)(v)\\\\right\\\\}=f^{\\\\prime \\\\prime}(u)+g^{\\\\prime \\\\prime}(v) \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nThen from Equations (1) and (2), $\\\\partial^{2} Y / \\\\partial t^{2}=a^{2}\\\\left(\\\\partial^{2} Y / \\\\partial x^{2}\\\\right)$.\\n',\n",
       " '\\n6.28. If $x=2 r-s$ and $y=r+2 s$, find $\\\\frac{\\\\partial^{2} U}{\\\\partial y \\\\partial x}$ in terms of derivatives with respect to $r$ and $s$.\\n\\nSolving $x=2 r-s, y=r+2 s$ for $r$ and $s: r=(2 x+y) / 5, s=(2 y-x) / 5$.\\n\\nThen $\\\\partial r / \\\\partial x=2 / 5, \\\\partial s / \\\\partial x=-1 / 5, \\\\partial r / \\\\partial y=1 / 5, \\\\partial s / \\\\partial y=2 / 5$. Hence, we have\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\frac{\\\\partial U}{\\\\partial x}=\\\\frac{\\\\partial U}{\\\\partial r} \\\\frac{\\\\partial r}{\\\\partial x}+\\\\frac{\\\\partial U}{\\\\partial s} \\\\frac{\\\\partial s}{\\\\partial x}=\\\\frac{2}{5} \\\\frac{\\\\partial U}{\\\\partial r}-\\\\frac{1}{5} \\\\frac{\\\\partial U}{\\\\partial s} \\\\\\\\\\n& \\\\frac{\\\\partial^{2} U}{\\\\partial y \\\\partial x}=\\\\frac{\\\\partial}{\\\\partial y}\\\\left(\\\\frac{\\\\partial U}{\\\\partial x}\\\\right)=\\\\frac{\\\\partial}{\\\\partial r}\\\\left(\\\\frac{2}{5} \\\\frac{\\\\partial U}{\\\\partial r}-\\\\frac{1}{5} \\\\frac{\\\\partial U}{\\\\partial s}\\\\right) \\\\frac{\\\\partial r}{\\\\partial y}+\\\\frac{\\\\partial}{\\\\partial s}\\\\left(\\\\frac{2}{5} \\\\frac{\\\\partial U}{\\\\partial r}-\\\\frac{1}{5} \\\\frac{\\\\partial U}{\\\\partial s}\\\\right) \\\\frac{\\\\partial s}{\\\\partial y} \\\\\\\\\\n&=\\\\left(\\\\frac{2}{5} \\\\frac{\\\\partial^{2} U}{\\\\partial r^{2}}-\\\\frac{1}{5} \\\\frac{\\\\partial^{2} U}{\\\\partial r \\\\partial s}\\\\right)\\\\left(\\\\frac{1}{5}\\\\right)+\\\\left(\\\\frac{2}{5} \\\\frac{\\\\partial^{2} U}{\\\\partial s}-\\\\frac{1}{5} \\\\frac{\\\\partial^{2} U}{\\\\partial s^{2}}\\\\right)\\\\left(\\\\frac{2}{5}\\\\right) \\\\\\\\\\n&=\\\\frac{1}{25}\\\\left(2 \\\\frac{\\\\partial^{2} U}{\\\\partial r^{2}}+3 \\\\frac{\\\\partial^{2} U}{\\\\partial r \\\\partial s}-2 \\\\frac{\\\\partial^{2} U}{\\\\partial s^{2}}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nassuming $U$ has continuous second partial derivatives.\\n\\n\\n\\\\section*{Implicit functions and jacobians}\\n',\n",
       " '6.29. If $U=x^{3} y$, find $d U / d t$ if\\n\\n\\n\\\\begin{gather*}\\nx^{5}+y=t \\\\text { and }  \\\\tag{1}\\\\\\\\\\nx^{2}+y^{3}=t^{2} \\\\tag{2}\\n\\\\end{gather*}\\n\\n\\nEquations (1) and (2) define $x$ and $y$ as (implicit) functions of $t$. Then differentiating with respect to $t$, we have\\n\\n\\n\\\\begin{gather*}\\n5 x^{4}(d x / d t)+d y / t=1  \\\\tag{3}\\\\\\\\\\n2 x(d x / d t)+3 y^{2}(d y / d t)=2 t \\\\tag{4}\\n\\\\end{gather*}\\n\\n\\nSolving Equations (3) and (4) simultaneously for $d x / d t$ and $d y / d t$,\\n\\n$$\\n\\\\frac{d x}{d t}=\\\\frac{\\\\left|\\\\begin{array}{cc}\\n1 & 1 \\\\\\\\\\n2 t & 3 y^{2}\\n\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{cc}\\n5 x^{4} & 1 \\\\\\\\\\n2 x & 3 y^{2}\\n\\\\end{array}\\\\right|}=\\\\frac{3 y^{2}-2 t}{15 x^{4} y^{2}-2 x}, \\\\quad \\\\frac{d y}{d t}=\\\\frac{\\\\left|\\\\begin{array}{cc}\\n5 x^{4} & 1 \\\\\\\\\\n2 x & 2 t\\n\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{cc}\\n5 x^{4} & 1 \\\\\\\\\\n2 x & 3 y^{2}\\n\\\\end{array}\\\\right|}=\\\\frac{10 x^{4} t-2 x}{15 x^{4} y^{2}-2 x}\\n$$\\n\\nThen $\\\\frac{d U}{d t}=\\\\frac{\\\\partial U}{\\\\partial x} \\\\frac{d x}{d t}+\\\\frac{\\\\partial U}{\\\\partial y} \\\\frac{d y}{d t}=\\\\left(3 x^{2} y\\\\right)\\\\left(\\\\frac{3 y^{2}-2 t}{15 x^{4} y^{2}-2 x}\\\\right)+\\\\left(x^{3}\\\\right)\\\\left(\\\\frac{10 x^{4} t-2 x}{15 x^{4} y^{2}-2 x}\\\\right)$.\\n',\n",
       " '\\n6.30. If $F(x, y, z)=0$ defines $z$ as an implicit function of $x$ and $y$ in a region $\\\\Re$ of the $x y$ plane, prove that (a) $\\\\partial z / \\\\partial x$ $=-F_{x} / F_{z}$ and (b) $\\\\partial z / \\\\partial y=-F_{y} / F_{z}$, where $F_{z} \\\\neq 0$.\\n\\nSince $z$ is a function of $x$ and $y, d z=\\\\frac{\\\\partial z}{\\\\partial x} d x+\\\\frac{\\\\partial z}{\\\\partial y} d y$.\\n\\nThen $d F=\\\\frac{\\\\partial F}{\\\\partial x} d x+\\\\frac{\\\\partial F}{\\\\partial y} d y+\\\\frac{\\\\partial F}{\\\\partial z} d z=\\\\left(\\\\frac{\\\\partial F}{\\\\partial x}+\\\\frac{\\\\partial F}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial x}\\\\right) d x+\\\\left(\\\\frac{\\\\partial F}{\\\\partial y}+\\\\frac{\\\\partial F}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial y}\\\\right) d y=0$.\\n\\nSince $x$ and $y$ are independent, we have\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial F}{\\\\partial x}+\\\\frac{\\\\partial F}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial x}=0  \\\\tag{1}\\\\\\\\\\n& \\\\frac{\\\\partial F}{\\\\partial y}+\\\\frac{\\\\partial F}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial y}=0 \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nfrom which the required results are obtained. If desired, equations (1) and (2) can be written directly.\\n',\n",
       " '\\n6.31. If $F(x, y, u, v)=0$ and $\\\\mathrm{G}(x, y, u, v)=0$, find (a) $\\\\partial u / \\\\partial x$, (b) $\\\\partial u / \\\\partial y$, (c) $\\\\partial v / \\\\partial x$, and (d) $\\\\partial v / \\\\partial y$.\\n\\nThe two equations in general define the dependent variables $u$ and $v$ as (implicit) functions of the independent variables $x$ and $y$. Using the subscript notation, we have\\n\\n\\n\\\\begin{align*}\\n& d F=F_{x} d x+F_{y} d y+F_{u} d u+F_{v} d v=0  \\\\tag{1}\\\\\\\\\\n& d G=G_{x} d x+G_{y} d y+G_{u} d u+G_{v} d v=0 \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nAlso, since $u$ and $v$ are functions of $x$ and $y$,\\n\\n\\n\\\\begin{align*}\\n& d u=u_{x} d x+u_{y} d y  \\\\tag{3}\\\\\\\\\\n& d v=v_{x} d x+v_{y} d y \\\\tag{4}\\n\\\\end{align*}\\n\\n\\nSubstituting Equations (3) and (4) in (1) and (2) yields\\n\\n\\n\\\\begin{align*}\\n& d F=\\\\left(F_{x}+F_{u} u_{x}+F_{v} v_{x}\\\\right) d x+\\\\left(F_{y}+F_{u} u_{y}+F_{v} v_{y}\\\\right) d y=0  \\\\tag{5}\\\\\\\\\\n& d G=\\\\left(G_{x}+G_{u} u_{x}+G_{v} v_{x}\\\\right) d x+\\\\left(G_{y}+G_{u} u_{y}+G_{v} v_{y}\\\\right) d y=0 \\\\tag{6}\\n\\\\end{align*}\\n\\n\\nSince $x$ and $y$ are independent, the coefficients of $d x$ and $d y$ in Equations (5) and (6) are zero. Hence, we obtain\\n\\n\\n\\\\begin{align*}\\n& \\\\left\\\\{\\\\begin{array}{l}\\nF_{u} u_{x}+F_{v} v_{x}=-F_{x} \\\\\\\\\\nG_{u} u_{x}+G_{v} v_{x}=-G_{x}\\n\\\\end{array}\\\\right.  \\\\tag{7}\\\\\\\\\\n& \\\\left\\\\{\\\\begin{array}{l}\\nF_{u} u_{y}+F_{v} v_{y}=-F_{y} \\\\\\\\\\nG_{u} u_{y}+G_{v} v_{y}=-G_{y}\\n\\\\end{array}\\\\right. \\\\tag{8}\\n\\\\end{align*}\\n\\n\\nSolving Equations (7) and (8) gives\\\\\\\\\\n(a) $u_{x} \\\\frac{\\\\partial u}{\\\\partial x}=\\\\frac{\\\\left|\\\\begin{array}{cc}-F_{x} & F_{v} \\\\\\\\ -G_{x} & G_{v}\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{cc}F_{u} & F_{v} \\\\\\\\ G_{u} & G_{v}\\\\end{array}\\\\right|}=-\\\\frac{\\\\frac{\\\\partial(F, G)}{\\\\partial(x, v)}}{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, v)}}$\\\\\\\\\\n(b) $v_{x}=\\\\frac{\\\\partial v}{\\\\partial x}=\\\\frac{\\\\left|\\\\begin{array}{ll}F_{u} & -F_{x} \\\\\\\\ G_{u} & -G_{x}\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{ll}F_{u} & F_{v} \\\\\\\\ G_{u} & G_{v}\\\\end{array}\\\\right|}=-\\\\frac{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, x)}}{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, v)}}$\\\\\\\\\\n(c) $u_{y}=\\\\frac{\\\\partial u}{\\\\partial y}=\\\\frac{\\\\left|\\\\begin{array}{ll}-F_{y} & F_{v} \\\\\\\\ -G_{y} & G_{v}\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{cc}F_{u} & F_{v} \\\\\\\\ G_{u} & G_{v}\\\\end{array}\\\\right|}=-\\\\frac{\\\\frac{\\\\partial(F, G)}{\\\\partial(y, v)}}{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, v)}}$\\\\\\\\\\n(d) $v_{y}=\\\\frac{\\\\partial v}{\\\\partial y}=\\\\frac{\\\\left|\\\\begin{array}{ll}F_{u} & -F_{y} \\\\\\\\ G_{u} & -G_{y}\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{ll}F_{u} & F_{v} \\\\\\\\ G_{u} & G_{v}\\\\end{array}\\\\right|}=-\\\\frac{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, y)}}{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, v)}}$\\n\\nThe functional determinant $\\\\left|\\\\begin{array}{ll}F_{u} & F_{v} \\\\\\\\ G_{u} & G_{v}\\\\end{array}\\\\right|$, denoted by $\\\\frac{\\\\partial(F, G)}{\\\\partial(u, v)}$ or $J\\\\left(\\\\frac{F, G}{u, v}\\\\right)$, is the Jacobian of $F$ and $G$ with respect to $u$ and $v$ and is supposed $\\\\neq 0$.\\n\\nNote that it is possible to devise mnemonic rules for writing at once the required partial derivatives in terms of Jacobians (see also Problem 6.33).\\n',\n",
       " '\\n6.32. If $u^{2}-v=3 x+y$ and $u-2 v^{2}=x-2 y$, find (a) $\\\\partial u / \\\\partial x$, (b) $\\\\partial v / \\\\partial x$, (c) $\\\\partial u / \\\\partial y$, and (d) $\\\\partial v / \\\\partial y$.\\n\\nMethod 1: Differentiate the given equations with respect to $x$, considering $u$ and $v$ as functions of $x$ and $y$. Then\\n\\n\\n\\\\begin{align*}\\n& 2 u \\\\frac{\\\\partial u}{\\\\partial x}-\\\\frac{\\\\partial v}{\\\\partial x}=3  \\\\tag{1}\\\\\\\\\\n& \\\\frac{\\\\partial v}{\\\\partial x}-4 v \\\\frac{\\\\partial v}{\\\\partial x}=1 \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nSolving, $\\\\frac{\\\\partial u}{\\\\partial x}=\\\\frac{1-12 v}{1-8 w}, \\\\frac{\\\\partial v}{\\\\partial x}=\\\\frac{2 u-3}{1-8 w}$.\\n\\nDifferentiating with respect to $y$, we have\\n\\n\\n\\\\begin{gather*}\\n2 u \\\\frac{\\\\partial u}{\\\\partial y}-\\\\frac{\\\\partial v}{\\\\partial y}=1  \\\\tag{3}\\\\\\\\\\n\\\\frac{\\\\partial u}{\\\\partial y}-4 v \\\\frac{\\\\partial v}{\\\\partial y}=-2 \\\\tag{4}\\n\\\\end{gather*}\\n\\n\\nSolving, $\\\\frac{\\\\partial u}{\\\\partial y}=\\\\frac{-2-4 v}{1-8 w}, \\\\frac{\\\\partial v}{\\\\partial y}=\\\\frac{-4 u-1}{1-8 w}$.\\n\\nWe have, of course, assumed that $1-8 u v \\\\neq 0$.\\n\\nMethod 2: The given equations are $F=u^{2}-v-3 x-y=0, G=u-2 v^{2}-x+2 y=0$. Then, by Problem 6.31,\\n\\n$$\\n\\\\frac{\\\\partial u}{\\\\partial x}=-\\\\frac{\\\\frac{\\\\partial(F, G)}{\\\\partial(x, v)}}{\\\\frac{\\\\partial(F, G)}{\\\\partial(u, v)}}=-\\\\left|\\\\begin{array}{ll}\\nF_{x} & F_{v} \\\\\\\\\\nG_{x} & G_{v} \\\\\\\\\\nF_{u} & F_{v} \\\\\\\\\\nG_{u} & G_{v}\\n\\\\end{array}\\\\right|=-\\\\left|\\\\begin{array}{cc}\\n-3 & -1 \\\\\\\\\\n-1 & -4 v \\\\\\\\\\n2 u & -1 \\\\\\\\\\n1 & -4 v\\n\\\\end{array}\\\\right|=\\\\frac{1-12 v}{1-8 w v}\\n$$\\n\\nprovided $1-8 u v \\\\neq 0$. Similarly, the other partial derivatives are obtained.\\n',\n",
       " '\\n6.33. If $F(u, v, w, x, y)=0, G(u, v, w, x, y)=0$, and $H(u, v, w, x, y)=0$, find (a) $\\\\left.\\\\frac{\\\\partial v}{\\\\partial y}\\\\right|_{x}$, (b) $\\\\left.\\\\frac{\\\\partial x}{\\\\partial v}\\\\right|_{w}$, (c) $\\\\left.\\\\frac{\\\\partial w}{\\\\partial u}\\\\right|_{y}$.\\n\\nFrom three equations in five variables, we can (theoretically at least) determine three variables in terms of the remaining two. Thus, three variables are dependent and two are independent. If we were asked to determine $\\\\partial v / \\\\partial y$, we would know that $v$ is a dependent variable and $y$ is an independent variable, but would not know the remaining independent variable. However, the particular notation $\\\\left.\\\\frac{\\\\partial v}{\\\\partial y}\\\\right|_{x}$ serves to indicate that we are to obtain $\\\\partial v / \\\\partial y$, keeping $x$ constant; i.e., $x$ is the other independent variable.\\n\\n(a) Differentiating the given equations with respect to $y$, keeping $x$ constant, gives\\n\\n\\n\\\\begin{gather*}\\nF_{u} u_{y}+F_{v} v_{y}+F_{w} w_{y}+F_{y}=0  \\\\tag{1}\\\\\\\\\\nG_{u} u_{y}+G_{v} v_{y}+G_{w} w_{y}+G_{y}=G_{y}=0  \\\\tag{2}\\\\\\\\\\nH_{u} u_{y}+H_{v} v_{y}+H_{w} w_{y}+H_{y}=0 \\\\tag{3}\\n\\\\end{gather*}\\n\\n\\nSolving simultaneously for $v_{y}$, we have\\n\\n$$\\nv_{y}=\\\\left.\\\\frac{\\\\partial v}{\\\\partial y}\\\\right|_{x}=-\\\\frac{\\\\left|\\\\begin{array}{lll}\\nF_{u} & F_{y} & F_{w} \\\\\\\\\\nG_{u} & G_{y} & G_{w} \\\\\\\\\\nH_{u} & H_{y} & H_{w}\\n\\\\end{array}\\\\right|}{\\\\left|\\\\begin{array}{lll}\\nF_{u} & F_{v} & F_{w} \\\\\\\\\\nG_{u} & G_{v} & G_{w} \\\\\\\\\\nH_{u} & H_{v} & H_{w}\\n\\\\end{array}\\\\right|}=-\\\\frac{\\\\frac{\\\\partial(F, G, H)}{\\\\partial(u, y, w)}}{\\\\frac{\\\\partial(F, G, H)}{\\\\partial(u, v, w)}}\\n$$\\n\\nEquations (1), (2), and (3) can also be obtained by using differentials as in Problem 6.31.\\n\\nThe Jacobian method is very suggestive for writing results immediately, as seen in this problem and Problem 6.31. Thus, observe that in calculating $\\\\left.\\\\frac{\\\\partial v}{\\\\partial y}\\\\right|_{x}$ the result is the negative of the quotient of two Jacobians, the numerator containing the independent variable $y$ and the denominator containing the dependent variable $v$ in the same relative positions. Using this scheme, we have\\n\\n$$\\n\\\\text { (b) }\\\\left.\\\\frac{\\\\partial x}{\\\\partial v}\\\\right|_{w}=-\\\\frac{\\\\frac{\\\\partial(F, G, H)}{\\\\partial(v, y, u)}}{\\\\frac{\\\\partial(F, G, H)}{\\\\partial(x, y, u)}} \\\\quad \\\\text { (c) }\\\\left.\\\\frac{\\\\partial w}{\\\\partial u}\\\\right|_{y}=-\\\\frac{\\\\frac{\\\\partial(F, G, H)}{\\\\partial(u, x, v)}}{\\\\frac{\\\\partial(F, G, H)}{\\\\partial(w, x, v)}}\\n$$\\n',\n",
       " '\\n6.34. If $z^{3}-x z-y=0$, prove that $\\\\frac{\\\\partial^{2} z}{\\\\partial x \\\\partial y}=-\\\\frac{3 z^{2}+x}{\\\\left(3 z^{2}-x\\\\right)^{3}}$\\n\\nDifferentiating with respect to $x$, keeping $y$ constant, and remembering that $z$ is the dependent variable depending on the independent variables $x$ and $y$, we find\\n\\n$$\\n3 z^{2} \\\\frac{\\\\partial z}{\\\\partial x}-x \\\\frac{\\\\partial z}{\\\\partial x}-z=0\\n$$\\n\\nand\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial z}{\\\\partial x}=\\\\frac{z}{3 z^{2}-x} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nDifferentiating with respect to $y$, keeping $x$ constant, we find\\n\\n$$\\n3 z^{2} \\\\frac{\\\\partial z}{\\\\partial y}-x \\\\frac{\\\\partial z}{\\\\partial y}-1=0\\n$$\\n\\nand\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial z}{\\\\partial x}=\\\\frac{z}{3 z^{2}-x} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nDifferentiating Equation (2) with respect to $x$ and using Equation (1), we have\\n\\n$$\\n\\\\frac{\\\\partial^{2}}{\\\\partial x \\\\partial y}=\\\\frac{-1}{\\\\left(3 z^{2}-x\\\\right)^{2}}\\\\left(6 z \\\\frac{\\\\partial z}{\\\\partial x}-1\\\\right)=\\\\frac{1-6 z\\\\left[z /\\\\left(3 z^{2}-x\\\\right)\\\\right]}{\\\\left(3 z^{2}-x\\\\right)^{2}}=-\\\\frac{3 z^{2}-x}{\\\\left(3 z^{2}-x\\\\right)^{3}}\\n$$\\n\\nThe result can also be obtained by differentiating Equation (1) with respect to y and using Equation (2).\\n',\n",
       " '\\n6.35. Let $u=f(x, y)$ and $v=g(x, y)$, where $f$ and $g$ are continuously differentiable in some region $\\\\Re$. Prove that a necessary and sufficient condition that there exists a functional relation between $u$ and $v$ of the form $\\\\phi(u, v)$ $=0$ is the vanishing of the Jacobian; i.e., $\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=0$ identically.\\\\\\\\\\nNecessity. We have to prove that if the functional relation $\\\\phi(u, v)=0$ exists, then the Jacobian $\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=0$\\\\\\\\\\nidentically. To do this, we note that\\n\\n$$\\n\\\\begin{aligned}\\nd \\\\phi & =\\\\phi_{u} d u+\\\\phi_{v} d v=\\\\phi_{u}\\\\left(u_{x} d x+u_{y} d y\\\\right)+\\\\phi_{v}\\\\left(v_{x} d x+v_{y} d y\\\\right) \\\\\\\\\\n& =\\\\left(\\\\phi_{u} u_{x}+\\\\phi_{v} v_{x}\\\\right) d x+\\\\left(\\\\phi_{u} u_{y}+\\\\phi_{v} v_{y}\\\\right) d y=0\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n\\n\\\\begin{align*}\\n& \\\\phi_{u} u_{x}+\\\\phi_{v} v_{x}=0  \\\\tag{1}\\\\\\\\\\n& \\\\phi_{u} u_{y}+\\\\phi_{v} v_{y}=0 \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nNow $\\\\phi_{u}$ and $\\\\phi_{v}$ cannot be identically zero, since if they were, there would be no functional relation, contrary to hypothesis. Hence, it follows from Equations (1) and (2) that $\\\\left|\\\\begin{array}{ll}u_{x} & v_{x} \\\\\\\\ u_{y} & v_{y}\\\\end{array}\\\\right|=\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=0$ identically. Sufficiency. We have to prove that if the Jacobian $\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=0$ identically, then there exists a functional\\\\\\\\\\nrelation between $u$ and $v$; i.e., $\\\\phi(u, v)=0$.\\n\\nLet us first suppose that both $u_{x}=0$ and $u_{y}=0$. In this case the Jacobian is identically zero and $u$ is a constant $c_{1}$, so that the trival functional relation $u=c_{1}$ is obtained.\\n\\nLet us now assume that we do not have both $u_{x}=0$ and $u_{y}=0$; for definiteness, assume $u_{x} \\\\neq 0$. We may then, according to Theorem 1, Page 133, solve for $x$ in the equation $u=f(x, y)$ to obtain $x=F(u, y)$, from which it follows that\\n\\n\\n\\\\begin{gather*}\\nu=f\\\\{F(u, y), y\\\\}  \\\\tag{1}\\\\\\\\\\nv=g\\\\{F(u, y), y\\\\} \\\\tag{2}\\n\\\\end{gather*}\\n\\n\\nFrom these we have, respectively,\\n\\n\\n\\\\begin{gather*}\\nd u=u_{x} d x+u_{y} d y=u_{x}\\\\left(F_{u} d u+F_{y} d y\\\\right)+u_{y} d y=u_{x} F_{u} d u+\\\\left(u_{x} F_{y}+u_{y}\\\\right) d y  \\\\tag{3}\\\\\\\\\\nd v=v_{x} d x+v_{y} d y=v_{x}\\\\left(F_{u} d u+F_{y} d y\\\\right)+v_{y} d y=v_{x} F_{u} d u+\\\\left(v_{x} F_{y}+v_{y}\\\\right) d y \\\\tag{4}\\n\\\\end{gather*}\\n\\n\\nFrom Equation (3), $u_{x} F_{u}=1$ and $u_{x} F_{y}+u_{y}=0$ or (5) $F_{y}=-u_{y} / u_{x}$. Using this, Equation (4) becomes\\n\\n\\n\\\\begin{equation*}\\nd v=v_{x} F_{u} d u+\\\\left\\\\{v_{x}\\\\left(-u_{y} / u_{x}\\\\right)+v_{y}\\\\right\\\\} d y=v_{x} F_{u} d u+\\\\left(\\\\frac{u_{x} v_{y}-u_{y} v_{x}}{u_{x}}\\\\right) d y \\\\tag{6}\\n\\\\end{equation*}\\n\\n\\nBut by hypothesis $\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=\\\\left|\\\\begin{array}{ll}u_{x} & u_{y} \\\\\\\\ v_{x} & v_{y}\\\\end{array}\\\\right|=u_{x} v_{y}-u_{y} v_{x}=0$ identically, so that Equation (6) becomes $d \\\\phi$ $=v_{x} F_{u} d u$. This means essentially that, referring to Equation (2), $\\\\partial v / \\\\partial y=0$, which means that $v$ is not dependent on $y$ but depends only on $u$; i.e., $v$ is a function of $u$, which is the same as saying that the functional relation $\\\\phi(u, v)=0$ exists.\\n',\n",
       " '\\n6.36 .\\n\\n(a) If $u=\\\\frac{x+y}{1-x y}$ and $v=\\\\tan ^{-1} x+\\\\tan ^{-1} y$, find $\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y w)}$. (b) Are $u$ and $v$ functionally related? If so, find the relationship.\\n\\n(a) $\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=\\\\left|\\\\begin{array}{ll}u_{x} & u_{y} \\\\\\\\ v_{x} & v_{y}\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{cc}\\\\frac{1+y^{2}}{(1-x y)^{2}} & \\\\frac{1+x^{2}}{(1-x y)^{2}} \\\\\\\\ \\\\frac{1}{1+x^{2}} & \\\\frac{1}{1+y^{2}}\\\\end{array}\\\\right|=0 \\\\quad$ if $x y \\\\neq 1$\\n\\n(b) By Problem 6.35, since the Jacobian is identically zero in a region, there must be a functional relationship between $u$ and $v$. This is seen to be $\\\\tan v=u$; i.e., $\\\\phi(u, v)=u-\\\\tan v=0$. We can show this directly by solving for $x$ (say) in one of the equations and then substituting in the other. Thus, for example, from $v=$ $\\\\tan ^{-1} x+\\\\tan ^{-1} y$, we find $\\\\tan ^{-1} x=v-\\\\tan ^{-1} y$ and so\\n\\n$$\\nx=\\\\tan \\\\left(v-\\\\tan ^{-1} y\\\\right)=\\\\frac{\\\\tan v-\\\\tan \\\\left(\\\\tan ^{-1} y\\\\right)}{1+\\\\tan v \\\\tan \\\\left(\\\\tan ^{-1} y\\\\right)}=\\\\frac{\\\\tan v-y}{1+y \\\\tan v}\\n$$\\n\\nThen substituting this in $u=(x+y) /(1-x y)$ and simplifying, we find $u=\\\\tan v$. 6.37. (a) If $x=u-v+w, y=u^{2}-v^{2}-w^{2}$ and $z=u^{3}+v$, evaluate the Jacobian $\\\\frac{\\\\partial(x, y, z)}{\\\\partial(u, v, w)}$, and (b) explain the\\\\\\\\\\nsignificance of the nonvanishing of this Jacobian.\\n\\n(a) $\\\\frac{\\\\partial(x, y, z)}{\\\\partial(u, v, w)}=\\\\left|\\\\begin{array}{lll}x_{u} & x_{v} & x_{w} \\\\\\\\ y_{u} & y_{v} & y_{w} \\\\\\\\ z_{u} & z_{v} & z_{w}\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{ccc}1 & -1 & 1 \\\\\\\\ 2 u & -2 v & -2 w \\\\\\\\ 3 u^{2} & 1 & 0\\\\end{array}\\\\right|=6 w u^{2}+2 u+6 u^{2} v+2 w$\\n\\n(b) The given equations can be solved simultaneously for $u, v, w$ in terms of $x, y, z$ in a region $\\\\Re$ if the Jacobian is not zero in $\\\\Re$.\\n\\n\\n\\\\section*{Transformations, curvilinear coordinates}\\n',\n",
       " '6.38. A region $\\\\Re$ in the $x y$ plane is bounded by $x+y=6, x-y=2$, and $y=0$. (a) Determine the region $\\\\Re^{\\\\prime}$ in the $u v$ plane into which $\\\\Re$ is mapped under the transformation $x=u+v, y=u-v$. (b) Compute $\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}$. (c) Compare the result of (b) with the ratio of the areas of $\\\\Re$ and $\\\\Re^{\\\\prime}$.\\n\\n(a) The region $\\\\Re$ shown shaded in Figure 6.9 (a) is a triangle bounded by the lines $x+y=6, x-y=2$, and $y$ $=0$, which for distinguishing purposes are shown dotted, dashed, and heavy, respectively.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-160}\\n\\\\end{center}\\n\\n(a) $x y$ plane\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-160(1)}\\n\\\\end{center}\\n\\n(b) $u v$ plane\\n\\nFigure 6.9\\n\\nUnder the given transformation, the line $x+y=6$ is transformed into $(u+v)+(u-v)=6$; i.e., $2 u=6$ or $u=3$, which is a line (shown dotted) in the $u v$ plane of Figure 6.9(b).\\n\\nSimilarly, $x-y=2$ becomes $(u+v)-(u-v)=2$ or $v=1$, which is a line (shown dashed) in the $u v$ plane. In like manner, $y=0$ becomes $u-v=0$ or $u=v$, which is a line shown heavy in the $u v$ plane. Then the required region is bounded by $u=3, v=1$, and $u=v$, and is shown shaded in Figure 6.9(b).\\n\\n(b) $\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}=\\\\left|\\\\begin{array}{ll}\\\\frac{\\\\partial x}{\\\\partial u} & \\\\frac{\\\\partial x}{\\\\partial v} \\\\\\\\ \\\\frac{\\\\partial y}{\\\\partial u} & \\\\frac{\\\\partial y}{\\\\partial v}\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{ll}\\\\frac{\\\\partial}{\\\\partial u}(u+v) & \\\\frac{\\\\partial}{\\\\partial u}(u+v) \\\\\\\\ \\\\frac{\\\\partial}{\\\\partial u}(u-v) & \\\\frac{\\\\partial}{\\\\partial v}(u-v)\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{cc}1 & 1 \\\\\\\\ 1 & -1\\\\end{array}\\\\right|=2$\\n\\n(c) The area of triangular region $\\\\Re$ is 4 , whereas the area of triangular region $\\\\Re^{\\\\prime}$ is 2 . Hence, the ratio is $4 / 2$ $=2$, agreeing with the value of the Jacobian in (b). Since the Jacobian is constant in this case, the areas of any regions $\\\\Re$ in the $x y$ plane are twice the areas of corresponding mapped regions $\\\\mathfrak{R}^{\\\\prime}$ in the $u v$ plane.\\n',\n",
       " '\\n6.39. A region $\\\\Re$ in the $x y$ plane is bounded by $x^{2}+y^{2}=a^{2}, x^{2}+y^{2}=b^{2}, x=0$, and $y=0$, where $0<a<b$.\\n\\n(a) Determine the region $\\\\Re^{\\\\prime}$ into which $\\\\Re$ is mapped under the transformation $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$, where $\\\\rho>0,0 \\\\leqq \\\\phi<2 \\\\pi$. (b) Discuss what happens when $a=0$. (c) compute $\\\\frac{\\\\partial(x, y)}{\\\\partial(\\\\rho, \\\\phi)}$. (d) compute $\\\\frac{\\\\partial(\\\\rho, \\\\phi)}{\\\\partial(x, y)}$.\\n\\n(a) The region $\\\\Re$ [shaded in Figure 6.10(a)] is bounded by $x=0$ (dotted), $y=0$ (dotted and dashed), $x^{2}+y^{2}$ $=a^{2}$ (dashed), and $x^{2}+y^{2}=b^{2}$ (heavy).\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-161}\\n\\\\end{center}\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-161(1)}\\n\\\\end{center}\\n\\n(b)\\n\\nFigure 6.10\\n\\nUnder the given transformation, $x^{2}+y^{2}=a^{2}$ and $x^{2}+y^{2}=b^{2}$ become $\\\\rho^{2}=a^{2}$ and $\\\\rho^{2}=b^{2}$ or $\\\\rho=a$ and $\\\\rho=b$, respectively. Also, $x=0, a \\\\leqq y \\\\leqq b$ becomes $\\\\phi=\\\\pi / 2, a \\\\leqq \\\\rho \\\\leqq b ; y=0, a \\\\leqq x \\\\leqq b$ becomes $\\\\phi=0, a \\\\leqq \\\\rho \\\\leqq b$.\\n\\nThe required region $\\\\mathfrak{R}^{\\\\prime}$ is shown shaded in Figure 6.10(b).\\n\\nAnother method: Using the fact that $\\\\rho$ is the distance from the origin $O$ of the $x y$ plane and $\\\\phi$ is the angle measured from the positive $x$ axis, it is clear that the required region is given by $a \\\\leqq \\\\rho \\\\leqq b, 0 \\\\leqq \\\\phi \\\\leqq \\\\pi / 2$, as indicated in Figure 6.10(b).\\n\\n(b) If $a=0$, the region $\\\\Re$ becomes one-fourth of a circular region of radius $b$ (bounded by three sides), while $\\\\mathfrak{R}^{\\\\prime}$ remains a rectangle. The reason for this is that the point $x=0, y=0$ is mapped into $\\\\rho=0, \\\\phi=$ an indeterminate and the transformation is not one to one at this point, which is sometimes called a singular point.\\n\\n(c) $\\\\frac{\\\\partial(x, y)}{\\\\partial(\\\\rho, \\\\phi)}=\\\\left|\\\\begin{array}{ll}\\\\frac{\\\\partial}{\\\\partial \\\\rho}(\\\\rho \\\\cos \\\\phi) & \\\\frac{\\\\partial}{\\\\partial \\\\phi}(\\\\rho \\\\cos \\\\phi) \\\\\\\\ \\\\frac{\\\\partial}{\\\\partial \\\\rho}(\\\\rho \\\\sin \\\\phi) & \\\\frac{\\\\partial}{\\\\partial \\\\phi}(\\\\rho \\\\sin \\\\phi)\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{cc}\\\\cos \\\\phi & -\\\\rho \\\\sin \\\\phi \\\\\\\\ \\\\sin \\\\phi & \\\\rho \\\\cos \\\\phi\\\\end{array}\\\\right|$ $=\\\\rho\\\\left(\\\\cos ^{2} \\\\phi+\\\\sin ^{2} \\\\phi\\\\right)=\\\\rho$\\n\\n(d) From Problem 6.43(b) we have, letting $u=\\\\rho, v=\\\\phi, \\\\frac{\\\\partial(x, y)}{\\\\partial(\\\\rho, \\\\phi)} \\\\frac{\\\\partial(\\\\rho, \\\\phi)}{\\\\partial(x, y)}=1$ so that, thing (c), $\\\\frac{\\\\partial(\\\\rho, \\\\phi)}{\\\\partial(x, y)}=\\\\frac{1}{\\\\rho}$\\n\\nThis can also be obtained by direct differentiation.\\n\\nNote that from the Jacobians of these transformations it is clear why $\\\\rho=0$ (i.e., $x=0, y=0$ ) is a singular point.\\n\\n\\n\\\\section*{Mean value theorem}\\n',\n",
       " '6.40. Prove the mean value theorem for functions of two variables.\\n\\nLet $f(t)=f\\\\left(x_{0}+h t, y_{0}+k t\\\\right)$. By the mean value theorem for functions of one variable,\\n\\n\\n\\\\begin{equation*}\\nF(1)=F(0)=F^{\\\\prime}(\\\\theta) 0<\\\\theta<1 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf $x=x_{0}+h t, y=y_{0}+k t$, then $F(t)=f(x, y)$, so that by Problem 6.17,\\n\\n$F^{\\\\prime}(t)=f_{x}(d x / d t)+f_{y}(d y / d t)=h f_{x}+k f_{y}$ and $F^{\\\\prime}(\\\\theta)=h f_{x}\\\\left(x_{0}+\\\\theta h, y_{0}+\\\\theta k\\\\right)+k f_{y}\\\\left(x_{0}+\\\\theta h, y_{0}+\\\\theta k\\\\right)$\\n\\nwhere $0<\\\\theta<1$. Thus, (1) becomes\\n\\n\\n\\\\begin{equation*}\\nf\\\\left(x_{0}+h, y_{0}+k\\\\right)-f\\\\left(x_{0}, y_{0}\\\\right)=h f_{x}\\\\left(x_{0}+\\\\theta h, y_{0}+\\\\theta k\\\\right)+k f_{y}\\\\left(x_{0}+\\\\theta h, y_{0}+\\\\theta k\\\\right) \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nwhere $0<\\\\theta<1$ as required.\\n\\nNote that Equation (2), which is analogous to Equation (1) of Problem 6.14, where $h=\\\\Delta x$, has the advantage of being more symmetric (and also more useful), since only a single number $\\\\theta$ is involved.\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '6.41. Let $f(x, y)=\\\\left\\\\{\\\\begin{array}{ll}x y\\\\left(\\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}}\\\\right) & (x, y) \\\\neq(0,0) \\\\\\\\ 0 & (x, y)=(0,0)\\\\end{array}\\\\right.$. Compute (a) $f_{x}(0,0)$, (b) $f_{y}(0,0)$, (c) $f_{x x}(0,0)$ (d) $f_{y y}(0,0)$, (e) $f_{x y}(0,0)$, and (f) $f_{y x}(0,0)$.\\n\\n(a) $\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(h, 0)-f(0,0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{0}{h}=0$\\n\\n(b) $\\\\lim _{h \\\\rightarrow 0} \\\\frac{f(0, k)-f(0,0)}{k}=\\\\lim _{k \\\\rightarrow 0} \\\\frac{0}{k}=0$\\n\\nIf $(x, y) \\\\neq(0,0)$,\\n\\n$$\\n\\\\begin{aligned}\\n& f_{x}(x, y)=\\\\frac{\\\\partial}{\\\\partial x}\\\\left\\\\{x y\\\\left(\\\\frac{x^{2}-y^{2}}{x^{2}-y^{2}}\\\\right)\\\\right\\\\}=x y\\\\left(\\\\frac{4 x y^{2}}{\\\\left(x^{2}+y^{2}\\\\right)^{2}}\\\\right)+y\\\\left(\\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}}\\\\right) \\\\\\\\\\n& f_{x}(x, y)=\\\\frac{\\\\partial}{\\\\partial y}\\\\left\\\\{x y\\\\left(\\\\frac{x^{2}-y^{2}}{x^{2}-y^{2}}\\\\right)\\\\right\\\\}=x y\\\\left(\\\\frac{-4 x y^{2}}{\\\\left(x^{2}+y^{2}\\\\right)^{2}}\\\\right)+x\\\\left(\\\\frac{x^{2}-y^{2}}{x^{2}+y^{2}}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n(c) $\\\\lim _{h \\\\rightarrow 0} \\\\frac{f_{x}(h, 0)-f_{x}(0,0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{0}{h}=0$\\n\\n(d) $\\\\lim _{k \\\\rightarrow 0} \\\\frac{f_{y}(0, k)-f_{y}(0,0)}{k}=\\\\lim _{k \\\\rightarrow 0} \\\\frac{0}{k}=0$\\n\\n(e) $\\\\lim _{k \\\\rightarrow 0} \\\\frac{f_{x}(0, k)-f_{x}(0,0)}{k}=\\\\lim _{k \\\\rightarrow 0} \\\\frac{-k}{k}=-1$\\n\\n(f) $\\\\lim _{h \\\\rightarrow 0} \\\\frac{f_{y}(h, 0)-f_{y}(0,0)}{h}=\\\\lim _{h \\\\rightarrow 0} \\\\frac{h}{h}=1$\\n\\nNote that $f_{x y} \\\\neq f_{y x}$ at $(0,0)$. See Problem 6.13.\\n',\n",
       " '\\n6.42. Show that under the transformation $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$ the equation $\\\\frac{\\\\partial^{2} V}{\\\\partial x^{2}}+\\\\frac{\\\\partial^{2} V}{\\\\partial y^{2}}=0$ become $\\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho^{2}}+\\\\frac{1}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}+\\\\frac{1}{\\\\rho^{2}} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\phi^{2}}=0$.\\n\\nWe have\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial V}{\\\\partial x}=\\\\frac{\\\\partial V}{\\\\partial \\\\rho} \\\\frac{\\\\partial \\\\rho}{\\\\partial x}+\\\\frac{\\\\partial V}{\\\\partial \\\\phi} \\\\frac{\\\\partial \\\\phi}{\\\\partial x}  \\\\tag{1}\\\\\\\\\\n& \\\\frac{\\\\partial V}{\\\\partial y}=\\\\frac{\\\\partial V}{\\\\partial \\\\rho} \\\\frac{\\\\partial \\\\rho}{\\\\partial y}+\\\\frac{\\\\partial V}{\\\\partial \\\\phi} \\\\frac{\\\\partial \\\\phi}{\\\\partial y} \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nDifferentiate $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$ with respect to $x$, remembering that $\\\\rho$ and $\\\\phi$ are functions of $x$ and $y$\\n\\n$$\\n1=-\\\\rho \\\\sin \\\\phi \\\\frac{\\\\partial \\\\phi}{\\\\partial x}+\\\\cos \\\\phi \\\\frac{\\\\partial \\\\rho}{\\\\partial x} . \\\\quad 0=\\\\rho \\\\cos \\\\phi \\\\frac{\\\\partial \\\\phi}{\\\\partial x}+\\\\sin \\\\phi \\\\frac{\\\\partial \\\\rho}{\\\\partial x}\\n$$\\n\\nSolving simultaneously,\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial \\\\rho}{\\\\partial x}=\\\\cos \\\\phi, \\\\quad \\\\frac{\\\\partial \\\\phi}{\\\\partial x}=-\\\\frac{\\\\sin \\\\phi}{\\\\rho} \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nSimilarly, differentiate with respect to $y$. Then\\n\\n$$\\n0=-\\\\rho \\\\sin \\\\phi \\\\frac{\\\\partial \\\\phi}{\\\\partial y}+\\\\cos \\\\phi \\\\frac{\\\\partial \\\\rho}{\\\\partial y}, \\\\quad 1=\\\\rho \\\\cos \\\\phi \\\\frac{\\\\partial \\\\phi}{\\\\partial y}+\\\\sin \\\\phi \\\\frac{\\\\partial \\\\rho}{\\\\partial y}\\n$$\\n\\nSolving simultaneously,\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial \\\\rho}{\\\\partial y}=\\\\sin \\\\phi, \\\\quad \\\\frac{\\\\partial \\\\phi}{\\\\partial y}=\\\\frac{\\\\cos \\\\phi}{\\\\rho} \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nThen, from Equations (1) and (2),\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial V}{\\\\partial x}=\\\\cos \\\\phi \\\\frac{\\\\partial V}{\\\\partial \\\\rho}-\\\\frac{\\\\sin \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}  \\\\tag{5}\\\\\\\\\\n& \\\\frac{\\\\partial V}{\\\\partial y}=\\\\sin \\\\phi \\\\frac{\\\\partial V}{\\\\partial \\\\rho}+\\\\frac{\\\\cos \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\phi} \\\\tag{6}\\n\\\\end{align*}\\n\\n\\nHence,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{\\\\partial^{2} V}{\\\\partial x^{2}}= & \\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\frac{\\\\partial V}{\\\\partial x}\\\\right)=\\\\frac{\\\\partial}{\\\\partial \\\\rho}\\\\left(\\\\frac{\\\\partial V}{\\\\partial x}\\\\right) \\\\frac{\\\\partial \\\\rho}{\\\\partial x}+\\\\frac{\\\\partial}{\\\\partial \\\\phi}\\\\left(\\\\frac{\\\\partial V}{\\\\partial x}\\\\right) \\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\\\\\\\n= & \\\\frac{\\\\partial}{\\\\partial \\\\rho}\\\\left(\\\\cos \\\\phi \\\\frac{\\\\partial V}{\\\\partial \\\\rho}-\\\\frac{\\\\sin \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}\\\\right) \\\\frac{\\\\partial \\\\rho}{\\\\partial x}+\\\\frac{\\\\partial}{\\\\partial \\\\phi}\\\\left(\\\\cos \\\\phi \\\\frac{\\\\partial V}{\\\\partial \\\\rho}-\\\\frac{\\\\sin \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}\\\\right) \\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\\\\\\\n= & \\\\left(\\\\cos \\\\phi \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho^{2}}+\\\\frac{\\\\sin \\\\phi}{\\\\rho^{2}} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}-\\\\frac{\\\\sin \\\\phi}{\\\\rho} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho}\\\\right)(\\\\cos \\\\phi) \\\\\\\\\\n& +\\\\left(-\\\\sin \\\\phi \\\\frac{\\\\partial V}{\\\\partial \\\\rho}+\\\\cos \\\\phi \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho \\\\partial \\\\phi}-\\\\frac{\\\\cos \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}-\\\\frac{\\\\sin \\\\phi}{\\\\rho} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\phi^{2}}\\\\right)\\\\left(-\\\\frac{\\\\sin \\\\phi}{\\\\rho}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nwhich simplifies to\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial^{2} V}{\\\\partial x^{2}}=\\\\cos ^{2} \\\\phi \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho^{2}}+\\\\frac{2 \\\\sin \\\\phi \\\\cos \\\\phi}{\\\\rho^{2}} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}-\\\\frac{2 \\\\sin \\\\phi \\\\cos \\\\phi}{\\\\rho} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho \\\\partial \\\\phi}+\\\\frac{\\\\sin ^{2} \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\rho}+\\\\frac{\\\\sin ^{2} \\\\phi}{\\\\rho^{2}} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\phi^{2}} \\\\tag{7}\\n\\\\end{equation*}\\n\\n\\nSimilarly,\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial^{2} V}{\\\\partial y^{2}}=\\\\sin ^{2} \\\\phi \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho^{2}}-\\\\frac{2 \\\\sin \\\\phi \\\\cos \\\\phi}{\\\\rho^{2}} \\\\frac{\\\\partial V}{\\\\partial \\\\phi}+\\\\frac{2 \\\\sin \\\\phi \\\\cos \\\\phi}{\\\\rho} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho \\\\partial \\\\phi}+\\\\frac{\\\\cos ^{2} \\\\phi}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\rho}+\\\\frac{\\\\cos ^{2} \\\\phi}{\\\\rho^{2}} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\phi^{2}} \\\\tag{8}\\n\\\\end{equation*}\\n\\n\\nAdding Equations (7) and (8), we find, as required, $\\\\frac{\\\\partial^{2} V}{\\\\partial x^{2}}+\\\\frac{\\\\partial^{2} V}{\\\\partial y^{2}}=\\\\frac{\\\\partial^{2} V}{\\\\partial \\\\rho^{2}}+\\\\frac{1}{\\\\rho} \\\\frac{\\\\partial V}{\\\\partial \\\\rho}+\\\\frac{1}{\\\\rho^{2}} \\\\frac{\\\\partial^{2} V}{\\\\partial \\\\phi^{2}}=0$.\\n',\n",
       " '\\n6.43. (a) If $x=f(u, v)$ and $y=g(u, v)$, where $u=\\\\phi(r, s)$ and $v=\\\\psi(r, s)$, prove that $\\\\frac{\\\\partial(x, y)}{\\\\partial(r, s)}=\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)} \\\\frac{\\\\partial(u, v)}{\\\\partial(r, s)}$.\\n\\n(b) Prove that $\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)} \\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=1$, provided $\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)} \\\\neq 0$, and interpret geometrically.\\\\\\\\\\n(a) $\\\\frac{\\\\partial(x, y)}{\\\\partial(r, s)}=\\\\left|\\\\begin{array}{ll}x_{r} & x_{s} \\\\\\\\ y_{r} & y_{s}\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{ll}x_{u} u_{r}+x_{v} v_{r} & x_{u} u_{s}+x_{v} v_{s} \\\\\\\\ y_{u} u_{r}+y_{v} v_{r} & y_{u} u_{s}+y_{v} v_{s}\\\\end{array}\\\\right|$\\n\\n$$\\n=\\\\left|\\\\begin{array}{ll}\\nx_{u} & x_{v} \\\\\\\\\\ny_{u} & y_{v}\\n\\\\end{array}\\\\right|\\\\left|\\\\begin{array}{cc}\\nu_{r} & u_{s} \\\\\\\\\\nv_{r} & v_{s}\\n\\\\end{array}\\\\right| w=\\\\frac{\\\\partial(x, y) \\\\partial(u, v)}{\\\\partial(u, v) \\\\partial(r, s)}\\n$$\\n\\nusing a theorem on multiplication of determinants (see Problem 6.108). We have assumed here, of course, the existence of the partial derivatives involved.\\n\\n(b) Place $r=x, s=y$ in the result of (a). Then $\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)} \\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=\\\\frac{\\\\partial(x, y)}{\\\\partial(x, y)}=1$.\\n\\nThe equations $x=f(u, v), y=g(u, v)$ define a transformation between points $(x, y)$ in the $x y$ plane and points $(u, v)$ in the $u v$ plane. The inverse transformation is given by $u=\\\\phi(x, y), v=\\\\psi(x, y)$. The result obtained states that the Jacobians of these transformations are reciprocals of each other.\\n',\n",
       " '\\n6.44. Show that $F(x y, z-2 x)=0$ satisfies, under suitable conditions, the equation $x(\\\\partial z / \\\\partial x)-y(\\\\partial z / \\\\partial y)=2 x$. What are these conditions?\\n\\nLet $u=x y, v=z-2 x$. Then $F(u, v)=0$ and\\n\\n\\n\\\\begin{equation*}\\nd F=F_{u} d u+F_{v} d v=F_{u}(x d y+y d x)+F_{v}(d z-2 d x)=0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nTaking $z$ as dependent variable and $x$ and $y$ as independent variables, we have $d z=z_{x} d x+z_{y} d y$. Then substituting in Equation (1), we find\\n\\n$$\\n\\\\left(y F_{u}+F_{v} z_{x}-2\\\\right) d x+\\\\left(x F_{u}+F_{v} z_{y}\\\\right) d y=0\\n$$\\n\\nHence, since $x$ and $y$ are independent, we have\\n\\n\\n\\\\begin{gather*}\\ny F_{u}+F_{v} z_{x}-2=0  \\\\tag{2}\\\\\\\\\\nx F_{u}+F_{v} z_{y}=0 \\\\tag{3}\\n\\\\end{gather*}\\n\\n\\nSolve for $F_{u}$ in Equation (3) and substitute in (2). Then we obtain the required result $x z_{x}-y z_{y}=2 x$ upon dividing by $F_{v}$ (supposed not equal to zero).\\n\\nThe result will certainly be valid if we assume that $F(u, v)$ is continuously differentiable and that $F_{v} \\\\neq 0$.\\n\\n',\n",
       " '7.1. Show that addition of vectors is commutative, i.e., $\\\\mathbf{A}+\\\\mathbf{B}=\\\\mathbf{B}+\\\\mathbf{A}$. See Figure 7.15.\\n\\n$$\\n\\\\mathbf{O P}+\\\\mathbf{P Q}=\\\\mathbf{O Q} \\\\text { or } \\\\mathbf{A}+\\\\mathbf{B}=\\\\mathbf{C}\\n$$\\n\\nand\\n\\n$$\\n\\\\mathbf{O R}+\\\\mathbf{R Q}=\\\\mathbf{O Q} \\\\text { or } \\\\mathbf{B}+\\\\mathbf{A}=\\\\mathbf{C}\\n$$\\n\\nThen $\\\\mathbf{A}+\\\\mathbf{B}=\\\\mathbf{B}+\\\\mathbf{A}$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-185}\\n\\\\end{center}\\n\\nFigure 7.15\\n',\n",
       " '\\n7.2. Show that the addition of vectors is associative, i.e., $\\\\mathbf{A}+(\\\\mathbf{B}+\\\\mathbf{C})=$ $(\\\\mathbf{A}+\\\\mathbf{B})+\\\\mathbf{C}$. See Figure 7.16.\\n\\n$\\\\mathbf{O P}+\\\\mathbf{P Q}=\\\\mathbf{O Q}=(\\\\mathbf{A}+\\\\mathbf{B})$ and $\\\\mathbf{P Q}+\\\\mathbf{Q R}=\\\\mathbf{P R}=(\\\\mathbf{B}+\\\\mathbf{C})$\\n\\nSince\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\mathbf{O P}+\\\\mathbf{P R}=\\\\mathbf{O R}=\\\\mathbf{D} \\\\text {, i.e., } \\\\mathbf{A}+(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{D} \\\\\\\\\\n& \\\\mathbf{O Q}+\\\\mathbf{Q R}=\\\\mathbf{O R}=\\\\mathbf{D} \\\\text {, i.e., }(\\\\mathbf{A}+\\\\mathbf{B})+\\\\mathbf{C}=\\\\mathbf{D}\\n\\\\end{aligned}\\n$$\\n\\nwe have $\\\\mathbf{A}+(\\\\mathbf{B}+\\\\mathbf{C})=(\\\\mathbf{A}+\\\\mathbf{B})+\\\\mathbf{C}$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-185(1)}\\n\\\\end{center}\\n\\nFigure 7.16\\n\\nExtensions of the results of Problems 7.1 and 7.2 show that the order of addition of any number of vectors is immaterial.\\n',\n",
       " '\\n7.3. An automobile travels 3 miles due north, then 5 miles northeast as shown in Figure 7.17. Represent these displacements graphically and determine the resultant displacement (a) graphically and (b) analytically.\\n\\nVector OP or A represents displacement of 3 miles due north\\n\\nVector $\\\\mathbf{P Q}$ or $\\\\mathbf{B}$ represents displacement of 5 miles northeast.\\n\\nVector $\\\\mathbf{O Q}$ or $\\\\mathbf{C}$ represents the resultant displacement or sum of vectors $\\\\mathbf{A}$ and $\\\\mathbf{B}$, i.e., $\\\\mathbf{C}=\\\\mathbf{A}+\\\\mathbf{B}$. This is the triangle law of vector addition.\\n\\nThe resultant vector $\\\\mathbf{O Q}$ can also be obtained by constructing the diagonal of the parallelogram $\\\\boldsymbol{O} \\\\boldsymbol{P} \\\\boldsymbol{Q} \\\\boldsymbol{R}$ having vectors $\\\\mathbf{O P}=\\\\mathbf{A}$ and $\\\\mathbf{O R}$ (equal to vector $\\\\mathbf{P Q}$ or $\\\\mathbf{B}$ ) as sides. This is the parallelogram law of vector addition.\\n\\n(a) Graphical Determination of Resultant. Lay off the 1-mile unit\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-185(2)}\\n\\\\end{center}\\n\\nFigure 7.17 on vector $\\\\mathbf{O Q}$ to find the magnitude 7.4 miles (approximately).\\n\\nAngle $E O Q=61.5^{\\\\circ}$, using a protractor. Then vector $\\\\mathbf{O Q}$ has magnitude 7.4 miles and direction $61.5^{\\\\circ}$ north of east.\\n\\n(b) Analytical Determination of Resultant. From triangle $O P Q$, denoting the magnitudes of $\\\\mathbf{A}, \\\\mathbf{B}, \\\\mathbf{C}$ by $A, B$, $C$, we have by the law of cosines\\n\\n$$\\nC^{2}=A^{2}+B^{2}-2 A B \\\\cos O P Q=3^{2}+5^{2}-2(3)(5) \\\\cos 135^{\\\\circ}=34+15 \\\\sqrt{2}=55.21\\n$$\\n\\nand $C=7.43$ (approximately).\\n\\nBy the law of sines, $\\\\frac{A}{\\\\sin \\\\angle O Q P}=\\\\frac{C}{\\\\sin \\\\angle O P Q}$. Then\\n\\n$$\\n\\\\sin \\\\angle O P Q=\\\\frac{A \\\\sin \\\\angle O P Q}{C}=\\\\frac{3(0.707)}{7.43}=0.2855 \\\\text { and } \\\\angle O Q P=16^{\\\\circ} 35^{\\\\prime}\\n$$\\n\\nThus, vector OQ has magnitude 7.43 miles and direction $\\\\left(45^{\\\\circ}+16^{\\\\circ} 35^{\\\\prime}\\\\right)=61^{\\\\circ} 35^{\\\\prime}$ north of east.\\n',\n",
       " '\\n7.4. Prove that if $\\\\mathbf{a}$ and $\\\\mathbf{b}$ are noncollinear, then $x \\\\mathbf{a}+y \\\\mathbf{b}=0$ implies $x=y=0$. Is the set $\\\\{\\\\mathbf{a}, \\\\mathbf{b}\\\\}$ linearly independent or linearly dependent?\\n\\nSuppose $x \\\\neq 0$. Then $x \\\\mathbf{a}+\\\\mathbf{y b}=\\\\mathbf{0}$ implies $x \\\\mathbf{a}=-y \\\\mathbf{b}$ or $\\\\mathbf{a}=-(y / x) \\\\mathbf{b}$; i.e., $\\\\mathbf{a}$ and $\\\\mathbf{b}$ must be parallel to the same line (collinear), contrary to hypothesis. Thus, $x=0$; then $y \\\\mathbf{b}=\\\\mathbf{0}$, from which $y=0$. The set is linearly independent.\\n',\n",
       " '\\n7.5. Prove that $x_{1} \\\\mathbf{a}+y_{1} \\\\mathbf{b}=x_{2} \\\\mathbf{a}+y_{2} \\\\mathbf{b}$, where $\\\\mathbf{a}$ and $\\\\mathbf{b}$ are noncollinear, then $x_{1}=x_{2}$ and $y_{1}=y_{2}$.\\n\\n$x_{1} \\\\mathbf{a}+y_{1} \\\\mathbf{b}=x_{2} \\\\mathbf{a}+y_{2} \\\\mathbf{b}$ can be written\\n\\n$$\\nx_{1} \\\\mathbf{a}+y_{1} \\\\mathbf{b}-\\\\left(x_{2} \\\\mathbf{a}+y_{2} \\\\mathbf{b}\\\\right)=\\\\mathbf{0} \\\\text { or }\\\\left(x_{1}-x_{2}\\\\right) \\\\mathbf{a}+\\\\left(y_{1}-y_{2}\\\\right) \\\\mathbf{b}=\\\\mathbf{0}\\n$$\\n\\nHence, by Problem 7.4, $x_{1}-x_{2}=0, y_{1}-y_{2}=0$, or $x_{1}=x_{2}, y_{1}=y_{2}$.\\n\\nExtensions are possible (see Problem 7.49).\\n',\n",
       " '\\n7.6. Prove that the diagonals of a parallelogram bisect each other.\\n\\nLet $A B C D$ be the given parallelogram with diagonals intersecting at $P$, as shown in Figure 7.18 .\\n\\nSince $\\\\mathbf{B D}+\\\\mathbf{a}=\\\\mathbf{b}, \\\\mathbf{B D}=\\\\mathbf{b}-\\\\mathbf{a}$. Then $\\\\mathbf{B P}=x(\\\\mathbf{b}-\\\\mathbf{a})$.\\n\\nSince $\\\\mathbf{A C}=\\\\mathbf{a}+\\\\mathbf{b}, \\\\mathbf{A P}=y(\\\\mathbf{a}+\\\\mathbf{b})$.\\n\\nBut $\\\\mathbf{A B}=\\\\mathbf{A P}+\\\\mathbf{P B}=\\\\mathbf{A P}-\\\\mathbf{B P}$; i.e., $\\\\mathbf{a}=y(\\\\mathbf{a}+\\\\mathbf{b})-x(\\\\mathbf{b}-\\\\mathbf{a})$ $=(x+y) \\\\mathbf{a}+(y-x) \\\\mathbf{b}$.\\n\\nSince $\\\\mathbf{a}$ and $\\\\mathbf{b}$ are noncollinear, we have, by Problem 7.5, $x+y=1$ and $y-x=0$; i.e., $x=y=1 / 2$ and $P$ is the midpoint of both diagonals.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-186}\\n\\\\end{center}\\n\\nFigure 7.18\\n',\n",
       " '\\n7.7. Prove that the line joining the midpoints of two sides of a triangle is parallel to the third side and has half its length.\\n\\nFrom Figure 7.19, $\\\\mathbf{A C}+\\\\mathbf{C B}=\\\\mathbf{A B}$ or $\\\\mathbf{b}+\\\\mathbf{a}=\\\\mathbf{c}$.\\n\\nLet $\\\\mathbf{D E}=\\\\mathbf{d}$ be the line joining the midpoints of sides $A C$ and $C B$. Then $\\\\mathbf{d}=\\\\mathrm{DC}+\\\\mathrm{CE}=\\\\frac{\\\\mathbf{1}}{\\\\mathbf{2}} \\\\mathbf{b}+\\\\frac{1}{\\\\mathbf{2}} \\\\mathbf{a}=\\\\frac{1}{2}(\\\\mathbf{b}+\\\\mathbf{a})=\\\\frac{1}{2} \\\\mathbf{c}$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-186(2)}\\n\\\\end{center}\\n\\nFigure 7.19\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-186(1)}\\n\\\\end{center}\\n\\nFigure 7.20 $(\\\\overline{O Q})^{2}=(\\\\overline{O R})^{2}+(\\\\overline{R Q})^{2}$.\\n\\nThen $(\\\\overline{O P})^{2}=(\\\\overline{O R})^{2}+(\\\\overline{R Q})^{2}+(\\\\overline{Q P})^{2}$ or $A^{2}=A_{1}^{2}+A_{2}^{2}+A_{3}^{2}$, i.e.. $A=\\\\sqrt{A_{1}^{2}+A_{2}^{2}+A_{3}^{2}}$.\\n',\n",
       " '\\n7.9. Determine the vector having initial point $P\\\\left(x_{1}, y_{1}, z_{1}\\\\right)$ and terminal point $Q\\\\left(x_{2}, y_{2}, z_{2}\\\\right)$ and find its magnitude. See Figure 7.21 .\\n\\nThe position vector of $P$ is $\\\\mathbf{r}_{1}=x_{1} \\\\mathbf{i}+y_{1} \\\\mathbf{j}+z_{1} \\\\mathbf{k}$.\\n\\nThe position vector of $Q$ is $\\\\mathbf{r}_{2}=x_{2} \\\\mathbf{i}+y_{2} \\\\mathbf{j}+z_{2} \\\\mathbf{k}$.\\n\\n$\\\\mathbf{r}_{1}=\\\\mathbf{P Q}=\\\\mathbf{r}_{2}$ or\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{P Q}=\\\\mathbf{r}_{2}-\\\\mathbf{r}_{1} & =\\\\left(x_{2} \\\\mathbf{i}+y_{2} \\\\mathbf{j}+z_{2} \\\\mathbf{k}\\\\right)-\\\\left(x_{1} \\\\mathbf{i}+y_{1} \\\\mathbf{j}+z_{1} \\\\mathbf{k}\\\\right) \\\\\\\\\\n& =\\\\left(x_{2}-x_{1}\\\\right) \\\\mathbf{i}+\\\\left(y_{2}-y_{1}\\\\right) \\\\mathbf{j}+\\\\left(z_{2}-z_{1}\\\\right) \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\nMagnitude of $\\\\mathbf{P Q}=\\\\overline{P Q}$\\n\\n$=\\\\sqrt{\\\\left(x_{2}-x_{1}\\\\right)^{2}+\\\\left(y_{2}-y_{1}\\\\right)^{2}+\\\\left(z_{2}-z_{1}\\\\right)^{2}}$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-187(2)}\\n\\\\end{center}\\n\\nFigure 7.21\\n\\nNote that this is the distance between points $P$ and $Q$.\\n\\n\\n\\\\section*{The dot or scalar product}\\n',\n",
       " '7.10. Prove that the projection of $\\\\mathbf{A}$ on $\\\\mathbf{B}$ is equal to $\\\\mathbf{A} \\\\cdot \\\\mathbf{b}$, where $\\\\mathbf{b}$, where $\\\\mathbf{b}$ is a unit vector in the direction of $\\\\mathbf{B}$.\\n\\nThrough the initial and terminal points of A pass planes perpendicular to $\\\\mathbf{B}$ at $G$ and $H$, respectively, as in Figure 7.22; then\\n\\nProjection of $\\\\mathbf{A}$ on $\\\\mathbf{B}=\\\\overline{G H}=\\\\overline{E F}=A \\\\cos \\\\theta=\\\\mathbf{A} \\\\cdot \\\\mathbf{b}$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-187(1)}\\n\\\\end{center}\\n\\nFigure 7.22\\n',\n",
       " '\\n7.11. Prove $\\\\mathbf{A} \\\\cdot(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{A} \\\\cdot \\\\mathbf{B}+\\\\mathbf{A} \\\\cdot \\\\mathbf{C}$. See Figure 7.23\\n\\nLet $\\\\mathbf{a}$ be a unit vector in the direction of $\\\\mathbf{A}$; then\\n\\nProjection of $(\\\\mathbf{B}+\\\\mathbf{C})$ on $\\\\mathbf{A}=$ projection of $\\\\mathbf{B}$ on $\\\\mathbf{A}+$ projection of $\\\\mathbf{C}$ on $\\\\mathbf{A}$\\n\\n$$\\n(\\\\mathbf{B}+\\\\mathbf{C}) \\\\cdot \\\\mathbf{a}=\\\\mathbf{B} \\\\cdot \\\\mathbf{a}+\\\\mathbf{C} \\\\cdot \\\\mathbf{a}\\n$$\\n\\nMultiplying by $A$.\\n\\n$$\\n(\\\\mathbf{B}+\\\\mathbf{C}) \\\\cdot A \\\\mathbf{a}=\\\\mathbf{B} \\\\cdot A \\\\mathbf{a}+\\\\mathbf{C} \\\\cdot A \\\\mathbf{a}\\n$$\\n\\nand\\n\\n$$\\n(\\\\mathbf{B}+\\\\mathbf{C}) \\\\cdot \\\\mathbf{A}=\\\\mathbf{B} \\\\cdot \\\\mathbf{A}+\\\\mathbf{C} \\\\cdot \\\\mathbf{A}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-187}\\n\\\\end{center}\\n\\nFigure 7.23\\n\\nThen by the commutative law for dot products.\\n\\n$$\\n\\\\mathbf{A} \\\\cdot(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{A} \\\\cdot \\\\mathbf{B}+\\\\mathbf{A} \\\\cdot \\\\mathbf{C}\\n$$\\n\\nand the distributive law is valid.\\n',\n",
       " '\\n7.12. Prove that $(\\\\mathbf{A}+\\\\mathbf{B}) \\\\cdot(\\\\mathbf{C}+\\\\mathbf{D})=\\\\mathbf{A} \\\\cdot \\\\mathbf{C}+\\\\mathbf{A} \\\\cdot \\\\mathbf{D}+\\\\mathbf{B} \\\\cdot \\\\mathbf{C}+\\\\mathbf{B} \\\\cdot \\\\mathbf{D}$.\\n\\nBy Problem 7.11, (A+B) $(\\\\mathbf{C}+\\\\mathbf{D})=\\\\mathbf{A} \\\\cdot(\\\\mathbf{C}+(\\\\mathbf{C}+\\\\mathbf{D})+\\\\mathbf{B} \\\\cdot(\\\\mathbf{C}+\\\\mathbf{D})=\\\\mathbf{A} \\\\cdot \\\\mathbf{C}+\\\\mathbf{A} \\\\cdot \\\\mathbf{D}+\\\\mathbf{B} \\\\cdot \\\\mathbf{C}+\\\\mathbf{B} \\\\cdot \\\\mathbf{D}$. The ordinary laws of algebra are valid for dot products where the operations are defined.\\n',\n",
       " '\\n7.13. Evaluate each of the following.\\n\\n(a) $\\\\mathbf{i} \\\\cdot \\\\mathbf{i}=|\\\\mathbf{i}||\\\\mathbf{i}| \\\\cos 0^{\\\\circ}=(1)(1)(1)=1$\\n\\n(b) $\\\\mathbf{i} \\\\cdot \\\\mathbf{k}=|\\\\mathbf{i}||\\\\mathbf{k}| \\\\cos 90^{\\\\circ}=(1)(1)(0)=0$\\n\\n(c) $\\\\mathbf{k} \\\\cdot \\\\mathbf{j}=|\\\\mathbf{k}||\\\\mathbf{j}| \\\\cos 90^{\\\\circ}=(1)(1)(0)=0$\\n\\n(d) $\\\\mathbf{j} \\\\cdot(2 \\\\mathbf{i}-3 \\\\mathbf{j}+\\\\mathbf{k})=2 \\\\mathbf{j} \\\\cdot \\\\mathbf{i}-3 \\\\mathbf{j} \\\\cdot \\\\mathbf{j}+\\\\mathbf{j} \\\\cdot \\\\mathbf{k}=0-3+0=-3$\\n\\n(e) $(2 \\\\mathbf{i}-\\\\mathbf{j}) \\\\cdot(3 \\\\mathbf{i}+\\\\mathbf{k})=2 \\\\mathbf{i} \\\\cdot(3 \\\\mathbf{i}+\\\\mathbf{k})-\\\\mathbf{j} \\\\cdot(3 \\\\mathbf{i}+\\\\mathbf{k})=6 \\\\mathbf{i} \\\\cdot \\\\mathbf{i}+2 \\\\mathbf{i} \\\\cdot \\\\mathbf{k}-3 \\\\mathbf{j} \\\\cdot \\\\mathbf{i}-\\\\mathbf{j} \\\\cdot \\\\mathbf{k}=6+0-0-0=6$\\n',\n",
       " '\\n7.14. If $\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}$ and $\\\\mathbf{B}=B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}$, prove that $\\\\mathbf{A} \\\\cdot \\\\mathbf{B}=A_{1} B_{1}+A_{2} B_{2}+A_{3} B_{3}$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{A} \\\\cdot \\\\mathbf{B}= & \\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\cdot\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n= & A_{1} \\\\mathbf{i} \\\\cdot\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right)+A_{2} \\\\mathbf{j} \\\\cdot\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right)+A_{3} \\\\mathbf{k} \\\\cdot\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n= & A_{1} B_{1} \\\\mathbf{i} \\\\cdot \\\\mathbf{i}+A_{1} B_{2} \\\\mathbf{i} \\\\cdot \\\\mathbf{j}+A_{1} B_{3} \\\\mathbf{i} \\\\cdot \\\\mathbf{k}+A_{2} B_{1} \\\\mathbf{j} \\\\cdot \\\\mathbf{i}+A_{2} B_{2} \\\\mathbf{j} \\\\cdot \\\\mathbf{j}+A_{2} B_{3} \\\\mathbf{j} \\\\cdot \\\\mathbf{k} \\\\\\\\\\n& +A_{3} B_{1} \\\\mathbf{k} \\\\cdot \\\\mathbf{i}+A_{3} B_{2} \\\\mathbf{k} \\\\cdot \\\\mathbf{j}+A_{3} B_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{k} \\\\\\\\\\n= & A_{1} B_{1}+A_{2} B_{2}+A_{3} B_{3}\\n\\\\end{aligned}\\n$$\\n\\nsince $\\\\mathbf{i} \\\\cdot \\\\mathbf{j}=\\\\mathbf{k} \\\\cdot \\\\mathbf{k}=1$ and all other dot products are zero.\\n',\n",
       " '\\n7.15. If $\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}$. show that $A=\\\\sqrt{\\\\mathrm{A} \\\\cdot \\\\mathrm{A}}=\\\\sqrt{A_{1}^{2}+A_{2}^{2}+A_{3}^{2}}$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\quad \\\\mathbf{A} \\\\cdot \\\\mathbf{A}= & (A)(A) \\\\cos 0=A^{2} \\\\text {. Then } A=\\\\sqrt{\\\\mathbf{A} \\\\cdot \\\\mathbf{A}} \\\\\\\\\\n\\\\text { Also, } \\\\mathbf{A} \\\\cdot \\\\mathbf{A} & =\\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\cdot\\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n& =\\\\left(A_{1}\\\\right)\\\\left(A_{1}\\\\right)+\\\\left(A_{2}\\\\right)\\\\left(A_{2}\\\\right)+\\\\left(A_{3}\\\\right)\\\\left(A_{3}\\\\right)=A_{1}^{2}+A_{2}^{2}+A_{3}^{2}\\n\\\\end{aligned}\\n$$\\n\\nBy Problem 7.14, taking $\\\\mathbf{B}=\\\\mathbf{A}$.\\n\\nThen $A=\\\\sqrt{\\\\mathbf{A} \\\\cdot \\\\mathbf{A}}=\\\\sqrt{A_{1}^{2}+A_{2}^{2}+A_{3}^{2}}$. is the magnitude of $\\\\mathbf{A}$. Sometimes $\\\\mathbf{A} \\\\cdot \\\\mathbf{A}$ is written $\\\\mathbf{A}^{2}$.\\n\\n\\n\\\\section*{The cross or vector product}\\n',\n",
       " '7.16. Prove $\\\\mathbf{A} \\\\times \\\\mathbf{B}=-\\\\mathbf{B} \\\\times \\\\mathbf{A}$.\\n\\n$\\\\mathbf{A} \\\\times \\\\mathbf{B}=\\\\mathbf{C}$ has magnitude $A B \\\\sin \\\\theta$ and direction such that $\\\\mathbf{A}, \\\\mathbf{B}$, and $\\\\mathbf{C}$ form a right-handed system. See Figure 7.24(a).\\n\\n$\\\\mathbf{B} \\\\times \\\\mathbf{A}=\\\\mathbf{D}$ has magnitude $B A \\\\sin \\\\theta$ and direction such that $\\\\mathbf{B}, \\\\mathbf{A}$, and $\\\\mathbf{D}$ form a right-handed system. See Figure 7.24(b).\\n\\nThen $\\\\mathbf{D}$ has the same magnitude as $\\\\mathbf{C}$ but is opposite in direction; i.e., $\\\\mathbf{C}=-\\\\mathbf{D}$ or $\\\\mathbf{A} \\\\times \\\\mathbf{B}=-\\\\mathbf{B} \\\\times \\\\mathbf{A}$.\\n\\nThe commutative law for cross products is not valid.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-188(1)}\\n\\\\end{center}\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-188}\\n\\\\end{center}\\n\\n(b)\\n\\nFigure 7.24\\n',\n",
       " '\\n7.17. Prove that $\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{A} \\\\times \\\\mathbf{B}+\\\\mathbf{A} \\\\times \\\\mathbf{C}$ for the case where $\\\\mathbf{A}$ is perpendicular to $\\\\mathbf{B}$ and also to $\\\\mathbf{C}$.\\n\\nSince $\\\\mathbf{A}$ is perpendicular to $\\\\mathbf{B}, \\\\mathbf{A} \\\\times \\\\mathbf{B}$ is a vector perpendicular to the plane of $\\\\mathbf{A}$ and $\\\\mathbf{B}$ and having magnitude $A B \\\\sin 90^{\\\\circ}=A B$ or magnitude of $A \\\\mathbf{B}$. This is equivalent to multiplying vector $\\\\mathbf{B}$ by $A$ and rotating the resultant vector through $90^{\\\\circ}$ to the position shown in Figure 7.25.\\n\\nSimilarly, $\\\\mathbf{A} \\\\times \\\\mathbf{C}$ is the vector obtained by multiplying $\\\\mathbf{C}$ by $A$ and rotating the resultant vector through $90^{\\\\circ}$ to the position shown.\\n\\nIn like manner, $\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})$ is the vector obtained by multiplying $\\\\mathbf{B}+\\\\mathbf{C}$ by $A$ and rotating the resultant vector through $90^{\\\\circ}$ to the position shown.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-189}\\n\\\\end{center}\\n\\nFigure 7.25\\n\\nSince $\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})$ is the diagonal of the parallelogram with $\\\\mathbf{A} \\\\times \\\\mathbf{B}$ and $\\\\mathbf{A} \\\\times \\\\mathbf{C}$ as sides, we have $\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{A} \\\\times \\\\mathbf{B}+\\\\mathbf{A} \\\\times \\\\mathbf{C}$.\\n',\n",
       " '\\n7.18. Prove that $\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{A} \\\\times \\\\mathbf{B}+\\\\mathbf{A} \\\\times \\\\mathbf{C}$ in the general case where $\\\\mathbf{A}, \\\\mathbf{B}$, and $\\\\mathbf{C}$ are noncoplanar. See Figure 7.26\\n\\nResolve $\\\\mathbf{B}$ into two component vectors, one perpendicular to $\\\\mathbf{A}$ and the other parallel to $\\\\mathbf{A}$, and denote them by $\\\\mathbf{B}_{\\\\perp}$ and $\\\\mathbf{B}_{\\\\|}$respectively. Then $\\\\mathbf{B}=\\\\mathbf{B}_{\\\\perp}+\\\\mathbf{B}_{\\\\|}$.\\n\\nIf $\\\\theta$ is the angle between $\\\\mathbf{A}$ and $\\\\mathbf{B}$, then $B_{\\\\perp}=B \\\\sin \\\\theta$. Thus, the magnitude of $\\\\mathbf{A} \\\\times \\\\mathbf{B}_{\\\\perp}$ is $A B \\\\sin \\\\theta$, the same as the magnitude of $\\\\mathbf{A} \\\\times \\\\mathbf{B}$. Also, the direction of $\\\\mathbf{A} \\\\times \\\\mathbf{B}_{\\\\perp}$ is the same as the direction of $\\\\mathbf{A} \\\\times \\\\mathbf{B}$. Hence, $\\\\mathbf{A}$ $\\\\times \\\\mathbf{B}_{\\\\perp}=\\\\mathbf{A} \\\\times \\\\mathbf{B}$.\\n\\nSimilarly, if $\\\\mathbf{C}$ is resolved into two component vectors $\\\\mathbf{C}_{\\\\|}$and $\\\\mathbf{C}_{\\\\perp}$, parallel and perpendicular, respectively, to $\\\\mathbf{A}$, then $\\\\mathbf{A} \\\\times \\\\mathbf{C}_{\\\\perp}=\\\\mathbf{A} \\\\times \\\\mathbf{C}$.\\n\\nAlso, since $\\\\mathbf{B}+\\\\mathbf{C}=\\\\mathbf{B}_{\\\\perp}+\\\\mathbf{B}_{\\\\|}+\\\\mathbf{C}_{\\\\perp}+\\\\mathbf{C}_{\\\\|}=\\\\left(\\\\mathbf{B}_{\\\\perp}+\\\\mathbf{C}_{\\\\perp}\\\\right)+\\\\left(\\\\mathbf{B}_{\\\\|}+\\\\mathbf{C}_{\\\\|}\\\\right)$, it follows that\\n\\n$$\\n\\\\mathbf{A} \\\\times\\\\left(\\\\mathbf{B}_{\\\\perp}+\\\\mathbf{C}_{\\\\perp}\\\\right)=\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-189(1)}\\n\\\\end{center}\\n\\nFigure 7.26\\n\\nNow $\\\\mathbf{B}_{\\\\perp}$ and $\\\\mathbf{C}_{\\\\perp}$ are vectors perpendicular to $\\\\mathbf{A}$, and so by Problem 7.17,\\n\\n$$\\n\\\\mathbf{A} \\\\times\\\\left(\\\\mathbf{B}_{\\\\perp}+\\\\mathbf{C}_{\\\\perp}\\\\right)=\\\\mathbf{A} \\\\times \\\\mathbf{B}_{\\\\perp}+\\\\mathbf{A} \\\\times \\\\mathbf{C}_{\\\\perp}\\n$$\\n\\nThen\\n\\n$$\\n\\\\mathbf{A} \\\\times(\\\\mathbf{B}+\\\\mathbf{C})=\\\\mathbf{A} \\\\times \\\\mathbf{B}+\\\\mathbf{A} \\\\times \\\\mathbf{C}\\n$$\\n\\nand the distributive law holds. Multiplying by -1 , using Problem 7.16, this becomes $(\\\\mathbf{B}+\\\\mathbf{C}) \\\\times \\\\mathbf{A}=\\\\mathbf{B} \\\\times \\\\mathbf{A}+\\\\mathbf{C}$ $\\\\times \\\\mathbf{A}$. Note that the order of factors in cross products is important. The usual laws of algebra apply only if proper order is maintained.\\n',\n",
       " '\\n7.19. (a) If $\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}$ and $\\\\mathbf{B}=B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}$, prove that $\\\\mathbf{A} \\\\times \\\\mathbf{B}=\\\\mathbf{A} \\\\times \\\\mathbf{B}=\\\\left|\\\\begin{array}{ccc}\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\ A_{1} & A_{2} & A_{3} \\\\\\\\ B_{1} & B_{2} & B_{3}\\\\end{array}\\\\right|$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{A} \\\\times \\\\mathbf{B}= & \\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\times\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n= & A_{1} \\\\mathbf{i} \\\\times\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right)+A_{2} \\\\mathbf{j} \\\\times\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right)+A_{3} \\\\mathbf{k} \\\\times\\\\left(B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n= & A_{1} B_{1} \\\\mathbf{i} \\\\times \\\\mathbf{i}+A_{1} B_{2} \\\\mathbf{i} \\\\times \\\\mathbf{j}+A_{1} B_{3} \\\\mathbf{i} \\\\times \\\\mathbf{k}+A_{2} B_{1} \\\\mathbf{j} \\\\times \\\\mathbf{i}+A_{2} B_{2} \\\\mathbf{j} \\\\times \\\\mathbf{j}+A_{2} B_{3} \\\\mathbf{j} \\\\times \\\\mathbf{k} \\\\\\\\\\n& +A_{3} B_{1} \\\\mathbf{k} \\\\times \\\\mathbf{i}+A_{3} B_{2} \\\\mathbf{k} \\\\times \\\\mathbf{j}+A_{3} B_{3} \\\\mathbf{k} \\\\times \\\\mathbf{k} \\\\\\\\\\n= & \\\\left(A_{2} B_{3}-A_{3} B_{2}\\\\right) \\\\mathbf{i}+\\\\left(A_{3} B_{1}-A_{1} B_{3}\\\\right) \\\\mathbf{j}+\\\\left(A_{1} B_{2}-A_{2} B_{1}\\\\right) \\\\mathbf{k}=\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\nA_{1} & A_{2} & A_{3} \\\\\\\\\\nB_{1} & B_{2} & B_{3}\\n\\\\end{array}\\\\right|\\n\\\\end{aligned}\\n$$\\n\\n(b) Use the determinant representation to prove the result of Problem 7.18.\\n',\n",
       " '\\n7.20. If $\\\\mathbf{A}=3 \\\\mathbf{i}-\\\\mathbf{j}+2 \\\\mathbf{k}$ and $\\\\mathbf{B}=2 \\\\mathbf{i}+3 \\\\mathbf{j}-\\\\mathbf{k}$, find $\\\\mathbf{A} \\\\times \\\\mathbf{B}$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{A} \\\\times \\\\mathbf{B} & =\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n3 & -1 & 2 \\\\\\\\\\n2 & 3 & -1\\n\\\\end{array}\\\\right|=\\\\mathbf{i}\\\\left|\\\\begin{array}{cc}\\n-1 & 2 \\\\\\\\\\n3 & -1\\n\\\\end{array}\\\\right|-\\\\mathbf{j}\\\\left|\\\\begin{array}{cc}\\n3 & 2 \\\\\\\\\\n2 & -1\\n\\\\end{array}\\\\right|+\\\\mathbf{k}\\\\left|\\\\begin{array}{cc}\\n3 & -1 \\\\\\\\\\n2 & 3\\n\\\\end{array}\\\\right| \\\\\\\\\\n& =-5 \\\\mathbf{i}+7 \\\\mathbf{j}+11 \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.21. Prove that the area of a parallelogram with sides $\\\\mathbf{A}$ and $\\\\mathbf{B}$ is\\n\\n$|\\\\mathbf{A} \\\\times \\\\mathbf{B}|$. See Figure 7.27.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\text { Area of parallelogram } & =h|\\\\mathbf{B}| \\\\\\\\\\n& =|\\\\mathbf{A}| \\\\sin \\\\theta|\\\\mathbf{B}| \\\\\\\\\\n& =|\\\\mathbf{A} \\\\times \\\\mathbf{B}|\\n\\\\end{aligned}\\n$$\\n\\nNote that the area of the triangle with sides $\\\\mathbf{A}$ and $\\\\mathbf{B}=$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-190}\\n\\\\end{center}\\n\\nFigure 7.27 $1 / 2|\\\\mathbf{A} \\\\times \\\\mathbf{B}|$.\\n',\n",
       " '\\n7.22. Find the area of the triangle with vertices at $\\\\mathrm{P}(2,3,5), \\\\mathrm{Q}(4,2,-1)$, and $\\\\mathrm{R}(3,6,4)$.\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\mathrm{PQ}=(4-2) \\\\mathbf{i}+(2-3) \\\\mathbf{j}+(-1-5) \\\\mathbf{k}=2 \\\\mathbf{i}-\\\\mathbf{j}-6 \\\\mathbf{k} \\\\\\\\\\n& \\\\mathrm{PR}=(3-2) \\\\mathbf{i}+(6-3) \\\\mathbf{j}+(4-5) \\\\mathbf{k}=\\\\mathbf{i}+3 \\\\mathbf{j}-\\\\mathbf{k} \\\\\\\\\\n& \\\\text { Area of triangle }=\\\\frac{1}{2}|\\\\mathrm{PQ} \\\\times \\\\mathrm{PR}|=\\\\frac{1}{2}|(2 \\\\mathbf{i}-\\\\mathbf{j}-6 \\\\mathbf{k}) \\\\times(\\\\mathrm{i}+3 \\\\mathbf{j}-\\\\mathbf{k})| \\\\\\\\\\n& =\\\\frac{1}{2}\\\\left\\\\|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n2 & -1 & -6 \\\\\\\\\\n1 & 3 & -1\\n\\\\end{array}\\\\right\\\\|=\\\\frac{1}{2}|19 \\\\mathbf{i}-4 \\\\mathbf{j}+7 \\\\mathbf{k}| \\\\\\\\\\n& =\\\\frac{1}{2} \\\\sqrt{(19)^{2}+(-4)^{2}+(7)^{2}}=\\\\frac{1}{2} \\\\sqrt{426}\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Triple products}\\n',\n",
       " '7.23. Show that $\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})$ is in absolute value equal to the volume of a parallelepiped with sides $\\\\mathbf{A}, \\\\mathbf{B}$, and $\\\\mathbf{C}$. See Figure 7.28.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-191}\\n\\\\end{center}\\n\\nFigure 7.28\\n\\nLet $\\\\mathbf{n}$ be a unit normal to parallelogram $I$, having the direction of $\\\\mathbf{B} \\\\times \\\\mathbf{C}$, and let $h$ be the height of the terminal point of $\\\\mathbf{A}$ above the parallelogram $I$.\\n\\nVolume of a parallelepiped $=($ height $h)($ area of parallelogram $I)$\\n\\n$$\\n\\\\begin{aligned}\\n& =(\\\\mathbf{A} \\\\cdot \\\\mathbf{n})(|\\\\mathbf{B} \\\\times \\\\mathbf{C}|) \\\\\\\\\\n& =\\\\mathbf{A} \\\\cdot\\\\{|\\\\mathbf{B} \\\\times \\\\mathbf{C}| \\\\mathbf{n}\\\\}=\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})\\n\\\\end{aligned}\\n$$\\n\\nIf $\\\\mathbf{A}, \\\\mathbf{B}$ and $\\\\mathbf{C}$ do not form a right-handed system, $\\\\mathbf{A} \\\\cdot \\\\mathbf{n}<0$ and the volume $=|\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})|$.\\n',\n",
       " '\\n7.24. If $\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}, \\\\mathbf{B}=B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}, \\\\mathbf{C}=C_{1} \\\\mathbf{i}+C_{2} \\\\mathbf{j}+C_{3} \\\\mathbf{k}$ show that\\n\\n$$\\n\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})=\\\\left|\\\\begin{array}{lll}\\nA_{1} & A_{2} & A_{3} \\\\\\\\\\nB_{1} & B_{2} & B_{3} \\\\\\\\\\nC_{1} & C_{2} & C_{3}\\n\\\\end{array}\\\\right|\\n$$\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C}) & =\\\\mathbf{A} \\\\cdot\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\nB_{1} & B_{2} & B_{3} \\\\\\\\\\nC_{1} & C_{2} & C_{3}\\n\\\\end{array}\\\\right| \\\\\\\\\\n& =\\\\left(A_{1} \\\\mathrm{i}+A_{2} \\\\mathrm{j}+A_{3} \\\\mathrm{k}\\\\right) \\\\cdot\\\\left[\\\\left(B_{2} C_{3}-B_{3} C_{2}\\\\right) \\\\mathrm{i}+\\\\left(B_{3} C_{1}-B_{1} C_{3}\\\\right) \\\\mathrm{j}+\\\\left(B_{1} C_{2}-B_{2} C_{1}\\\\right) \\\\mathrm{k}\\\\right] \\\\\\\\\\n& =A_{1}\\\\left(B_{2} C_{3}-B_{3} C_{2}\\\\right)+A_{2}\\\\left(B_{3} C_{1}-B_{1} C_{3}\\\\right)+A_{3}\\\\left(B_{1} C_{2}-B_{2} C_{1}\\\\right)=\\\\left|\\\\begin{array}{lll}\\nA_{1} & A_{2} & A_{3} \\\\\\\\\\nB_{1} & B_{2} & B_{3} \\\\\\\\\\nC_{1} & C_{2} & C_{3}\\n\\\\end{array}\\\\right| .\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.25. Find the volume of a parallelepiped with sides $\\\\mathbf{A}=3 \\\\mathbf{i}-\\\\mathbf{j}, \\\\mathbf{B}=\\\\mathbf{j}+2 \\\\mathbf{k}, \\\\mathbf{C}=\\\\mathbf{i}+5 \\\\mathbf{j}+4 \\\\mathbf{k}$.\\n\\nBy Problems 7.23 and 7.24, volume of parallelepiped $\\\\left.=|\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})|=\\\\left|\\\\begin{array}{ccc}3 & -1 & 0 \\\\\\\\ 0 & 1 & 2 \\\\\\\\ 1 & 5 & 4\\\\end{array}\\\\right||=|-20 \\\\right\\\\rvert\\\\,=20$.\\n',\n",
       " '\\n7.26. Prove that $\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})=(\\\\mathbf{A} \\\\times \\\\mathbf{B}) \\\\cdot \\\\mathbf{C}$, i.e., the dot and cross can be interchanged.\\n\\nBy Problem 7.24: $\\\\mathbf{A} \\\\cdot(\\\\mathbf{B} \\\\times \\\\mathbf{C})=\\\\left|\\\\begin{array}{lll}A_{1} & A_{2} & A_{3} \\\\\\\\ B_{1} & B_{2} & B_{3} \\\\\\\\ C_{1} & C_{2} & C_{3}\\\\end{array}\\\\right|,(\\\\mathbf{A} \\\\times \\\\mathbf{B}) \\\\cdot \\\\mathbf{C}=\\\\mathbf{C} \\\\cdot(\\\\mathbf{A} \\\\times \\\\mathbf{B})=\\\\left|\\\\begin{array}{lll}C_{1} & C_{2} & C_{3} \\\\\\\\ A_{1} & A_{2} & A_{3} \\\\\\\\ B_{1} & B_{2} & B_{3}\\\\end{array}\\\\right|$\\n\\nSince the two determinants are equal, the required result follows.\\n',\n",
       " '\\n7.27. Let $\\\\mathbf{r}_{1}=x_{1} \\\\mathbf{i}+y_{1} \\\\mathbf{j}+z_{1} \\\\mathbf{k}, \\\\mathbf{r}_{2}=x_{2} \\\\mathbf{i}+y_{2} \\\\mathbf{j}+z_{2} \\\\mathbf{k}$ and $\\\\mathbf{r}_{3}=x_{3} \\\\mathbf{i}+y_{3} \\\\mathbf{j}+z_{3} \\\\mathbf{k}$ be the position vectors of points $\\\\mathrm{P}_{1}\\\\left(x_{1}, y_{1}\\\\right.$, $\\\\left.z_{1}\\\\right), \\\\mathrm{P}_{2}\\\\left(x_{2}, y_{\\\\mathrm{x}}, z_{2}\\\\right)$, and $\\\\mathrm{P}_{3}\\\\left(x_{3}, y_{3}, z_{3}\\\\right)$. Find an equation for the plane passing through $\\\\mathrm{P}_{1}, \\\\mathrm{P}_{2}$, and $\\\\mathrm{P}_{3}$. See Figure 7.29.\\n\\nWe assume that $\\\\mathrm{P}_{1}, \\\\mathrm{P}_{2}$, and $\\\\mathrm{P}_{3}$ do not lie in the same straight line; hence, they determine a plane.\\n\\nLet $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}$ denote the position vectors of any point $\\\\mathrm{P}(x, y, z)$ in the plane. Consider vectors $\\\\overrightarrow{\\\\mathrm{P}}_{1} \\\\vec{P}_{2}$ $=\\\\mathbf{r}_{2}-\\\\mathbf{r}_{1}, \\\\overrightarrow{\\\\mathrm{P}}_{1} \\\\overrightarrow{\\\\mathrm{P}}_{3}=\\\\mathbf{r}_{3}-\\\\mathbf{r}_{1}$ and $\\\\overrightarrow{\\\\mathrm{P}_{1} \\\\mathrm{P}}=\\\\mathbf{r}-\\\\mathbf{r}_{1}$ which all lie in the plane. Then\\n\\n$$\\n\\\\mathrm{P}_{1} \\\\mathrm{P} \\\\cdot \\\\mathrm{P}_{1} \\\\mathrm{P}_{2} \\\\times \\\\mathrm{P}_{1} \\\\mathrm{P}_{3}=0\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-192}\\n\\\\end{center}\\n\\nFigure 7.29\\n\\nor\\n\\n$$\\n\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{1}\\\\right) \\\\cdot\\\\left(\\\\mathbf{r}_{2}-\\\\mathbf{r}_{1}\\\\right) \\\\times\\\\left(\\\\mathbf{r}_{3}-\\\\mathbf{r}_{1}\\\\right)=0\\n$$\\n\\nIn terms of rectangular coordinates this becomes\\n\\n$$\\n\\\\begin{gathered}\\n{\\\\left[\\\\left(x-x_{1}\\\\right) \\\\mathbf{i}+\\\\left(y-y_{1}\\\\right) \\\\mathbf{j}+\\\\left(z-z_{1}\\\\right) \\\\mathbf{k}\\\\right] \\\\cdot\\\\left[\\\\left(x_{2}-x_{1}\\\\right) \\\\mathbf{i}+\\\\left(y_{2}-y_{1}\\\\right) \\\\mathbf{j}+\\\\left(z_{2}-z_{1}\\\\right) \\\\mathbf{k}\\\\right]} \\\\\\\\\\n\\\\times\\\\left[\\\\left(x_{3}-x_{1}\\\\right) \\\\mathbf{i}+\\\\left(y_{3}-y_{1}\\\\right) \\\\mathbf{j}+\\\\left(z_{3}-z_{1}\\\\right) \\\\mathbf{k}\\\\right]=0\\n\\\\end{gathered}\\n$$\\n\\nor, using Problem 7.24,\\n\\n$$\\n\\\\left|\\\\begin{array}{ccc}\\nx-x_{1} & y-y_{1} & z-z_{1} \\\\\\\\\\nx_{2}-x_{1} & y_{2}-y_{1} & z_{2}-z_{1} \\\\\\\\\\nx_{3}-x_{1} & y_{3}-y_{1} & z_{3}-z_{1}\\n\\\\end{array}\\\\right|=0\\n$$\\n',\n",
       " '\\n7.28. Find an equation for the plane passing through the points $P_{1}(3,1,-2), P_{2}(-1,2,4), P_{3}(2,-1,1)$.\\n\\nThe positions vectors of $P_{1}, P_{2}, P_{3}$ and any point $P(x, y, z)$ on the plane are respectively\\n\\n$$\\n\\\\mathbf{r}_{1}=3 \\\\mathbf{i}+\\\\mathbf{j}-2 \\\\mathbf{k}, \\\\mathbf{r}_{2}=-\\\\mathbf{i}+2 \\\\mathbf{j}+4 \\\\mathbf{k}, \\\\mathbf{r}_{3}=2 \\\\mathbf{i}-\\\\mathbf{j}+\\\\mathbf{k}, \\\\mathbf{r}=x \\\\mathbf{i}+j \\\\mathbf{j}+z \\\\mathbf{k}\\n$$\\n\\nThen $\\\\mathbf{P} \\\\mathbf{P}_{1}=\\\\mathbf{r}-\\\\mathbf{r}_{1}, \\\\mathbf{P}_{2} \\\\mathbf{P}_{1}=\\\\mathbf{r}_{2}-\\\\mathbf{r}_{1}, \\\\mathbf{P}_{3} \\\\mathbf{P}_{1}=\\\\mathbf{r}_{3}-\\\\mathbf{r}_{1}$, all lie in the required plane and so the required equation is $\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{1}\\\\right) \\\\cdot\\\\left(\\\\mathbf{r}_{2}-\\\\mathbf{r}_{1}\\\\right) \\\\times\\\\left(\\\\mathbf{r}_{3}-\\\\mathbf{r}_{1}\\\\right)=0$, i.e.,\\n\\n$$\\n\\\\begin{gathered}\\n\\\\{(x-3) \\\\mathbf{i}+(y-1) \\\\mathbf{j}+(z+2) \\\\mathbf{k}\\\\} \\\\cdot\\\\{-4 \\\\mathbf{i}+\\\\mathbf{j}+6 \\\\mathbf{k}\\\\} \\\\times\\\\{-\\\\mathbf{i}-2 \\\\mathbf{j}+3 \\\\mathbf{k}\\\\}=0 \\\\\\\\\\n\\\\{(x-3) \\\\mathbf{i}+(y-1) \\\\mathbf{j}+(z+2) \\\\mathbf{k}\\\\} \\\\cdot\\\\{15 \\\\mathbf{i}+6 \\\\mathbf{j}+9 \\\\mathbf{k}\\\\}=0 \\\\\\\\\\n15(x-3)+6(y-1)+9(z+2)=0 \\\\quad \\\\text { or } \\\\quad 5 x-2 y+3 z=11\\n\\\\end{gathered}\\n$$\\n\\nAnother method: By Problem 7.27, the required equation is\\n\\n$$\\n\\\\left|\\\\begin{array}{ccc}\\nx-3 & y-1 & z+2 \\\\\\\\\\n-1-3 & 2-1 & 4+2 \\\\\\\\\\n2-3 & -1-1 & 1+2\\n\\\\end{array}\\\\right|=0 \\\\quad \\\\text { or } \\\\quad 5 x+2 y+3 z=11\\n$$\\n',\n",
       " '\\n7.29 (1) If $\\\\mathbf{A}=\\\\mathbf{i}+\\\\mathbf{j}, \\\\mathbf{B}=2 \\\\mathbf{i}-3 \\\\mathbf{j}+\\\\mathbf{k}$, and $\\\\mathbf{C}=4 \\\\mathbf{j}-3 \\\\mathbf{k}$, find (a) $(\\\\mathbf{A} \\\\times \\\\mathbf{B}) \\\\times \\\\mathbf{C}$, (b) $\\\\mathbf{A} \\\\times(\\\\mathbf{B} \\\\times \\\\mathbf{C})$.\\n\\n(a) $\\\\mathbf{A} \\\\times \\\\mathbf{B}=\\\\left|\\\\begin{array}{ccc}\\\\mathrm{i} & \\\\mathrm{j} & \\\\mathrm{k} \\\\\\\\ 1 & 1 & 0 \\\\\\\\ 2 & -3 & 1\\\\end{array}\\\\right|=\\\\mathbf{i}-\\\\mathbf{j}-5 \\\\mathbf{k}$. Then $(\\\\mathbf{A} \\\\times \\\\mathbf{B}) \\\\times \\\\mathbf{C}=\\\\left|\\\\begin{array}{ccc}\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\ 1 & -1 & -5 \\\\\\\\ 0 & 4 & -3\\\\end{array}\\\\right|=23 \\\\mathbf{i}+3 \\\\mathbf{j}+4 \\\\mathbf{k}$.\\n\\n(b) $\\\\mathbf{B} \\\\times \\\\mathbf{C}=\\\\left|\\\\begin{array}{ccc}\\\\mathrm{i} & \\\\mathrm{j} & \\\\mathrm{k} \\\\\\\\ 2 & -3 & 1 \\\\\\\\ 0 & 4 & -3\\\\end{array}\\\\right|=5 \\\\mathbf{i}+6 \\\\mathbf{j}+8 \\\\mathbf{k}$. Then $\\\\mathbf{A} \\\\times(\\\\mathbf{B} \\\\times \\\\mathbf{C})=\\\\left|\\\\begin{array}{lll}\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\ 1 & 1 & 0 \\\\\\\\ 5 & 6 & 8\\\\end{array}\\\\right|=8 \\\\mathbf{i}-8 \\\\mathbf{j}+\\\\mathbf{k}$.\\n\\nIt can be proved that, in general, $(\\\\mathbf{A} \\\\times \\\\mathbf{B}) \\\\times \\\\mathbf{C} \\\\neq \\\\mathbf{A} \\\\times(\\\\mathbf{B} \\\\times \\\\mathbf{C})$.\\n',\n",
       " '\\n7.29 (2) $\\\\mathbf{A} \\\\times(\\\\mathbf{B} \\\\times \\\\mathbf{C})=\\\\mathbf{B}(\\\\mathbf{A}, \\\\mathbf{C})-\\\\mathbf{C}(\\\\mathbf{A}, \\\\mathbf{B})$. Use the same vectors as in Problem 7.29 (1). (Note: sometimes remembered with the phrase \"back to cab.\")\\n\\n\\n\\\\section*{Derivatives}\\n',\n",
       " '7.30. If $\\\\mathbf{r}=\\\\left(t^{3}+2 t\\\\right) \\\\mathbf{i}-3 e^{-2 t} \\\\mathbf{j}+2 \\\\sin 5 t \\\\mathbf{k}$, find (a) $\\\\frac{d \\\\mathbf{r}}{d t}$, (b) $\\\\left|\\\\frac{d \\\\mathbf{r}}{d t}\\\\right|$, (c) $\\\\frac{d^{2} \\\\mathbf{r}}{d t^{2}}$, and (d) $\\\\left|\\\\frac{d^{2} \\\\mathbf{r}}{d t^{2}}\\\\right|$ at $t=0$, and give a possible\\\\\\\\\\nphysical significance.\\n\\n(a) $\\\\frac{d \\\\mathrm{r}}{d t}=\\\\frac{d}{d t}\\\\left(t^{3}+2 t\\\\right) \\\\mathbf{i}+\\\\frac{d}{d t}\\\\left(-3 e^{-2 t}\\\\right) \\\\mathbf{j}+\\\\frac{d}{d t}(2 \\\\sin 5 t) \\\\mathbf{k}=\\\\left(3 t^{2}+2\\\\right) \\\\mathbf{i}+6 e^{-2 t} \\\\mathbf{j}+10 \\\\cos 5 t \\\\mathbf{k}$\\n\\nAt $t=0, d \\\\mathbf{r} / d t=2 \\\\mathbf{i}+6 \\\\mathbf{j}+10 \\\\mathbf{k}$\\n\\n(b) From (a), $|d \\\\mathbf{r} / d t|=\\\\sqrt{(2)^{2}+(6)^{2}+(10)^{2}}=\\\\sqrt{140}=2 \\\\sqrt{35}$ at $t=0$.\\n\\n(c) $\\\\frac{d^{2} \\\\mathbf{r}}{d t^{2}}=\\\\frac{d}{d t}\\\\left(\\\\frac{d \\\\mathbf{r}}{d t}\\\\right)=\\\\frac{d}{d t}\\\\left\\\\{\\\\left(3 t^{2}+2\\\\right) \\\\mathbf{i}+6 e^{-2 t} \\\\mathbf{j}+10 \\\\cos 5 t \\\\mathbf{k}\\\\right\\\\}=6 t \\\\mathbf{i}-12 e^{-2 t} \\\\mathbf{j}-50 \\\\sin 5 t \\\\mathbf{k}$\\n\\nAt $t=0, d^{2} \\\\mathbf{r} / d t^{2}=-12 \\\\mathbf{j}$.\\n\\n(d) From (c), $\\\\quad\\\\left|d^{2} \\\\mathbf{r} / d t^{2}\\\\right|=12$ at $t=0$.\\n\\nIf $t$ represents time, these represent, respectively, the velocity, magnitude of the velocity, acceleration, and magnitude of the acceleration at $t=0$ of a particle moving along the space curve $x=t^{3}+2 t, y=-3 e^{-2 t}, z=2$ $\\\\sin 5 t$.\\n',\n",
       " '\\n7.31. Prove that $\\\\frac{d}{d u}(\\\\mathbf{A} \\\\cdot \\\\mathbf{B})=\\\\mathrm{A} \\\\cdot \\\\frac{d \\\\mathbf{B}}{d u}+\\\\frac{d \\\\mathbf{A}}{d u} \\\\cdot \\\\mathbf{B}$ where $\\\\mathbf{A}$ and $\\\\mathbf{B}$ are differentiable functions of $u$.\\n\\nMethod 1:\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{d}{d u}(\\\\mathbf{A} \\\\cdot \\\\mathbf{B}) & =\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{(\\\\mathbf{A}+\\\\Delta \\\\mathbf{A}) \\\\cdot(\\\\mathbf{B}+\\\\Delta \\\\mathbf{B})-\\\\mathbf{A} \\\\cdot \\\\mathbf{B}}{\\\\Delta u} \\\\\\\\\\n& =\\\\lim _{\\\\Delta u \\\\rightarrow 0} \\\\frac{\\\\mathbf{A} \\\\cdot \\\\Delta \\\\mathbf{B}+\\\\Delta \\\\mathbf{A} \\\\cdot \\\\mathbf{B}+\\\\Delta \\\\mathbf{A} \\\\cdot \\\\Delta \\\\mathbf{B}}{\\\\Delta u} \\\\\\\\\\n& =\\\\lim _{\\\\Delta u \\\\rightarrow 0}\\\\left(\\\\mathrm{~A} \\\\cdot \\\\frac{\\\\Delta \\\\mathbf{B}}{\\\\Delta u}+\\\\frac{\\\\Delta \\\\mathbf{A}}{\\\\Delta u} \\\\cdot \\\\mathbf{B}+\\\\frac{\\\\Delta \\\\mathbf{A}}{\\\\Delta u} \\\\cdot \\\\Delta \\\\mathbf{B}\\\\right)=\\\\mathrm{A} \\\\cdot \\\\frac{d \\\\mathbf{B}}{d u}+\\\\frac{d \\\\mathbf{A}}{d u} \\\\cdot \\\\mathbf{B}\\n\\\\end{aligned}\\n$$\\n\\nMethod 2:\\n\\nLet $\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}, \\\\mathbf{B}+B_{1} \\\\mathbf{i}+B_{2} \\\\mathbf{j}+B_{3} \\\\mathbf{k}$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{d}{d u}(\\\\mathbf{A} \\\\cdot \\\\mathbf{B}) & =\\\\frac{d}{d u}\\\\left(A_{1} B_{1}+A_{2} B_{2}+A_{3} B_{3}\\\\right) \\\\\\\\\\n& =\\\\left(A_{1} \\\\frac{d B_{1}}{d u}+A_{2} \\\\frac{d B_{2}}{d u}+A_{3} \\\\frac{d B_{3}}{d u}\\\\right)+\\\\left(\\\\frac{d A_{1}}{d u} B_{1}+\\\\frac{d A_{2}}{d u} B_{2}+\\\\frac{d A_{3}}{d u} B_{3}\\\\right) \\\\\\\\\\n& =\\\\mathbf{A} \\\\cdot \\\\frac{d \\\\mathbf{B}}{d u}+\\\\frac{d \\\\mathbf{A}}{d u} \\\\cdot \\\\mathbf{B}\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.32. If $\\\\phi(x, y, z)=x^{2} y z$ and $\\\\mathbf{A}=3 x^{2} y \\\\mathbf{i}+y z^{2} \\\\mathbf{j}-x z \\\\mathbf{k}$, find $\\\\mathbf{A}=3 x^{2} y \\\\mathbf{i}+y z^{2} \\\\mathbf{j}-x z \\\\mathbf{k}$, find $\\\\frac{\\\\partial^{2}}{\\\\partial y \\\\partial z}(\\\\phi \\\\mathbf{A})$ at the point\\\\\\\\\\n$(1,-2,-1)$.\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\phi \\\\mathbf{A}=\\\\left(x^{2} y z\\\\right)\\\\left(3 x^{2} y \\\\mathbf{i}+y z^{2} \\\\mathbf{j}-x z \\\\mathbf{k}\\\\right)=3 \\\\mathbf{x}^{4} y^{2} z \\\\mathbf{i}+x^{2} y^{2} z^{3} \\\\mathbf{j}-x^{3} y z^{2} \\\\mathbf{k} \\\\\\\\\\n& \\\\frac{\\\\partial}{\\\\partial z}(\\\\phi \\\\mathbf{A})=\\\\frac{\\\\partial}{\\\\partial z}\\\\left(3 \\\\mathbf{x}^{4} y^{2} z \\\\mathbf{i}+x^{2} y^{2} z^{3} \\\\mathbf{j}-x^{3} y^{2} z^{3} \\\\mathbf{k}\\\\right)=3 \\\\mathbf{x}^{4} y^{2} \\\\mathbf{i}+3 x^{2} y^{2} z^{2} \\\\mathbf{j}-2 x^{3} y z \\\\mathbf{k} \\\\\\\\\\n& \\\\frac{\\\\partial^{2}}{\\\\partial y \\\\partial z}(\\\\phi \\\\mathbf{A})=\\\\frac{\\\\partial}{\\\\partial z}\\\\left(3 \\\\mathbf{x}^{4} y^{2} \\\\mathbf{i}+3 x^{2} y^{2} z^{2} \\\\mathbf{j}-2 x^{3} y z \\\\mathbf{k}\\\\right)=6 \\\\mathbf{x}^{4} y \\\\mathbf{i}+6 x^{2} y z^{2} \\\\mathbf{j}-2 x^{3} z \\\\mathbf{k} \\\\\\\\\\n& \\\\text { If } x=1, y=-2, z=-1, \\\\text { this becomes }-12 \\\\mathbf{i}-12 \\\\mathbf{j}+2 \\\\mathbf{k} .\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.33. If $\\\\mathbf{A}=x^{2} \\\\sin y \\\\mathbf{i}+z^{2} \\\\cos y \\\\mathbf{j}-x y^{2} \\\\mathbf{k}$, find $d \\\\mathbf{A}$.\\n\\n\\n\\\\section*{Method 1:}\\n$$\\n\\\\begin{aligned}\\n\\\\frac{\\\\partial \\\\mathbf{A}}{\\\\partial x} & =2 x \\\\sin y \\\\mathbf{i}-y^{2} \\\\mathbf{k}, \\\\quad \\\\frac{\\\\partial \\\\mathbf{A}}{\\\\partial y} x^{2} \\\\cos y \\\\mathbf{i}-z^{2} \\\\sin y \\\\mathbf{j}-2 x y \\\\mathbf{k}, \\\\quad \\\\frac{\\\\partial \\\\mathbf{A}}{\\\\partial z}=2 z \\\\cos y \\\\mathbf{j} \\\\\\\\\\nd \\\\mathbf{A} & =\\\\frac{\\\\partial \\\\mathbf{A}}{\\\\partial x} d x+\\\\frac{\\\\partial \\\\mathbf{A}}{\\\\partial y} d y+\\\\frac{\\\\partial \\\\mathbf{A}}{\\\\partial z} d z \\\\\\\\\\n& =\\\\left(2 x \\\\sin y \\\\mathbf{i}-y^{2} \\\\mathbf{k}\\\\right) d x+\\\\left(x^{2} \\\\cos y \\\\mathbf{i}-z^{2} \\\\sin y \\\\mathbf{j}-2 x y \\\\mathbf{k}\\\\right) d y+(2 z \\\\cos y \\\\mathbf{j}) d z \\\\\\\\\\n& =\\\\left(2 x \\\\sin y d x+x^{2} \\\\cos y d y\\\\right) \\\\mathbf{i}+\\\\left(2 z \\\\cos y d z-z^{2} \\\\sin y d y\\\\right) \\\\mathbf{j}-\\\\left(y^{2} d x+2 x y d y\\\\right) \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\nMethod 2:\\n\\n$$\\n\\\\begin{aligned}\\nd \\\\mathbf{A} & =d\\\\left(x^{2} \\\\sin y\\\\right) \\\\mathbf{i}+d\\\\left(z^{2} \\\\cos y\\\\right) \\\\mathbf{j}-d\\\\left(x y^{2}\\\\right) \\\\mathbf{k} \\\\\\\\\\n& =\\\\left(2 x \\\\sin y d x+x^{2} \\\\cos y d y\\\\right) \\\\mathbf{i}+\\\\left(2 z \\\\cos y d z-z^{2} \\\\sin y d y\\\\right) \\\\mathbf{j}-\\\\left(y^{2} d x+2 x y d y\\\\right) \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Gradient, divergence, and curl}\\n',\n",
       " '7.34. If $\\\\phi=x^{2} y z^{3}$ and $\\\\mathbf{A}=x z \\\\mathbf{i}-y^{2} \\\\mathbf{j}+2 x^{2} y \\\\mathbf{k}$, find (a) $\\\\nabla \\\\phi$, (b) $\\\\nabla \\\\cdot \\\\mathbf{A}$, (c) $\\\\nabla \\\\times \\\\mathbf{A}$, (d) $\\\\operatorname{div}(\\\\phi \\\\mathbf{A})$, (e) $\\\\operatorname{curl}(\\\\phi \\\\mathbf{A})$.\\n\\n(a) $\\\\nabla \\\\phi=\\\\left(\\\\mathbf{i} \\\\frac{\\\\partial}{\\\\partial x}+\\\\mathbf{j} \\\\frac{\\\\partial}{\\\\partial y}+\\\\mathbf{k} \\\\frac{\\\\partial}{\\\\partial z}\\\\right) \\\\phi=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} \\\\mathbf{k}=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x^{2} y z^{3}\\\\right) \\\\mathbf{i}+\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x^{2} y z^{3}\\\\right) \\\\mathbf{j}+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(x^{2} y z^{3}\\\\right) \\\\mathbf{k}$\\n\\n$$\\n=2 x y z^{3} \\\\mathbf{i}+x^{2} z^{3} \\\\mathbf{j}+3 x^{2} y z^{2} \\\\mathbf{k}\\n$$\\n\\n(b) $\\\\nabla \\\\cdot \\\\mathbf{A}=\\\\left(\\\\mathbf{i} \\\\frac{\\\\partial}{\\\\partial x}+\\\\mathbf{j} \\\\frac{\\\\partial}{\\\\partial y}+\\\\mathbf{k} \\\\frac{\\\\partial}{\\\\partial z}\\\\right) \\\\cdot\\\\left(x z \\\\mathbf{i}-y^{2} \\\\mathbf{j}+2 x^{2} y \\\\mathbf{k}\\\\right)$\\n\\n$$\\n=\\\\frac{\\\\partial}{\\\\partial x}(x z)+\\\\frac{\\\\partial}{\\\\partial y}\\\\left(-y^{2}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(2 x^{2} y\\\\right)=z-2 y\\n$$\\n\\n(c) $\\\\nabla \\\\times \\\\mathbf{A}=\\\\left(\\\\mathbf{i} \\\\frac{\\\\partial}{\\\\partial x}+\\\\mathbf{j} \\\\frac{\\\\partial}{\\\\partial y}+\\\\mathbf{k} \\\\frac{\\\\partial}{\\\\partial z}\\\\right) \\\\times\\\\left(x z \\\\mathbf{i}-y^{2} \\\\mathbf{j}+2 x^{2} y \\\\mathbf{k}\\\\right)$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n\\\\partial / \\\\partial x & \\\\partial / \\\\partial y & \\\\partial / \\\\partial z \\\\\\\\\\nx z & -y^{2} & 2 x^{2} y\\n\\\\end{array}\\\\right| \\\\\\\\\\n& =\\\\left(\\\\frac{\\\\partial}{\\\\partial x}\\\\left(2 x^{2} y\\\\right)-\\\\frac{\\\\partial}{\\\\partial z}\\\\left(-y^{2}\\\\right)\\\\right) \\\\mathbf{i}+\\\\left(\\\\frac{\\\\partial}{\\\\partial z}(x z)-\\\\frac{\\\\partial}{\\\\partial x}\\\\left(2 x^{2} y\\\\right)\\\\right) \\\\mathbf{j}+\\\\left(\\\\frac{\\\\partial}{\\\\partial x}\\\\left(-y^{2}\\\\right)-\\\\frac{\\\\partial}{\\\\partial y}(x z)\\\\right) \\\\mathbf{k} \\\\\\\\\\n& =2 x^{2} \\\\mathbf{i}+(x-4 x y) \\\\mathbf{j}\\n\\\\end{aligned}\\n$$\\n\\n(d) $\\\\operatorname{div}(\\\\phi \\\\mathbf{A})=\\\\nabla \\\\cdot(\\\\phi \\\\mathbf{A})=\\\\nabla \\\\cdot\\\\left(x^{3} y z^{4} \\\\mathbf{i}-x^{2} y^{3} z^{3} \\\\mathbf{j}+2 x^{4} y^{2} z^{3} \\\\mathbf{k}\\\\right)$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x^{3} y z^{4}\\\\right)+\\\\frac{\\\\partial}{\\\\partial y}\\\\left(-x^{2} y^{3} z^{3}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(2 x^{4} y^{2} z^{3}\\\\right) \\\\\\\\\\n& =3 x^{2} y z^{4}-3 x^{2} y^{2} z^{3}+6 x^{4} y^{2} z^{2}\\n\\\\end{aligned}\\n$$\\n\\n(e) $\\\\operatorname{curl}(\\\\phi \\\\mathbf{A})=\\\\nabla \\\\times(\\\\phi \\\\mathbf{A})=\\\\nabla \\\\times\\\\left(x^{3} y z^{4} \\\\mathbf{i}-x^{2} y^{3} z^{3} \\\\mathbf{j}+2 x^{4} y^{2} z^{3} \\\\mathbf{k}\\\\right)$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n\\\\partial / \\\\partial x & \\\\partial / \\\\partial y & \\\\partial / \\\\partial z \\\\\\\\\\nx^{3} y z^{4} & -x^{2} y^{3} z^{3} & 2 x^{4} y^{2} z^{3}\\n\\\\end{array}\\\\right| \\\\\\\\\\n& =\\\\left(4 x^{4} y z^{3}-3 x^{2} y^{3} z^{2}\\\\right) \\\\mathbf{i}+\\\\left(4 x^{3} y z^{3}-8 x^{3} y^{2} z^{3}\\\\right) \\\\mathbf{j}-\\\\left(2 x y^{3} z^{3}+x^{3} z^{4}\\\\right) \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.35.\\n\\nProve $\\\\nabla \\\\cdot(\\\\phi \\\\mathbf{A})=(\\\\nabla \\\\phi) \\\\cdot \\\\mathbf{A}+\\\\phi(\\\\nabla \\\\cdot \\\\mathbf{A})$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\nabla \\\\cdot(\\\\phi \\\\mathbf{A})= & \\\\nabla \\\\cdot\\\\left(\\\\phi A_{1} \\\\mathbf{i}+\\\\phi A_{2} \\\\mathbf{j}+\\\\phi A_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n= & \\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\phi A_{1}\\\\right)+\\\\frac{\\\\partial}{\\\\partial y}\\\\left(\\\\phi A_{2}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(\\\\phi A_{3}\\\\right) \\\\\\\\\\n& =\\\\frac{\\\\partial \\\\phi}{\\\\partial x} A_{1}+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} A_{2}+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} A_{3}+\\\\phi\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial x}+\\\\frac{\\\\partial A_{2}}{\\\\partial y}+\\\\frac{\\\\partial A_{3}}{\\\\partial z}\\\\right) \\\\\\\\\\n& =\\\\left(\\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} \\\\mathbf{k}\\\\right) \\\\cdot\\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n& +\\\\phi\\\\left(\\\\frac{\\\\partial}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial}{\\\\partial z} \\\\mathbf{k}\\\\right) \\\\cdot\\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\\\\\\\n= & (\\\\nabla \\\\phi) \\\\cdot \\\\mathbf{A}+\\\\phi(\\\\nabla \\\\cdot \\\\mathbf{A})\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.36. Express a formula for the tangent plane to the surface $\\\\phi(x, y, z)=0$ at one of its points $P_{0}\\\\left(x_{0}, y_{0}, z_{0}\\\\right)$.\\n\\n$$\\n(\\\\nabla \\\\phi)_{0} \\\\cdot\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right)=0\\n$$\\n',\n",
       " '\\n7.37. Find a unit normal to the surface $2 x^{2}+4 y z-5 z^{2}=-10$ at the point $P(3,-1,2)$.\\n\\nBy Problem 7.36, a vector normal to the surface is\\n\\n$$\\n\\\\nabla\\\\left(2 x^{2}+4 y z-5 z^{2}\\\\right)=4 x \\\\mathbf{i}+4 z \\\\mathbf{j}+(4 y-10 z) \\\\mathbf{k}=12 \\\\mathbf{i}+8 \\\\mathbf{j}-24 \\\\mathbf{k} \\\\text { at }(3,-1,2)\\n$$\\n\\nThem a unit normal to the surface at $P$ is\\n\\n$$\\n\\\\frac{12 \\\\mathbf{i}+8 \\\\mathbf{j}-24 \\\\mathbf{k}}{\\\\sqrt{(12)^{2}+(8)^{2}+(-24)^{2}}}=\\\\frac{3 \\\\mathbf{i}+2 \\\\mathbf{j}-6 \\\\mathbf{k}}{7}\\n$$\\n\\nAnother unit normal to the surface at $P$ is\\n\\n$$\\n-\\\\frac{3 \\\\mathbf{i}+2 \\\\mathbf{j}-6 \\\\mathbf{k}}{7}\\n$$\\n',\n",
       " '\\n7.38. If $\\\\phi=2 x^{2} y-x z^{3}$, find (a) $\\\\nabla \\\\phi$ and (b) $\\\\nabla^{2} \\\\phi$.\\n\\n(a) $\\\\nabla \\\\phi=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} \\\\mathbf{k}=\\\\left(4 x y-z^{3}\\\\right) \\\\mathbf{i}+2 x^{2} \\\\mathbf{j}-3 x z^{2} \\\\mathbf{k}$\\n\\n(b) $\\\\nabla^{2} \\\\phi=$ Laplacian of $\\\\phi=\\\\nabla \\\\cdot \\\\nabla \\\\phi=\\\\frac{\\\\partial}{\\\\partial x}\\\\left(4 x y-z^{3}\\\\right)+\\\\frac{\\\\partial}{\\\\partial y}\\\\left(2 x^{2}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(-3 x z^{2}\\\\right)=4 y-6 x z$\\n\\n\\n\\\\section*{Another method:}\\n$$\\n\\\\begin{aligned}\\n\\\\nabla^{2} \\\\phi & =\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial x^{2}}+\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial y^{2}}+\\\\frac{\\\\partial^{2} \\\\phi}{\\\\partial z^{2}}=\\\\frac{\\\\partial^{2}}{\\\\partial x^{2}}\\\\left(2 x^{2} y-x z^{3}\\\\right)+\\\\frac{\\\\partial^{2}}{\\\\partial y^{2}}\\\\left(2 x^{2} y-x z^{3}\\\\right)+\\\\frac{\\\\partial^{2}}{\\\\partial z^{2}}\\\\left(2 x^{2} y-x z^{3}\\\\right) \\\\\\\\\\n& =4 y-6 x z\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n7.39. Prove div curl $\\\\mathbf{A}=0$\\n\\n$$\\n\\\\begin{aligned}\\n\\\\operatorname{div} \\\\text { curl } \\\\mathbf{A} & =\\\\nabla \\\\cdot(\\\\nabla \\\\times \\\\mathbf{A})=\\\\nabla \\\\cdot\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n\\\\partial / \\\\partial x & \\\\partial / \\\\partial y & \\\\partial / \\\\partial z \\\\\\\\\\nA_{1} & A_{2} & A_{3}\\n\\\\end{array}\\\\right| \\\\\\\\\\n& =\\\\nabla \\\\cdot\\\\left[\\\\left(\\\\frac{\\\\partial A_{3}}{\\\\partial y}-\\\\frac{\\\\partial A_{2}}{\\\\partial z}\\\\right) \\\\mathbf{i}+\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial z}-\\\\frac{\\\\partial A_{3}}{\\\\partial x}\\\\right) \\\\mathbf{j}+\\\\left(\\\\frac{\\\\partial A_{2}}{\\\\partial x}-\\\\frac{\\\\partial A_{1}}{\\\\partial y}\\\\right) \\\\mathrm{k}\\\\right. \\\\\\\\\\n& =\\\\frac{\\\\partial}{\\\\partial x}\\\\left(\\\\frac{\\\\partial A_{3}}{\\\\partial y}-\\\\frac{\\\\partial A_{2}}{\\\\partial z}\\\\right)+\\\\frac{\\\\partial}{\\\\partial y}\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial z}-\\\\frac{\\\\partial A_{3}}{\\\\partial x}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(\\\\frac{\\\\partial A_{2}}{\\\\partial x}-\\\\frac{\\\\partial A_{1}}{\\\\partial y}\\\\right. \\\\\\\\\\n& =\\\\frac{\\\\partial^{2} A_{3}}{\\\\partial x \\\\partial y}-\\\\frac{\\\\partial^{2} A_{2}}{\\\\partial x \\\\partial z}+\\\\frac{\\\\partial^{2} A_{1}}{\\\\partial y \\\\partial z}-\\\\frac{\\\\partial^{2} A_{3}}{\\\\partial y \\\\partial x}+\\\\frac{\\\\partial^{2} A_{2}}{\\\\partial z}-\\\\frac{\\\\partial^{2} A_{1}}{\\\\partial z \\\\partial y} \\\\\\\\\\n& =0\\n\\\\end{aligned}\\n$$\\n\\nassuming that $\\\\mathbf{A}$ has continuous second partial derivatives so that the order of differentiation is immaterial.\\n\\n\\n\\\\section*{Jacobians and curvilinear coordinates}\\n',\n",
       " '7.40. Find $d s^{2}$ in (a) cylindrical and (b) spherical coordinates and determine the scale factors.\\n\\n(a) Method 1:\\n\\n$$\\n\\\\begin{gathered}\\nx=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi,=z \\\\\\\\\\nd x=-\\\\rho \\\\sin \\\\phi d \\\\phi+\\\\cos \\\\phi d \\\\phi \\\\rho, \\\\quad d y=\\\\rho \\\\cos \\\\phi d \\\\phi+\\\\sin \\\\phi d \\\\rho, \\\\quad d z=d z\\n\\\\end{gathered}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nd s^{2} & =d x^{2}+d y^{2}+d z^{2}=(-\\\\rho \\\\sin \\\\phi d \\\\phi+\\\\cos \\\\phi d \\\\rho)^{2}+(\\\\rho \\\\cos \\\\phi d \\\\phi+\\\\sin \\\\phi d \\\\rho)^{2}+(d z)^{2} \\\\\\\\\\n& =(d \\\\rho)^{2}+\\\\rho^{2}(d \\\\phi)^{2}+(d z)^{2}=h_{1}^{2}(d \\\\rho)^{2}+h_{2}^{2}(d \\\\phi)^{2}+d_{3}^{2}(d z)^{2}\\n\\\\end{aligned}\\n$$\\n\\nand $h_{1}=h_{\\\\rho}=1, h_{2}=h_{\\\\phi}=\\\\rho, h_{3}=h_{\\\\mathrm{z}}=1$ are the scale factors.\\n\\nMethod 2: $\\\\quad$ The position vector is $\\\\mathbf{r}=\\\\rho \\\\cos \\\\phi \\\\mathbf{i}+\\\\rho \\\\sin \\\\phi \\\\mathbf{j}+z \\\\mathbf{k}$. Then\\n\\n$$\\n\\\\begin{aligned}\\nd \\\\mathbf{r} & =\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial \\\\rho} d \\\\rho+\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial \\\\phi} d \\\\phi+\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial z} d z \\\\\\\\\\n& =(\\\\cos \\\\phi \\\\mathbf{i}+\\\\sin \\\\phi \\\\mathbf{j}) d \\\\rho+(-\\\\rho \\\\sin \\\\phi \\\\mathbf{i}+\\\\rho \\\\cos \\\\phi \\\\mathbf{j}) d \\\\phi+\\\\mathbf{k} d z \\\\\\\\\\n& =(\\\\cos \\\\phi d \\\\rho-\\\\rho \\\\sin \\\\phi d \\\\phi) \\\\mathbf{i}+(\\\\sin \\\\phi d \\\\rho+\\\\rho \\\\cos \\\\phi d \\\\phi) \\\\mathbf{j}+\\\\mathbf{k} d z\\n\\\\end{aligned}\\n$$\\n\\nThus, $d s^{2}=d \\\\mathbf{r} \\\\cdot d \\\\mathbf{r}=(\\\\cos \\\\phi d \\\\rho-\\\\rho \\\\sin \\\\phi d \\\\phi)^{2}+(\\\\sin \\\\phi d \\\\rho+\\\\rho \\\\cos \\\\phi d \\\\phi)^{2}+(d z)^{2}$\\n\\n$$\\n=(d \\\\rho)^{2}+\\\\rho^{2}(d \\\\phi)^{2}+(d z)^{2}\\n$$\\n\\n(b) $x=r \\\\sin \\\\theta \\\\cos \\\\phi, \\\\quad y=r \\\\sin \\\\theta \\\\sin \\\\phi, \\\\quad z=r \\\\cos \\\\theta$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n& d x=-r \\\\sin \\\\theta \\\\sin \\\\phi d \\\\phi+r \\\\cos \\\\theta \\\\cos \\\\phi d \\\\theta+\\\\sin \\\\theta \\\\cos \\\\phi d r \\\\\\\\\\n& d y=r \\\\sin \\\\theta \\\\cos \\\\phi d \\\\phi+r \\\\cos \\\\theta \\\\sin \\\\phi d \\\\theta+\\\\sin \\\\theta \\\\sin \\\\phi d r \\\\\\\\\\n& d z=-r \\\\sin \\\\theta d \\\\phi+\\\\cos \\\\theta d r\\n\\\\end{aligned}\\n$$\\n\\nand\\n\\n$$\\n(d s)^{2}=(d x)^{2}+(d y)^{2}+(d z)^{2}=(d r)^{2}+r^{2}(d \\\\theta)^{2}+r^{2} \\\\sin ^{2} \\\\theta(d \\\\phi)^{2}\\n$$\\n\\nThe scale factors are $h_{1}=h_{r}=1, h_{2}=h_{\\\\theta}=r, h_{3}=h_{\\\\phi}=r \\\\sin \\\\theta$.\\n',\n",
       " '\\n7.41. Find the volume element $d V$ in (a) cylindrical and (b) spherical coordinates and sketch.\\n\\nThe volume element in orthogonal curvilinear coordinates $u_{1}, u_{2}, u_{3}$ is\\n\\n$$\\nd V=h_{1} h_{2} h_{3} d u_{1} d u_{2} d u_{3}=\\\\left|\\\\frac{\\\\partial(x, y, z)}{\\\\partial\\\\left(u_{1}, u_{2}, u_{3}\\\\right)}\\\\right| d u_{1} d u_{2} d u_{3}\\n$$\\n\\n(a) In cylindrical coordinates, $u_{1}=\\\\rho, u_{2}=\\\\phi, u_{3}=z, h_{1}=1, h_{2}=\\\\rho, h_{3}=1$ [see Problem 7.40(a)]. Then\\n\\n$$\\nd V=(1)(\\\\rho)(1) d \\\\rho d \\\\phi d z=\\\\rho d \\\\rho d \\\\phi d z\\n$$\\n\\nThis can also be observed directly from Figure 7.30(a).\\n\\n(b) In spherical coordinates, $u_{1}=r, u_{2}=\\\\theta, u_{3}=\\\\phi, h_{1}=1, h_{2}=r, h_{3}=r \\\\sin \\\\theta$ [see Problem 7.40(b)]. Then\\n\\n$$\\nd V=(1)(r)(r \\\\sin \\\\theta) d r d \\\\theta d \\\\phi=r^{2} \\\\sin \\\\theta d r d \\\\theta d \\\\phi\\n$$\\n\\nThis can also be observed directly from Figure 7.30(b).\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-197}\\n\\\\end{center}\\n\\n(a) Volume element in cylindrical coordinates.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-197(1)}\\n\\\\end{center}\\n\\n(b) Volume element in spherical coordinates.\\n\\nFigure 7.30\\n',\n",
       " '\\n7.42. Express in cylindrical coordinates: (a) $\\\\operatorname{grad} \\\\Phi$, (b) div $\\\\mathbf{A}$, and (c) $\\\\nabla^{2} \\\\Phi$.\\n\\nLet $u_{1}=\\\\rho, u_{2}=\\\\phi, u_{3}=z, h_{1}=1, h_{2}=\\\\rho, h_{3}=1$ [see Problem 7.40(a) and (b).] Then\\n\\n(a) $\\\\operatorname{grad} \\\\Phi=\\\\nabla \\\\Phi=\\\\frac{1}{1} \\\\frac{\\\\partial \\\\Phi}{\\\\partial \\\\rho} \\\\mathbf{e}_{1}+\\\\frac{1}{\\\\rho} \\\\frac{\\\\partial \\\\Phi}{\\\\partial \\\\phi} \\\\mathbf{e}_{2}+\\\\frac{1}{1} \\\\frac{\\\\partial \\\\Phi}{\\\\partial z} \\\\mathbf{e}_{3}=\\\\frac{\\\\partial \\\\Phi}{\\\\partial \\\\rho} \\\\mathbf{e}_{1}+\\\\frac{1}{\\\\rho} \\\\frac{\\\\partial \\\\Phi}{\\\\partial \\\\phi} \\\\mathbf{e}_{2}+\\\\frac{\\\\partial \\\\Phi}{\\\\partial z} \\\\mathbf{e}_{3}$\\n\\nwhere $\\\\mathbf{e}_{1}, \\\\mathbf{e}_{2}, \\\\mathbf{e}_{3}$ are the unit vectors in the directions of increasing $\\\\rho, \\\\phi, z$, respectively.\\n\\n(b) $\\\\operatorname{div} \\\\mathbf{A}=\\\\nabla \\\\cdot \\\\mathbf{A}=\\\\frac{1}{(1)(\\\\rho)(1)}\\\\left[\\\\frac{\\\\partial}{\\\\partial \\\\rho}\\\\left((\\\\rho)(1) A_{1}\\\\right)+\\\\frac{\\\\partial}{\\\\partial \\\\phi}\\\\left((1)(1) A_{2}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left((1)(\\\\rho) A_{3}\\\\right)\\\\right]$\\n\\n$$\\n=\\\\frac{1}{\\\\rho}\\\\left[\\\\frac{\\\\partial}{\\\\partial \\\\rho}\\\\left(\\\\rho A_{1}\\\\right)+\\\\frac{\\\\partial A_{2}}{\\\\partial \\\\phi}+\\\\frac{\\\\partial A_{3}}{\\\\partial z}\\\\right]\\n$$\\n\\nwhere $\\\\mathbf{A}=A_{1} \\\\mathbf{e}_{1}+A_{2} \\\\mathbf{e}_{2}+A_{3} \\\\mathbf{e}_{3}$.\\n\\n(c) $\\\\nabla^{2} \\\\Phi=\\\\frac{1}{(1)(\\\\rho)(1)}\\\\left[\\\\frac{\\\\partial}{\\\\partial \\\\rho}\\\\left(\\\\frac{(\\\\rho)(1)}{(1)} \\\\frac{\\\\partial \\\\phi}{\\\\partial \\\\rho}\\\\right)+\\\\frac{\\\\partial}{\\\\partial \\\\phi}\\\\left(\\\\frac{(1)(1)}{(\\\\rho)} \\\\frac{\\\\partial \\\\Phi}{\\\\partial \\\\phi}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(\\\\frac{(1)(\\\\rho)}{(1)} \\\\frac{\\\\partial \\\\Phi}{\\\\partial z}\\\\right)\\\\right]$\\n\\n$=\\\\frac{1}{\\\\rho} \\\\frac{\\\\partial}{\\\\partial \\\\rho}\\\\left(\\\\rho \\\\frac{\\\\partial \\\\Phi}{\\\\partial \\\\rho}\\\\right)+\\\\frac{1}{\\\\rho^{2}} \\\\frac{\\\\partial^{2} \\\\Phi}{\\\\partial \\\\phi^{2}}+\\\\frac{\\\\partial^{2} \\\\Phi}{\\\\partial z^{2}}$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '7.43. Prove that $\\\\operatorname{grad} f(r)=\\\\frac{f^{\\\\prime}(r)}{r} \\\\mathbf{r}$, where $r=\\\\sqrt{x^{2}+y^{2}+z^{2}}$ and $f^{\\\\prime}(r)=d f$ is $d f / d r$ is assumed to exist.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\operatorname{grad} f(r) & =\\\\nabla f(r)=\\\\frac{\\\\partial}{\\\\partial x} f(r) \\\\mathbf{i}+\\\\frac{\\\\partial}{\\\\partial y} f(r) \\\\mathbf{j}+\\\\frac{\\\\partial}{\\\\partial z} f(r) \\\\mathbf{k} \\\\\\\\\\n& =f^{\\\\prime}(r) \\\\frac{\\\\partial r}{\\\\partial x} \\\\mathbf{i}+f^{\\\\prime}(r) \\\\frac{\\\\partial r}{\\\\partial y} \\\\mathbf{j}+f^{\\\\prime}(r) \\\\frac{\\\\partial r}{\\\\partial z} \\\\mathbf{k} \\\\\\\\\\n& =f^{\\\\prime}(r) \\\\frac{x}{r} \\\\mathbf{i}+f^{\\\\prime}(r) \\\\frac{y}{r} \\\\mathbf{j}+f^{\\\\prime}(r) \\\\frac{z}{r} \\\\mathbf{k}=\\\\frac{f^{\\\\prime}(r)}{r}(x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k})=\\\\frac{f^{\\\\prime}(r)}{r} \\\\mathbf{r}\\n\\\\end{aligned}\\n$$\\n\\nAnother method: In orthogonal curvilinear coordinates $u_{1}, u_{2}, u_{3}$, we have\\n\\n\\n\\\\begin{equation*}\\n\\\\nabla \\\\Phi=\\\\frac{1}{h_{1}} \\\\frac{\\\\partial \\\\Phi}{\\\\partial u_{1}} \\\\mathbf{e}_{1}+\\\\frac{1}{h_{2}} \\\\frac{\\\\partial \\\\Phi}{\\\\partial u_{2}} \\\\mathbf{e}_{2}+\\\\frac{1}{h_{3}} \\\\frac{\\\\partial \\\\Phi}{\\\\partial u_{3}} \\\\mathbf{e}_{3} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf, in particular, we use spherical coordinates, we have $u_{1}=r, u_{2}=\\\\theta, u_{3}=\\\\phi$. Then letting $\\\\Phi=f(r)$, a function of $r$ alone, the last two terms on the right of Equation (1) are zero. Hence, on observing that $\\\\mathbf{e}_{1}=\\\\mathbf{r} / r$ and $h_{1},=1$, we have, the result\\n\\n\\n\\\\begin{equation*}\\n\\\\nabla f(r)=\\\\frac{1}{1} \\\\frac{\\\\partial f(r)}{\\\\partial r} \\\\frac{\\\\mathbf{r}}{r}=\\\\frac{f^{\\\\prime}(r)}{r} \\\\mathbf{r} \\\\tag{2}\\n\\\\end{equation*}\\n',\n",
       " \"\\n\\n7.44. (a) Find the Laplacian of $\\\\phi=f(r)$. (b) Prove that $\\\\phi=1 / r$ is a solution of Laplace's equation $\\\\nabla^{2} \\\\phi=0$.\\n\\n(a) By Problem 7.43,\\n\\n$$\\n\\\\nabla \\\\phi=\\\\nabla f(r)=\\\\frac{f^{\\\\prime}(r)}{r} \\\\mathbf{r}\\n$$\\n\\nBy Problem 7.35, assuming that $f(r)$ has continuous second partial derivatives, we have\\n\\n$$\\n\\\\begin{aligned}\\n\\\\text { Laplacian of } \\\\phi & =\\\\nabla^{2} \\\\phi=\\\\nabla \\\\cdot(\\\\nabla \\\\phi)=\\\\nabla \\\\cdot\\\\left\\\\{\\\\frac{f^{\\\\prime}(r)}{r} \\\\mathbf{r}\\\\right\\\\} \\\\\\\\\\n& =\\\\nabla\\\\left\\\\{\\\\frac{f^{\\\\prime}(r)}{r}\\\\right\\\\} \\\\cdot \\\\mathbf{r}+\\\\frac{f^{\\\\prime}(r)}{r}(\\\\nabla \\\\cdot \\\\mathbf{r})=\\\\frac{1}{r} \\\\frac{d}{d r}\\\\left\\\\{\\\\frac{f^{\\\\prime}(r)}{r}\\\\right\\\\} \\\\mathbf{r} \\\\cdot \\\\mathbf{r}+\\\\frac{f^{\\\\prime}(r)}{r}(3) \\\\\\\\\\n& =\\\\frac{r f^{\\\\prime \\\\prime}(r)+f^{\\\\prime}(r)}{r^{3}} r^{2}+\\\\frac{3 f^{\\\\prime}(r)}{r}=f^{\\\\prime \\\\prime}(r)+\\\\frac{2}{r} f^{\\\\prime}(r)\\n\\\\end{aligned}\\n$$\\n\\nAnother method: In spherical coordinates, we have\\n\\n$$\\n\\\\nabla^{2} U=\\\\frac{1}{r^{2}} \\\\frac{\\\\partial}{\\\\partial r}\\\\left(r^{2} \\\\frac{\\\\partial U}{\\\\partial r}\\\\right)+\\\\frac{1}{r^{2} \\\\sin \\\\theta} \\\\frac{\\\\partial}{\\\\partial \\\\theta}\\\\left(\\\\sin \\\\theta \\\\frac{\\\\partial U}{\\\\partial \\\\theta}\\\\right)+\\\\frac{1}{r^{2} \\\\sin ^{2} \\\\theta} \\\\frac{\\\\partial^{2} U}{\\\\partial \\\\phi^{2}}\\n$$\\n\\nIf $U=f(r)$, the last two terms on the right are zero and we find\\n\\n$$\\n\\\\nabla^{2} f(r)=\\\\frac{1}{r^{2}} \\\\frac{d}{d r}\\\\left(r^{2} f^{\\\\prime}(r)\\\\right)=f^{\\\\prime \\\\prime}(r)+\\\\frac{2}{r} f^{\\\\prime}(r)\\n$$\\n\\n(b) From the result in (a), we have\\n\\n$$\\n\\\\nabla^{2}\\\\left(\\\\frac{1}{r}\\\\right)=\\\\frac{d^{2}}{d r^{2}}\\\\left(\\\\frac{1}{r}\\\\right)+\\\\frac{2}{r} \\\\frac{d}{d r}\\\\left(\\\\frac{1}{r}\\\\right)=\\\\frac{2}{r^{3}}-\\\\frac{2}{r^{3}}=0\\n$$\\n\\nshowing that $1 / r$ is a solution of Laplace's equation.\\n\",\n",
       " '\\n7.45. A particle moves along a space curve $\\\\mathbf{r}=\\\\mathbf{r}(t)$, where $t$ is the time measured from some initial time. If $v=|d \\\\mathbf{r} / d t|=d s / d t$ is the magnitude of the velocity of the particle ( $s$ is the arc length along the space curve measured from the initial position), prove that the acceleration a of the particle is given by\\n\\n$$\\n\\\\mathbf{a}=\\\\frac{d v}{d t} \\\\mathbf{T}+\\\\frac{v^{2}}{\\\\rho} \\\\mathbf{N}\\n$$\\n\\nwhere $\\\\mathbf{T}$ and $\\\\mathbf{N}$ are unit tangent and normal vectors to the space curve and\\n\\n$$\\n\\\\rho=\\\\left|\\\\frac{d^{2} \\\\mathbf{r}}{d s^{2}}\\\\right|^{-1}=\\\\left\\\\{\\\\left(\\\\frac{d^{2} x}{d s^{2}}\\\\right)^{2}+\\\\left(\\\\frac{d^{2} y}{d s^{2}}\\\\right)^{2}+\\\\left(\\\\frac{d^{2} z}{d s^{2}}\\\\right)^{2}\\\\right\\\\}^{-1 / 2}\\n$$\\n\\nThe velocity of the particle is given by $\\\\mathbf{v}=v \\\\mathbf{T}$. Then the acceleration is given by\\n\\n\\n\\\\begin{equation*}\\n\\\\mathbf{a}=\\\\frac{d \\\\mathbf{v}}{d t}=\\\\frac{d}{d t}(v \\\\mathbf{T})=\\\\frac{d v}{d t} \\\\mathbf{T}+v \\\\frac{d \\\\mathbf{T}}{d t}=\\\\frac{d v}{d t} \\\\mathbf{T}+v \\\\frac{d \\\\mathbf{T}}{d s} \\\\frac{d s}{d t}=\\\\frac{d v}{d t} \\\\mathbf{T}+v^{2} \\\\frac{d \\\\mathbf{T}}{d s} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSince $\\\\mathbf{T}$ has a unit magnitude, we have $\\\\mathbf{T} \\\\cdot \\\\mathbf{T}=1$. Then, differentiating with respect to $s$,\\n\\n$$\\n\\\\mathbf{T} \\\\cdot \\\\frac{d \\\\mathbf{T}}{d s}+\\\\frac{d \\\\mathbf{T}}{d s} \\\\cdot \\\\mathbf{T}=0, \\\\quad 2 \\\\mathbf{T} \\\\cdot \\\\frac{d \\\\mathbf{T}}{d s}=0 \\\\quad \\\\text { or } \\\\quad \\\\mathbf{T} \\\\cdot \\\\frac{d \\\\mathbf{T}}{d s}=0\\n$$\\n\\nfrom which it follows that $d \\\\mathbf{T} / d s$ is perpendicular to $\\\\mathbf{T}$. Denoting by $\\\\mathbf{N}$ the unit vector in the direction of $d \\\\mathbf{T} /$ $d s$, and called the principal normal to the space curve, we have\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{d \\\\mathbf{T}}{d s}=\\\\kappa \\\\mathbf{N} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nwhere $k$ is the magnitude of $d \\\\mathbf{T} / d s$. Now, since $\\\\mathbf{T}=d / \\\\mathbf{r} / d s$ [see Equation (7), Page 168], we have $d \\\\mathbf{T} / d s=d^{2} \\\\mathbf{r} /$ $d s^{2}$. Hence,\\n\\n$$\\n\\\\kappa=\\\\left|\\\\frac{d^{2} \\\\mathbf{r}}{d s^{2}}\\\\right|=\\\\left\\\\{\\\\left(\\\\frac{d^{2} x}{d s^{2}}\\\\right)^{2}+\\\\left(\\\\frac{d^{2} y}{d s^{2}}\\\\right)^{2}+\\\\left(\\\\frac{d^{2}}{d s}\\\\right.\\\\right.\\n$$\\n\\nDefining $\\\\rho=1 / k$, Equation (2) becomes $d \\\\mathbf{T} / d s=\\\\mathbf{N} / \\\\rho$. Thus, from Equation (1) we have, as required,\\n\\n$$\\n\\\\mathbf{a}=\\\\frac{d v}{d t} \\\\mathbf{T}+\\\\frac{v^{2}}{\\\\rho} \\\\mathbf{N}\\n$$\\n\\nThe components $d v / d t$ and $v^{2} / \\\\rho$ in the direction of $\\\\mathbf{T}$ and $\\\\mathbf{N}$ are called the tangential and normal components of the acceleration, the latter being sometimes called the centripetal acceleration. The quantities $\\\\rho$ and $k$ are, respectively, the radius of curvature and curvature of the space curve.\\n\\n',\n",
       " '8.1. Find equations for the (a) tangent plane and (b) normal line to the surface $x^{2} y z+3 y^{2}=2 x z^{2}-8 z$ at the point $(1,2,-1)$.\\n\\n(a) The equation of the surface is $F=x^{2} y z+3 y^{2}-2 x z^{2}+8 z=0$. A normal line to the surface at $(1,2,-1)$ is\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{N}_{0}=\\\\left.\\\\nabla F\\\\right|_{(1,2,-1)} & =\\\\left(2 x y z-2 z^{2}\\\\right) \\\\mathbf{i}+\\\\left(x^{2} z+6 y\\\\right) \\\\mathbf{j}+\\\\left.(x y-4 x z+8) \\\\mathbf{k}\\\\right|_{(1,2,-1)} \\\\\\\\\\n& =-6 \\\\mathbf{i}+11 \\\\mathbf{j}+14 \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\nReferring to Figure 8.1:\\n\\nThe vector from $O$ to any point $(x, y, z)$ on the tangent plane is $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}$.\\n\\nThe vector from $O$ to the point $(1,2,-1)$ on the tangent plane is $\\\\mathbf{r}_{0}=\\\\mathbf{i}+2 \\\\mathbf{j}-\\\\mathbf{k}$.\\n\\nThe vector $\\\\mathbf{r}-\\\\mathbf{r}_{0}=(x-1) \\\\mathbf{i}+(y-2) \\\\mathbf{j}+(z+1) \\\\mathbf{k}$ lies in the tangent plane and is thus perpendicular to $\\\\mathbf{N}_{0}$.\\n\\nThen the required equation is\\n\\n$$\\n\\\\begin{gathered}\\n\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right) \\\\cdot \\\\mathbf{N}_{0}=0 \\\\quad \\\\text { i.e., } \\\\quad\\\\{(x-1) \\\\mathbf{i}+(y-2) \\\\mathbf{j}+(z+1) \\\\mathbf{k}\\\\} \\\\cdot\\\\{-6 \\\\mathbf{i}+11 \\\\mathbf{j}+14 \\\\mathbf{k}\\\\}=0 \\\\\\\\\\n-6(x-1)+11(y-2)+14(z+1)=0 \\\\text { or } 6 x-11 y-14 z+2=0\\n\\\\end{gathered}\\n$$\\n\\n(b) Let $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}$ be the vector from $O$ to any point $(x, y, z)$ of the normal $\\\\mathbf{N}_{0}$. The vector from $O$ to the point $(1,2,-1)$ on the normal is $\\\\mathbf{r}_{0}=2 \\\\mathbf{i}+2 \\\\mathbf{j}-\\\\mathbf{k}$. The vector $\\\\mathbf{r}-\\\\mathbf{r}_{0}=(x-1) \\\\mathbf{i}+(y-2) \\\\mathbf{j}+(z+1) \\\\mathbf{k}$ is collinear with $\\\\mathbf{N}_{0}$. Then\\n\\n$$\\n\\\\left(r-r_{0}\\\\right) \\\\times N_{0}=0 \\\\quad \\\\text { i.e., } \\\\quad\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\nx-1 & y-2 & x+1 \\\\\\\\\\n-6 & 11 & 14\\n\\\\end{array}\\\\right|=0\\n$$\\n\\nwhich is equivalent to the equations\\n\\n$$\\n11(x-1)=-6(y-2), 14(y-2)=11(z+1), 14(x-1)=-6(z+1)\\n$$\\n\\nThese can be written as\\n\\n$$\\n\\\\frac{x-1}{-6}=\\\\frac{y-2}{11}=\\\\frac{z+1}{14}\\n$$\\n\\noften called the standard form for the equations of a line. By setting each of these ratios equal to the parameter $t$, we have\\n\\n$$\\nx=1-6 t, \\\\quad y=2+11 t, \\\\quad z=14 t-1\\n$$\\n\\ncalled the parametric equations for the line.\\n',\n",
       " '\\n8.2. In what point does the normal line of Problem 8.1(b) meet the plane $x+3 y-2 z=10$ ?\\n\\nSubstituting the parametric equations of Problem 8.1(b), we have\\n\\n$$\\n1-6 t+3(2+11 t)-2(14 t-1)=10 \\\\text { or } t=-1\\n$$\\n\\nThen $x=1-6 t=7, y=2+11 t=-9, z=14 t-1=-15$ and the required point is $(7,-9,-15)$.\\n',\n",
       " '\\n8.3. Show that the surface $x^{2}-2 y z+y^{3}=4$ is perpendicular to any member of the family of surfaces $x^{2}+1=$ $(2-4 a) y^{2}+a z^{2}$ at the point of intersection $(1,-1,2)$.\\n\\nLet the equations of the two surfaces be written in the form\\n\\n$$\\nF=x^{2}-2 y z+y^{3}-4=0 \\\\text { and } G=x^{2}+1-(2-4 a) y^{2}-a z^{2}=0\\n$$\\n\\nThen\\n\\n$$\\n\\\\nabla F=2 x \\\\mathbf{i}+\\\\left(3 y^{2}-2 z\\\\right) \\\\mathbf{j}-2 y \\\\mathbf{k}, \\\\quad \\\\nabla G=2 x \\\\mathbf{i}-2(2-4 a) y \\\\mathbf{j}-2 a z \\\\mathbf{k}\\n$$\\n\\nThus, the normals to the two surfaces at $(1,-1,2)$ are given by\\n\\n$$\\n\\\\mathbf{N}_{1}=2 \\\\mathbf{i}-\\\\mathbf{j}+2 \\\\mathbf{k}, \\\\mathbf{N}_{2}=2 \\\\mathbf{i}+2(2-4 a) \\\\mathbf{j}-4 a \\\\mathbf{k}\\n$$\\n\\nSince $\\\\mathbf{N}_{1} \\\\cdot \\\\mathbf{N}_{2}=(2)(2)-2(2-4 a)-(2)(4 a) \\\\equiv 0$, it it follows that $\\\\mathbf{N}_{1}$ and $\\\\mathbf{N}_{2}$ are perpendicular for all $a$, and so the required result follows.\\n',\n",
       " '\\n8.4. The equation of a surface is given in spherical coordinates by $F(r, \\\\theta, \\\\phi)=0$, where we suppose that $F$ is continuously differentiable. (a) Find an equation for the tangent plane to the surface at the point $\\\\left(r_{0}, \\\\theta_{0}, \\\\phi_{0}\\\\right)$. (b) Find an equation for the tangent plane to the surface $r=4 \\\\cos \\\\theta$ at the point $(2 \\\\sqrt{2}, \\\\pi / 4,3 \\\\pi / 4)$. (c) Find a set of equations for the normal line to the surface in ( ) at the indicated point.\\n\\n(a) The gradient of $\\\\Phi$ in orthogonal curvilinear coordinates is\\n\\n$$\\n\\\\nabla \\\\Phi=\\\\frac{1}{h_{1}} \\\\frac{\\\\partial \\\\Phi}{\\\\partial u_{1}} \\\\mathbf{e}_{1}+\\\\frac{1}{h_{2}} \\\\frac{\\\\partial \\\\Phi}{\\\\partial u_{2}} \\\\mathbf{e}_{2}+\\\\frac{1}{h_{3}} \\\\frac{\\\\partial \\\\Phi}{\\\\partial u_{3}} \\\\mathbf{e}_{3}\\n$$\\n\\nwhere\\n\\n$$\\n\\\\mathbf{e}_{1}=\\\\frac{1}{h_{1}} \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u_{1}}, \\\\quad \\\\mathbf{e}_{2}=\\\\frac{1}{h_{2}} \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u_{2}}, \\\\quad \\\\mathbf{e}_{3}=\\\\frac{1}{h_{3}} \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u_{3}}\\n$$\\n\\n(see Pages 170 and 172).\\n\\nIn spherical coordinates $u_{1}=r, u_{2}=\\\\theta, u_{3}=\\\\phi, h_{1}=1, h_{2}=r, h_{3}=r \\\\sin \\\\theta$ and $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}=r \\\\sin \\\\theta \\\\cos$ $\\\\phi \\\\mathbf{i}+r \\\\sin \\\\theta \\\\sin \\\\phi \\\\mathbf{j}+r \\\\cos \\\\theta \\\\mathbf{k}$.\\n\\nThen\\n\\n\\\\[\\n\\\\left\\\\{\\\\begin{array}{l}\\n\\\\mathbf{e}_{1}=\\\\sin \\\\theta \\\\cos \\\\theta \\\\mathbf{i}+\\\\sin \\\\theta \\\\sin \\\\theta \\\\mathbf{j}+\\\\cos \\\\theta \\\\mathbf{k}  \\\\tag{1}\\\\\\\\\\n\\\\mathbf{e}_{2}=\\\\cos \\\\theta \\\\cos \\\\phi \\\\mathbf{i}+\\\\cos \\\\theta \\\\sin \\\\phi \\\\mathbf{j}-\\\\sin \\\\theta \\\\mathbf{k} \\\\\\\\\\n\\\\mathbf{e}_{3}=-\\\\sin \\\\phi \\\\mathbf{i}+\\\\cos \\\\phi \\\\mathbf{j}\\n\\\\end{array}\\\\right.\\n\\\\]\\n\\nand\\n\\n\\n\\\\begin{equation*}\\n\\\\nabla F=\\\\frac{\\\\partial F}{\\\\partial r} \\\\mathrm{e}_{1}+\\\\frac{1}{r} \\\\frac{\\\\partial F}{\\\\partial \\\\theta} \\\\mathrm{e}_{2}+\\\\frac{1}{r \\\\sin \\\\theta} \\\\frac{\\\\partial F}{\\\\partial \\\\phi} \\\\mathrm{e}_{3} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nAs on Page 196, the required equation is $\\\\left.\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right) \\\\cdot \\\\nabla F\\\\right|_{P}=0$.\\n\\nNow, substituting Equations (1) and (2), we have\\n\\n$$\\n\\\\begin{aligned}\\n\\\\left.\\\\nabla F\\\\right|_{P}= & \\\\left\\\\{\\\\left.\\\\frac{\\\\partial F}{\\\\partial r}\\\\right|_{P} \\\\sin \\\\theta_{0} \\\\cos \\\\phi_{0}+\\\\left.\\\\frac{1}{r_{0}} \\\\frac{\\\\partial F}{\\\\partial \\\\theta}\\\\right|_{P} \\\\cos \\\\theta_{0} \\\\cos \\\\phi_{0}-\\\\left.\\\\frac{\\\\sin \\\\phi_{0}}{r_{0} \\\\sin \\\\theta_{0}} \\\\frac{\\\\partial F}{\\\\partial \\\\phi}\\\\right|_{P}\\\\right\\\\} \\\\mathbf{i} \\\\\\\\\\n& +\\\\left\\\\{\\\\left.\\\\frac{\\\\partial F}{\\\\partial r}\\\\right|_{P} \\\\sin \\\\theta_{0} \\\\sin \\\\phi_{0}+\\\\left.\\\\frac{1}{r_{0}} \\\\frac{\\\\partial F}{\\\\partial \\\\theta}\\\\right|_{P} \\\\cos \\\\theta_{0} \\\\sin \\\\phi_{0}+\\\\left.\\\\frac{\\\\cos \\\\phi_{0}}{r_{0} \\\\sin \\\\theta_{0}} \\\\frac{\\\\partial F}{\\\\partial \\\\phi}\\\\right|_{P}\\\\right\\\\} \\\\mathbf{j} \\\\\\\\\\n& +\\\\left\\\\{\\\\left.\\\\frac{\\\\partial F}{\\\\partial r}\\\\right|_{P} \\\\cos \\\\theta_{0}-\\\\left.\\\\frac{1}{r_{0}} \\\\frac{\\\\partial F}{\\\\partial \\\\theta}\\\\right|_{P} \\\\sin \\\\theta_{0}\\\\right\\\\} \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\nDenoting the expressions in braces by $A, B, C$, respectively, so that $\\\\left.\\\\nabla F\\\\right|_{p}=A \\\\mathbf{i}+B \\\\mathbf{j}+C \\\\mathbf{k}$, we see that the required equation is $A\\\\left(x-x_{0}\\\\right)+B\\\\left(y-y_{0}\\\\right)+C\\\\left(z-z_{0}\\\\right)=0$. This can be written in spherical coordinates by using the transformation equations for $x, y$, and $z$ in these coordinates.\\n\\n(b) We have $F=r-4 \\\\cos \\\\theta=0$. Then $\\\\partial F / \\\\partial r=1, \\\\partial F / \\\\partial \\\\theta=4 \\\\sin \\\\theta, \\\\partial F / \\\\partial \\\\phi=0$.\\n\\nSince $r_{0}=2 \\\\sqrt{2}, \\\\theta_{0}=\\\\pi / 4, \\\\phi_{0}=3 \\\\pi / 4$, we have from (a), $\\\\left.\\\\nabla F\\\\right|_{p}=A \\\\mathbf{i}+B \\\\mathbf{j}+C \\\\mathbf{k}=-\\\\mathbf{i}+\\\\mathbf{j}$.\\n\\nFrom the transformation equations, the given point has rectangular coordinates $(-\\\\sqrt{2}, \\\\sqrt{2}, 2)$, and so $r-r_{0}=(x+\\\\sqrt{2}) \\\\mathbf{i}+(y-\\\\sqrt{2}) \\\\mathbf{j}+(z-2) \\\\mathbf{k}$.\\n\\nThe required equation of the plane is thus $-(x+\\\\sqrt{2})+(y-\\\\sqrt{2})=0$ or $y-x=2 \\\\sqrt{2}$. In spherical coordinates this becomes $r \\\\sin \\\\theta \\\\sin \\\\phi-r \\\\sin \\\\theta \\\\cos \\\\phi=2 \\\\sqrt{2}$.\\n\\nIn rectangular coordinates the equation $r=4 \\\\cos \\\\theta$ becomes $\\\\left.x^{2}+y^{2}+(z-2)^{2}\\\\right)=4$ and the tangent plane can be determined from this as in Problem 8.1. In other cases, however, it may not be so easy to obtain the equation in rectangular form, and in such cases the method of part $(a)$ is simpler to use.\\n\\n(c) The equations of the normal line can be represented by\\n\\n$$\\n\\\\frac{x+\\\\sqrt{2}}{-1}=\\\\frac{y-\\\\sqrt{2}}{1}=z=2\\n$$\\n\\n\\n\\\\section*{Tangent Line and Normal Plane to a Curve}\\n',\n",
       " '8.5. Find equations for (a) the tangent line and (b) the normal plane to the curve $x=t-\\\\cos t, y=3+\\\\sin 2 t, z=$ $1+\\\\cos 3 t$ at the point where $t=1 / 2 \\\\pi$.\\n\\n(a) The vector from origin $O$ (see Figure 8.2) to any point of curve $C$ is $\\\\mathbf{R}=(t-\\\\cos t) \\\\mathbf{i}+(3+\\\\sin 2 t) \\\\mathbf{j}+(1+$ $\\\\cos 3 t) \\\\mathbf{k}$. Then a vector tangent to $C$ at the point where $t=\\\\frac{1}{2} \\\\pi$ is\\n\\n$$\\n\\\\mathbf{T}_{0}=\\\\left.\\\\frac{d \\\\mathbf{R}}{d t}\\\\right|_{t=1 / 2 \\\\pi}=(1+\\\\sin t) i+2 \\\\cos 2 t \\\\mathbf{j}-\\\\left.3 \\\\sin 3 t \\\\mathbf{k}\\\\right|_{t=1 / 2 \\\\pi}=2 \\\\mathbf{i}-2 \\\\mathbf{j}+3 \\\\mathbf{k}\\n$$\\n\\nThe vector from $O$ to the point where $t=1 / 2 \\\\pi$ is $\\\\mathbf{r}_{0}=1 / 2 \\\\pi \\\\mathbf{i}+3 \\\\mathbf{j}+\\\\mathbf{k}$.\\n\\nThe vector from $O$ to any point $(x, y, z)$ on the tangent line is $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}$.\\n\\nThen $\\\\left.\\\\mathbf{r}-\\\\mathbf{r}_{0}=\\\\left(x-\\\\frac{1}{2} \\\\pi\\\\right) \\\\mathbf{i}+y-3\\\\right) \\\\mathbf{j}+(z-1) \\\\mathbf{k}$ is collinear with $\\\\mathbf{T}_{0}$, so that the required equation is\\n\\n$$\\n\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right) \\\\times \\\\mathbf{T}_{0}=\\\\mathbf{0}, \\\\quad \\\\text { i.e., } \\\\quad\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\nx-\\\\frac{1}{2} \\\\pi & y-3 & z-1 \\\\\\\\\\n2 & -2 & 3\\n\\\\end{array}\\\\right|=0\\n$$\\n\\nand the required equations are $\\\\frac{x-\\\\frac{1}{2} \\\\pi}{2}=\\\\frac{y-3}{-2}=\\\\frac{z-1}{3}$ or, in parametric form, $x=2 t+\\\\frac{1}{2} \\\\pi, y=3-2 t$,\\\\\\\\\\n$z=3 t+1$.\\n\\n(b) Let $r=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}$ be the vector from $O$ to any point $(x, y, z)$ of the normal plane. The vector from $O$ to the point where $t=\\\\frac{1}{2} \\\\pi$ is $\\\\mathbf{r}_{0}=\\\\frac{1}{2} \\\\pi \\\\mathbf{i}+3 \\\\mathbf{j}+\\\\mathbf{k}$. The vector $\\\\mathbf{r}-\\\\mathbf{r}_{0}=\\\\left(x-\\\\frac{1}{2} \\\\pi\\\\right) \\\\mathbf{i}+(y-3) \\\\mathbf{j}+(z-1) \\\\mathbf{k}$ lies in the normal plane and, hence, is perpendicular to $\\\\mathbf{T}_{0}$. Then the required equation is $\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right) \\\\cdot \\\\mathbf{T}_{0}=0$ or 2 $\\\\left(x-\\\\frac{1}{2} \\\\pi\\\\right)-2(y-3)+3(z-1)=0$.\\n',\n",
       " '\\n8.6. Find equations for (a) the tangent line and (b) the normal plane to the curve $3 x^{2} y+y^{2} z=-2,2 x z-x^{2} y=3$ at the point $(1,-1,1)$.\\n\\n(a) The equations of the surfaces intersecting in the curve are\\n\\n$$\\nF=3 x^{2} y+y^{2} z+2=0, G=2 x z-x^{2} y-3=0\\n$$\\n\\nThe normals to each surface at the point $P(1,-1,1)$ are, respectively,\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\mathbf{N}_{1}=\\\\left.\\\\nabla F\\\\right|_{P}=6 x y \\\\mathbf{i}+\\\\left(3 x^{2}+2 y z\\\\right) \\\\mathbf{j}+y^{2} \\\\mathbf{k}=-6+\\\\mathbf{j}+\\\\mathbf{k} \\\\\\\\\\n& \\\\mathbf{N}_{2}=\\\\left.\\\\nabla G\\\\right|_{P}=(2 z-2 x y) \\\\mathbf{i}-x^{2} \\\\mathbf{j}+2 x \\\\mathbf{k}=4 \\\\mathbf{i}-\\\\mathbf{j}+2 \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\nThen a tangent vector to the curve at $P$ is\\n\\n$$\\n\\\\mathbf{T}_{0}=\\\\mathbf{N}_{1} \\\\times \\\\mathbf{N}_{2}=(-6 \\\\mathbf{i}+\\\\mathbf{j}+\\\\mathbf{k}) \\\\times(4-\\\\mathbf{j}+2 \\\\mathbf{k})=3 \\\\mathbf{i}+16 \\\\mathbf{j}+2 \\\\mathbf{k}\\n$$\\n\\nThus, as in Problem 8.5(a), the tangent line is given by\\n\\n$$\\n\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right) \\\\times \\\\mathbf{T}_{0}=0 \\\\text { or }\\\\{(x-1) \\\\mathbf{i}+(y+1) \\\\mathbf{j}+(z-1) \\\\mathbf{k}\\\\} \\\\times\\\\{3 \\\\mathbf{i}+16 \\\\mathbf{j}+2 \\\\mathbf{k}\\\\}=\\\\mathbf{0}\\n$$\\n\\ni.e.,\\n\\n$$\\n\\\\frac{x-1}{3}=\\\\frac{y+1}{16}=\\\\frac{z-1}{2} \\\\quad \\\\text { or } \\\\quad x=1+3 t, \\\\quad y=16 t-1, \\\\quad z=2 t+1\\n$$\\n\\n(b) As in Problem 8.5(b), the normal plane is given by\\n\\n$$\\n\\\\left(r-\\\\mathbf{r}_{0}\\\\right) \\\\cdot \\\\mathbf{T}_{0}=0 \\\\text { or }\\\\{(x-1) \\\\mathbf{i}+(y+1) \\\\mathbf{j}+(z-1) \\\\mathbf{k}\\\\} \\\\cdot\\\\{3 \\\\mathbf{i}+16 \\\\mathbf{j}+2 \\\\mathbf{k}\\\\}=0\\n$$\\n\\ni.e.,\\n\\n$$\\n3(x-1)+16(y+1)+2(z-1)=0 \\\\text { or } 3 x+16 y+2 z=-11\\n$$\\n\\nThe results in (a) and (b) can also be obtained by using Equations (7) and (10), respectively, from Page 197.\\n',\n",
       " '\\n8.7. Establish equation (10), from Page 197.\\n\\nSuppose the curve is defined by the intersection of two surfaces whose equations are $F(x, y, z)=0, G(x$, $y, z)=0$, where we assume $F$ and $G$ to be continuously differentiable.\\n\\nThe normals to each surface at point $P$ are given, respectively, by $\\\\mathbf{N}_{1}=\\\\left.\\\\nabla F\\\\right|_{P}$ and $\\\\mathbf{N}_{2}=\\\\left.\\\\nabla G\\\\right|_{P}$. Then a tangent vector to the curve at $P$ is $\\\\mathbf{T}_{0}=\\\\mathbf{N}_{1} \\\\times \\\\mathbf{N}_{2}=\\\\left.\\\\nabla F\\\\right|_{P} \\\\times\\\\left.\\\\nabla G\\\\right|_{P}$. Thus, the equation of the normal plane is $\\\\left(\\\\mathbf{r}-\\\\mathbf{r}_{0}\\\\right) \\\\cdot \\\\mathbf{T}_{0}=0$. Now\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{T}_{0} & =\\\\left.\\\\nabla F\\\\right|_{P} \\\\times\\\\left.\\\\nabla G\\\\right|_{P}=\\\\left.\\\\left\\\\{\\\\left(F_{x} i+F_{y} j+F_{z} k\\\\right) \\\\times\\\\left(G_{x} i+G_{y} j+G_{z} k\\\\right)\\\\right\\\\}\\\\right|_{P} \\\\\\\\\\n& =\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\nF_{x} & F_{y} & F_{z} \\\\\\\\\\nG_{x} & G_{y} & G_{z}\\n\\\\end{array}\\\\right|_{P}=\\\\left|\\\\begin{array}{cc}\\nF_{y} & F_{z} \\\\\\\\\\nG_{y} & G_{z}\\n\\\\end{array}\\\\right|_{P} \\\\mathbf{i}+\\\\left|\\\\begin{array}{cc}\\nF_{x} & F_{x} \\\\\\\\\\nG_{x} & G_{x}\\n\\\\end{array}\\\\right|_{P} \\\\mathbf{j}+\\\\left|\\\\begin{array}{cc}\\nF_{x} & F_{y} \\\\\\\\\\nG_{x} & G_{y}\\n\\\\end{array}\\\\right|_{P} \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\nand so the required equation is\\n\\n$$\\n\\\\left.\\\\left(r-r_{0}\\\\right) \\\\cdot \\\\nabla F\\\\right|_{P}=0 \\\\quad \\\\text { or } \\\\quad\\\\left|\\\\begin{array}{ll}\\nF_{y} & F_{z} \\\\\\\\\\nG_{y} & G_{z}\\n\\\\end{array}\\\\right|_{P}\\\\left(x-x_{0}\\\\right)+\\\\left|\\\\begin{array}{ll}\\nF_{z} & F_{x} \\\\\\\\\\nG_{z} & G_{x}\\n\\\\end{array}\\\\right|_{P}\\\\left(y-y_{0}\\\\right)+\\\\left|\\\\begin{array}{cc}\\nF_{x} & F_{y} \\\\\\\\\\nG_{x} & G_{y}\\n\\\\end{array}\\\\right|_{P}\\\\left(z-z_{0}\\\\right)=0\\n$$\\n\\n\\n\\\\section*{Envelopes}\\n',\n",
       " '8.8. Prove that the envelope of the family $\\\\phi(x, y, \\\\alpha)=0$, if it exists, can be obtained by solving simultaneously the equations $\\\\phi=0$ and $\\\\phi_{\\\\alpha}=0$.\\n\\nAssume parametric equations of the envelope to be $x=f(\\\\alpha), y=g(\\\\alpha)$. Then $\\\\phi(f(\\\\alpha), g(\\\\alpha), \\\\alpha)=0$ identically, so, upon differentiating with respect to $\\\\alpha$ (assuming that $\\\\phi, f$, and $g$ have continuous derivatives), we have\\n\\n\\n\\\\begin{equation*}\\n\\\\phi_{x} f^{\\\\prime}(\\\\alpha)+\\\\phi_{y} g^{\\\\prime}(\\\\alpha)+\\\\phi_{\\\\alpha}=0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nThe slope of any member of the family $\\\\phi(x, y, \\\\alpha)=0$ at $(x, y)$ is given by $\\\\phi_{x} d x+\\\\phi_{y} d y=0$ or $\\\\frac{d y}{d x}=-\\\\frac{\\\\phi_{x}}{\\\\phi_{y}}$. The slope of the envelope at $(x, y)$ is $\\\\frac{d y}{d x}=\\\\frac{d y / d \\\\alpha}{d x / d \\\\alpha}=\\\\frac{g^{\\\\prime}(\\\\alpha)}{f^{\\\\prime}(\\\\alpha)}$. Then at any point where the envelope and a member of the family are tangent, we must have\\n\\n\\n\\\\begin{equation*}\\n-\\\\frac{\\\\phi_{x}}{\\\\phi_{y}}=\\\\frac{g^{\\\\prime}(\\\\alpha)}{f^{\\\\prime}(\\\\alpha)} \\\\quad \\\\text { or } \\\\quad \\\\phi_{x} f^{\\\\prime}(\\\\alpha)+\\\\phi_{y} g^{\\\\prime}(\\\\alpha)=0 \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nComparing Equations (2) with (1), we see that $\\\\phi_{\\\\alpha}=0$, and the required result follows.\\n',\n",
       " '\\n8.9. (a) Find the envelope of the family $x \\\\sin \\\\alpha+y \\\\cos \\\\alpha=1$. (b) Illustrate the results geometrically.\\n\\n(a) By Problem 8.8 the envelope, if it exists, is obtained by solving simultaneously the equations $\\\\phi(x, y, \\\\alpha)$ $=x \\\\sin \\\\alpha+y \\\\cos \\\\alpha-1=0$ and $\\\\phi_{\\\\alpha}(x, y, \\\\alpha)=x \\\\cos \\\\alpha-y \\\\cos \\\\alpha=0$. From these equations we find $x=\\\\sin$ $\\\\alpha, y=\\\\cos \\\\alpha$ or $x^{2}+y^{2}=1$.\\n\\n(b) The given family is a family of straight lines, some members of which are indicated in Figure 8.5. The envelope is the circle $x^{2}+y^{2}=1$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-216}\\n\\\\end{center}\\n\\nFig. 8.5\\n',\n",
       " '\\n8.10. Find the envelope of the family of surfaces $z=2 \\\\alpha x-a^{2} y$.\\n\\nBy a generalization of Problem 8.8, the required envelope, if it exists, is obtained by solving simultaneously the equations\\n\\n\\n\\\\begin{equation*}\\n\\\\phi=2 \\\\alpha x-\\\\alpha^{2} y-z=0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nand\\n\\n\\n\\\\begin{equation*}\\n\\\\phi_{\\\\alpha}=2 x-2 \\\\alpha y=0 \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nFrom Equation (2), $\\\\alpha=x / y$. Then substitution in Equation (1) yields $x^{2}=y z$, the required envelope.\\n',\n",
       " '\\n8.11. Find the envelope of the two-parameter family of surfaces $z=\\\\alpha x+\\\\beta y-\\\\alpha \\\\beta$.\\n\\nThe envelope of the family $F(x, y, z, \\\\alpha, \\\\beta)=0$, if it exists, is obtained by eliminating $\\\\alpha$ and $\\\\beta$ between the equations $F=0, F_{\\\\alpha}=0, F_{\\\\beta}=0$ (see Problem 8.43). Now\\n\\n$$\\nF=z-\\\\alpha x-\\\\beta y+\\\\alpha \\\\beta=0, F_{\\\\alpha}=-x+\\\\beta=0, F_{\\\\beta}=-y+\\\\alpha=0\\n$$\\n\\nThen $\\\\beta=x, \\\\alpha=y$, and we have $z=x y$.\\n\\n\\n\\\\section*{Directional derivatives}\\n',\n",
       " '8.12. Find the directional derivative of $F=x^{2} y z^{3}$ along the curve $x=e^{-u}, y=2 \\\\sin u+1, z=u-\\\\cos u$ at the point $P$ where $u=0$.\\n\\nThe point $P$ corresponding to $u=0$ is $(1,1,-1)$. Then\\n\\n$$\\n\\\\nabla F=2 x y z^{3} \\\\mathbf{i}+x^{2} z^{3} \\\\mathbf{j}+3 x^{2} y z^{2} \\\\mathbf{k}=-2 \\\\mathbf{i}-\\\\mathbf{j}+3 \\\\mathbf{k} \\\\text { at } P\\n$$\\n\\nA tangent vector to the curve is\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{d r}{d u} & =\\\\frac{d}{d u}\\\\left\\\\{e^{-u} \\\\mathbf{i}+(2 \\\\sin u+1) \\\\mathbf{j}+(u-\\\\cos u) k\\\\right\\\\} \\\\\\\\\\n& =-e^{-u} \\\\mathbf{i}+2 \\\\cos u \\\\mathbf{j}+(1+\\\\sin u) \\\\mathbf{k}=-\\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k} \\\\text { at } P\\n\\\\end{aligned}\\n$$\\n\\nand the unit tangent vector in this direction is\\n\\n$$\\n\\\\mathbf{T}_{0}=\\\\frac{-\\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k}}{\\\\sqrt{6}}\\n$$\\n\\nThen\\n\\n$$\\n\\\\text { Directional derivative }=\\\\nabla F . \\\\mathbf{T}_{0}=(-2 \\\\mathbf{i}-\\\\mathbf{j}+3 \\\\mathbf{k}) \\\\cdot\\\\left(\\\\frac{-\\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k}}{\\\\sqrt{6}}\\\\right)=\\\\frac{3}{\\\\sqrt{6}}=\\\\frac{1}{2} \\\\sqrt{6}\\n$$\\n\\nSince this is positive, $F$ is increasing in this direction.\\n',\n",
       " '\\n8.13. Prove that the greatest rate of change of $F$, i.e., the maximum directional derivative, takes place in the direction of, and has the magnitude of, the vector $\\\\nabla F$.\\n\\n$$\\n\\\\frac{d F}{d s}=\\\\nabla F \\\\cdot \\\\frac{d \\\\mathbf{r}}{d s} \\\\text { is the projection of } \\\\nabla F \\\\text { in the direction } \\\\frac{d \\\\mathbf{r}}{d s} \\\\text {. This projection is a maximum when } \\\\nabla F \\\\text { and }\\n$$\\n\\n$d \\\\mathbf{r} / d s$ have the same direction. Then the maximum value of $d F / d s$ takes place in the direction of $\\\\nabla F$, and the magnitude is $|\\\\nabla F|$.\\n',\n",
       " '\\n8.14. (a) Find the directional derivative of $U=2 x^{3} y-3 y^{2} z$ at $P(1,2,-1)$ in a direction toward $Q(3,-1,5)$. (b) In what direction from $P$ is the directional derivative a maximum? (c) What is the magnitude of the maximum directional derivative?\\n\\n(a) $\\\\nabla U=6 x^{2} y \\\\mathbf{i}+\\\\left(2 x^{3}-6 y z\\\\right) \\\\mathbf{j}-3 y^{2} \\\\mathbf{k}=12 \\\\mathbf{i}+14 \\\\mathbf{j}-12 \\\\mathbf{k}$ at $P$.\\n\\nThe vector from $P$ to $Q=(3-1) \\\\mathbf{i}+(-1-2) \\\\mathbf{j}+[5-(-1)] \\\\mathbf{k}=2 \\\\mathbf{i}-3 \\\\mathbf{j}+6 \\\\mathbf{k}$\\n\\nThe unit vector from $P$ to $\\\\mathrm{Q}=\\\\mathrm{T}=\\\\frac{2 \\\\mathbf{i}-3 \\\\mathbf{j}+6 \\\\mathbf{k}}{\\\\sqrt{(2)^{2}+(-3)^{2}+(6)^{2}}}=\\\\frac{2 \\\\mathbf{i}-3 \\\\mathbf{j}+6 \\\\mathbf{k}}{7}$\\n\\nThen\\n\\nDirectional derivative at $\\\\mathrm{P}=(12 \\\\mathbf{i}+14 \\\\mathbf{j}-12 \\\\mathbf{k}) \\\\cdot\\\\left(\\\\frac{2 \\\\mathbf{i}-3 \\\\mathbf{j}+6 \\\\mathbf{k}}{7}\\\\right)=-\\\\frac{90}{7}$\\n\\ni.e., $U$ is decreasing in this direction.\\n\\n(b) From Problem 8.13, the directional derivative is a maximum in the direction $12 \\\\mathbf{i}+14 \\\\mathbf{j}-12 \\\\mathbf{k}$.\\n\\n(c) From Problem 8.13, the value of the maximum directional derivative is $|12 \\\\mathbf{i}+14 \\\\mathbf{j}-12 \\\\mathbf{k}|=$ $\\\\sqrt{144+196+144}=22$.\\n\\n\\n\\\\section*{Differentiation under the integral sign}\\n',\n",
       " \"8.15. Prove Leibnitz's rule for differentiating under the integral sign.\\n\\nLet $\\\\phi(\\\\boldsymbol{\\\\alpha})=\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f(x, \\\\boldsymbol{\\\\alpha}) d x$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Delta \\\\phi & =\\\\phi(\\\\alpha+\\\\Delta \\\\alpha)-\\\\phi(\\\\alpha)=\\\\int_{u_{1}(\\\\alpha+\\\\Delta \\\\alpha}^{u_{2}(\\\\alpha+\\\\Delta \\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x-\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f(x, \\\\alpha) d x \\\\\\\\\\n& =\\\\int_{u_{1}(\\\\alpha+\\\\Delta \\\\alpha}^{u_{1}(\\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x+\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha)+\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha+\\\\Delta \\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x-\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f(x, \\\\alpha) d x \\\\\\\\\\n& =\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)}[f(x, \\\\alpha+\\\\Delta \\\\alpha)-f(x, \\\\alpha)] d x+\\\\int_{u_{2}(\\\\alpha)}^{u_{2}(\\\\alpha+\\\\Delta \\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x-\\\\int_{u_{1}(\\\\alpha)}^{u_{1}(\\\\alpha+\\\\Delta \\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x\\n\\\\end{aligned}\\n$$\\n\\nBy the mean value theorem for integrals, we have\\n\\n\\n\\\\begin{gather*}\\n\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)}[f(x, \\\\alpha+\\\\Delta \\\\alpha)-f(x, \\\\alpha)] d x=\\\\Delta \\\\alpha \\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f(x, \\\\xi) d x  \\\\tag{1}\\\\\\\\\\n\\\\int_{u_{1}(\\\\alpha)}^{u_{1}(\\\\alpha+\\\\Delta \\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x=f\\\\left(\\\\xi_{1}, \\\\alpha+\\\\Delta \\\\alpha\\\\right)\\\\left[u_{1}(\\\\alpha+\\\\Delta \\\\alpha)-u_{1}(\\\\alpha)\\\\right] \\\\tag{2}\\n\\\\end{gather*}\\n\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{u_{2}(\\\\alpha)}^{u_{2}(\\\\alpha+\\\\Delta \\\\alpha)} f(x, \\\\alpha+\\\\Delta \\\\alpha) d x=f\\\\left(\\\\xi_{2}, \\\\alpha+\\\\Delta \\\\alpha\\\\right)\\\\left[u_{1}(\\\\alpha+\\\\Delta \\\\alpha)-u_{1}(\\\\alpha)\\\\right] \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nwhere $\\\\xi$ is between $\\\\alpha+\\\\Delta \\\\alpha$, $\\\\xi_{1}$ is between $u_{1}(\\\\alpha)$ and $u_{1}(\\\\alpha+\\\\Delta \\\\alpha)$ and $\\\\xi_{2}$ is between $u_{2}(\\\\alpha)$ and $u_{2}(\\\\alpha+\\\\Delta \\\\alpha)$.\\n\\nThen\\n\\n$$\\n\\\\frac{\\\\Delta \\\\phi}{\\\\Delta \\\\phi}=\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f_{\\\\alpha}(x, \\\\xi) d x+f\\\\left(\\\\xi_{2}, \\\\alpha+\\\\Delta \\\\alpha\\\\right) \\\\frac{\\\\Delta u_{2}}{\\\\Delta \\\\alpha}-f\\\\left(\\\\xi_{1}, \\\\alpha+\\\\Delta \\\\alpha\\\\right) \\\\frac{\\\\Delta u_{1}}{\\\\Delta \\\\alpha}\\n$$\\n\\nTaking the limit as $\\\\Delta \\\\alpha \\\\rightarrow 0$, making use of the fact that the functions are assumed to have continuous derivatives, we obtain\\n\\n$$\\n\\\\frac{d \\\\phi}{d \\\\phi}=\\\\int_{u_{1}(\\\\alpha)}^{u_{2}(\\\\alpha)} f_{\\\\alpha}(x, \\\\xi) d x+f\\\\left(\\\\xi_{2}, \\\\alpha+\\\\Delta \\\\alpha\\\\right) \\\\frac{\\\\Delta u_{2}}{\\\\Delta \\\\alpha}-f\\\\left(\\\\xi_{1}, \\\\alpha+\\\\Delta \\\\alpha\\\\right) \\\\frac{\\\\Delta u_{1}}{\\\\Delta \\\\alpha}\\n$$\\n\",\n",
       " \"\\n8.16. If $\\\\phi(\\\\alpha)=\\\\int_{\\\\alpha}^{\\\\alpha^{2}} \\\\frac{\\\\sin \\\\alpha x}{x} d x$, find $\\\\phi^{\\\\prime}(\\\\alpha)$ where $\\\\alpha \\\\neq 0$.\\n\\nBy Leibniz's rule,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\phi^{\\\\prime}(\\\\alpha) & =\\\\int_{\\\\alpha}^{\\\\alpha^{2}} \\\\frac{\\\\partial}{\\\\partial a}\\\\left(\\\\frac{\\\\sin \\\\alpha x}{x}\\\\right) d x+\\\\frac{\\\\sin \\\\left(\\\\alpha \\\\cdot \\\\alpha^{2}\\\\right)}{\\\\alpha^{2}} \\\\frac{d}{d \\\\alpha}\\\\left(\\\\alpha^{2}\\\\right)-\\\\frac{\\\\sin (\\\\alpha \\\\cdot \\\\alpha)}{\\\\alpha} \\\\frac{d}{d \\\\alpha}(\\\\alpha) \\\\\\\\\\n& =\\\\int_{\\\\alpha}^{\\\\alpha^{2}} \\\\cos \\\\alpha x d x+\\\\frac{2 \\\\sin \\\\alpha^{3}}{\\\\alpha}-\\\\frac{\\\\sin \\\\alpha^{2}}{\\\\alpha} \\\\\\\\\\n& =\\\\left.\\\\frac{\\\\sin \\\\alpha x}{\\\\alpha}\\\\right|_{\\\\alpha} ^{a^{2}}+-\\\\frac{2 \\\\sin \\\\alpha^{3}}{\\\\alpha}-\\\\frac{\\\\sin \\\\alpha^{2}}{\\\\alpha}=\\\\frac{3 \\\\sin \\\\alpha^{3}-2 \\\\sin \\\\alpha^{2}}{\\\\alpha}\\n\\\\end{aligned}\\n$$\\n\",\n",
       " \"\\n8.17. If $\\\\int_{0}^{\\\\pi} \\\\frac{d x}{\\\\alpha-\\\\cos x}=\\\\frac{\\\\pi}{\\\\sqrt{\\\\alpha^{2}-1}} \\\\cdot \\\\alpha>1$, find $\\\\int_{0}^{\\\\pi} \\\\frac{d x}{(2-\\\\cos x)^{2}}$ (See Problem 5.58.)\\n\\nBy Leibniz's rule, if $\\\\phi(\\\\alpha)=\\\\int_{0}^{\\\\pi} \\\\frac{d x}{(\\\\alpha-\\\\cos x)}=\\\\pi\\\\left(\\\\alpha^{2}-1\\\\right)^{-1 / 2}$, then\\n\\n$$\\n\\\\phi(\\\\alpha)=-\\\\int_{0}^{\\\\pi} \\\\frac{d x}{(\\\\alpha-\\\\cos x)}=\\\\frac{1}{2} \\\\pi\\\\left(\\\\alpha^{2}-1\\\\right)^{-3 / 2} 2 \\\\alpha=\\\\frac{-\\\\pi \\\\alpha}{\\\\left(\\\\alpha^{2}-1\\\\right)^{3 / 2}}\\n$$\\n\\nThus, $\\\\int_{0}^{\\\\pi} \\\\frac{d x}{(\\\\alpha-\\\\cos x)}=\\\\frac{-\\\\pi \\\\alpha}{\\\\left(\\\\alpha^{2}-1\\\\right)^{3 / 2}}$, from which $\\\\int_{0}^{\\\\pi} \\\\frac{d x}{(2-\\\\cos x)^{2}}=\\\\frac{2 \\\\pi}{3 \\\\sqrt{3}}$.\\n\\n\\n\\\\section*{Integration under the integral sign}\\n\",\n",
       " \"8.18. Prove the result (18), on Page 198, for integration under the integral sign.\\n\\nConsider:\\n\\nBy Leibniz's rule,\\n\\n\\n\\\\begin{equation*}\\n\\\\psi(\\\\alpha)=\\\\int_{u_{1}}^{u_{2}}\\\\left\\\\{\\\\int_{\\\\alpha}^{\\\\alpha} f(x, \\\\alpha) d x\\\\right\\\\} d x \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\n$$\\n\\\\psi^{\\\\prime}(\\\\alpha)=\\\\int_{u_{1}}^{u_{2}} \\\\frac{\\\\partial}{\\\\partial \\\\alpha}\\\\left\\\\{\\\\int_{\\\\alpha}^{\\\\alpha} f(x, \\\\alpha) d x\\\\right\\\\} d x=\\\\int_{u_{1}}^{u_{2}} f(x, \\\\alpha) d x=\\\\phi(\\\\alpha)\\n$$\\n\\nThen, by integration,\\n\\n\\n\\\\begin{equation*}\\n\\\\psi(\\\\alpha)=\\\\int_{\\\\alpha}^{\\\\alpha} \\\\phi(\\\\alpha) d \\\\alpha+c \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSince $\\\\psi(a)=0$ from Equation (1), we have $c=0$ in (2). Thus from Equation (1) and (2) with $c=0$, we find\\n\\n$$\\n\\\\int_{u_{1}}^{u_{2}}\\\\left\\\\{\\\\int_{\\\\alpha}^{\\\\alpha} f(x, \\\\alpha) d x\\\\right\\\\} d x=\\\\int_{\\\\alpha}^{\\\\alpha}\\\\left\\\\{\\\\int_{u_{1}}^{u_{2}} f(x, \\\\alpha) d x\\\\right\\\\} d x\\n$$\\n\\nPutting $\\\\alpha=b$, the required result follows.\\n\",\n",
       " '\\n8.19. Prove that $\\\\int_{0}^{\\\\pi} \\\\ln \\\\left(\\\\frac{b-\\\\cos x}{a-\\\\cos x}\\\\right) d x=\\\\pi \\\\ln \\\\left(\\\\frac{b+\\\\sqrt{b^{2}-1}}{a+\\\\sqrt{a^{2}-1}}\\\\right)$ if $a, b>1$.\\n\\nFrom Problem 5.58, $\\\\int_{0}^{\\\\pi} \\\\frac{d x}{\\\\alpha-\\\\cos x}=\\\\frac{\\\\pi}{\\\\sqrt{\\\\alpha^{2}-1}} \\\\cdot \\\\alpha>1$.\\n\\nIntegrating the left side with respect to $\\\\alpha$ from $a$ to $b$ yields\\n\\n$$\\n\\\\int_{0}^{\\\\pi}\\\\left\\\\{\\\\int_{a}^{b} \\\\frac{d x}{\\\\alpha-\\\\cos x}\\\\right\\\\} d x=\\\\left.\\\\int_{0}^{\\\\pi} \\\\operatorname{In}(\\\\alpha-\\\\cos x)\\\\right|_{a} ^{b} d x \\\\int_{0}^{\\\\pi} \\\\operatorname{In}\\\\left(\\\\frac{b-\\\\cos x}{a-\\\\cos x}\\\\right) d x\\n$$\\n\\nIntegrating the right side with respect to $\\\\alpha$ to $b$ yields\\n\\n$$\\n\\\\int_{0}^{\\\\pi} \\\\frac{\\\\pi d \\\\alpha}{\\\\sqrt{\\\\alpha^{2}-1}}=\\\\pi \\\\ln \\\\left(\\\\alpha+\\\\left.\\\\sqrt{\\\\left.a^{2}-1\\\\right)}\\\\right|_{a} ^{b}=\\\\pi \\\\ln \\\\left(\\\\frac{b+\\\\sqrt{b^{2}-1}}{a+\\\\sqrt{a^{2}-1}}\\\\right)\\\\right.\\n$$\\n\\nand the required result follows.\\n\\n\\n\\\\section*{Maxima and minima}\\n',\n",
       " '8.20. Prove that a necessary condition for $f(x, y)$ to have a relative extremum (maximum or minimum) at $\\\\left(x_{0}, y_{0}\\\\right)$ is that $f_{x}\\\\left(x_{0}, y_{0}\\\\right)=0, f_{y}\\\\left(x_{0}, y_{0}\\\\right)=0$.\\n\\nIf $f\\\\left(x_{0}, y_{0}\\\\right)$ is to be an extreme value for $f(x, y)$, then it must be an extreme value for $f\\\\left(x, y_{0}\\\\right)$ and $f\\\\left(x_{0}\\\\right.$, $y$ ). But a necessary condition that these have extreme values at $x_{x}=0$ and $y=y_{0}$, respectively, is $f_{x}\\\\left(x_{0}, y_{0}\\\\right)=0$, $f_{y}\\\\left(x_{0}, y_{0}\\\\right)=0$ (using results for functions of one variable).\\n',\n",
       " '\\n8.21. Let $f$ be continuous and have continuous partial derivatives of order two, at least, in a region $R$ with the critical point $P_{0}\\\\left(x_{0}, y_{0}\\\\right)$ an interior point. Determine the sufficient conditions for relative extrema at $P_{0}$.\\n\\nIn the case of one variable, sufficient conditions for a relative extrema were formulated through the second derivative [if positive then a relative minimum, if negative then a relative maximum, if zero a possible point of inflection but more investigation is necessary]. In the case of $z=f(x, y)$ that is before us we can expect the second partial derivatives to supply information. (See Figure 8.6.)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-219}\\n\\\\end{center}\\n\\nFig. 8.6\\n\\nFirst observe that solutions of the quadratic equation $A t^{2}+2 B t+C=0$ are $t=\\\\frac{-2 B \\\\pm \\\\sqrt{4 B^{2}-4 A C}}{2 A}$.\\n\\nFurther observe that the nature of these solutions is determined by $B^{2}-A C$. If the quantity is positive, the solutions are real and distinct; if negative, they are complex conjugate; and if zero, the two solutions are coincident.\\n\\nThe expression $B^{2}-A C$ also has the property of invariance with respect to plane rotations\\n\\n$$\\n\\\\begin{aligned}\\n& x=\\\\bar{x} \\\\cos \\\\theta-\\\\bar{y} \\\\sin \\\\theta \\\\\\\\\\n& y=\\\\bar{x} \\\\cos \\\\theta-\\\\bar{y} \\\\sin \\\\theta\\n\\\\end{aligned}\\n$$\\n\\nIt has been discovered that with the identifications $A=f_{x x}, B=f_{x y}, C=f_{y y}$, we have the partial derivative form $f_{x y}^{2}-f_{x x} f_{y y}$ that characterizes relative extrema.\\n\\nThe demonstration of invariance of this form can be found in analytic geometric books. However, if you would like to put the problem in the context of the second partial derivative, observe that\\n\\n$$\\n\\\\begin{aligned}\\n& f_{\\\\bar{x}}=f_{x} \\\\frac{\\\\partial x}{\\\\partial \\\\bar{x}}+f_{x} \\\\frac{\\\\partial y}{\\\\partial \\\\bar{x}}=f_{x} \\\\cos \\\\theta+f_{y} \\\\sin \\\\theta \\\\\\\\\\n& f_{\\\\bar{y}}=f_{x} \\\\frac{\\\\partial x}{\\\\partial \\\\bar{x}}+f_{y} \\\\frac{\\\\partial y}{\\\\partial \\\\bar{y}}=-f_{x} \\\\sin \\\\theta+f_{y} \\\\cos \\\\theta\\n\\\\end{aligned}\\n$$\\n\\nThen, using the chain rule to compute the second partial derivatives and proceeding by straightforward but tedious calculation, we show that.\\n\\n$$\\nf_{x y}^{2}=f_{x x} f_{y y}=f_{\\\\bar{x} \\\\bar{y}}^{2}-f_{\\\\overline{x x}} f_{\\\\overline{y y}}\\n$$\\n\\nThe following equivalences are a consequence of this invariant form (independently of direction in the tangent plane at $P_{0}$ ):\\n\\n\\\\[\\n\\\\begin{array}{lll}\\nf_{x y}^{2}=f_{x x} f_{y y}<0 & \\\\text { and } & f_{x x} f_{y y}>0 \\\\\\\\\\nf_{x y}^{2}=f_{x x} f_{y y}<0 & \\\\text { and } & f_{x x} f_{y y}<0 \\\\tag{2}\\n\\\\end{array}\\n\\\\]\\n\\nThe key relation is (1) because in order that this equivalence hold, both terms $f_{x} f_{y}$ must have the same sign. We can look to the one-variable case (make the same argument for each coordinate direction) and conclude that there is a relative minimum at $P_{0}$ if both partial derivatives are positive and a relative maximum if both are negative. We can make this argument for any pair of coordinate directions because of the invariance under rotation that was established.\\n\\nIf relation (2) holds, then the point is called a saddle point. If the quadratic form is zero, no information results.\\n\\nObserve that this situation is analogous to the one-variable extreme value theory in which the nature of $f$ at $x$, and with $f^{\\\\prime}(x)=0$, is undecided if $f^{\\\\prime \\\\prime}(x)=0$.\\n',\n",
       " '\\n8.22. Find the relative maxima and minima of $f(x, y)=x^{3}+y^{3}-3 x-12 y+20$.\\n\\n$f_{x}=3 x^{2}-3=0$ when $x= \\\\pm 1, f_{y}=3 y^{2}-12=0$ when $y= \\\\pm 2$. Then critical points are $P(1,2), Q(-1,2)$, $R(1,-2), S(-1,-2)$.\\n\\n$f_{x x}=6 x, f_{y y}=0$. Then $\\\\Delta=f_{x x} f_{y y}-f^{2}{ }_{x y}=36 x y$.\\n\\nAt $P(1,2), \\\\Delta>0$ and $f_{x x}$ (or $f_{y y}$ ) $>0$; hence $P$ is a relative minimum point.\\n\\nAt $Q(-1,2), \\\\Delta<0$ and $Q$ is neither a relative maximum or minimum point.\\n\\nAt $R(1,-2), \\\\Delta<0$ and $R$ is neither a relative maximum or minimum point.\\n\\nAt $S(-1,-2), \\\\Delta>0$ and $f_{x x}$ (or $f_{y y}$ ) <0 so $S$ is a relative maximum point.\\n\\nThus, the relative minimum value of $f(x, y)$ occurring at $P$ is 2 , while the relative maximum value occurring at $S$ is 38 . Points $Q$ and $R$ are saddle points.\\n',\n",
       " '\\n8.23. A rectangular box, open at the top, is to have a volume of 32 cubic feet. What must be the dimensions so that the total surface is a minimum?\\n\\nIf $x, y$, and $z$ are the edges (see Fig. 8.7), then\\n\\nVolume of box $=V=x y z=32$\\n\\nSurface area of box $=S=x y+2 y z+2 x z$\\n\\nor, since $z=32 / x y$ from Equation (1),\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-221}\\n\\\\end{center}\\n\\nFig. 8.7\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial S}{\\\\partial x}=y-\\\\frac{64}{x^{2}}=0 \\\\text { when } x^{2} y=64  \\\\tag{3}\\\\\\\\\\n& \\\\frac{\\\\partial S}{\\\\partial y}=x-\\\\frac{64}{y^{2}}=0 \\\\text { when } x y^{2}=64 \\\\tag{4}\\n\\\\end{align*}\\n\\n\\nDividing Equations (3) and (4), we find $y=x$ so that $x^{3}=64$ or $x=y=4$ and $z=2$.\\n\\nFor $x=y=4, \\\\Delta=S_{x x} S_{y y}-S_{x y}^{2}=\\\\left(\\\\frac{128}{x^{3}}\\\\right)\\\\left(\\\\frac{128}{y^{3}}\\\\right)-1>0$ and $\\\\mathrm{s}_{x x}=\\\\frac{128}{x^{3}}>0$. Hence, it follows that the dimensions 4 feet $\\\\times 4$ feet $\\\\times 2$ feet give the minimum surface.\\n\\n\\n\\\\section*{Lagrange multipliers for maxima and minima}\\n',\n",
       " '8.24. Consider $F(x, y, z)$ subject to the constraint condition $G(x, y, z)=0$. Prove that a necessary condition that $F(x, y, z)$ have an extreme value is that $F_{x} G_{y}-F_{y} G_{x}=0$.\\n\\nSince $G(x, y, z)=0$, we can consider $z$ as a function of $x$ and $y$-say, $z=f(x, y)$. A necessary condition that $F[x, y, f(x, y)]$ have an extreme value is that the partial derivatives with respect to $x$ and $y$ be zero. This gives\\n\\n\\n\\\\begin{align*}\\n& F_{x}+F_{z} z_{x}=0  \\\\tag{1}\\\\\\\\\\n& F_{y}+F_{z} Z_{y}=0 \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nSince $G(x, y, z)=0$, we also have\\n\\n\\n\\\\begin{align*}\\n& G_{x}+G_{x} z_{x}=0  \\\\tag{3}\\\\\\\\\\n& G_{y}+G_{z} z_{y}=0 \\\\tag{4}\\n\\\\end{align*}\\n\\n\\nFrom Equations (1) and (3) we have\\n\\n\\n\\\\begin{equation*}\\nF_{x} G_{x}-F_{x} G_{x}=0 \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nand from Equations (2) and (4) we have\\n\\n\\n\\\\begin{equation*}\\nF_{y} G_{z}-F_{z} G_{y}=0 \\\\tag{6}\\n\\\\end{equation*}\\n\\n\\nThen from Equations (5) and (6) we find $F_{x} G_{y}-F_{y} G_{x}=0$.\\n\\nThese results hold only if $F_{z} \\\\neq 0, G_{z} \\\\neq 0$.\\n',\n",
       " '\\n8.25. Referring to Problem 8.24, show that the stated condition is equivalent to the conditions $\\\\phi_{x}=0, \\\\phi_{y}=0$ where $\\\\phi=F+\\\\lambda G$ and $\\\\lambda$ is a constant.\\n\\nIf $\\\\phi_{x}=0, F_{x}+\\\\lambda G_{x}=0$. If $\\\\phi_{y}=0, F_{y}+\\\\lambda G_{y}=0$. Elimination of $\\\\lambda$ between these equations yields $F_{x} G_{y}-$ $F_{y} G_{x}=0$.\\n\\nThe multiplier $\\\\lambda$ is the Lagrange multiplier. If desired, we can consider equivalently $\\\\phi=\\\\lambda F+G$ where $\\\\phi_{x}=0, \\\\phi_{y}=0$.\\n',\n",
       " '\\n8.26. Find the shortest distance from the origin to the hyperbola $x^{2}+8 x y+7 y^{2}=225, z=0$.\\n\\nWe must find the minimum value of $x^{2}+y^{2}$ (the square of the distance from the origin to any point in the $x y$ plane) subject to the constraint $x^{2}+8 x y+7 y^{2}=225$.\\n\\nAccording to the method of Lagrange multipliers, we consider $\\\\phi=x^{2}+8 x y+7 y^{2}-225+\\\\lambda\\\\left(x^{2}+y^{2}\\\\right)$. Then\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\phi_{x}=2 x+8 y+2 \\\\lambda x=0 \\\\quad \\\\text { or } \\\\quad(\\\\lambda+1) x+4 y=0 \\\\\\\\\\n& \\\\phi_{y}=8 x+14 y+2 \\\\lambda y=0 \\\\quad \\\\text { or } \\\\quad 4 x+(\\\\lambda+7) y=0\\n\\\\end{aligned}\\n$$\\n\\nFrom Equations (1) and (2), since $(x, y) \\\\neq(0,0)$, we must have\\n\\n$$\\n\\\\left|\\\\begin{array}{cc}\\n\\\\lambda+1 & 4 \\\\\\\\\\n4 & \\\\lambda+7\\n\\\\end{array}\\\\right|=0 \\\\text {, i.e., } \\\\lambda^{2}+8 \\\\lambda-9=\\\\text { or } \\\\lambda=1,-9\\n$$\\n\\nCase 1: $\\\\quad \\\\lambda=1$. From Equation (1) or (2), $x=-2 y$, and substitution in $x^{2}+8 x y+7 y^{2}=225$ yields $-5 y^{2}=225$, for which no real solution exists.\\n\\nCase 2: $\\\\lambda=-9$. From Equation (1) or (2), $y=2 x$, and substitution in $x^{2}+8 x y+7 y^{2}=225$ yields $45 x^{2}=225$. Then $x^{2}=5, y^{2}=4 x^{2}=20$ and so $x^{2}+y^{2}=25$. Thus, the required shortest distance is $\\\\sqrt{25}=5$.\\n',\n",
       " '\\n8.27. (a) Find the maximum and minimum values of $x^{2}+y^{2}+z^{2}$ subject to the constraint conditions $x^{2} / 4+y^{2} / 5+$ $z^{2} / 25=1$ and $z=x+y$. (b) Give a geometric interpretation of the result in (a).\\n\\n(a) We must find the extrema of $F=x^{2}+y^{2}+z^{2}$ subject to the constraint conditions $\\\\phi_{1}=\\\\frac{x^{2}}{4}+\\\\frac{x^{2}}{5}+$ $\\\\frac{z^{2}}{25}-1=0$ and $\\\\phi_{2}=x+y-z=0$. In this case we use two Lagrange multipliers $\\\\lambda_{1}, \\\\lambda_{2}$ and consider the function\\n\\n$$\\nG=F+\\\\lambda_{1} \\\\phi_{1}+\\\\lambda_{2} \\\\phi_{2}=x^{2}+y^{2}+z^{2}+\\\\lambda_{1}\\\\left(\\\\frac{x^{2}}{4}+\\\\frac{y^{2}}{5}+\\\\frac{z^{2}}{25}-1\\\\right)+\\\\lambda_{2}(x+y-z)\\n$$\\n\\nTaking the partial derivatives of $G$ with respect to $x, y, z$ and setting them equal to zero, we find\\n\\n\\n\\\\begin{equation*}\\nG_{x}=2 x+\\\\frac{\\\\lambda_{1} x}{2}+\\\\lambda_{2}=0, \\\\quad G_{y}=2 y+\\\\frac{2 \\\\lambda_{1} y}{5}+\\\\lambda_{2}=0, \\\\quad G_{x}=2 z+\\\\frac{2 \\\\lambda_{1} z}{25}-\\\\lambda_{2}=0 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSolving these equations for $x, y, z$, we find\\n\\n\\n\\\\begin{equation*}\\nx=\\\\frac{-2 \\\\lambda_{2}}{\\\\lambda_{1}+4}, \\\\quad y=\\\\frac{-5 \\\\lambda_{2}}{2 \\\\lambda_{1}+10}, \\\\quad z=\\\\frac{25 \\\\lambda_{2}}{2 \\\\lambda_{1}+50} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nFrom the second constraint condition, $x+y-z=0$, we obtain, on division by $\\\\lambda_{2}$, assumed different from zero (this is justified, since otherwise we would have $x=0, y=0, z=0$, which would not satisfy the first constraint condition), the result\\n\\n$$\\n\\\\frac{2}{\\\\lambda_{1}+4}+\\\\frac{5}{2 \\\\lambda_{1}+10}+\\\\frac{25}{2 \\\\lambda_{1}+50}=0\\n$$\\n\\nMultiplying both sides by $2\\\\left(\\\\lambda_{1}+4\\\\right)\\\\left(\\\\lambda_{1}+5\\\\right)\\\\left(\\\\lambda_{1}+5\\\\right)\\\\left(\\\\lambda_{1}+25\\\\right)$ and simplifying yields\\n\\n$$\\n17 \\\\lambda_{1}^{2}+245 \\\\lambda_{1}+750=0 \\\\text { or }\\\\left(\\\\lambda_{1}+10\\\\right)\\\\left(17 \\\\lambda_{1}+75\\\\right)=0\\n$$\\n\\nfrom which $\\\\lambda_{1}=-10$ or $-75 / 17$.\\n\\nCase 1: $\\\\lambda_{1}=-10$.\\n\\nFrom (2), $x=\\\\frac{1}{3} \\\\lambda_{2}, y=\\\\frac{1}{2} \\\\lambda_{2}, z=5 / 6 \\\\lambda_{2}$. Substituting in the first constraint condition, $x^{2} / 4+y^{2} / 5+z^{2} / 25$ $=1$, yields $\\\\lambda_{2}^{2}=180 / 19$ or $\\\\lambda_{2}= \\\\pm 6 \\\\sqrt{5 / 19}$. This gives the two critical points\\n\\n$$\\n(2 \\\\sqrt{5 / 19}, 3 \\\\sqrt{5 / 19}, 5 \\\\sqrt{5 / 19}) . \\\\quad(-2 \\\\sqrt{5 / 19},-3 \\\\sqrt{5 / 19},-5 \\\\sqrt{5 / 19})\\n$$\\n\\nThe value of $x^{2}+y^{2}+z^{2}$ corresponding to these critical points is $(20+45+125) / 19=10$.\\n\\nCase 2: $\\\\lambda_{1}=-75 / 17$.\\n\\nFrom (2), $x=34 / 7 \\\\lambda_{2}, y=-17 / 4 \\\\lambda_{2}, z=17 / 28 \\\\lambda_{2}$. Substituting in the first constraint condition, $x^{2} / 4+y^{2} / 5$ $+z^{2} / 25=1$, yields $\\\\lambda_{2}= \\\\pm 140 /(17 \\\\sqrt{646})$ which give the critical points\\n\\n$$\\n(40 / \\\\sqrt{646},-35 \\\\sqrt{646}, 5 / \\\\sqrt{646}) . \\\\quad(-40 / \\\\sqrt{646},-35 \\\\sqrt{646},-5 / \\\\sqrt{646})\\n$$\\n\\nThe value of $x^{2}+y^{2}+z^{2}$ corresponding to these is $(1600+1225+25) / 646=75 / 17$.\\n\\nThus, the required maximum value is 10 and the minimum value is 75/17.\\n\\n(b) Since $x^{2}+y^{2}+z^{2}$ represents the square of the distance of $(x, y, z)$ from the origin $(0,0,0)$, the problem is equivalent to determining the largest and smallest distances from the origin to the curve of intersection of the ellipsoid $x^{2} / 4+y^{2} / 5+z^{2} / 25=1$ and the plane $z=x+y$. Since this curve is an ellipse, we have the interpretation that $\\\\sqrt{10}$ and $\\\\sqrt{75 / 17}$ are the lengths of the semimajor and semiminor axes of this ellipse.\\n\\nThe fact that the maximum and minimum values happen to be given by $-\\\\lambda_{1}$ in both Case 1 and Case 2 is more than a coincidence. It follows, in fact, on multiplying Equations (1) by $x, y$, and $z$ in succession and adding, for we then obtain\\n\\n$$\\n2 x^{2}+\\\\frac{\\\\lambda_{1} x^{2}}{2}+\\\\lambda_{2} x+2 y^{2}+\\\\frac{2 \\\\lambda_{1} y^{2}}{5}+\\\\lambda_{2} y+2 z^{2}+\\\\frac{2 \\\\lambda_{1} z^{2}}{25}-\\\\lambda_{2} z=0\\n$$\\n\\ni.e.,\\n\\n$$\\nx^{2}+y^{2}+z^{2}+\\\\lambda_{1}\\\\left(\\\\frac{x^{2}}{4}+\\\\frac{y^{2}}{5}+\\\\frac{z^{2}}{25}\\\\right)+\\\\lambda_{2}(x+y-z)=0\\n$$\\n\\nThen, using the constraint conditions, we find $x^{2}+y^{2}+z^{2}=-\\\\lambda_{1}$.\\n\\nFor a generalization of this problem, see Problem 8.76.\\n\\n\\n\\\\section*{Applications to errors}\\n',\n",
       " '8.28. The period $T$ of a simple pendulum of length $l$ is given by $T=2 \\\\sqrt{l / g}$. Find (a) the error and (b) the percent error made in computing $T$ by using $l=2 \\\\mathrm{~m}$ and $g=9.75 \\\\mathrm{~m} / \\\\mathrm{sec}^{2}$, if the true values are $l=19.5 \\\\mathrm{~m}$ and $g=$ $9.81 \\\\mathrm{~m} / \\\\mathrm{sec}^{2}$.\\n\\n(a) $T=2 \\\\pi l^{1 / 2} g^{-1 / 2}$. Then\\n\\n\\n\\\\begin{equation*}\\nd T=\\\\left(2 \\\\pi g^{-1 / 2}\\\\left(\\\\frac{1}{2} l^{-1 / 2} d l\\\\right)+\\\\left(2 \\\\pi l^{1 / 2}\\\\right)\\\\left(-\\\\frac{1}{2} g^{-3 / 2} d g\\\\right)=\\\\frac{\\\\pi}{\\\\sqrt{l g}} d l-\\\\pi \\\\sqrt{\\\\frac{1}{g^{3}}} d g\\\\right. \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\n$$\\n\\\\text { Error in } g=\\\\Delta g=d g=+0.06 ; \\\\text { error in } l=\\\\Delta l=d l=-0.5\\n$$\\n\\nThe error in $T$ is actually $\\\\Delta T$, which is in this case approximately equal to $d T$. Thus, we have from Equation (1),\\n\\n$$\\n\\\\text { Error in } T=d T=\\\\frac{\\\\pi}{\\\\sqrt{(2)(9.75)}}(-0.05)-\\\\pi \\\\sqrt{\\\\frac{2}{(9.75)^{3}}}(+0.06)=-0.0444 \\\\mathrm{sec} \\\\text { (approx.) }\\n$$\\n\\nThe value of $T$ for $l=2, g=9.75$ is $T=2 \\\\pi \\\\sqrt{\\\\frac{2}{9.75}}=2.846 \\\\mathrm{sec}$ (approx.)\\\\\\\\\\n(b) Percent error (or relative error) in $T=\\\\frac{d T}{T}=\\\\frac{-0.0444}{2.846}=-1.56 \\\\%$.\\n\\nAnother method: $\\\\quad$ Since $\\\\ln T=\\\\ln 2 \\\\pi+\\\\frac{1}{2} \\\\ln l-\\\\frac{1}{2} \\\\ln g$,\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{d T}{T}=\\\\frac{1}{2} \\\\frac{d l}{l}-\\\\frac{1}{2} \\\\frac{d g}{g}=\\\\frac{1}{2}\\\\left(\\\\frac{-0.05}{2}\\\\right)-\\\\frac{1}{2}\\\\left(\\\\frac{+0.06}{9.75}\\\\right)=-1.56 \\\\% \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nas before. Note that Equation (2) can be written\\n\\n$$\\n\\\\text { Percent error in } T=\\\\frac{1}{2} \\\\text { Percent error in } l-\\\\frac{1}{2} \\\\text { Percent error in } g\\n$$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " \"8.29. Evaluate $\\\\int_{0}^{1} \\\\frac{x-1}{\\\\operatorname{In} x} d x$.\\n\\nIn order to evaluate this integral, we resort to the following device. Define\\n\\n$$\\n\\\\phi(\\\\alpha)=\\\\int_{0}^{1} \\\\frac{x^{\\\\alpha}-1}{\\\\operatorname{In} x} d x \\\\quad \\\\alpha>0\\n$$\\n\\nThen by Leibniz's rule\\n\\n$$\\n\\\\phi^{\\\\prime}(\\\\alpha)=\\\\int_{0}^{1} \\\\frac{\\\\partial}{\\\\partial \\\\alpha}\\\\left(\\\\frac{x^{\\\\alpha}-1}{\\\\operatorname{In} x}\\\\right) d x=\\\\int_{0}^{1} \\\\frac{x^{\\\\alpha} \\\\operatorname{In} x}{\\\\operatorname{In} x} d x=\\\\int_{0}^{1} d x=\\\\frac{1}{\\\\alpha+1}\\n$$\\n\\nIntegrating with respect to $\\\\alpha, \\\\phi(\\\\alpha)=\\\\ln (\\\\alpha+1)+c$. But since $\\\\phi(0)=0, c=0$, and so $\\\\phi(\\\\alpha)=\\\\ln (\\\\alpha+1)$.\\n\\nThen the value of the required integral is $\\\\phi(1)=\\\\ln 2$.\\n\\nThe applicability of Leibniz's rule can be justified here, since if we define $F(x, \\\\alpha)=\\\\left(x^{\\\\alpha}-1\\\\right) / \\\\ln x, 0<x<$ $1, F(0, \\\\alpha)=0, F(1, \\\\alpha)=\\\\alpha$, then $F(x, \\\\alpha)$ is continuous in both $x$ and $\\\\alpha$ for $0 \\\\leqq x \\\\leqq 1$ and all finite $\\\\alpha>0$.\\n\",\n",
       " '\\n8.30. Find constants $a$ and $b$ for which $F(a, b)=\\\\int_{0}^{\\\\pi}\\\\left\\\\{\\\\sin x-\\\\left(a x^{2}+b x\\\\right)\\\\right\\\\}^{2} d x$ is a minimum.\\n\\nThe necessary conditions for a minimum are $\\\\partial F / \\\\partial a=0$. Performing these differentiations, we obtain\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\frac{\\\\partial F}{\\\\partial a}=\\\\int_{0}^{\\\\pi} \\\\frac{\\\\partial}{\\\\partial a}\\\\left\\\\{\\\\sin x-\\\\left(a x^{2}+b x\\\\right)\\\\right\\\\}^{2} d x=-2 \\\\int_{0}^{\\\\pi} x^{2}\\\\left\\\\{\\\\sin x-\\\\left(a x^{2}+b x\\\\right)\\\\right\\\\} d x=0 \\\\\\\\\\n& \\\\frac{\\\\partial F}{\\\\partial b}=\\\\int_{0}^{\\\\pi} \\\\frac{\\\\partial}{\\\\partial b}\\\\left\\\\{\\\\sin x-\\\\left(a x^{2}+b x\\\\right)\\\\right\\\\}^{2} d x=-2 \\\\int_{0}^{\\\\pi} x\\\\left\\\\{\\\\sin x-\\\\left(a x^{2}+b x\\\\right)\\\\right\\\\} d x=0\\n\\\\end{aligned}\\n$$\\n\\nFrom these we find\\n\\n$$\\n\\\\left\\\\{\\\\begin{array}{l}\\n\\\\alpha \\\\int_{0}^{\\\\pi} x^{4} d x+b \\\\int_{0}^{\\\\pi} x^{3} d x=\\\\int_{0}^{\\\\pi} x^{2} \\\\sin x d x \\\\\\\\\\n\\\\alpha \\\\int_{0}^{\\\\pi} x^{3} d x+b \\\\int_{0}^{\\\\pi} x^{2} d x=\\\\int_{0}^{\\\\pi} x \\\\sin x d x\\n\\\\end{array}\\\\right.\\n$$\\n\\nor\\n\\n$$\\n\\\\left\\\\{\\\\begin{array}{l}\\n\\\\frac{\\\\pi^{5} a}{5}+\\\\frac{\\\\pi^{4} b}{4}=\\\\pi^{2}-4 \\\\\\\\\\n\\\\frac{\\\\pi^{4} a}{4}+\\\\frac{\\\\pi^{3} b}{3}=\\\\pi\\n\\\\end{array}\\\\right.\\n$$\\n\\nSolving for $a$ and $b$, we find\\n\\n$$\\na=\\\\frac{20}{\\\\pi^{3}}-\\\\frac{320}{\\\\pi^{5}} \\\\approx-0.40065 . \\\\quad b=\\\\frac{240}{\\\\pi^{4}}-\\\\frac{12}{\\\\pi^{2}} \\\\approx 1.24798\\n$$\\n\\nWe can show that for these values, $F(a, b)$ is indeed a minimum using the sufficiency conditions on Page 200.\\n\\nThe polynomial $a x^{2}+b x$ is said to be a least square approximation of $\\\\sin x$ over the interval $(0, \\\\pi)$. The ideas involved here are of importance in many branches of mathematics and their applications.\\n\\n',\n",
       " '9.1. (a) Sketch the region $\\\\Re$ in the $x y$ plane bounded by $y=x^{2}, x=2, y=1$. (b) Give a physical interpretation to $\\\\iint_{\\\\Re}\\\\left(x^{2}+y^{2}\\\\right) d x d y$. (c) Evaluate the double integral in (b).\\n\\n(a) The required region $\\\\Re$ is shown shaded in Figure 9.6.\\n\\n(b) Since $x^{2}+y^{2}$ is the square of the distance from any point $(x, y)$ to $(0,0)$, we can consider the double integral as representing the polar moment of inertia (i.e., moment of intertia with respect to the origin) of the region $\\\\Re$ (assuming unit density).\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-238}\\n\\\\end{center}\\n\\nFigure 9.6\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-238(1)}\\n\\\\end{center}\\n\\nFigure 9.7\\n\\nWe can also consider the double integral as representing the mass of the region $\\\\Re$, assuming a density varying as $x^{2}+y^{2}$.\\n\\n(c) Method 1: The double integral can be expressed as the iterated integral\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{x=1}^{2} \\\\int_{y=1}^{x^{2}}\\\\left(x^{2}+y^{2}\\\\right) d y d x & =\\\\int_{x=1}^{2}\\\\left\\\\{\\\\int_{y=1}^{x^{2}}\\\\left(x^{2}+y^{2}\\\\right) d y\\\\right\\\\} d x=\\\\int_{x=1}^{2} x^{2} y+\\\\left.\\\\frac{y^{2}}{3}\\\\right|_{y=1} ^{x^{2}} \\\\\\\\\\nd x & =\\\\int_{x=1}^{2}\\\\left(x^{4}+\\\\frac{x^{6}}{3}-x^{2}-\\\\frac{1}{3}\\\\right) d x=\\\\frac{1006}{105}\\n\\\\end{aligned}\\n$$\\n\\nThe integration with respect to $y$ (keeping $x$ constant) from $y=1$ to $y=x^{2}$ corresponds formally to summing in a vertical column (see Figure 9.6). The subsequent integration with respect to $x$ from $x=1$ to $x=2$ corresponds to addition of contributions from all such vertical columns between $x=1$ and $x=2$.\\n\\nMethod 2: The double integral can also be expressed as the iterated integral\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{y=1}^{4} \\\\int_{x=\\\\sqrt{y}}^{2}\\\\left(x^{2}+y^{2}\\\\right) d x d y & =\\\\int_{y=1}^{4}\\\\left\\\\{\\\\int_{x=\\\\sqrt{y}}^{2}\\\\left(x^{2}+y^{2}\\\\right) d x\\\\right\\\\} d y=\\\\int_{y=1}^{4} \\\\frac{x^{3}}{3}+\\\\left.x y^{2}\\\\right|_{x=\\\\sqrt{y}} ^{2} d y \\\\\\\\\\n& =\\\\int_{x=1}^{2}\\\\left(x^{4}+\\\\frac{x^{6}}{3}-x^{2}-\\\\frac{1}{3}\\\\right) d x=\\\\frac{1006}{105}\\n\\\\end{aligned}\\n$$\\n\\nIn this case the vertical column of region $\\\\Re$ in Figure 9.6 is replaced by a horizontal column, as in Figure 9.7. Then the integration with respect to $x$ (keeping $y$ constant) from $x=\\\\sqrt{y}$ to $x=2$ corresponds to summing in this horizontal column. Subsequent integration with respect to $y$ from $y=1$ to $y=4$ corresponds to addition of contributions for all such horizontal columns between $y=1$ and $y=4$.\\n',\n",
       " '\\n9.2. Find the volume of the region bounded by the elliptic paraboloid $z=4-x^{2}-\\\\frac{1}{4} y^{2}$ and the plane $z=0$.\\n\\nBecause of the symmetry of the elliptic paraboloid, the result can be obtained by multiplying the first octant volume by 4 .\\n\\nLetting $z=0$ yields $4 x^{2}+y^{2}=16$. The limits of integration are determined from this equation. The required volume is\\n\\n$$\\n4 \\\\int_{0}^{2} \\\\int_{0}^{2 \\\\sqrt{4-x^{2}}}\\\\left(4-x^{2}-\\\\frac{1}{4} y^{2}\\\\right) d y d x=4 \\\\int_{0}^{2}\\\\left(4 y-x^{2} y-\\\\frac{1}{4} \\\\frac{y^{3}}{3}\\\\right)_{0}^{2 \\\\sqrt{4-x^{2}}} d x=16 \\\\Pi\\n$$\\n\\nHint: Use trigonometric substitutions to complete the integrations.\\n',\n",
       " '\\n9.3. The geometric model of a material body is a plane region $R$ bounded by $y=x^{2}$ and $y=\\\\sqrt{2-x^{2}}$ on the interval $0 \\\\leqq x \\\\leqq 1$, and with a density function $\\\\rho=x y$. (a) Draw the graph of the region. (b) Find the mass of the body. (c) Find the coordinates of the center of mass.\\n\\n(a) See Figure 9.8.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-239}\\n\\\\end{center}\\n\\nFigure 9.8\\n\\n(b)\\n\\n$$\\n\\\\begin{aligned}\\nM & =\\\\int_{a}^{b} \\\\int_{f_{1}}^{f_{2}} \\\\rho d y d x=\\\\int_{0}^{1} \\\\int_{x^{2}}^{\\\\sqrt{2-x^{2}}} y x d y d x=\\\\int_{0}^{1}\\\\left[\\\\frac{y^{2}}{2}\\\\right]_{x^{2}}^{\\\\sqrt{2-x^{2}}} x d x \\\\\\\\\\n& =\\\\int_{0}^{1} \\\\frac{1}{2} x\\\\left(2-x^{2}-x^{4}\\\\right) d x=\\\\left[\\\\frac{x^{2}}{2}-\\\\frac{x^{4}}{8}-\\\\frac{x^{6}}{12}\\\\right]_{0}^{1}=\\\\frac{7}{24}\\n\\\\end{aligned}\\n$$\\n\\n(c) The coordinates of the center of mass are defined to be\\n\\n$$\\n\\\\bar{x}=\\\\frac{1}{M} \\\\int_{a}^{b} \\\\int_{f_{1}(x)}^{f_{2}(x)} x \\\\rho d y d x \\\\text { and } \\\\bar{y}=\\\\frac{1}{M} \\\\int_{a}^{b} \\\\int_{f_{1}(x)}^{f_{2}(x)} y \\\\rho d y d x\\n$$\\n\\nwhere\\n\\n$$\\nM=\\\\int_{a}^{b} \\\\int_{f_{1}(x)}^{f_{2}(x)} \\\\rho d y d x\\n$$\\n\\nThus,\\n\\n$$\\n\\\\begin{aligned}\\nM \\\\bar{x} & =\\\\int_{0}^{1} \\\\int_{x^{2}}^{\\\\sqrt{2 x-x^{2}}} x x y d y d x=\\\\int_{0}^{1} x^{2}\\\\left[\\\\frac{y^{2}}{2}\\\\right]_{x^{2}}^{\\\\sqrt{2-x^{2}}} d x=\\\\int_{0}^{1} x^{2} \\\\frac{1}{2}\\\\left[2-x^{2}-x^{4}\\\\right] d x \\\\\\\\\\n& =\\\\left[\\\\frac{x^{3}}{3}-\\\\frac{x^{5}}{10}-\\\\frac{x^{7}}{14}\\\\right]_{0}^{1}=-\\\\frac{1}{3}-\\\\frac{1}{10} \\\\frac{1}{14}=\\\\frac{17}{105} \\\\\\\\\\nM \\\\bar{y} & =\\\\int_{0}^{1} \\\\int_{x^{2}}^{\\\\sqrt{2 x-5}} y x d y d x=-\\\\frac{13}{120}+4 \\\\frac{\\\\sqrt{2}}{15}\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n9.4. Find the volume of the region common to the intersecting cylinders $x^{2}+y^{2}=a^{2}$ and $x^{2}+z^{2}=a^{2}$.\\n\\nRequired volume $=8$ times volume of region shown in Figure 9.9\\n\\n$$\\n\\\\begin{aligned}\\n& =8 \\\\int_{x=0}^{a} \\\\int_{y=0}^{\\\\sqrt{a^{2}-x^{2}}} z d y d x \\\\\\\\\\n& =8 \\\\int_{x=0}^{a} \\\\int_{y=0}^{\\\\sqrt{a^{2}-x^{2}}}=\\\\sqrt{a^{2}-x^{2}} d y d x \\\\\\\\\\n& =8 \\\\int_{x=0}^{a}\\\\left(a^{2}-x^{2}\\\\right) d x=\\\\frac{16 a^{3}}{3}\\n\\\\end{aligned}\\n$$\\n\\nAs an aid in setting up this integral, note that $z d y d x$ corresponds to the volume of a column such as shown darkly shaded in Figure 9.9. Keeping $x$ constant and integrating with respect to $y$ from $y=0$ to $y=\\\\sqrt{a^{2}-x^{2}}$ corresponds to adding the volumes of all such columns in a slab parallel to the $y z$ plane, thus giving the volume of this slab. Finally, integrating with respect to $x$ from $x=0$ to $x=a$ corresponds to adding the volumes of all such slabs in the region, thus giving the required volume.\\n',\n",
       " '\\n9.5. Find the volume of the region bounded by $z=x+y, z=6, x=0, y=0, z=0$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-240(1)}\\n\\\\end{center}\\n\\nFigure 9.9\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-240}\\n\\\\end{center}\\n\\nFigure 9.10\\n\\nRequired volume $=$ volume of region shown in Figure 9.10\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\int_{x=0}^{6} \\\\int_{y=0}^{6-x}\\\\{6-(x+y)\\\\} d y d x \\\\\\\\\\n& =\\\\int_{x=0}^{6}(6-x) y-\\\\left.\\\\frac{1}{2} y^{2}\\\\right|_{y=0} ^{6-x} d x \\\\\\\\\\n& =\\\\int_{x=0}^{6} \\\\frac{1}{2}(6-x)^{2} d x=36\\n\\\\end{aligned}\\n$$\\n\\nIn this case the volume of a typical column (shown darkly shaded) corresponds to $\\\\{6-(x+y)\\\\} d y d x$. The limits of integration are then obtained by integrating over the region $\\\\Re$ of Figure 9.10. Keeping $x$ constant and integrating with respect to $y$ from $y=0$ to $y=6-x$ (obtained from $z=6$ and $z=x+y$ ) corresponds to summing all columns in a slab parallel to the $y z$ plane. Finally, integrating with respect to $x$ from $x=0$ to $x=6$ corresponds to adding the volumes of all such slabs and gives the required volume.\\n\\n\\n\\\\section*{Transformation of double integrals}\\n',\n",
       " \"9.6. Justify Equation (9), Page 225, for changing variables in a double integral.\\n\\nIn rectangular coordinates, the double integral of $F(x, y)$ over the region $\\\\Re$ (shaded in Figure 9.11) is $\\\\iint_{\\\\Re}(F(x, y) d x d y$. We can also evaluate this double integral by considering a grid formed by a family of $u$ and $v$ curvilinear coordinate curves constructed on the region $\\\\mathfrak{R}$, as shown in Figure 9.11.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-241}\\n\\\\end{center}\\n\\nFigure 9.11\\n\\nLet $P$ be any point with coordinates $(x, y)$ or $(u, v)$, where $x=f(u, v)$ and $y=g(u, v)$. Then the vector $\\\\mathbf{r}$ from $O$ to $p$ is given by $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}=f(u, v) \\\\mathbf{i}+g(u, v) \\\\mathbf{j}$. The tangent vectors to the coordinate curves $u=c_{1}$ and $v=c_{2}$, where $c_{1}$ and $c_{2}$ are constants, are $\\\\partial \\\\mathbf{r} / \\\\partial v$ and $\\\\partial \\\\mathbf{r} / \\\\partial u$, respectively. Then the area of region $\\\\Delta \\\\Re$ of Figure 9.11 is given approximately by $\\\\left|\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u} \\\\times \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial v}\\\\right| \\\\Delta u \\\\Delta v$.\\n\\nBut\\n\\n$$\\n\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u} \\\\times \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial v}=\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n\\\\frac{\\\\partial x}{\\\\partial u} & \\\\frac{\\\\partial y}{\\\\partial u} & 0 \\\\\\\\\\n\\\\frac{\\\\partial x}{\\\\partial v} & \\\\frac{\\\\partial y}{\\\\partial v} & 0\\n\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{cc}\\n\\\\frac{\\\\partial x}{\\\\partial u} & \\\\frac{\\\\partial y}{\\\\partial u} \\\\\\\\\\n\\\\frac{\\\\partial x}{\\\\partial v} & \\\\frac{\\\\partial y}{\\\\partial v}\\n\\\\end{array}\\\\right| \\\\mathbf{k}=\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)} \\\\mathbf{k}\\n$$\\n\\nso that\\n\\n$$\\n\\\\left|\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u} \\\\times \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial v}\\\\right| \\\\Delta u \\\\Delta v=\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| \\\\Delta u \\\\Delta v\\n$$\\n\\nThe double integral is the limit of the sum\\n\\n$$\\n\\\\sum F\\\\{f(u, v), g(u, v)\\\\}\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| \\\\Delta u \\\\Delta v\\n$$\\n\\ntaken over the entire region $\\\\Re$. An investigation reveals that this limit is\\n\\n$$\\n\\\\iint_{\\\\Re} F\\\\{f(u, v), g(u, v)\\\\}=\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| d u d v\\n$$\\n\\nwhere $\\\\Re^{\\\\prime}$ is the region in the $u v$ plane into which the region $\\\\Re$ is mapped under the transformation $x=f(u, v)$, $y=g(u, v)$.\\n\\nAnother method of justifying this method of change of variables makes use of line integrals and Green's theorem in the plane (see Problem 10.32).\\n\",\n",
       " '\\n9.7. If $u=x^{2}-y^{2}$ and $v=2 x y$, find $\\\\partial(u, v)$ in terms of $u$ and $v$.\\n\\n$$\\n\\\\frac{\\\\partial(u, v)}{\\\\partial(x, y)}=\\\\left|\\\\begin{array}{ll}\\nu_{x} & u_{y} \\\\\\\\\\nv_{x} & v_{y}\\n\\\\end{array}\\\\right|=\\\\left|\\\\begin{array}{cc}\\n2 x & -2 y \\\\\\\\\\n2 y & 2 x\\n\\\\end{array}\\\\right|=4\\\\left(x^{2}+y^{2}\\\\right)\\n$$\\n\\nFrom the identity $\\\\left(x^{2}+y^{2}\\\\right)^{2}=\\\\left(x^{2}-y^{2}\\\\right)^{2}+(2 x y)^{2}$, we have\\n\\n$$\\n\\\\left(x^{2}+y^{2}\\\\right)^{2}=u^{2}+v^{2} \\\\quad \\\\text { and } \\\\quad x^{2}+y^{2}=\\\\sqrt{u^{2}+v^{2}}\\n$$\\n\\nThen, by Problem 6.43,\\n\\n$$\\n\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}=\\\\frac{1}{\\\\partial(u, v) / \\\\partial(x, y)}=\\\\frac{1}{4\\\\left(x^{2}+y^{2}\\\\right)}=\\\\frac{1}{4 \\\\sqrt{u^{2}+v^{2}}}\\n$$\\n\\nAnother method: Solve the given equations for $x$ and $y$ in terms of $u$ and $v$ and find the Jacobian directly.\\n',\n",
       " '\\n9.8. Find the polar moment of inertia of the region in the $x y$ plane bounded by $x^{2}-y^{2}=1, x^{2}-y^{2}=9, x y=2, x y=$ 4 , assuming unit density.\\n\\nUnder the transformation $x^{2}-y^{2}=u, 2 x y=v$, the required region $\\\\Re$ in the $x y$ plane, shaded in Figure 9.12(a), is mapped into region $\\\\Re^{\\\\prime}$ of the $u v$ plane, shaded in Figure 9.12(b). Then:\\n\\n$$\\n\\\\begin{aligned}\\n\\\\text { Required polar moment of inertia } & =\\\\iint_{\\\\Re}\\\\left(x^{2}+y^{2}\\\\right) d x d y=\\\\iint_{\\\\Re^{\\\\prime}}\\\\left(x^{2}+y^{2}\\\\right)\\\\left|\\\\begin{array}{l}\\n\\\\partial(x, y) \\\\\\\\\\n\\\\partial(u, v)\\n\\\\end{array}\\\\right| d u d v \\\\\\\\\\n& =\\\\iint_{\\\\Re^{\\\\prime}} \\\\sqrt{u^{2}+v^{2}} \\\\frac{d u d v}{4 \\\\sqrt{u^{2}+v^{2}}}=\\\\frac{1}{4} \\\\int_{u=1}^{9} \\\\int_{v=4}^{8} d u d v=8\\n\\\\end{aligned}\\n$$\\n\\nwhere we have used the results of Problem 9.7.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-242(1)}\\n\\\\end{center}\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-242}\\n\\\\end{center}\\n\\n(b)\\n\\nFigure 9.12\\n\\nNote that the limits of integration for the region $\\\\Re^{\\\\prime}$ can be constructed directly from the region $\\\\Re$ in the $x y$ plane without actually constructing the region $\\\\mathfrak{R}^{\\\\prime}$. In such case we use a grid, as in Problem 9.6. The coordinates $(u, v)$ are curvilinear coordinates, in this case called hyperbolic coordinates.\\n',\n",
       " '\\n9.9 Evaluate $\\\\iint_{\\\\Re} \\\\sqrt{x^{2}+y^{2}} d x d y$, where $\\\\Re$ is the region in the $x y$ plane bounded by $x^{2}+y^{2}=4$ and $x^{2}+y^{2}=9$.\\n\\nThe presence of $x^{2}+y^{2}$ suggests the use of polar coordinates $(\\\\rho, \\\\phi)$, where $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$ (see Problem 6.39). Under this transformation the region $\\\\Re$ [Figure 9.13(a)] is mapped into the region $\\\\Re^{\\\\prime}$ [Figure $9.13(b)]$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-243}\\n\\\\end{center}\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-243(1)}\\n\\\\end{center}\\n\\n(b)\\n\\nFigure 9.13\\n\\nSince $\\\\frac{\\\\partial(x, y)}{\\\\partial(\\\\rho, \\\\phi)}=\\\\rho$, it follows that\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{\\\\Re} \\\\sqrt{x^{2}+y^{2}} d x d y & =\\\\iint_{\\\\mathcal{R}^{\\\\prime}} \\\\sqrt{x^{2}+y^{2}}\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(\\\\rho, \\\\phi)}\\\\right| d \\\\rho d \\\\phi=\\\\iint_{\\\\mathcal{K}^{\\\\prime}} \\\\rho \\\\cdot \\\\rho d d \\\\phi \\\\\\\\\\n& =\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\int_{\\\\rho=2}^{3} \\\\rho^{2} d \\\\rho d \\\\phi=\\\\left.\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\frac{\\\\rho^{3}}{3}\\\\right|_{2} ^{3} d \\\\phi=\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\frac{19}{3} d \\\\phi=\\\\frac{38 \\\\pi}{3}\\n\\\\end{aligned}\\n$$\\n\\nWe can also write the integration limits for $\\\\mathfrak{R}^{\\\\prime}$ immediately on observing the region $\\\\mathfrak{R}$, since for fixed $\\\\phi$. $\\\\rho$ varies from $\\\\rho=2$ to $\\\\rho=3$ within the sector shown dashed in Figure 9.13(a). An integration with respect to $\\\\phi$ from $\\\\phi=0$ to $\\\\phi=2 \\\\pi$ then gives the contribution from all sectors. Geometrically, $\\\\rho d \\\\rho d \\\\phi$ represents the area $d A$, as shown in Figure 9.13(a).\\n',\n",
       " '\\n9.10. Find the area of the region in the $x y$ plane bounded by the lemniscate $\\\\rho^{2}=a^{2} \\\\cos 2 \\\\phi$.\\n\\nHere the curve is given directly in polar coordinates $(\\\\rho, \\\\phi)$. By assigning various to $\\\\phi$ and finding corresponding values of $\\\\rho$, we obtain the graph shown in Figure 9.14. The required area (making use of symmetry) is\\n\\n$$\\n\\\\begin{aligned}\\n4 \\\\int_{\\\\phi=0}^{\\\\pi / 4} \\\\int_{\\\\rho=0}^{a \\\\sqrt{\\\\cos 2 \\\\phi}} \\\\rho d \\\\rho d \\\\phi & =\\\\left.4 \\\\int_{\\\\phi=0}^{\\\\pi / 4} \\\\frac{\\\\rho^{3}}{2}\\\\right|_{\\\\rho=0} ^{a \\\\sqrt{\\\\cos 2 \\\\phi}} d \\\\phi \\\\\\\\\\n& =2 \\\\int_{\\\\phi=0}^{\\\\pi / 4} a^{2} \\\\cos 2 \\\\phi d \\\\phi=\\\\left.a^{2} \\\\sin 2 \\\\phi\\\\right|_{\\\\phi=0} ^{\\\\pi / 4}=a^{2}\\n\\\\end{aligned}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-244}\\n\\\\end{center}\\n\\nFigure 9.14\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-244(1)}\\n\\\\end{center}\\n\\nFigure 9.15\\n\\n\\n\\\\section*{Triple integrals}\\n',\n",
       " '9.11. (a) Sketch the three-dimensional region $\\\\Re$ bounded by $x+y+z=a(a>0), x=0, y=0, z=0$. (b) Give a physical interpretation to\\n\\n$$\\n\\\\iiint_{\\\\Re}\\\\left(x^{2}+y^{2}+z^{2}\\\\right) d x d y d z\\n$$\\n\\n(c) Evaluate the triple integral in (b).\\n\\n(a) The required region $\\\\Re$ is shown in Figure 9.15.\\n\\n(b) Since $x^{2}+y^{2}+z^{2}$ is the square of the distance from any point $(x, y, z)$ to $(0,0,0)$, we can consider the triple integral as representing the polar moment of inertia (i.e., moment of inertia with respect to the origin) of the region $\\\\Re$ (assuming unit density).\\n\\nWe can also consider the triple integral as representing the mass of the region if the density varies as $x^{2}+y^{2}+z^{2}$.\\n\\n(c) The triple integral can be expressed as the iterated integral\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{x=0}^{a} \\\\int_{y=0}^{a-x} \\\\int_{z=0}^{a-x-y}\\\\left(x^{2}\\\\right. & \\\\left.+y^{2}+z^{2}\\\\right) d z d y d x \\\\\\\\\\n& =\\\\int_{x=0}^{a} \\\\int_{y=0}^{a-x} x^{2} z+y^{2} z+\\\\left.\\\\frac{z^{3}}{3}\\\\right|_{z=0} ^{a-x-y} d y d x \\\\\\\\\\n& =\\\\int_{x=0}^{a} \\\\int_{y=0}^{a-x}\\\\left\\\\{x^{2}(a-x)-x^{2} y+(a-x) y^{2}-y^{3}+\\\\frac{(a-x-y)^{3}}{3}\\\\right\\\\} d y d x \\\\\\\\\\n& =\\\\int_{x=0}^{a} x^{2}(a-x) y-\\\\frac{x^{2} y^{2}}{2}+\\\\frac{(a-x) y^{3}}{3}-\\\\frac{y^{4}}{4}-\\\\left.\\\\frac{(a-x-y)^{4}}{12}\\\\right|_{y=0} ^{a-x} d x \\\\\\\\\\n& =\\\\int_{0}^{a}\\\\left\\\\{x^{2}(a-x)^{2}-\\\\frac{x^{2}(a-x)^{2}}{2}+\\\\frac{(a-x)^{4}}{3}-\\\\frac{(a-x)^{4}}{4}+\\\\frac{(a-x)^{4}}{12}\\\\right\\\\} d x \\\\\\\\\\n& =\\\\int_{0}^{a}\\\\left\\\\{\\\\frac{x^{2}(a-x)^{2}}{2}+\\\\frac{(a-x)^{4}}{6}\\\\right\\\\} d x=\\\\frac{a^{5}}{20}\\n\\\\end{aligned}\\n$$\\n\\nThe integration with respect to $z$ (keeping $x$ and $y$ constant) from $z=0$ to $z=a-x-y$ corresponds to summing the polar moments of inertia (or masses) corresponding to each cube in a vertical column. The subsequent integration with respect to $y$ from $y=0$ to $y=a-x$ (keeping $x$ constant) corresponds to addition of contributions from all vertical columns contained in a slab parallel to the $y z$ plane. Finally, integration with respect to $x$ from $x=0$ to $x=a$ adds up contributions from all slabs parallel to the $y z$ plane.\\n\\nAlthough this integration has been accomplished in the order $z, y, x$, any other order is is clearly possible and the final answer should be the same.\\n',\n",
       " '\\n9.12. Find (a) the volume and (b) the centroid of the region $\\\\Re$ bounded by the parabolic cylinder $z=4-x^{2}$ and the planes $x=0, y=6, z=0$, assuming the density to be a constant $\\\\sigma$.\\n\\nThe region $\\\\mathfrak{R}$ is shown in Figure 9.16.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-245}\\n\\\\end{center}\\n\\nFigure 9.16\\n\\n(a) Required volume $=\\\\iiint \\\\mathrm{dx} d y d z$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\int_{x=0}^{2} \\\\int_{y=0}^{6} \\\\int_{z=0}^{4-x^{2}} d z d y d x \\\\\\\\\\n& =\\\\int_{x=0}^{2} \\\\int_{y=0}^{6}\\\\left(4-x^{2}\\\\right) d y d x \\\\\\\\\\n& =\\\\left.\\\\int_{x=0}^{2}\\\\left(4-x^{2}\\\\right) y\\\\right|_{y=0} ^{6} d x \\\\\\\\\\n& =\\\\int_{x=0}^{2}\\\\left(2-6 x^{2}\\\\right) d x=32\\n\\\\end{aligned}\\n$$\\n\\n(b) Total mass $=\\\\int_{x=0}^{2} \\\\int_{y=0}^{6} \\\\int_{z=0}^{4-x^{2}} \\\\sigma d z d y d x=32 \\\\sigma$ by (a), since $\\\\sigma$ is constant. Then\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\bar{x}=\\\\frac{\\\\text { Total moment about } y z \\\\text { plane }}{\\\\text { Total mass }}=\\\\frac{\\\\int_{\\\\mathrm{x}=0}^{2} \\\\int_{\\\\mathrm{y}=0}^{6} \\\\int_{\\\\mathrm{z}=0}^{4-\\\\mathrm{x}^{2}} \\\\sigma x d z d y d x}{\\\\text { Total mass }}=\\\\frac{24}{32 \\\\sigma}=\\\\frac{3}{4} \\\\\\\\\\n& \\\\bar{y}=\\\\frac{\\\\text { Total moment about } x z \\\\text { plane }}{\\\\text { Total mass }}=\\\\frac{\\\\int_{\\\\mathrm{x}=0}^{2} \\\\int_{\\\\mathrm{y}=0}^{6} \\\\int_{\\\\mathrm{z}=0}^{4-\\\\mathrm{x}^{2}} \\\\sigma y d z d y d x}{\\\\text { Total mass }}=\\\\frac{96 \\\\sigma}{32 \\\\sigma}=3 \\\\\\\\\\n& \\\\bar{z}=\\\\frac{\\\\text { Total moment about } x y \\\\text { plane }}{\\\\text { Total mass }}=\\\\frac{\\\\int_{\\\\mathrm{x}=0}^{2} \\\\int_{\\\\mathrm{y}=0}^{6} \\\\int_{\\\\mathrm{z}=0}^{4-\\\\mathrm{x}^{2}} \\\\sigma z d z d y d x}{\\\\text { Total mass }}=\\\\frac{256 \\\\sigma / 5}{32 \\\\sigma}=\\\\frac{8}{5}\\n\\\\end{aligned}\\n$$\\n\\nThus, the centroid has coordinates $(3 / 4,3,8 / 5)$.\\n\\nNote that the value for $\\\\bar{y}$ could have been predicted because of symmetry.\\n\\n\\n\\\\section*{Transformation of triple integrals}\\n',\n",
       " \"9.13. Justify Equation (11), Page 225, for changing variables in a triple integral.\\n\\nBy analogy with Problem 9.6, we construct a grid of curvilinear coordinate surfaces which subdivide the region $\\\\Re$ into subregions, a typical one of which is $\\\\Delta \\\\Re$ (see Figure 9.17).\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-246}\\n\\\\end{center}\\n\\nFigure 9.17\\n\\nThe vector $\\\\mathbf{r}$ from the origin $O$ to point $P$ is\\n\\n$$\\nr=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}=f(u, v, w) \\\\mathbf{i}+g(u, v, w) \\\\mathbf{j}+h(u, v, w) \\\\mathbf{k}\\n$$\\n\\nassuming that the transformation equations are $x=f(u, v, w), y=g(u, v, w)$, and $z=h(u, v, w)$.\\n\\nTangent vectors to the coordinate curves corresponding to the intersection of pairs of coordinate surfaces are given by $\\\\partial \\\\mathbf{r} / \\\\partial u, \\\\partial \\\\mathbf{r} / \\\\partial v, \\\\partial \\\\mathbf{r} / \\\\partial w$. Then the volume of the region $\\\\Delta \\\\Re$ of Figure 9.17 is given approximately by\\n\\n$$\\n\\\\left|\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial u} \\\\cdot \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial v} \\\\times \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial w}\\\\right| \\\\Delta u \\\\Delta v \\\\Delta w=\\\\left|\\\\frac{\\\\partial(x, y, z)}{\\\\partial(u, v, w)}\\\\right| \\\\Delta u \\\\Delta v \\\\Delta w\\n$$\\n\\nThe triple integral of $F(x, y, z)$ over the region is the limit of the sum\\n\\n$$\\n\\\\sum F\\\\{f(u, v, w), g(u, v, w), h(u, v, w)\\\\}\\\\left|\\\\frac{\\\\partial(x, y, z)}{\\\\partial(u, v, w)}\\\\right| \\\\Delta u \\\\Delta v \\\\Delta w\\n$$\\n\\nAn investigation reveals that this limit is\\n\\n$$\\n\\\\iiint F\\\\{f(u, v, w), g(u, v, w), h(u, v, w)\\\\}\\\\left|\\\\frac{\\\\partial(x, y, z)}{\\\\partial(u, v, w)}\\\\right| d u d v d w\\n$$\\n\\nwhere $\\\\Re^{\\\\prime}$ is the region in the $u v w$ space into which the region $\\\\Re$ is mapped under the transformation.\\n\\nAnother method for justifying this change of variables in triple integrals makes use of Stokes's theorem (see Problem 10.84).\\n\",\n",
       " '\\n9.14. What is the mass of a circular cylindrical body represented by the region $0 \\\\leqq \\\\rho \\\\leqq c, 0 \\\\leqq \\\\phi \\\\leqq 2 \\\\pi, 0 \\\\leqq z \\\\leqq$ $h$, and with the density function $\\\\mu=z \\\\sin ^{2} \\\\phi$ ?\\n\\n$$\\nM=\\\\int_{0}^{h} \\\\int_{0}^{2 \\\\pi} \\\\int_{0}^{c} z \\\\sin ^{2} \\\\phi \\\\rho d \\\\rho d \\\\phi d z=\\\\pi\\n$$\\n',\n",
       " '\\n9.15. Use spherical coordinates to calculate the volume of a sphere of radius $a$.\\n\\n$$\\nV=8 \\\\int_{0}^{a} \\\\int_{0}^{\\\\pi / 2} \\\\int_{0}^{\\\\pi / 2} a^{2} \\\\sin \\\\theta d r d \\\\theta d \\\\phi=\\\\frac{4}{3} \\\\pi a^{3}\\n$$\\n',\n",
       " '\\n9.16. Express $\\\\iiint_{\\\\Re^{\\\\prime}} F(x, y, z) d x d y d z$ in (a) cylindrical and (b) spherical coordinates.\\n\\n(a) The transformation equations in cylindrical coordinates are $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi, z=z$.\\n\\nAs in Problem 6.39, $\\\\partial(x, y, z) / \\\\partial(\\\\rho, \\\\phi, z)=\\\\rho$. Then, by Problem 9.13, the triple integral becomes\\n\\n$$\\n\\\\iiint_{\\\\Re^{\\\\prime}} G(\\\\rho, \\\\phi, z) \\\\rho d \\\\rho d \\\\phi d z\\n$$\\n\\nwhere $\\\\Re^{\\\\prime}$ is the region in the $\\\\rho, \\\\phi, z$ space corresponding to $\\\\Re$ and where $G(\\\\rho, \\\\phi, z \\\\equiv F(\\\\rho \\\\cos \\\\phi, \\\\rho \\\\sin \\\\phi, z)$.\\\\\\\\\\n(b) The transformation equations in spherical coordinates are $x=r \\\\sin \\\\theta \\\\cos \\\\phi, y=r \\\\sin \\\\theta \\\\sin \\\\phi, z=r \\\\cos \\\\theta$.\\n\\nBy Problem 6.101, $\\\\partial(x, y, z) / \\\\partial(r, \\\\theta, \\\\phi)=r^{2} \\\\sin \\\\theta$. Then, by Problem 9.13, the triple integral becomes\\n\\n$$\\n\\\\iiint_{\\\\Re^{\\\\prime}} H(r, \\\\theta, \\\\phi) r^{2} \\\\sin \\\\theta d r d \\\\theta d \\\\phi\\n$$\\n\\nwhere $\\\\Re^{\\\\prime}$ is the region in the $r, \\\\theta, \\\\phi$ space corresponding to $\\\\Re$, and where $H(r, \\\\theta, \\\\phi) \\\\equiv F(r \\\\sin \\\\theta \\\\cos \\\\phi$, $r \\\\sin \\\\theta \\\\sin \\\\phi, r \\\\cos \\\\theta)$.\\n',\n",
       " '\\n9.17. Find the volume of the region above the $x y$ plane bounded by the paraboloid $z=x^{2}+y^{2}$ and the cylinder $x^{2}+y^{2}=a^{2}$.\\n\\nThe volume is most easily found by using cylindrical coordinates. In these coordinates the equations for the paraboloid and cylinder are, respectively, $z=\\\\rho^{2}$ and $\\\\rho=a$. Then\\n\\nRequired volume $=4$ times volume shown in Figure 9.18\\n\\n$$\\n\\\\begin{aligned}\\n& =4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{a} \\\\int_{z=0}^{\\\\rho^{2}} \\\\rho d z d \\\\rho d \\\\phi \\\\\\\\\\n& =4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{a} \\\\rho^{3} d \\\\rho d \\\\phi \\\\\\\\\\n& =\\\\left.4 \\\\int_{h i=0}^{\\\\pi / 2} \\\\frac{\\\\rho^{4}}{4}\\\\right|_{=0} ^{a} d \\\\phi=\\\\frac{\\\\pi}{2} a^{4}\\n\\\\end{aligned}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-247}\\n\\\\end{center}\\n\\nFigure 9.18\\n\\nThe integration with respect to $z$ (keeping $\\\\rho$ and $\\\\phi$ constant) from $z=0$ to $z=\\\\rho^{2}$ corresponds to summing the cubical volumes (indicated by $d V$ ) in a vertical column extending from the $x y$ plane to the paraboloid. The subsequent integration with respect to $\\\\rho$ (keeping $\\\\phi$ constant) from $\\\\rho=0$ to $\\\\rho=a$ corresponds to addition of volumes of all columns in the wedge-shaped region. Finally, integration with respect to $\\\\phi$ corresponds to adding volumes of all such wedge-shaped regions.\\n\\nThe integration can also be performed in other orders to yield the same result.\\n\\nWe can also set up the integral by determining the region $\\\\Re^{\\\\prime}$ in $\\\\rho, \\\\phi, z$ space into which $\\\\Re$ is mapped by the cylindrical coordinate transformation.\\n',\n",
       " '\\n9.18. (a) Find the moment of inertia about the $z$ axis of the region in Problem 9.17, assuming that the density is the constant $\\\\sigma$. (b) Find the radius of gyration.\\n\\n(a) The moment of inertia about the $z$ axis is\\n\\n$$\\n\\\\begin{aligned}\\nI_{z} & =4 \\\\int_{\\\\phi_{0}}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{a} \\\\int_{z=0}^{\\\\rho^{2}} \\\\rho^{2} \\\\sigma \\\\rho d z d \\\\rho d \\\\phi \\\\\\\\\\n& =4 \\\\sigma \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{a} \\\\rho^{5} d \\\\rho d \\\\phi=\\\\left.4 \\\\sigma \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\frac{\\\\rho^{6}}{6}\\\\right|_{\\\\rho=0} ^{a} d \\\\phi=\\\\frac{\\\\pi a^{6} \\\\sigma}{3}\\n\\\\end{aligned}\\n$$\\n\\nThe result can be expressed in terms of the mass $M$ of the region, since, by Problem 9.17,\\n\\n$$\\nM=\\\\text { volume } \\\\times \\\\text { desnity }=\\\\frac{\\\\pi}{2} a^{4} \\\\sigma \\\\quad \\\\text { so that } \\\\quad I_{z}=\\\\frac{\\\\pi a^{6} \\\\sigma}{3}=\\\\frac{\\\\pi a^{6}}{3} \\\\cdot \\\\frac{2 M}{\\\\pi a^{4}}=\\\\frac{2}{3} M a^{2}\\n$$\\n\\nNote that in setting up the integral for $\\\\boldsymbol{I}_{z}$ we can think of $\\\\sigma \\\\rho d z d \\\\rho d \\\\phi d z d \\\\rho d \\\\phi$ as being the mass of the cubical volume element, $\\\\rho^{2} \\\\sigma \\\\rho d z d \\\\rho d \\\\phi$ as the moment of inertia of this mass with respect to the $z$ axis, and $\\\\iiint_{\\\\Re^{\\\\prime}} \\\\rho^{2} \\\\sigma \\\\rho d z d \\\\rho d \\\\phi$ as the total moment of inertia about the $z$ axis. The limits of integration are determined as in Problem 9.17.\\n\\n(b) The radius of gyration is the value $K$ such that $M K^{2}=\\\\frac{2}{3} M a^{2}$; i.e., $K^{2}=\\\\frac{2}{3} a^{2}$ or $K=a \\\\sqrt{2 / 3}$.\\n\\nThe physical significance of $K$ is that if all the mass $M$ were concentrated in a thin cylindrical shell of radius $K$, then the moment of inertia of this shell about the axis of the cylinder would be $I_{z}$.\\n',\n",
       " '\\n9.19. (a) Find the volume of the region bounded above by the sphere $x^{2}+y^{2}+z^{2}=a^{2}$ and below by the cone $z^{2}$ $\\\\sin ^{2} \\\\alpha=\\\\left(x^{2}+y^{2}\\\\right) \\\\cos ^{2} \\\\alpha$, where $\\\\alpha$ is a constant such that $0 \\\\leqq \\\\alpha \\\\leqq \\\\pi$. (b) From the result in (a), find the volume of a sphere of radius $a$.\\n\\nIn spherical coordinates the equation of the sphere is $r=a$ and that of the cone is $\\\\theta=\\\\alpha$. This can been directly or by using the transformation equations $x=r \\\\sin \\\\theta \\\\cos \\\\phi, y=r \\\\sin \\\\theta \\\\sin \\\\phi, z=r \\\\cos \\\\theta$. For example, $z^{2} \\\\sin ^{2} \\\\alpha=\\\\left(x^{2}+y^{2}\\\\right) \\\\cos ^{2} \\\\alpha$ becomes, on using these equations, $r^{2} \\\\cos ^{2} \\\\theta \\\\sin ^{2} \\\\alpha=\\\\left(r^{2} \\\\sin ^{2} \\\\theta \\\\cos ^{2} \\\\phi+r^{2} \\\\sin ^{2} \\\\theta\\\\right.$ $\\\\left.\\\\sin ^{2} \\\\phi\\\\right) \\\\cos ^{2} \\\\alpha$, i.e., $r^{2} \\\\cos ^{2} \\\\theta \\\\sin ^{2} \\\\alpha=r^{2} \\\\sin ^{2} \\\\theta \\\\cos ^{2} \\\\alpha$, from which $\\\\tan \\\\theta= \\\\pm \\\\tan \\\\alpha$ and $\\\\operatorname{so} \\\\theta=\\\\alpha$ or $\\\\theta=\\\\pi-\\\\alpha$. It is sufficient to consider one of these-say, $\\\\theta=\\\\alpha$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-248}\\n\\\\end{center}\\n\\nFigure 9.19\\n\\n(a) Required volume $=4$ times volume (shaded) in Figure 9.19\\n\\n$$\\n\\\\begin{aligned}\\n& =4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\alpha} \\\\int_{r=0}^{\\\\rho^{2}} r^{2} \\\\sin \\\\theta d r d \\\\theta d \\\\phi \\\\\\\\\\n& =\\\\left.4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\alpha} \\\\frac{r^{3}}{3} \\\\sin \\\\theta\\\\right|_{r=0} ^{\\\\alpha} d \\\\theta d \\\\phi \\\\\\\\\\n& =\\\\frac{4 a^{3}}{3} \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\alpha} \\\\sin \\\\theta d \\\\theta d \\\\phi \\\\\\\\\\n& =\\\\frac{4 a^{3}}{3} \\\\int_{\\\\phi=0}^{\\\\pi / 2}-\\\\left.\\\\cos \\\\theta\\\\right|_{\\\\theta=0} ^{\\\\alpha} d \\\\phi \\\\\\\\\\n& =\\\\frac{2 \\\\pi a^{3}}{3}(1-\\\\cos \\\\alpha)\\n\\\\end{aligned}\\n$$\\n\\nThe integration with respect to $r$ (keeping $\\\\theta$ and $\\\\phi$ constant) from $r=0$ to $r=a$ corresponds to summing the volumes of all cubical elements (such as indicated by $d V$ ) in a column extending from $r=0$ to $r=a$. The subsequent integration with respect to $\\\\theta$ (keeping $\\\\phi$ constant) from $\\\\theta=0$ to $\\\\theta=\\\\pi / 4$ corresponds to summing the volumes of all columns in the wedge-shaped region. Finally, integration with respect to $\\\\phi$ corresponds to adding volumes of all such wedge-shaped regions.\\n\\n(b) Letting $\\\\alpha=\\\\pi$, the volume of the sphere thus obtained is\\n\\n$$\\n\\\\frac{2 \\\\pi a^{3}}{3}(1-\\\\cos \\\\pi)=\\\\frac{4}{3} \\\\pi a^{3}\\n$$\\n',\n",
       " '\\n9.20. (a) Find the centroid of the region in Problem 9.19. (b) Use the result in (a) to find the centroid of a hemisphere.\\n\\n(a) The centroid ( $\\\\bar{x}, \\\\bar{y}, \\\\bar{z})$ is, due to symmetry, given by $\\\\bar{x}=\\\\bar{y}=0$ and\\n\\n$$\\n\\\\bar{z}=\\\\frac{\\\\text { Total moment about } x y \\\\text { plane }}{\\\\text { Total mass }}=\\\\frac{\\\\iiint z \\\\sigma d V}{\\\\iiint \\\\sigma d V}\\n$$\\n\\nSince $z=r \\\\cos \\\\theta$ and $\\\\sigma$ is constant, the numerator is\\n\\n$$\\n\\\\begin{aligned}\\n4 \\\\sigma \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\alpha} \\\\int_{r=0}^{\\\\rho^{2}} r \\\\cos \\\\theta \\\\cdot r^{2} \\\\sin \\\\theta d r d \\\\theta d \\\\phi & =\\\\left.4 \\\\sigma \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\alpha} \\\\frac{r^{4}}{4}\\\\right|_{r=0} ^{a} \\\\sin \\\\theta \\\\cos \\\\theta d \\\\theta d \\\\phi \\\\\\\\\\n& =\\\\sigma a^{4} \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\alpha} \\\\sin \\\\theta \\\\cos \\\\theta d \\\\theta d \\\\phi \\\\\\\\\\n& =\\\\left.\\\\sigma a^{4} \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\frac{\\\\sin ^{2} \\\\theta}{2}\\\\right|_{\\\\theta=0} ^{a} d \\\\phi=\\\\frac{\\\\pi \\\\sigma a^{4} \\\\sin ^{2} \\\\alpha}{4}\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\nThe denominator, obtained by multiplying the result of Problem 9.19(a) by $\\\\sigma$, is $\\\\frac{2}{3} \\\\pi \\\\sigma a^{3}(1-\\\\cos \\\\alpha)$.\\n\\n$$\\n\\\\bar{z}=\\\\frac{\\\\frac{1}{4} \\\\pi \\\\sigma a^{4} \\\\sin ^{2} \\\\alpha}{\\\\frac{2}{3} \\\\pi \\\\sigma a^{3}(1-\\\\cos \\\\alpha)}=\\\\frac{3}{8} a(1+\\\\cos \\\\alpha)\\n$$\\n\\n(b) Letting $\\\\alpha=\\\\pi / 2, \\\\bar{z}=\\\\frac{3}{8} \\\\mathrm{a}$.\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '9.21. Prove that (a) $\\\\int_{0}^{1}\\\\left\\\\{\\\\int_{0}^{1} \\\\frac{x-y}{(x+y)^{3}} d y\\\\right\\\\} d x=\\\\frac{1}{2}$ and (b) $\\\\int_{0}^{1}\\\\left\\\\{\\\\int_{0}^{1} \\\\frac{x-y}{(x+y)^{3}} d x\\\\right\\\\} d y=-\\\\frac{1}{2}$,\\n\\n(a) $\\\\int_{0}^{1}\\\\left\\\\{\\\\int_{0}^{1} \\\\frac{x-y}{(x+y)^{3}} d y\\\\right\\\\} d x=\\\\int_{0}^{1}\\\\left\\\\{\\\\int_{0}^{1} \\\\frac{2 x-(x+y)}{(x+y)^{3}} d y\\\\right\\\\} d x$\\n\\n$$\\n=\\\\int_{0}^{1}\\\\left\\\\{\\\\int_{0}^{1}\\\\left(\\\\frac{2 x}{(x+y)^{3}}-\\\\frac{1}{(x+y)^{2}}\\\\right) d y\\\\right\\\\} d x\\n$$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left.\\\\int_{0}^{1}\\\\left(\\\\frac{-x}{(x+y)^{2}}-\\\\frac{1}{x+y}\\\\right)\\\\right|_{y=0} ^{1} d x \\\\\\\\\\n& =\\\\int_{0}^{1} \\\\frac{d x}{(x+y)^{2}}-\\\\left.\\\\frac{-1}{x+1}\\\\right|_{0} ^{1}=\\\\frac{1}{2}\\n\\\\end{aligned}\\n$$\\n\\n(b) This follows at once on formally interchanging $x$ and $y$ in (a) to obtain\\n\\n$\\\\iint_{\\\\Re} \\\\frac{x-y}{(x+y)^{3}} d x d y, \\\\int_{0}^{1}\\\\left\\\\{\\\\int_{0}^{1} \\\\frac{x-y}{(x+y)^{3}} d x\\\\right\\\\} d y=-\\\\frac{1}{2}$ and then multiplying both sides by -1.\\n\\nThis example shows that interchange in order of integration may not always produce equal results. A sufficient condition under which the order may be interchanged is that the double integral over the corresponding region exists. In this case $\\\\iint_{\\\\Re} \\\\frac{x-y}{(x+y)^{3}} d x d y$, where $\\\\Re$ is the region $0 \\\\leqq x \\\\leqq 1,0 \\\\leqq y \\\\leqq 1$, fails to exist because of the discontinuity of the integrand at the origin. The integral is actually an improper double integral (see Chapter 12).\\n',\n",
       " \"\\n9.22. Prove that $\\\\int_{0}^{x}\\\\left\\\\{\\\\int_{0}^{t} F(u) d u\\\\right\\\\} d t=\\\\int_{0}^{x}(x-u) F(u) d u$\\n\\nLet $I(x)=\\\\int_{0}^{x}\\\\left\\\\{\\\\int_{0}^{t} F(u) d u\\\\right\\\\} d t, \\\\quad J(x)=\\\\int_{0}^{z}(x-u) F(u) d u . \\\\quad$ Then\\n\\n$$\\nI^{\\\\prime}(x)=\\\\int_{0}^{z} F(u) d u, \\\\quad J^{\\\\prime}(x)=\\\\int_{0}^{z} F(u) d u\\n$$\\n\\nusing Leibniz's rule, Page 198. Thus, $I^{\\\\prime}(x)=J^{\\\\prime}(x)$, and so $I(x)=J(x)=c$, where $c$ is a constant. Since $I(0)=$ $J(0)=0, c=0$, and so $I(x)=J(x)$.\\n\\nThe result is sometimes written in the form\\n\\n$$\\n\\\\int_{0}^{x} \\\\int_{0}^{x} F(x) d x^{2}=\\\\int_{0}^{x}(x-u) F(u) d u\\n$$\\n\\nThe result can be generalized to give (see Problem 9.58)\\n\\n$$\\n\\\\int_{0}^{x} \\\\int_{0}^{x} \\\\cdots \\\\int_{0}^{x} F(x) d x^{n}=\\\\frac{1}{(n-1) !} \\\\int_{0}^{x}(x-u)^{n-1} F(u) d u\\n$$\\n\\n\",\n",
       " '10.1. Evaluate $\\\\int_{(0,1)}^{(1,2)}\\\\left(x^{2}-y\\\\right) d x+\\\\left(y^{2}+x\\\\right) d y$ along (a) a straight line from $(0,1)$ to $(1,2)$, (b) a straight lines from $(0,1)$ to $(1,1)$ and then from $(1,1)$ to $(1,2)$, and (c) the parabola $x=t, y=t^{2}+1$.\\n\\n(a) An equation for the line joining $(0,1)$ and $(1,2)$ in the $x y$ plane is $y=x+1$. Then $d y=d x$ and the line integral equals\\n\\n$$\\n\\\\int_{x=0}^{1}\\\\left\\\\{x^{2}-(x+1)\\\\right\\\\} d x+\\\\left\\\\{(x+1)^{2}+x\\\\right\\\\} d x=\\\\int_{0}^{1}\\\\left(2 x^{2}+2 x\\\\right) d x=5 / 3\\n$$\\n\\n(b) Along the straight line from $(0,1)$ to $(1,1), y=1, d y=0$ and the line integral equals\\n\\n$$\\n\\\\int_{x=0}^{1}\\\\left(x^{2}-1\\\\right) d x+(1+x)(0)=\\\\int_{0}^{1}\\\\left(x^{2}-1\\\\right) d x=-2 / 3\\n$$\\n\\nAlong the straight line from $(1,1)$ to $(1,2), x=1, d x=0$ and the line integral equals\\n\\n$$\\n\\\\int_{y=1}^{2}(1-y)(0)+\\\\left(y^{2}+1\\\\right) d y=\\\\int_{t}^{2}\\\\left(y^{2}+1\\\\right) d y=10 / 3\\n$$\\n\\nThen the required value $=-2 / 3+10 / 3=8.3$.\\n\\n(c) Since $t=0$ at $(0,1)$ and $t=1$ at $(1,2)$, the line integral equals\\n\\n$$\\n\\\\int_{t=0}^{1}\\\\left\\\\{t^{2}-\\\\left(t^{2}+1\\\\right) d t+\\\\left\\\\{\\\\left(t^{2}+1\\\\right)^{2}+t\\\\right\\\\} 2 t d t=\\\\int_{0}^{1}\\\\left(2 t^{5}+4 t^{2}+2 t^{2}+2 t-1\\\\right) d t=2\\\\right.\\n$$\\n',\n",
       " '\\n10.2. If $\\\\mathbf{A}=\\\\left(3 x^{2}-6 y z\\\\right) \\\\mathbf{i}+(2 y+3 x z) \\\\mathbf{j}+\\\\left(1-4 x y z^{2}\\\\right) \\\\mathbf{k}$, evaluate $\\\\int_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}$ from $(0,1,1)$ to $(1,1,1)$ along the following paths $C$ :\\n\\n(a) $x=t, y=t^{2}, z=t^{3}$\\n\\n(b) The straight lines from $(0,0,0)$ to $(0,0,1)$, then to $(0,1,1)$, and then to $(1,1,1)$\\n\\n(c) The straight line joining $(0,0,0)$ and $(1,1,1)$\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r} & \\\\left.=\\\\int_{C}\\\\left\\\\{\\\\left(3 x^{2}-6 y z\\\\right) \\\\mathbf{i}+(2 y+3 x z)\\\\right\\\\} \\\\mathbf{j}+\\\\left(1-4 x y z^{2}\\\\right) \\\\mathbf{k}\\\\right\\\\} \\\\cdot(d x \\\\mathbf{i}+d y \\\\mathbf{j}+d z \\\\mathbf{k}) \\\\\\\\\\n& =\\\\int_{C}\\\\left\\\\{\\\\left(3 x^{2}-6 y z\\\\right) d x+(2 y+3 x z) d y+\\\\left(1-4 x y z^{2}\\\\right) d z\\\\right.\\n\\\\end{aligned}\\n$$\\n\\n(a) If $x=t, y=t^{2}, z=t^{3}$, points $(0,0,0)$ and $(1,1,1)$ correspond to $t=0$ and $t=1$, respectively. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r} & =\\\\int_{t=0}^{1}\\\\left\\\\{3 t^{2}-6\\\\left(t^{2}\\\\right)\\\\left(t^{3}\\\\right)\\\\right\\\\} d t+\\\\left\\\\{2 t^{2}+3(t)\\\\left(t^{3}\\\\right)\\\\right\\\\} d\\\\left(t^{2}\\\\right)+\\\\left\\\\{1-4(t)\\\\left(t^{2}\\\\right)\\\\left(t^{3}\\\\right)^{2}\\\\right\\\\} d\\\\left(t^{3}\\\\right) \\\\\\\\\\n& \\\\left.=\\\\int_{t=0}^{1}\\\\left\\\\{3 t^{2}-6 t^{5}\\\\right\\\\} d t+\\\\left(4 t^{3}+6 t^{5}\\\\right)\\\\right\\\\} d t+\\\\left(3 t^{2}-12 t^{11}\\\\right) d t=2\\n\\\\end{aligned}\\n$$\\n\\nAnother method: Along $C, \\\\mathbf{A}=\\\\left(3 t^{2}-6 t^{5}\\\\right) \\\\mathbf{i}+\\\\left(2 t^{2}+3 t^{4}\\\\right) \\\\mathbf{j}+\\\\left(1-4 t^{9}\\\\right) \\\\mathbf{k}$ and $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}=t \\\\mathbf{i}+t^{2} \\\\mathbf{j}+t^{3} \\\\mathbf{k}$, $d \\\\mathbf{r}=\\\\left(\\\\mathbf{i}+2 t \\\\mathbf{j}+3 t^{2} \\\\mathbf{k}\\\\right) d t$. Then\\n\\n$$\\n\\\\int_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=\\\\int_{0}^{1}\\\\left(3 t^{2}-6 t^{5}\\\\right) d t+\\\\left(4 t^{3}+6 t^{5}\\\\right) d t+\\\\left(3 t^{2}-12 t^{11}\\\\right) d t=2\\n$$\\n\\n(b) Along the straight line from $(0,0,0)$ to $(0,1,1), x=0, y=0, d x=0, d y=0$, while $z$ varies from 0 to 1 . Then the integral over this part of the path is\\n\\n$$\\n\\\\int_{z=0}^{1}\\\\left\\\\{3(0)^{2}-6(0)(z)\\\\right\\\\} 0+\\\\left\\\\{2(0)+3(0)(z) 0+\\\\left\\\\{1-4(0)(0)\\\\left(z^{2}\\\\right)\\\\right\\\\} d z=\\\\int_{z=0}^{1} d z=1\\\\right.\\n$$\\n\\nAlong the straight line from $(0,0,1)$ to $(0,1,1), x=0, z=1, d x=0, d z=0$, while $y$ varies from 0 to 1 . Then the integral over this part of the path is\\n\\n$$\\n\\\\int_{y=0}^{1}\\\\left\\\\{3(0)^{2}-6(y)(1)\\\\right\\\\} 0+\\\\{2 y+3(0)(1)\\\\} d y+\\\\left\\\\{1-4(0)(y)(1)^{2}\\\\right\\\\} 0=\\\\int_{y=0}^{1} 2 y d y=1\\n$$\\n\\nAlong the straight line from $(0,1,1)$, to $(1,1,1), v=1, z=1, d y=0, d z=0$, while $x$ varies from 0 to 1 . Then the integral over this part of the path is\\n\\n$$\\n\\\\int_{x=0}^{1}\\\\left\\\\{3 x^{2}-6(1)(1)\\\\right\\\\} d x+\\\\{2(1)+3 x(1)\\\\} 0+\\\\left\\\\{1-4 x(1)(1)^{2}\\\\right\\\\} 0=\\\\int_{x=0}^{1}\\\\left(3 x^{2}-6\\\\right) d x=-5\\n$$\\n\\nAdding,\\n\\n$$\\n\\\\int_{C} \\\\mathbf{A} \\\\cdot d x=1+1-5=-3\\n$$\\n\\n(c) The straight line joining $(0,0,0)$ and $(1,1,1)$ is given in parametric form by $x=t, y=t, z=t$. Then\\n\\n$$\\n\\\\int_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=\\\\int_{t=0}^{1}\\\\left(3 t^{2}-6 t^{2}\\\\right) d t+\\\\left(2 t+3 t^{2}\\\\right) d t+\\\\left(1-4 t^{4}\\\\right) d t=6 / 5\\n$$\\n',\n",
       " '\\n10.3. Find the work done in moving a particle once around an ellipse $C$ in the $x y$ plane, if the ellipse has its center at the origin with semimajor and semiminor axes 4 and 3, respectively, as indicated in Figure 10.7, and if the force field is given by\\n\\n$$\\n\\\\mathbf{F}=(3 x-4 y+2 z) \\\\mathbf{i}+\\\\left(4 x+2 y-3 z^{2}\\\\right) \\\\mathbf{j}+\\\\left(2 x z-4 y^{2}+z^{3}\\\\right) \\\\mathbf{k}\\n$$\\n\\nIn the plane $z=0, \\\\mathbf{F}=(3 x-4 y) \\\\mathbf{i}+(4 x+2 y) \\\\mathbf{j}-4 y^{2} \\\\mathbf{k}$, and $d \\\\mathbf{r}=d x \\\\mathbf{i}+d y \\\\mathbf{j}$, so that the work done is\\n\\n$$\\n\\\\begin{aligned}\\n\\\\oint_{C} \\\\mathbf{F} \\\\cdot d \\\\mathbf{r} & =\\\\int_{C}\\\\left\\\\{(3 x-4 y) \\\\mathbf{i}+(4 x+2 y) \\\\mathbf{j}-4 y^{2} \\\\mathbf{k}\\\\right\\\\} \\\\cdot(d x \\\\mathbf{i}+d y \\\\mathbf{j}) \\\\\\\\\\n& =\\\\oint_{C}(3 x-4 y) d x+(4 x+2 y) d y\\n\\\\end{aligned}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-263}\\n\\\\end{center}\\n\\nFigure 10.7\\n\\nChoose the parametric equations of the ellipse as $x=4 \\\\cos t, y=3 \\\\sin t$, where $t$ varies from 0 to $2 \\\\pi$ (see Figure 10.7). Then the line integral equals\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\int_{t=0}^{2 \\\\pi}\\\\{3(4 \\\\cos t)-4(3 \\\\sin t)\\\\}\\\\{-4 \\\\sin t\\\\} d t+\\\\{4(4 \\\\cos t)+2(3 \\\\sin t)\\\\}\\\\{3 \\\\cos t\\\\} d t \\\\\\\\\\n& =\\\\int_{t=0}^{2 \\\\pi}(48-30 \\\\sin t \\\\cos t) d t=\\\\left.\\\\left(48 t-15 \\\\sin ^{2} t\\\\right)\\\\right|_{0} ^{2 \\\\pi}=96 \\\\pi\\n\\\\end{aligned}\\n$$\\n\\nIn traversing $C$ we have chosen the counterclockwise direction indicated in Figure 10.7. We call this the positive direction or say that $C$ has been traversed in the positive sense. If $C$ were traversed in the clockwise (negative) direction, the value of the integral would be $-96 \\\\pi$.\\n',\n",
       " \"\\n10.4. Evaluate $\\\\int_{C} y d s$ along the curve $C$ given by $y=2 \\\\sqrt{x}$ from $x=3$ to $x=24$.\\n\\nSince $d s=\\\\sqrt{d x^{2}+d y^{2}}=\\\\sqrt{1+\\\\left(y^{\\\\prime}\\\\right)^{2}} d x=\\\\sqrt{1+1 / x d x}$, we have\\n\\n$$\\n\\\\int_{C} y d s=\\\\int_{2}^{24} 2 \\\\sqrt{x} \\\\sqrt{1+1 / x} d x=2 \\\\int_{3}^{24} \\\\sqrt{x+1} d x=\\\\left.\\\\frac{4}{3}(x+1)^{3 / 2}\\\\right|_{3} ^{24}=156\\n$$\\n\\n\\n\\\\section*{Green's theorem in the plane}\\n\",\n",
       " \"10.5. Prove Green's theorem in the plane if $C$ is a closed curve which has the property that any straight line parallel to the coordinate axes cuts $C$ in, at most, two points.\\n\\nLet the equations of the curves $A E B$ and $A F B$ (see Figure 10.8) be $y=Y_{1}(x)$ and $y=Y_{2}(x)$, respectively. If $\\\\Re$ is the region bounded by $C$, we have\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{\\\\Re} \\\\frac{\\\\partial P}{\\\\partial y} d x d y & =\\\\int_{x=a}^{b}\\\\left[\\\\int_{y=Y_{1}(x)}^{Y_{2}(x)} \\\\frac{\\\\partial P}{\\\\partial y} d y\\\\right] d x \\\\\\\\\\n& =\\\\left.\\\\int_{x=a}^{b} P(x, y)\\\\right|_{y=Y_{1}(x)} ^{Y_{2}(x)} d x=\\\\int_{a}^{b}\\\\left[P\\\\left(x, Y_{2}\\\\right)-P\\\\left(x, Y_{1}\\\\right)\\\\right] d x \\\\\\\\\\n& =-\\\\int_{a}^{b} P\\\\left(x, Y_{1}\\\\right) d x-\\\\int_{b}^{a} P\\\\left(x, Y_{2}\\\\right) d x=-\\\\oint_{C} P d x\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n\\n\\\\begin{equation*}\\n\\\\oint_{C} P d x=-\\\\iint_{\\\\Re} \\\\frac{\\\\partial P}{\\\\partial y} d x d y \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-264}\\n\\\\end{center}\\n\\nFigure 10.8\\n\\nSimilarly, let the equations of curves $E A F$ and $E B F$ be $x=X_{1}(y)$ and $x=X_{2}(y)$, respectively. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{\\\\Re} \\\\frac{\\\\partial Q}{\\\\partial x} d x d y & =\\\\int_{y=c}^{f}\\\\left[\\\\int_{x=x_{1}(y)}^{x_{2}(y)} \\\\frac{\\\\partial Q}{\\\\partial x} d x\\\\right] d y=\\\\int_{c}^{f}\\\\left[Q\\\\left(X_{2}, y\\\\right)-Q\\\\left(X_{1}, y\\\\right)\\\\right] d y \\\\\\\\\\n& =\\\\int_{f}^{c} Q\\\\left(X_{1}, y\\\\right) d y+\\\\int_{c}^{f} Q\\\\left(X_{2}, y\\\\right) d y=\\\\oint_{C} Q d y\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n\\n\\\\begin{equation*}\\n\\\\oint_{C} Q d y=\\\\iint_{\\\\Re} \\\\frac{\\\\partial Q}{\\\\partial x} d x d y \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nAdding Equations (1) and (2),\\n\\n$$\\n\\\\oint_{C} P d x+Q d y=\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y\\n$$\\n\",\n",
       " \"\\n10.6. Verify Green's theorem in the plane for\\n\\n$$\\n\\\\oint_{C}\\\\left(2 x y-x^{2}\\\\right) d x+\\\\left(x+y^{2}\\\\right) d y\\n$$\\n\\nwhere $C$ is the closed curve of the region bounded by $y=x^{2}$ and $y^{2}=x$.\\n\\nThe plane curve $y=x^{2}$ and $y^{2}=x$ intersect at $(0,0)$ and $(1,1)$. The positive direction in traversing $C$ is as shown in Figure 10.9.\\n\\nAlong $y=x^{2}$, the line integral equals\\n\\n$$\\n\\\\int_{x=0}^{1}\\\\left\\\\{(2 x)\\\\left(x^{2}\\\\right)-x^{2}\\\\right\\\\} d x+\\\\left\\\\{x+\\\\left(x^{2}\\\\right)^{2}\\\\right\\\\} d\\\\left(x^{2}\\\\right)=\\\\int_{0}^{1}\\\\left(2 x^{3}+x^{2}+2 x^{5}\\\\right) d x=7 / 6\\n$$\\n\\nAlong $y^{2}=x$, the line integral equals\\n\\n$$\\n\\\\int_{y=1}^{0}\\\\left\\\\{(2)\\\\left(y^{2}\\\\right)(y)-\\\\left(y^{2}\\\\right)^{2}\\\\right\\\\} d\\\\left(y^{2}\\\\right)+\\\\left\\\\{y^{2}+y^{2}\\\\right\\\\} d y=\\\\int_{1}^{0}\\\\left(4 y^{4}-2 y^{5}+2 y^{2}\\\\right) d y=-17 / 15\\n$$\\n\\nThen the required line integral $=7 / 6-17 / 15=1 / 30$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y & =\\\\iint_{\\\\Re}\\\\left\\\\{\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x+y^{2}\\\\right)-\\\\frac{\\\\partial}{\\\\partial y}\\\\left(2 x y-x^{2}\\\\right)\\\\right\\\\} d x d y \\\\\\\\\\n& =\\\\iint_{\\\\Re}(1-2 x) d x d y=\\\\int_{x=0}^{1} \\\\int_{y=x^{2}}^{\\\\sqrt{x}}(1-2 x) d y d x \\\\\\\\\\n& =\\\\left.\\\\int_{x=0}^{1}(y-2 x y)\\\\right|_{y=x^{2}} ^{\\\\sqrt{x}} d x \\\\\\\\\\n& =\\\\int_{0}^{1}\\\\left(x^{1 / 2}-2 x^{3 / 2}-x^{2}+2 x^{3}\\\\right) d x=1 / 30\\n\\\\end{aligned}\\n$$\\n\\nHence, Green's theorem is verified.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-265}\\n\\\\end{center}\\n\\nFigure 10.9\\n\",\n",
       " \"\\n10.7. Extend the proof of Green's theorem in the plane given in Problem 10.5 to the curves $C$ for which lines parallel to the coordinate axes may cut $C$ in more than two points.\\n\\nConsider a closed curve $C$ such as is shown in Figure 10.10, in which lines parallel to the axes may meet $C$ in more than two points. By constructing line $S T$, the region is divided into two regions $\\\\Re_{1}$ and $\\\\Re_{2}$, which are of the type considered in Problem 10.5 and for which Green's theorem applies, i.e.,\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{S T U S} P d x+Q d y=\\\\iint_{\\\\Re_{1}}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{S V T S} P d x+Q d y=\\\\iint_{\\\\Re_{1}}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-266}\\n\\\\end{center}\\n\\nFigure 10.10\\n\\nAdding the left-hand sides of Equations (1) and (2), and omitting the integrand $P d x+Q d y$ in each case, we have\\n\\n$$\\n\\\\int_{S T U S}+\\\\int_{S V T S}=\\\\int_{S T}+\\\\int_{T U S}+\\\\int_{S V T}+\\\\int_{T S}=\\\\int_{T U S}+\\\\int_{S V T}=\\\\int_{T U S V T}\\n$$\\n\\nusing the fact that $\\\\int_{S T}=-\\\\int_{T S}$. Adding the right-hand sides of Equations (1) and (2), omitting the integrand, $\\\\iint_{\\\\Re_{1}}+\\\\iint_{\\\\Re_{2}}=\\\\iint_{\\\\Re}$, where $\\\\Re$ con-\\\\\\\\\\nsists of regions $\\\\Re_{1}$ and $\\\\Re_{2}$.\\n\\nThen $\\\\int_{T U S V T} P d x+Q d y=\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y$, and the theorem is proved.\\n\\nA region $\\\\Re$ such as is considered here and in Problem 10.5, for which any closed lying in $\\\\Re$ can be continuously shrunk to a point without leaving $\\\\Re$, is called a simply connected region. A region which is not simply connected is called multiply connected. We have shown here that Green's theorem in the plane applies to simply connected regions bounded by closed curves. In Problem 10.10 the theorem is extended to multiply connected regions.\\n\\nFor more complicated simply connected regions, it may be necessary to construct more lines, such as $S T$, to establish the theorem.\\n\",\n",
       " \"\\n10.8. Show that the area bounded by a simple closed curve $C$ is given by $\\\\frac{1}{2} \\\\oint_{C} x d y-y d x$.\\n\\nIn Green's theorem, put $P=-y, Q=x$. Then\\n\\n$$\\n\\\\oint_{C} x d y-y d x=\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial}{\\\\partial x}(x)-\\\\frac{\\\\partial}{\\\\partial y}(-y)\\\\right) d x d y=2 \\\\iint_{\\\\Re} d x d y=2 A\\n$$\\n\\nwhere $A$ is the required area. Thus, $A=\\\\frac{1}{2} \\\\oint_{C} x d y-y d x$.\\n\",\n",
       " '\\n10.9. Find the area of the ellipse $x=a \\\\cos \\\\theta, y=b \\\\sin \\\\theta$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\text { Area } & =\\\\frac{1}{2} \\\\oint_{C} x d y-y d x=\\\\frac{1}{2} \\\\int_{0}^{2 \\\\pi}(a \\\\cos \\\\theta)(b \\\\cos \\\\theta) d \\\\theta-(b \\\\sin \\\\theta)(-a \\\\sin \\\\theta) d \\\\theta \\\\\\\\\\n& =\\\\frac{1}{2} \\\\int_{0}^{2 \\\\pi} a b\\\\left(\\\\cos ^{2} \\\\theta+\\\\sin ^{2} \\\\theta\\\\right) d \\\\theta=\\\\frac{1}{2} \\\\int_{0}^{2 \\\\pi} a b d \\\\theta=\\\\pi a b\\n\\\\end{aligned}\\n$$\\n',\n",
       " \"\\n10.10. Show that Green's theorem in the plane is also valid for a multiply connected region $\\\\Re$ such as is shown in Figure 10.11.\\n\\nThe shaded region $\\\\Re$, shown in Figure 10.11, is multiply connected, since not every closed curve lying in $\\\\Re$ can be shrunk to a point without leaving $\\\\Re$, as is observed by considering a curve surrounding $D E F G D$, for example. The boundary of $\\\\Re$, which consists of the exterior boundary AHJKLA and the interior boundary $D E F G D$, is to be traversed in the positive direction, so that a person traveling in this direction always has the region on his left. It is seen that the positive directions are those indicated Figure 10.11.\\n\\nIn order to establish the theorem, construct a line such as $A D$, called a crosscut, connecting the exterior and interior boundaries. The region bounded by ADEFGDALKJHA is simply connected, and so Green's theorem is valid. Then\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-267}\\n\\\\end{center}\\n\\nFigure 10.11\\n\\n$$\\n\\\\oint_{A D E F G D A L K J H A} P d x+Q d y=\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y\\n$$\\n\\nBut the integral on the left, leaving out the integrand, is equal to\\n\\n$$\\n\\\\int_{A D}+\\\\int_{D E F G D}+\\\\int_{D A}+\\\\int_{A L K J H A}=\\\\int_{D E F G D}+\\\\int_{A L K J H A}\\n$$\\n\\nsince $\\\\int_{A D}=-\\\\int_{D A}$. Thus, if $C_{1}$ is the curve ALKJHA, $C_{2}$ is the curve DEFGD, and $C$ is the boundary of $\\\\Re$ consisting of $C_{1}$ and $C_{2}$ (traversed in the positive directions), then $\\\\int_{C_{1}}+\\\\int_{C_{2}}=\\\\int_{C}$ and so\\n\\n$$\\n\\\\oint_{C} P d x+Q d y=\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y\\n$$\\n\\n\\n\\\\section*{Independence of the path}\\n\",\n",
       " \"10.11. Let $P(x, y)$ and $Q(x, y)$ be continuous and have continuous first partial derivatives at each point of a simply connected region $\\\\Re$. Prove that a necessary and sufficient condition that $\\\\oint_{C} P d x+Q d y=0$ around every closed path $C$ in $\\\\Re$ is that $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$ identically in $\\\\Re$.\\n\\nSufficiency. Suppose $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$. Then, by Green's theorem,\\n\\n$$\\n\\\\oint_{C} P d x+Q d y=\\\\iint_{\\\\Re}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y=0\\n$$\\n\\nwhere $\\\\Re$ is the region bounded by $C$.\\n\\nNecessity. Suppose $\\\\oint_{C} P d x+Q d y=0$ around every closed path $C$ in $\\\\Re$ and that $\\\\partial P / \\\\partial y \\\\neq \\\\partial Q / \\\\partial x$ at some point of $\\\\Re$. In particular, suppose $\\\\partial P / \\\\partial y-\\\\partial Q / \\\\partial x>0$ at the point $\\\\left(x_{0}, y_{0}\\\\right)$.\\n\\nBy hypothesis, $\\\\partial P / \\\\partial y$ and $\\\\partial Q$ are continuous in $\\\\Re$, so that there must be some region $\\\\tau$ containing $\\\\left(x_{0}, y_{0}\\\\right)$ as an interior point for which $\\\\partial P / \\\\partial y-\\\\partial Q / \\\\partial x>0$. If $\\\\Gamma$ is the boundary of $\\\\tau$, then by Green's theorem,\\n\\n$$\\n\\\\oint_{C} P d x+Q d y=\\\\iint_{\\\\tau}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y>0\\n$$\\n\\ncontradicting the hypothesis that $\\\\oint_{\\\\Gamma} P d x+Q d y=\\\\iint_{\\\\tau}\\\\left(\\\\frac{\\\\partial Q}{\\\\partial x}-\\\\frac{\\\\partial P}{\\\\partial y}\\\\right) d x d y>0$ for all closed curves in in $\\\\Re$. Thus, $\\\\partial Q / \\\\partial x-\\\\partial P / \\\\partial y$ cannot be positive.\\n\\nSimilarly, we can show that $\\\\partial Q / \\\\partial x-\\\\partial P / \\\\partial y$ cannot be negative, and it follows that it must be identically zero; i.e., $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$ identically in $\\\\Re$.\\n\",\n",
       " '\\n10.12 Let $P$ and $Q$ be defined as in Problem 10.11. Prove that a necessary and sufficient condition that $\\\\int_{A}^{B} P d x+Q d y$ be independent of the path in $\\\\Re$ joining points $A$ and $B$ is that $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$ identically in $\\\\Re$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-268}\\n\\\\end{center}\\n\\nFigure 10.12\\n\\nSufficiency. If $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$, then by Problem 10.11,\\n\\n$$\\n\\\\int_{A D B E A} P d x+Q d y=0\\n$$\\n\\n(See Figure 10.12.) From this, omitting for brevity the integrand $P d x+Q d y$, we have\\n\\n$$\\n\\\\int_{A D B}+\\\\int_{B E A}=0, \\\\quad \\\\int_{A D B}=-\\\\int_{B E A}=\\\\int_{A E B} \\\\text { and so } \\\\int_{C_{1}}=\\\\int_{C_{2}}\\n$$\\n\\ni.e., the integral is independent of the path.\\n\\nNecessity. If the integral is independent of the path, then for all paths $C_{1}$ and $C_{2}$ in $\\\\Re$ we have\\n\\n$$\\n\\\\int_{C_{1}}=\\\\int_{C_{2}}, \\\\quad \\\\int_{A D B}=\\\\int_{A E B} \\\\text { and } \\\\int_{\\\\text {ADBEA }}=0\\n$$\\n\\nFrom this it follows that the line integral around any closed path in $\\\\Re$ is zero, and, hence, by Problem 10.11 that $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$.\\n',\n",
       " '\\n10.13. Let $P$ and $Q$ be as in Problem 10.11. (a) Prove that a necessary and sufficient condition that $P d x+Q d y$ be an exact differential of a function $\\\\varphi(x, y)$ is that $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$. (b) Show that in such case\\n\\n$\\\\int_{A}^{B} P d x+Q d y=\\\\int_{A}^{B} d \\\\phi=\\\\phi(B)-\\\\phi(A)$ where $\\\\mathrm{A}$ and $\\\\mathrm{B}$ are any two points.\\n\\n(a) Necessity. If $P d x+Q d y=d \\\\phi=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} d x+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} d y$, an exact differential, then\\n\\n\\n\\\\begin{align*}\\n& \\\\partial \\\\phi / \\\\partial x=P  \\\\tag{1}\\\\\\\\\\n& \\\\partial \\\\phi / \\\\partial y=0 \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nThus, by differentiating Equations (1) and (2) with respect to $y$ and $x$, respectively, $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$, since we are assuming continuity of the partial derivatives.\\n\\nSufficiency. By Problem 10.12, if $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$, then $\\\\int P d x+Q d y$ is independent of the path joining two points. In particular, let the two points be $(a, b)$ and $(x, y)$ and define\\n\\n$$\\n\\\\phi(x, y)=\\\\int_{(a, b)}^{(x, y)} P d x+Q d y\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n\\\\phi(x+\\\\Delta x, y)-\\\\phi(x, y) & =\\\\int_{(a, b)}^{(x+\\\\Delta x, y)} P d x+Q d y-\\\\int_{(a, b)}^{(x, y)} P d x+Q d y \\\\\\\\\\n& =\\\\int_{(x, y)}^{(x+\\\\Delta x, y)} P d x+Q d y\\n\\\\end{aligned}\\n$$\\n\\nSince the last integral is independent of the path joining $(x, y)$ and $(x+\\\\Delta x, y)$, we can choose the path to be a straight line joining these points (see Figure 10.13) so that $d y=0$. Then, by the mean value theorem for integrals,\\n\\n$$\\n\\\\frac{\\\\phi(x+\\\\Delta x, y)-\\\\phi(x, y)}{\\\\Delta x}=\\\\frac{1}{\\\\Delta x} \\\\int_{(x, y)}^{(x+\\\\Delta x, y)} P d x=P(x+\\\\theta \\\\Delta x, y) \\\\quad 0<\\\\theta<1\\n$$\\n\\nTaking the limit as $\\\\Delta x \\\\rightarrow 0$, we have $\\\\partial \\\\phi / \\\\partial x=P$.\\n\\nSimilarly, we can show that $\\\\partial \\\\phi / \\\\partial y=Q$.\\n\\nThus, it follows that $P d x+Q d y=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} d x+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} d y=d \\\\phi$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-269}\\n\\\\end{center}\\n\\nFigure 10.13\\n\\n(b) Let $A=\\\\left(x_{1}, y_{1}\\\\right)$ and $B=\\\\left(x_{2}, y_{2}\\\\right)$. From (a),\\n\\n$$\\n\\\\phi(x, y)=\\\\int_{(a, b)}^{(x, y)} P d x+Q d y\\n$$\\n\\nThen, omitting the integrand $P d x+Q d y$, we have\\n\\n$$\\n\\\\int_{A}^{B}=\\\\int_{\\\\left(x_{1}, y_{1}\\\\right)}^{\\\\left(x_{2}, y_{2}\\\\right)}=\\\\int_{(a, b)}^{\\\\left(x_{2}, y_{2}\\\\right)}-\\\\int_{(a, b)}^{\\\\left(x_{1}, y_{1}\\\\right)}=\\\\phi\\\\left(x_{2}, y_{2}\\\\right)-\\\\phi\\\\left(x_{1}, y_{1}\\\\right)=\\\\phi(B)-\\\\phi(A)\\n$$\\n',\n",
       " '\\n10.14. (a) Prove that $\\\\int_{(1,2)}^{(3,4)}\\\\left(6 x y^{2}-y^{3}\\\\right) d x+\\\\left(6 x^{2} y-3 x y^{2}\\\\right) d y d y$ is independent of the path joining $(1,2)$ and $(3,4)$. (b) Evaluate the integral in (a).\\n\\n(a) $P=6 x y 2-y 3, Q=6 x 2 y-3 x y 2$. Then $\\\\partial P / \\\\partial y=12 x y-3 y 2=\\\\partial Q / \\\\partial x$ and, by Problem 10.12, the line integral is independent of the path.\\n\\n(b) Method 1: Since the line integral is independent of the path, choose any path joining $(1,2)$ and $(3,4)$, for example, that consisting of lines from $(1,2)$ to $(3,2)$ (along which $y=2, d y=0$ ) and then $(3,2)$ to $(3,4)$ (along which $x=3, d x=0$ ). Then the required integral equals\\n\\n$$\\n\\\\int_{x=1}^{3}(24 x-8) d x+\\\\int_{y=2}^{4}\\\\left(54 y-9 y^{2}\\\\right) d y=80+156=236\\n$$\\n\\nMethod 2: Since $\\\\frac{\\\\partial P}{\\\\partial y}=\\\\frac{\\\\partial Q}{\\\\partial x}$, we must have\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial y}=6 x^{2} y-3 x y^{2}  \\\\tag{1}\\\\\\\\\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial y}=6 x^{2} y-3 x y^{2} \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nFrom Equation (1), $\\\\phi=3 x^{2} y^{2}-x y^{3}+f(y)$. From Equation (2), $\\\\phi=3 x^{2} y^{2}-x y^{3}+g(x)$. The only way in which these two expressions for $\\\\phi$ are equal is if $f(y)=g(x)=c$, a constant. Hence, $\\\\phi=3 x^{2} y^{2}-x y^{3}+c$. Then, by Problem 10.13.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{(1.2)}^{(3.4)}\\\\left(6 x y^{2}-y^{3}\\\\right) d x+\\\\left(6 x^{2} y-3 x y^{2}\\\\right) d y & =\\\\int_{(1.2)}^{(3.4)} d\\\\left(3 x^{2} y^{2}-x y^{3}+c\\\\right) \\\\\\\\\\n& =3 x^{2} y^{2}-x y^{3}+\\\\left.c\\\\right|_{(1,2)} ^{(3,4)}=236\\n\\\\end{aligned}\\n$$\\n\\nNote that in this evaluation the arbitrary constant $c$ can be omitted. See also Problem 6.16.\\n\\nWe could also have noted by inspection that\\n\\n$$\\n\\\\begin{aligned}\\n\\\\left(6 x y^{2}-y^{3}\\\\right) d x+\\\\left(6 x^{2} y-3 x y^{2}\\\\right) d y & =\\\\left(6 x y^{2} d x+6 x^{2} y d y\\\\right)-\\\\left(y^{3} d x+3 x y^{2} d y\\\\right) \\\\\\\\\\n& =d\\\\left(3 x^{2} y^{2}\\\\right)-d\\\\left(x y^{3}\\\\right)=d\\\\left(3 x^{2} y^{2}-x y^{3}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nfrom which it is clear that $\\\\phi=3 x^{2} y^{2}-x y^{3}+c$.\\n',\n",
       " '\\n10.15. Evaluate $\\\\oint\\\\left(x^{2} y \\\\cos x+2 x y \\\\sin x-y^{2} e^{x}\\\\right) d x+\\\\left(x^{2} \\\\sin x-2 y e^{x}\\\\right) d y$ around the hypocycloid $x^{2 / 3}+$\\\\\\\\\\n$y^{2 / 3}=a^{2 / 3}$.\\n\\n$$\\nP=x^{2} y \\\\cos x+2 x y \\\\sin x-y^{2} e^{x}, Q=x^{2} \\\\sin x-2 y e^{x}\\n$$\\n\\nThen $\\\\partial P / \\\\partial y=x^{2} \\\\cos x+2 x \\\\sin x-2 y e^{x}=\\\\partial Q / \\\\partial x$, so that, by Problem 10.11, the line integral around any closed path—in particular, $x^{2 / 3}+y^{2 / 3}=a^{2 / 3}$-is zero.\\n\\n\\n\\\\section*{Surface integrals}\\n',\n",
       " '10.16. If $\\\\gamma$ is the angle between the normal line to any point $(x, y, z)$ of a surface $S$ and the positive $z$ axis, prove that\\n\\n$$\\n|\\\\sec \\\\gamma|=\\\\sqrt{1+z_{x}^{2}+z_{y}^{2}}=\\\\frac{\\\\sqrt{F_{x}^{2}+F_{y}^{2}+F_{z}^{2}}}{\\\\left|F_{z}\\\\right|}\\n$$\\n\\naccording as the equation for $S$ is $z=f(x, y)$ or $F(x, y, z)=0$.\\n\\nIf the equation for $S$ is $F(x, y, z)=0$, a normal to $S$ at $(x, y, z)$ is $\\\\nabla F=F_{x} \\\\mathbf{i}+F_{y} \\\\mathbf{j}+F_{z} \\\\mathbf{k}$. Then\\n\\n$$\\n\\\\nabla F \\\\cdot \\\\mathrm{K}=|\\\\nabla F||\\\\mathrm{k}| \\\\cos \\\\gamma \\\\quad \\\\text { or } \\\\quad F_{z}=\\\\sqrt{F_{x}^{2}+F_{y}^{2}+F_{z}^{2}} \\\\cos \\\\gamma\\n$$\\n\\nfrom which $|\\\\sec \\\\gamma|=\\\\frac{\\\\sqrt{F_{x}^{2}+F_{y}^{2}+F_{z}^{2}}}{\\\\left|F_{z}\\\\right|}$ as required. as required.\\n\\nIn case the equation is $z=f(x, y)$, we can write $F(x, y)=0$, from which $F_{x}=-z_{x}, F_{y}-z_{y}, F_{z}=1$ and we find $|\\\\sec \\\\gamma|=\\\\sqrt{1+z_{x}^{2}+z_{y}^{2}}$.\\n',\n",
       " '\\n10.17. Evaluate $\\\\iint_{S} U(x, y, z) d S$, where $S$ is the surface of the paraboloid $z=2-\\\\left(x^{2}+y^{2}\\\\right)$ above the $x y$ plane and $U(x, y, z)$ is equal to (a) 1 , (b) $x^{2}+y^{2}, y^{2}$, and (c) $3 z$. Give a physical interpretation in each case. (See Figure 10.14.)\\n\\nThe required integral is equal to\\n\\n\\n\\\\begin{equation*}\\n\\\\iint_{\\\\Re} U(x, y, z) \\\\sqrt{1+z_{x}^{2}+z_{y}^{2}} d x d y . \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere $\\\\mathfrak{R}$ is the projection of $S$ on the $x y$ plane given by $x^{2}+y^{2}=2, z=0$.\\n\\nSince $z_{x}=-2 x, z_{y}=-2 y,(1)$ can be written\\n\\n$\\\\iint_{\\\\Re} U(x, y, z) \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y$\\n\\n(a) If $\\\\mathrm{U}(\\\\mathrm{x}, \\\\mathrm{y}, \\\\mathrm{z})=1$, (2) becomes\\n\\n$$\\n\\\\iint_{\\\\Re} \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-270}\\n\\\\end{center}\\n\\nFigure 10.14\\n\\nTo evaluate this, transform to polar coordinates $(\\\\rho, \\\\phi)$. Then the integral becomes\\n\\n$$\\n\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\int_{\\\\rho=0}^{\\\\sqrt{2}} \\\\sqrt{1+4 \\\\rho^{2}} \\\\rho d \\\\rho d \\\\phi=\\\\left.\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\frac{1}{12}\\\\left(1+4 \\\\rho^{2}\\\\right)^{3 / 2}\\\\right|_{\\\\rho=0} ^{\\\\sqrt{2}} d \\\\phi=\\\\frac{13 \\\\pi}{3}\\n$$\\n\\nPhysically, this could represent the surface area of $S$ or the mass of $S$ assuming unit density.\\n\\n(b) If $\\\\mathrm{U}(\\\\mathrm{x}, \\\\mathrm{y}, \\\\mathrm{z})=\\\\mathrm{x} 2+\\\\mathrm{y} 2$, (2) becomes $\\\\iint_{\\\\Re}\\\\left(x^{2}+y^{2}\\\\right) \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y$ or, in polar coordinates,\\n\\n$$\\n\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\int_{\\\\rho=0}^{\\\\sqrt{2}} \\\\rho^{3} \\\\sqrt{1+4 \\\\rho^{2}} d \\\\rho d \\\\phi=\\\\frac{149 \\\\pi}{30}\\n$$\\n\\nwhere the integration with respect to $\\\\rho$ is accomplished by the substitution $\\\\sqrt{1+4 \\\\rho^{2}}=u$.\\n\\nPhysically, this could represent the moment of inertia of $S$ about the $z$ axis assuming unit density, or the mass of $S$ assuming a density $=x^{2}+y^{2}$.\\n\\n(c) If $\\\\mathrm{U}(\\\\mathrm{x}, \\\\mathrm{y}, \\\\mathrm{z})=3 \\\\mathrm{z}$, (2) becomes\\n\\n$$\\n\\\\iint_{\\\\Re} 3 z \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y=\\\\iint_{\\\\Re} 3\\\\left\\\\{2-\\\\left(x^{2}+y^{2}\\\\right)\\\\right\\\\} \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y\\n$$\\n\\nor, in polar coordinates,\\n\\n$$\\n\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\int_{\\\\rho=0}^{\\\\sqrt{2}} 3 \\\\rho\\\\left(2-\\\\rho^{2}\\\\right) \\\\sqrt{1+4 \\\\rho^{2}} d \\\\rho d \\\\phi=\\\\frac{111 \\\\pi}{10}\\n$$\\n\\nPhysically, this could represent the mass of $S$ assuming a density $=3 z$, or three times the first moment of $S$ about the $x y$ plane.\\n',\n",
       " '\\n10.18. Find the surface area of a hemisphere of radius $a$ cut off by a cylinder having this radius as diameter.\\n\\nEquations for the hemisphere and cylinder (see Figure 10.15) are given, respectively, by $x^{2}+y^{2}+z^{2}=a^{2}$ (or $z \\\\sqrt{a^{2}-x^{2}-y^{2}}$ ) and $(x-a / 2)^{2}+y^{2}=a^{2} / 4\\\\left(\\\\right.$ or $\\\\left.x^{2}+y^{2}=a x\\\\right)$.\\n\\nSince\\n\\n$$\\nz_{x}=\\\\frac{-x}{\\\\sqrt{a^{2}-x^{2}-y^{2}}} \\\\quad \\\\text { and } \\\\quad z_{y}=\\\\frac{-y}{\\\\sqrt{a^{2}-x^{2}-y^{2}}}\\n$$\\n\\nwe have\\n\\n$$\\n\\\\text { Required surface area }=2 \\\\iint_{\\\\Re} \\\\sqrt{1+z_{x}^{2}+z_{y}^{2}} d x d y=2 \\\\iint_{\\\\Re} \\\\frac{a}{\\\\sqrt{a^{2}-x^{2}-y^{2}}} d x d y\\n$$\\n\\nTwo methods of evaluation are possible.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-271}\\n\\\\end{center}\\n\\nFigure 10.15\\n\\nMethod 1: Using polar coordinates.\\n\\nSince $x^{2}+y^{2}=a x$ in polar coordinates is $\\\\rho=a \\\\cos \\\\phi$, the integral becomes\\n\\n$$\\n\\\\begin{aligned}\\n2 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{a \\\\cos \\\\phi} \\\\frac{a}{\\\\sqrt{a^{2}-\\\\rho^{2}}} \\\\rho d \\\\rho d \\\\phi & =2 a \\\\int_{\\\\phi=0}^{\\\\pi / 2}-\\\\left.\\\\sqrt{a^{2}-\\\\rho^{2}}\\\\right|_{\\\\rho=0} ^{a \\\\cos \\\\phi} d \\\\phi \\\\\\\\\\n& =2 a^{2} \\\\int_{0}^{\\\\pi / 2}(1-\\\\sin \\\\phi) d \\\\phi=(\\\\pi-2) a^{2}\\n\\\\end{aligned}\\n$$\\n\\nMethod 2: The integral is equal to\\n\\n$$\\n\\\\begin{aligned}\\n2 \\\\int_{x=0}^{a} \\\\int_{y=0}^{\\\\sqrt{a x-x^{2}}} \\\\frac{a}{\\\\sqrt{a^{2}-x^{2}-y^{2}}} d x d y & =\\\\left.2 a \\\\int_{x=0}^{a} \\\\sin ^{-1} \\\\frac{y}{\\\\sqrt{a x-x^{2}}}\\\\right|_{y=0} ^{\\\\sqrt{a x-x^{2}}} d x \\\\\\\\\\n& =2 a \\\\int_{0}^{a} \\\\sin ^{-1} \\\\sqrt{\\\\frac{x}{a+x}} d x\\n\\\\end{aligned}\\n$$\\n\\nLetting $x=a \\\\tan ^{2} \\\\theta$, this integral becomes\\n\\n$$\\n\\\\begin{aligned}\\n4 a^{2} \\\\int_{0}^{\\\\pi / 4} \\\\theta \\\\tan \\\\theta \\\\sec ^{2} \\\\theta d \\\\theta & =4 a^{2}\\\\left\\\\{\\\\left.\\\\frac{1}{2} \\\\theta \\\\tan ^{2} \\\\theta\\\\right|_{0} ^{\\\\pi / 4}-\\\\frac{1}{2} \\\\int_{0}^{\\\\pi / 4} \\\\tan ^{2} \\\\theta d \\\\theta\\\\right\\\\} \\\\\\\\\\n& =2 a^{2}\\\\left\\\\{\\\\left.\\\\theta \\\\tan ^{2} \\\\theta\\\\right|_{0} ^{\\\\pi / 4}-\\\\int_{0}^{\\\\pi / 4}\\\\left(\\\\sec ^{2} \\\\theta-1\\\\right) d \\\\theta\\\\right\\\\} \\\\\\\\\\n& =2 a^{2}\\\\left\\\\{\\\\pi / 4-\\\\left.(\\\\tan \\\\theta-\\\\theta)\\\\right|_{0} ^{\\\\pi / 4}\\\\right\\\\}=(\\\\pi-2) a^{2}\\n\\\\end{aligned}\\n$$\\n\\nNote that these integrals are actually improper and should be treated by appropriate limiting procedures (see Problem 5.74 and Chapter 12).\\n',\n",
       " '\\n10.19. Find the centroid of the surface in Problem 10.17.\\n\\n$$\\n\\\\text { By symmetry, } \\\\bar{x}=\\\\bar{y}=0 \\\\quad \\\\text { and } \\\\quad \\\\overline{\\\\mathrm{z}}=\\\\frac{\\\\iint_{S} z d S}{\\\\iint_{S} z d S}=\\\\frac{\\\\iint_{\\\\Re} z \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y}{\\\\iint_{\\\\Re} \\\\sqrt{1+4 x^{2}+4 y^{2}} d x d y}\\n$$\\n\\nThe numerator and denominator can be obtained from the results of Problems 10.17(c) and 10.17(a), respectively, and we thus have $\\\\bar{z}=\\\\frac{37 \\\\pi / 10}{13 \\\\pi / 3}=\\\\frac{111}{130}$.\\n',\n",
       " '\\n10.20. Evalute $\\\\iint_{S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S$, where $\\\\mathbf{A}=x y \\\\mathbf{i}-x^{2} \\\\mathbf{j}+(x+z) \\\\mathbf{k}, S$ is that portion of the plane $2 x+2 y+z=6$ included in the first octant, and $\\\\mathbf{n}$ is a unit normal to $S$. (See Figure 10.16.)\\n\\nA normal to $S$ is $\\\\nabla(2 x+2 y+z-6)=2 \\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k}$, and so\\n\\n$$\\n\\\\mathbf{n}=\\\\frac{2 \\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k}}{\\\\sqrt{2^{2}+2^{2}+1^{2}}}=\\\\frac{2 \\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k}}{3}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{A} \\\\cdot \\\\mathbf{n} & =\\\\left\\\\{x y \\\\mathbf{i}-x^{2} \\\\mathbf{j}+(x+z) \\\\mathbf{k}\\\\right\\\\} \\\\cdot\\\\left(\\\\frac{2 \\\\mathbf{i}+2 \\\\mathbf{j}+\\\\mathbf{k}}{3}\\\\right) \\\\\\\\\\n& =\\\\frac{2 x y-2 x^{2}+(x+z)}{3} \\\\\\\\\\n& =\\\\frac{2 x y-2 x^{2}+(x+6-2 x-2 y)}{3} \\\\\\\\\\n& =\\\\frac{2 x y-2 x^{2}-x-2 y+6}{3}\\n\\\\end{aligned}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-272}\\n\\\\end{center}\\n\\nFigure 10.16\\n\\nThe required surface integral is, therefore,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{S}\\\\left(\\\\frac{2 x y-2 x^{2}-x-2 y+6}{3}\\\\right) d S & =\\\\iint_{\\\\Re}\\\\left(\\\\frac{2 x y-2 x^{2}-x-2 y+6}{3}\\\\right) \\\\sqrt{1+z_{x}^{2}+z_{y}^{2}} d x d y \\\\\\\\\\n& =\\\\iint_{\\\\Re}\\\\left(\\\\frac{2 x y-2 x^{2}-x-2 y+6}{3}\\\\right) \\\\sqrt{1^{2}+2^{2}+2^{2}} d x d y \\\\\\\\\\n& =\\\\int_{x=0}^{3} \\\\int_{y=0}^{3-x}\\\\left(2 x y-2 x^{2}-x-2 y+6\\\\right) d y d x \\\\\\\\\\n& =\\\\left.\\\\int_{x=0}^{3}\\\\left(x y^{2}-2 x^{2} y-x y-y^{2}+6 y\\\\right)\\\\right|_{0} ^{3-x} d x=27 / 4\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n10.21. In dealing with surface integrals we have restricted ourselves to surface which are two-sided. Give an example of a surface which is not two-sided.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-273}\\n\\\\end{center}\\n\\nFigure 10.17\\n\\nTake a strip of paper such as $A B C D$, as shown in Figure 10.17. Twist the strip so that points $A$ and $B$ fall on $D$ and $C$, respectively, as in the figure. If $\\\\mathbf{n}$ is the positive normal at point $P$ of the surface, we find that as n moves around the surface, it reverses its original direction when it reaches $P$ again. If we tried to color only one side of the surface, we would find the whole thing colored. This surface, called a Möbius strip, is an example of a one-sided surface. This is sometimes called a nonorientable surface. A two-sided surface is orientable.\\n\\n\\n\\\\section*{The divergence theorem}\\n',\n",
       " \"10.22. Prove the divergence theorem. (See Figure 10.18.)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-273(1)}\\n\\\\end{center}\\n\\nFigure 10.18\\n\\nLet $S$ be a closed surface which is such that any line parallel to the coordinate axes cuts $S$ in, at most, two points. Assume the equations of the lower and upper portions $S_{1}$ and $S_{2}$ to be $z=f_{1}(x, y)$ and $z=f_{2}(x, y)$ respectively. Denote the projection of the surface on the $x y$ plane by $\\\\Re$. Consider\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iiint_{V} \\\\frac{\\\\partial A_{3}}{\\\\partial z} d V & =\\\\iiint_{V} \\\\frac{\\\\partial A_{3}}{\\\\partial z} d z d y d x=\\\\iint_{\\\\Re}\\\\left[\\\\int_{z=f_{1}(x, y)}^{f_{2}(x, y)} \\\\frac{\\\\partial A_{3}}{\\\\partial z} d z\\\\right] d y d x \\\\\\\\\\n& =\\\\left.\\\\iint_{\\\\Re} A_{3}(x, y, z)\\\\right|_{z=f_{1}} ^{f_{2}} d y d x=\\\\iint_{\\\\Re}\\\\left[A_{3}\\\\left(x, y, f_{2}\\\\right)-A_{3}\\\\left(x, y, f_{1}\\\\right)\\\\right] d y d x\\n\\\\end{aligned}\\n$$\\n\\nwith $\\\\mathbf{k}$.\\n\\nFor the upper portion $S_{2}, d y d x=\\\\cos \\\\gamma_{2} d S_{2}=\\\\mathbf{k} \\\\cdot \\\\mathbf{n}_{2} d S_{2}$ since the normal $\\\\mathbf{n}_{2}$ to $S_{2}$ makes an acute angle $\\\\gamma_{2}$\\n\\nFor the lower portion $S_{1}, d y d x=-\\\\cos \\\\gamma_{1} d S_{1}=-\\\\mathbf{k} \\\\cdot \\\\mathbf{n}_{1} d S_{1}$ since the normal $\\\\mathbf{n}_{1}$ to $S_{1}$ makes an obtuse angle $\\\\gamma_{1}$ with $\\\\mathbf{k}$.\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\iint_{\\\\Re} A_{3}\\\\left(x, y, f_{2}\\\\right) d y d x=\\\\iint_{S_{2}} A_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{n}_{2} d S_{2} \\\\\\\\\\n& \\\\iint_{\\\\Re} A_{3}\\\\left(x, y, f_{1}\\\\right) d y d x=-\\\\iint_{S_{1}} A_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{n}_{1} d S_{1}\\n\\\\end{aligned}\\n$$\\n\\nand\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{\\\\Re} A_{3}\\\\left(x, y, f_{2}\\\\right) d y d x-\\\\iint_{\\\\Re} A_{3}\\\\left(x, y, f_{1}\\\\right) d y d x & =\\\\iint_{S_{2}} A_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{n}_{2} d S_{2}+\\\\iint_{S_{1}} A_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{n}_{1} d S_{1} \\\\\\\\\\n& =\\\\iint_{S} A_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{n} d S\\n\\\\end{aligned}\\n$$\\n\\nso that\\n\\n\\n\\\\begin{equation*}\\n\\\\iiint_{V} \\\\frac{\\\\partial A_{3}}{\\\\partial z} d V=\\\\iint_{S} A_{3} \\\\mathbf{k} \\\\cdot \\\\mathbf{n} d S \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSimilarly, by projecting $S$ on the other coordinate planes,\\n\\n\\n\\\\begin{align*}\\n& \\\\iiint_{V} \\\\frac{\\\\partial A_{1}}{\\\\partial x} d V=\\\\iint_{S} A_{3} \\\\mathbf{i} \\\\cdot \\\\mathbf{n} d S  \\\\tag{2}\\\\\\\\\\n& \\\\iiint_{V} \\\\frac{\\\\partial A_{2}}{\\\\partial y} d V=\\\\iint_{S} A_{3} \\\\mathbf{j} \\\\cdot \\\\mathbf{n} d S \\\\tag{3}\\n\\\\end{align*}\\n\\n\\nAdding Equations (1), (2), and (3),\\n\\n$$\\n\\\\iiint_{V}\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial x}+\\\\frac{\\\\partial A_{2}}{\\\\partial y}+\\\\frac{\\\\partial A_{3}}{\\\\partial z}\\\\right) d V=\\\\iint_{S}\\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right) \\\\mathbf{n} d S\\n$$\\n\\nor\\n\\n$$\\n\\\\iiint_{V} \\\\nabla \\\\cdot \\\\mathbf{A} d V=\\\\iint_{S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S\\n$$\\n\\nThe theorem can be extended to surfaces which are such that lines parallel to the coordinate axes meet them in more than two points. To establish this extension, subdivide the region bounded by $S$ into subregions whose surfaces do satisfy this condition. The procedure is analogous to that used in Green's theorem for the plane.\\n\",\n",
       " '\\n10.23. Verify the divergence theorem for $\\\\mathbf{A}=(2 x-z) \\\\mathbf{i}+x^{2} y \\\\mathbf{j}-x z^{2} \\\\mathbf{k}$ taken over the region bounded by $x=0, x=1, y$ $=0, y=1, z=0, z=1$.\\n\\nWe first evaluate $\\\\iint_{S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S$, where $S$ is the surface of the cube in Figure 10.19.\\n\\nFace DEFG: $\\\\mathbf{n}=\\\\mathbf{i}, x=1$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{D E F G} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S & =\\\\int_{0}^{1} \\\\int_{0}^{1}\\\\left\\\\{(2-z) \\\\mathbf{i}+\\\\mathbf{j}-z^{2} \\\\mathbf{k}\\\\right\\\\} \\\\cdot \\\\mathbf{i} d y d z \\\\\\\\\\n& =\\\\int_{0}^{1} \\\\int_{0}^{1}(2-z) d y d z=3 / 2\\n\\\\end{aligned}\\n$$\\n\\nFace ABCO: $\\\\mathbf{n}=-\\\\mathbf{i}, x=0$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{A B C O} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S & =\\\\int_{0}^{1} \\\\int_{0}^{1}(-z \\\\mathbf{i}) \\\\cdot(-\\\\mathbf{i}) d y d z \\\\\\\\\\n& =\\\\int_{0}^{1} \\\\int_{0}^{1} z d y d z=1 / 2\\n\\\\end{aligned}\\n$$\\n\\nFace ABEF: $\\\\mathbf{n}=\\\\mathbf{j}, y=1$. Then\\n\\n$$\\n\\\\iint_{A B E F} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S=\\\\int_{0}^{1} \\\\int_{0}^{1}\\\\left\\\\{(2-z) \\\\mathbf{i}+x^{2} \\\\mathbf{j}-x z^{2} \\\\mathbf{k}\\\\right\\\\} \\\\cdot \\\\mathbf{j} d x d z=\\\\int_{0}^{1} \\\\int_{0}^{1} x^{2} d x d z=1 / 3\\n$$\\n\\nFace OGDC: $\\\\mathbf{n}=-\\\\mathbf{j}, y=0$. Then\\n\\n$$\\n\\\\iint_{O G D C} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S=\\\\int_{0}^{1} \\\\int_{0}^{1}\\\\left\\\\{(2 x-z) \\\\mathbf{i}-x z^{2} \\\\mathbf{k}\\\\right\\\\} \\\\cdot(-\\\\mathbf{j}) d x d z=0\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-275}\\n\\\\end{center}\\n\\nFigure 10.19\\n\\nFace BCDE: $\\\\mathbf{n}=\\\\mathbf{k}, z=1$. Then\\n\\n$$\\n\\\\iint_{B C D E} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S=\\\\int_{0}^{1} \\\\int_{0}^{1}\\\\left\\\\{(2 x-1) \\\\mathbf{i}+x^{2} \\\\mathbf{y} \\\\mathbf{j}-x \\\\mathbf{k}\\\\right\\\\} \\\\cdot \\\\mathbf{k} d x d y=\\\\int_{0}^{1} \\\\int_{0}^{1}-x d x d y-1 / 2\\n$$\\n\\nFace AFGO: $\\\\mathbf{n}=-\\\\mathbf{k}, z=0$. Then\\n\\n$$\\n\\\\iint_{A F G O} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S=\\\\int_{0}^{1} \\\\int_{0}^{1}\\\\left\\\\{2 x \\\\mathbf{i}-x^{2} \\\\mathbf{y} \\\\mathbf{j}\\\\right\\\\} \\\\cdot(-\\\\mathbf{k}) d x d y=0\\n$$\\n\\nAdding $\\\\iint_{S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S=\\\\frac{3}{2}+\\\\frac{1}{2}+\\\\frac{1}{3}+0-\\\\frac{1}{2}+0=\\\\frac{11}{6}$. Since\\n\\n$$\\n\\\\iiint_{V} \\\\nabla \\\\cdot \\\\mathbf{A} d V=\\\\int_{0}^{1} \\\\int_{0}^{1} \\\\int_{0}^{1}\\\\left(2+x^{2}-2 x z\\\\right) d x d y d z=\\\\frac{11}{6}\\n$$\\n\\nthe divergence theorem is verified in this case.\\n',\n",
       " '\\n10.24. Evaluate $\\\\iint_{S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d s$, where $S$ is a closed surface.\\n\\nBy the divergence theorem,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{S} \\\\mathbf{r} \\\\cdot \\\\mathbf{n} d S & =\\\\iiint_{V} \\\\nabla \\\\cdot \\\\mathbf{r} d V \\\\\\\\\\n& =\\\\iiint_{V}\\\\left(\\\\frac{\\\\partial}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial}{\\\\partial z} \\\\mathbf{k}\\\\right) \\\\cdot(x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}) d V \\\\\\\\\\n& =\\\\iiint_{V}\\\\left(\\\\frac{\\\\partial x}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial y}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial z}{\\\\partial z} \\\\mathbf{k}\\\\right) d V=3 \\\\iiint_{V} d V=3 V\\n\\\\end{aligned}\\n$$\\n\\nwhere $V$ is the volume enclosed by $S$.\\n',\n",
       " \"\\n10.25. Evaluate $\\\\iint_{S} x z^{2} d y d z+\\\\left(x^{2} y-z^{3}\\\\right) d z d x+\\\\left(2 x y+y^{2} z\\\\right) d x d y$, where $S$ is the entire surface of the hemispherical region bounded by $z=\\\\sqrt{a^{2}-x^{2}-y^{2}}$ and $z=0$ (a) by the divergence theorem (Green's theorem in space) and (b) directly.\\n\\n(a) Since $d y d z=d S \\\\cos \\\\alpha, d z d x=d S d S \\\\cos \\\\beta$, and $d x d y=d S \\\\cos \\\\gamma$, the integral can be written\\n\\n$$\\n\\\\iint_{S}\\\\left\\\\{x z^{2} \\\\cos \\\\alpha+\\\\left(x^{2} y-z^{3}\\\\right) \\\\cos \\\\beta+\\\\left(2 x y+y^{2} z\\\\right) \\\\cos \\\\gamma\\\\right\\\\} d S=\\\\iint_{S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S\\n$$\\n\\nwhere $\\\\mathbf{A}=x z^{2} \\\\mathbf{i}+\\\\left(x^{2} y-z^{3}\\\\right) \\\\mathbf{j}+\\\\left(2 x y+y^{2} z\\\\right) \\\\mathbf{k}$ and $\\\\mathbf{n}=\\\\cos \\\\alpha \\\\mathbf{i}+\\\\cos \\\\beta \\\\mathbf{j}+\\\\cos \\\\gamma \\\\mathbf{k}$, the outward drawn unit normal.\\n\\nThen, by the divergence theorem the integral equals\\n\\n$$\\n\\\\iiint_{V} \\\\nabla \\\\cdot \\\\mathbf{A} d V=\\\\iiint_{V}\\\\left\\\\{\\\\frac{\\\\partial}{\\\\partial x}\\\\left(x z^{2}\\\\right)+\\\\frac{\\\\partial}{\\\\partial y}\\\\left(x^{2} y-z^{3}\\\\right)+\\\\frac{\\\\partial}{\\\\partial z}\\\\left(2 x y+y^{2} z\\\\right)\\\\right\\\\} d V=\\\\iiint_{V}\\\\left(x^{2}+y^{2}+z^{2}\\\\right) d V\\n$$\\n\\nwhere $V$ is the region bounded by the hemisphere and the $x y$ plane.\\n\\nBy use of spherical coordinates, as in Problem 9.19, this integral is equal to\\n\\n$$\\n4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\theta=0}^{\\\\pi / 2} \\\\int_{r=0}^{\\\\alpha} r^{2} \\\\cdot r^{2} \\\\sin \\\\theta d r d \\\\theta d \\\\phi=\\\\frac{2 \\\\pi a^{5}}{5}\\n$$\\n\\n(b) If $S_{1}$ is the convex surface of the hemispherical region and $S_{2}$ is the base $(z=0)$, then\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\iint_{S_{1}} x z^{2} d y d z=\\\\int_{y=-a}^{a} \\\\int_{z=0}^{\\\\sqrt{a^{2}-y^{2}}} z^{2} \\\\sqrt{a^{2}-y^{2}-z^{2}} d z d y-\\\\int_{y=-a}^{a} \\\\int_{z=0}^{\\\\sqrt{a^{2}-x^{2}}}-z^{2} \\\\sqrt{a^{2}-y^{2}-z^{2}} d z d x \\\\\\\\\\n& \\\\iint_{S_{1}}\\\\left(x^{2} y-z^{3}\\\\right) d y d x=\\\\int_{x=-a}^{a} \\\\int_{x=0}^{\\\\sqrt{a^{2}-x^{2}}}\\\\left\\\\{x^{2} \\\\sqrt{a^{2}-y^{2}-z^{2}}-z^{3}\\\\right\\\\} d z d x \\\\\\\\\\n& \\\\quad-\\\\int_{x=-a}^{a} \\\\int_{z=0}^{\\\\sqrt{a^{2}-x^{2}}}\\\\left\\\\{-x^{2} \\\\sqrt{a^{2}-x^{2}-z^{2}}-z^{3}\\\\right\\\\} d z d x \\\\\\\\\\n& \\\\iint_{S_{1}}\\\\left(2 x y-y^{2} z\\\\right) d x d y=\\\\int_{x=-a}^{a} \\\\int_{y=-\\\\sqrt{a^{2}-x^{2}}}^{\\\\sqrt{a^{2}-x^{2}}}\\\\left\\\\{2 x y+y^{2} \\\\sqrt{a^{2}-y^{2}-z^{2}}\\\\right\\\\} d y d x \\\\\\\\\\n& \\\\iint_{S_{2}} x z^{2} d y d z=0, \\\\quad \\\\iint_{S_{2}}\\\\left(x^{2} y-z^{3}\\\\right) d z d x=0, \\\\\\\\\\n& \\\\iint_{S_{2}}\\\\left(2 x y-y^{2} z\\\\right) d x d y=\\\\iint_{S_{2}}\\\\left\\\\{2 x y-y^{2}(0)\\\\right\\\\} d x d y=\\\\int_{x=-a}^{a} \\\\int_{y=-\\\\sqrt{a^{2}-x^{2}}}^{\\\\sqrt{a^{2}-x^{2}}} 2 x y d y d x=0\\n\\\\end{aligned}\\n$$\\n\\nBy addition of the preceding, we obtain\\n\\n$$\\n\\\\begin{aligned}\\n4 \\\\int_{y=0}^{a} \\\\int_{x=0}^{\\\\sqrt{a^{2}-y^{2}}} z^{2} \\\\sqrt{a^{2}-y^{2}-z^{2}} d z d y+4 \\\\int_{x=0}^{a} \\\\int_{z=0}^{\\\\sqrt{a^{2}-x^{2}}} x^{2} \\\\sqrt{a^{2}-x^{2}-z^{2}} d z d x \\\\\\\\\\n+4 \\\\int_{x=0}^{a} \\\\int_{y=0}^{\\\\sqrt{a^{2}-x^{2}}} y^{2} \\\\sqrt{a^{2}-x^{2}-y^{2}} d y d x\\n\\\\end{aligned}\\n$$\\n\\nSince by symmetry all these integrals are equal, the result, on using polar coordinates, is\\n\\n$$\\n12 \\\\int_{x=0}^{a} \\\\int_{y=0}^{\\\\sqrt{a^{2}-x^{2}}} y^{2} \\\\sqrt{a^{2}-x^{2}-y^{2}} d y d x=12 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{a} \\\\rho^{2} \\\\sin ^{2} \\\\phi \\\\sqrt{a^{2}-\\\\rho^{2}} \\\\rho d \\\\rho d \\\\phi=\\\\frac{2 \\\\pi a^{5}}{5}\\n$$\\n\\n\\n\\\\section*{Stokes's theorem}\\n\",\n",
       " \"10.26. Prove Stokes's theorem.\\n\\nLet $S$ be a surface which is such that its projections on the $x y, y z$, and $x z$ planes are are regions bounded by simple closed curves, as indicated in Figure 10.20. Assume $S$ to have representation $z=f(x, y)$ or $x=$ $g(y, z)$ or $y=h(x, z)$, where $f, g$, and $h$ are single-valued, continuous, and differentiable functions. We must show that\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{S}(\\\\nabla \\\\times \\\\mathbf{A}) \\\\cdot \\\\mathbf{n} d S & =\\\\iint_{S}\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S \\\\\\\\\\n& =\\\\int_{C} A \\\\cdot d \\\\mathbf{r}\\n\\\\end{aligned}\\n$$\\n\\nwhere $C$ is the boundary of $S$.\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\text { Consider first } \\\\iint_{S}\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S \\\\\\\\\\n& \\\\text { Since } \\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)=\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n\\\\frac{\\\\partial}{\\\\partial x} & \\\\frac{\\\\partial}{\\\\partial y} & \\\\frac{\\\\partial}{\\\\partial z} \\\\\\\\\\nA_{1} & 0 & 0\\n\\\\end{array}\\\\right|=\\\\frac{\\\\partial A_{1}}{\\\\partial z} \\\\mathbf{j}-\\\\frac{\\\\partial A_{1}}{\\\\partial y} \\\\mathbf{k}\\n\\\\end{aligned}\\n$$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-277}\\n\\\\end{center}\\n\\nFigure 10.20\\n\\n\\n\\\\begin{equation*}\\n\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S=\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial z} \\\\mathbf{n} \\\\cdot \\\\mathbf{j}-\\\\frac{\\\\partial A_{1}}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k}\\\\right) d S \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf $z=f(x, y)$ is taken as the equation of $S$, then the position vector to any point of $S$ is $\\\\mathbf{r}=x \\\\mathbf{i}+y \\\\mathbf{j}+z \\\\mathbf{k}=x \\\\mathbf{i}+$ $y \\\\mathbf{j}+f(x, y) \\\\mathbf{k}$ so that $\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial y}=\\\\mathbf{j}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\mathbf{k}=\\\\mathbf{j}+\\\\frac{\\\\partial f}{\\\\partial y} \\\\mathbf{k}$. But $\\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial y}$ is a vector tangent to $S$ and thus perpendicular to $\\\\mathbf{n}$, so that\\n\\n$$\\n\\\\mathbf{n} \\\\cdot \\\\frac{\\\\partial \\\\mathbf{r}}{\\\\partial y}=\\\\mathbf{n} \\\\cdot \\\\mathbf{j}+\\\\frac{\\\\partial z}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k}=0 \\\\quad \\\\text { or } \\\\quad \\\\mathbf{n} \\\\cdot \\\\mathbf{j}=-\\\\frac{\\\\partial z}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k}\\n$$\\n\\nSubstitute in Equation (1) to obtain\\n\\n$$\\n\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial z} \\\\mathbf{n} \\\\cdot \\\\mathbf{j}-\\\\frac{\\\\partial A_{1}}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k}\\\\right) d S=\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k}-\\\\frac{\\\\partial A_{1}}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k}\\\\right) d S\\n$$\\n\\nor\\n\\n\\n\\\\begin{equation*}\\n\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S=-\\\\left(\\\\frac{\\\\partial A_{1}}{\\\\partial z}+\\\\frac{\\\\partial A_{1}}{\\\\partial y} \\\\frac{\\\\partial z}{\\\\partial y}\\\\right) \\\\mathbf{n} \\\\cdot \\\\mathbf{k} d S \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nNow on $S, A_{1}(x, y, z)=A_{1}[x, y, f(x, y)]=F(x, y)$; hence, $\\\\frac{\\\\partial A_{1}}{\\\\partial y}+\\\\frac{\\\\partial A_{1}}{\\\\partial z} \\\\frac{\\\\partial z}{\\\\partial y}=\\\\frac{\\\\partial F}{\\\\partial y}$ and Equation (2) becomes\\n\\n$$\\n\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S=-\\\\frac{\\\\partial F}{\\\\partial y} \\\\mathbf{n} \\\\cdot \\\\mathbf{k} d S=-\\\\frac{\\\\partial F}{\\\\partial y} d x d y\\n$$\\n\\nThen\\n\\n$$\\n\\\\iint_{S}\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S=\\\\iint_{\\\\Re}-\\\\frac{\\\\partial F}{\\\\partial y} d x d y\\n$$\\n\\nwhere $\\\\Re$ is the projection of $S$ on the $x y$ plane. By Green's theorem for the plane, the last integral equals $\\\\oint_{\\\\Gamma} F d x$ where $\\\\Gamma$ is the boundary of $\\\\Re$. Since at each point $(x, y)$ of $\\\\Gamma$ the value of $F$ is the same as the value of $A_{1}$ at each point $(x, y, z)$ of $C$, and since $d x$ is the same for both curves, we must have\\n\\n$$\\n\\\\oint_{\\\\Gamma} F d x=\\\\oint_{C} A_{1} d x\\n$$\\n\\nor\\n\\n$$\\n\\\\iint_{S}\\\\left[\\\\nabla \\\\times\\\\left(A_{1} \\\\mathbf{i}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S=\\\\oint_{C} A_{1} d x\\n$$\\n\\nSimilarly, by projections on the other coordinate planes,\\n\\n$$\\n\\\\iint_{S}\\\\left[\\\\nabla \\\\times\\\\left(\\\\mathbf{A}_{2} \\\\mathbf{j}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} \\\\mathrm{d} S=\\\\oint_{C} A_{2} d y, \\\\quad \\\\iint_{S}\\\\left[\\\\nabla \\\\times\\\\left(A_{3} \\\\mathbf{k}\\\\right)\\\\right] \\\\cdot \\\\mathbf{n} d S=\\\\oint_{C} A_{3} d z\\n$$\\n\\nThus, by addition,\\n\\n$$\\n\\\\iint_{S}(\\\\nabla \\\\times \\\\mathbf{A}) \\\\cdot \\\\mathbf{n} d S=\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}\\n$$\\n\\nThe theorem is also valid for surfaces $S$ which may not satisfy these imposed restrictions. Assume that $S$ can be subdivided into surfaces $S_{1}, S_{2}, \\\\ldots S_{k}$ with boundaries $C_{1}, C_{2}, \\\\ldots, C_{k}$, which do satisfy the restrictions. Then Stokes's theorem holds for each such surface. Adding these surface integrals, the total surface integral over $S$ is obtained. Adding the corresponding line integrals over $C_{1}, C_{2} \\\\ldots, C_{k}$, the line integral over $C$ is obtained.\\n\",\n",
       " \"\\n10.27. Verify Stokes's theorem for $\\\\mathbf{A}=3 y \\\\mathbf{i}-x z \\\\mathbf{j}+y z^{2} \\\\mathbf{k}$, where $S$ is the surface of the paraboloid $2 z=x^{2}+y^{2}$ bounded by $z=2$ and $C$ is its boundary. See Figure 10.21 .\\n\\nThe boundary $C$ of $S$ is a circle with equations $x^{2}+y^{2}=4, z=2$ and parametric equations $x=2 \\\\cos t, y=$ $2 \\\\sin t, z=2$, where $0 \\\\leqq t<2 \\\\pi$. Then\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-278}\\n\\\\end{center}\\n\\nFigure 10.21\\n\\n$$\\n\\\\begin{aligned}\\n\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r} & =\\\\oint_{C} 3 y d x-x z d y+y z^{2} d z \\\\\\\\\\n& =\\\\int_{2 \\\\pi}^{0} 3(2 \\\\sin t)(-2 \\\\sin t) d t-(2 \\\\cos t)(2)(2 \\\\cos t) d t \\\\\\\\\\n& =\\\\int_{0}^{2 \\\\pi}\\\\left(12 \\\\sin ^{2} t+8 \\\\cos ^{2} t\\\\right) d t=20 \\\\pi\\n\\\\end{aligned}\\n$$\\n\\nAlso,\\n\\n$$\\n\\\\nabla \\\\times \\\\mathbf{A}=\\\\left|\\\\begin{array}{ccc}\\n\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\\\n\\\\frac{\\\\partial}{\\\\partial x} & \\\\frac{\\\\partial}{\\\\partial y} & \\\\frac{\\\\partial}{\\\\partial z} \\\\\\\\\\n3 y & -x z & y z^{2}\\n\\\\end{array}\\\\right|=\\\\left(z^{2}+x\\\\right) \\\\mathbf{i}-(z+3) \\\\mathbf{k}\\n$$\\n\\nand\\n\\n$$\\n\\\\mathbf{n}=\\\\frac{\\\\nabla\\\\left(x^{2}+y^{2}-2 z\\\\right)}{\\\\left|\\\\nabla\\\\left(x^{2}+y^{2}-2 z\\\\right)\\\\right|}=\\\\frac{x \\\\mathbf{i}+y \\\\mathbf{j}-\\\\mathbf{k}}{\\\\sqrt{x^{2}+y^{2}+1}}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n\\\\iint_{S}(\\\\nabla \\\\times \\\\mathbf{A}) \\\\cdot \\\\mathbf{n} d S & =\\\\iint_{\\\\Re}(\\\\nabla \\\\cdot A) \\\\cdot \\\\mathbf{n} \\\\frac{d x d y}{|\\\\mathbf{n} \\\\cdot \\\\mathbf{k}|}=\\\\iint_{\\\\Re}\\\\left(x z^{2}+x^{2}+z+3\\\\right) d x d \\\\\\\\\\n& =\\\\iint_{\\\\Re}\\\\left\\\\{x\\\\left(\\\\frac{x^{2}+y^{2}}{2}\\\\right)^{2}+x^{2}+\\\\frac{x^{2}+y^{2}}{2}+3\\\\right\\\\} d x d y\\n\\\\end{aligned}\\n$$\\n\\nIn polar coordinates this becomes\\n\\n$$\\n\\\\int_{\\\\phi=0}^{2 \\\\pi} \\\\int_{\\\\rho=0}^{2}\\\\left\\\\{(\\\\rho \\\\cos \\\\phi)\\\\left(\\\\rho^{4} / 2\\\\right)+\\\\rho^{2} \\\\cos ^{2} \\\\phi+\\\\rho^{2} / 2+3\\\\right\\\\} \\\\rho d \\\\rho d \\\\phi=20 \\\\pi\\n$$\\n\",\n",
       " \"\\n10.28. Prove that a necessary and sufficient condition that $\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=0$ for every closed curve $C$ is that $\\\\nabla \\\\times \\\\mathbf{A}=0$ identically.\\n\\nSufficiency. Suppose $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$. Then, by Stokes's theorem,\\n\\n$$\\n\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=\\\\iint_{S}(\\\\nabla \\\\times \\\\mathbf{A}) \\\\cdot \\\\mathbf{n} d S=0\\n$$\\n\\nNecessity. Suppose $\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=0$ around every closed path $C$, and assume $\\\\nabla \\\\times \\\\mathbf{A} \\\\neq \\\\mathbf{0}$ at some point $P$. Then, assuming $\\\\nabla \\\\times \\\\mathbf{A}$ is continuous, there will be a region with $P$ as an interior point, where $\\\\nabla \\\\times \\\\mathbf{A} \\\\neq \\\\mathbf{0}$. Let $S$ be a surface contained in this region whose normal $\\\\mathbf{n}$ at each point has the same direction as $\\\\nabla \\\\times \\\\mathbf{A} ;$ i.e., $\\\\nabla \\\\times \\\\mathbf{A}=$ $\\\\alpha \\\\mathbf{n}$ where $\\\\alpha$ is a positive constant. Let $C$ be the boundary of $S$. Then, by Stokes's theorem,\\n\\n$$\\n\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=\\\\iint_{S}(\\\\nabla \\\\times \\\\mathbf{A}) \\\\cdot \\\\mathbf{n} d S=\\\\alpha \\\\iint_{S} \\\\mathbf{n} \\\\cdot \\\\mathbf{n} d S>0\\n$$\\n\\nwhich contradicts the hypothesis that $\\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=0$ and shows that $\\\\nabla \\\\times \\\\mathbf{A}=0$.\\n\\nIt follows that $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$ is also a necessary and sufficient condition for a line integral $\\\\int_{P_{1}}^{P_{2}} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}$ to be independent of the path joining points $P_{1}$ and $P_{2}$.\\n\",\n",
       " '\\n10.29. Prove that a necessary and sufficient condition that $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$ is that $\\\\mathbf{A}=\\\\nabla \\\\phi$.\\n\\nSufficiency. If $\\\\mathbf{A}=\\\\nabla \\\\phi$, then $\\\\nabla \\\\times \\\\mathbf{A}=\\\\nabla \\\\times \\\\nabla \\\\phi=\\\\mathbf{0}$ by Problem 7.80.\\n\\nNecessity. If $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$, then by Problem $10.28, \\\\oint_{C} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=\\\\mathbf{0}$ around every closed path and $\\\\int_{P_{1}}^{P_{2}} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}$ is independent of the path joining two points, which we take as $(a, b, c)$ and $(x, y, z)$. Let us define\\n\\n$$\\n\\\\phi(x, y, z)=\\\\int_{(a, b, c)}^{(x, y, z)} \\\\mathbf{A} \\\\cdot d \\\\mathbf{r}=\\\\int_{(a, b, c)}^{(x, y, z)} A_{1} d x+A_{2} d y+A_{3} d z\\n$$\\n\\nThen\\n\\n$$\\n\\\\phi(x+\\\\Delta x, y, z)-\\\\phi(x, y, z)=\\\\int_{(x, y, z)}^{(x+\\\\Delta x, y, z)} A_{1} d x+A_{2} d y+A_{3} d z\\n$$\\n\\nSince the last integral is independent of the path joining $(x, y, z)$ and $(x+\\\\Delta x, y, z)$, we can choose the path to be a straight line joining these points so that $d y$ and $d z$ are zero. Then\\n\\n$$\\n\\\\frac{\\\\phi(x+\\\\Delta x, y, z)-\\\\phi(x, y, z)}{\\\\Delta x}=\\\\frac{1}{\\\\Delta x} \\\\int_{(x, y, z)}^{(x+\\\\Delta x, y, z)} A_{1} d x=A_{1}(x+\\\\theta \\\\Delta x, y, z) \\\\quad 0<\\\\theta<1\\n$$\\n\\nwhere we have applied the law of the mean for integrals.\\n\\nTaking the limit of both sides as $\\\\Delta x \\\\rightarrow 0$ gives $\\\\partial \\\\phi / \\\\partial x=A_{1}$.\\n\\nSimilarly, we can show that $\\\\partial \\\\phi / \\\\partial y=A_{2}, \\\\partial \\\\phi / \\\\partial z=A_{3}$. Thus,\\n\\n$$\\n\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} \\\\mathbf{k}=\\\\nabla \\\\phi\\n$$\\n',\n",
       " '\\n10.30. (a) Prove that a necessary and sufficient condition that $A_{1} d x+A_{2} d y+A_{3} d z=d \\\\phi$, an exact differential, is that $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$ where $\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}$. (b) Show that in such case,\\n\\n$$\\n\\\\int_{\\\\left(x_{1}, y_{1}, z_{1}\\\\right)}^{\\\\left(x_{2}, y_{2}, z_{2}\\\\right)} A_{1} d x+A_{2} d y+A_{3} d z=\\\\int_{\\\\left(x_{1}, y_{1}, z_{1}\\\\right)}^{\\\\left(x_{2}, y_{2}, z_{2}\\\\right)} d \\\\phi=\\\\phi\\\\left(x_{2}, y_{2}, z_{2}\\\\right)-\\\\phi\\\\left(x_{1}, y_{1}, z_{1}\\\\right)\\n$$\\n\\n(a) Necessity. If $A_{1} d x+A_{2} d y+A_{3} d z=d \\\\phi=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} d x+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} d y+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} d z$, then\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial x}=A_{1}  \\\\tag{1}\\\\\\\\\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial y}=A_{2}  \\\\tag{2}\\\\\\\\\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial z}=A_{3} \\\\tag{3}\\n\\\\end{align*}\\n\\n\\nThen, by differentiating, and assuming continuity of the partial derivatives, we have\\n\\n$$\\n\\\\frac{\\\\partial A_{1}}{\\\\partial y}=\\\\frac{\\\\partial A_{2}}{\\\\partial x}, \\\\quad \\\\frac{\\\\partial A_{2}}{\\\\partial z}=\\\\frac{\\\\partial A_{3}}{\\\\partial y}, \\\\quad \\\\frac{\\\\partial A_{1}}{\\\\partial z}=\\\\frac{\\\\partial A_{3}}{\\\\partial x}\\n$$\\n\\nwhich is precisely the condition $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$.\\n\\nAnother method: If $A_{1} d x+A_{2} d y+A_{3} d z=d \\\\phi$, then\\n\\n$$\\n\\\\mathbf{A}=A_{1} \\\\mathbf{i}+A_{2} \\\\mathbf{j}+A_{3} \\\\mathbf{k}=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} \\\\mathbf{i}+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} \\\\mathbf{j}+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} \\\\mathbf{k}=\\\\nabla \\\\phi\\n$$\\n\\nfrom which $\\\\nabla \\\\times \\\\mathbf{A}=\\\\nabla \\\\times \\\\nabla \\\\phi=\\\\mathbf{0}$.\\n\\nSufficiency. If $\\\\nabla \\\\times \\\\mathbf{A}=\\\\mathbf{0}$, then by Problem $10.29, \\\\mathbf{A}=\\\\nabla \\\\phi$ and\\n\\n$$\\nA_{1} d x+A_{2} d y+A_{3} d z=\\\\mathrm{A} \\\\cdot d r=\\\\nabla \\\\phi \\\\cdot d r=\\\\frac{\\\\partial \\\\phi}{\\\\partial x} d x+\\\\frac{\\\\partial \\\\phi}{\\\\partial y} d y+\\\\frac{\\\\partial \\\\phi}{\\\\partial z} d z=d \\\\phi\\n$$\\n\\n(b) From (a),\\n\\n$$\\n\\\\phi(x, y, z)=\\\\int_{(a, b, c)}^{(x, y, z)} A_{1} d x+A_{2} d y+A_{3} d z\\n$$\\n\\nThen, omitting the integrand $A_{1} d x+A_{2} d y+A_{3} d z$, we have\\n\\n$$\\n\\\\int_{\\\\left(x_{1}, y_{1}, z_{1}\\\\right)}^{\\\\left(x_{2}, y_{2}, z_{2}\\\\right)}=\\\\int_{(a, b, c)}^{\\\\left(x_{2}, y_{2}, z_{2}\\\\right)}--\\\\iint_{(a, b, c)}^{\\\\left(x_{1}, y_{1}, z_{1}\\\\right)}=\\\\left(\\\\not\\\\left(x_{2}, y_{2}, z_{2}\\\\right) \\\\cdot-\\\\mid \\\\not\\\\left(x_{1}, y_{1}, z_{1}\\\\right)\\\\right.\\n$$\\n',\n",
       " '\\n10.31. (a) Prove that $\\\\mathbf{F}=\\\\left(2 x z^{3}+6 y\\\\right) \\\\mathbf{i}+(6 x-2 y z) \\\\mathbf{j}+\\\\left(3 x^{2} z^{2}-y^{2}\\\\right) \\\\mathbf{k}$ is a conservative force field. (b) Evaluate $\\\\int_{C} \\\\mathbf{F}$. $d \\\\mathbf{r}$ where $C$ is any path from $(1,-1,1)$ to $(2,1,-1)$. (c) Give a physical interpretation of the results.\\n\\n(a) A force field $\\\\mathbf{F}$ is conservative if the line integral $\\\\int_{C} \\\\mathbf{F} \\\\cdot d \\\\mathbf{r}$ is independent of the path $C$ joining any two points. A necessary and sufficient condition that $\\\\mathrm{F}$ be conservative is that $\\\\nabla \\\\times \\\\mathbf{F}=\\\\mathbf{0}$.\\n\\nSince here $\\\\nabla \\\\times \\\\mathrm{F}=\\\\left|\\\\begin{array}{ccc}\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\ \\\\frac{\\\\partial}{\\\\partial x} & \\\\frac{\\\\partial}{\\\\partial y} & \\\\frac{\\\\partial}{\\\\partial z} \\\\\\\\ 2 x z^{3}+6 y & 6 x-2 y z & 3 x^{2} z^{2}-y^{2}\\\\end{array}\\\\right|=\\\\mathbf{0}, \\\\quad \\\\mathbf{F}$ is conservative\\\\\\\\\\n(b) Method 1: By Problem 10.30, F $\\\\cdot d \\\\mathbf{r}=\\\\left(2 x z^{3}+6 y\\\\right) d x+(6 x-2 y z) d y+\\\\left(3 x^{2} z^{2}-y^{2}\\\\right) d z$ is an exact differential $d \\\\phi$, where $\\\\phi$ is such that\\n\\n\\n\\\\begin{align*}\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial x}=2 x z^{3}+6 y  \\\\tag{1}\\\\\\\\\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial y}=6 x-2 y z  \\\\tag{2}\\\\\\\\\\n& \\\\frac{\\\\partial \\\\phi}{\\\\partial z}=3 x^{2} z^{2}-y^{2} \\\\tag{3}\\n\\\\end{align*}\\n\\n\\nFrom these we obtain, respectively,\\n\\n$$\\n\\\\begin{gathered}\\n\\\\phi=x^{2} z^{3}+6 x y+f_{1}(y, z) \\\\\\\\\\n\\\\phi=6 x y-y^{2} z+f_{2}(x, z) \\\\\\\\\\n\\\\phi=x^{2} y^{2}-y^{2} z+f_{3}(x, y)\\n\\\\end{gathered}\\n$$\\n\\nThese are consistent if $f_{1}(y, z)=-y^{2} z+c, f_{2}(x, z)=x^{2} z^{3}+c$, and $f_{3}(x, y)=6 x y+c$, in which case $\\\\phi=x^{2} z^{3}$ $+6 x y-y^{2} z+c$. Thus, by Problem 10.30,\\n\\n$$\\n\\\\int_{(1,-1,1)}^{(2,1,-1)} \\\\mathrm{F} \\\\cdot d \\\\mathrm{r}=x^{2} z^{3}+6 x y-y^{2} z+\\\\left.c\\\\right|_{(1,-1,1)} ^{(2,1,-1)}=15\\n$$\\n\\nAlternatively, we may notice by inspection that\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathbf{F} \\\\cdot d \\\\mathbf{r} & =\\\\left(2 x z^{3} d x+3 x^{2} z^{2} d z\\\\right)+(6 y d x+6 x d y)-\\\\left(2 y z d y+y^{2} d z\\\\right) \\\\\\\\\\n& =d\\\\left(x^{2} z^{3}\\\\right)+d(6 x y)-d\\\\left(y^{2} z\\\\right)=d\\\\left(x^{2} z^{3}+6 x y-y^{2} z+c\\\\right) \\\\text { from which } \\\\phi \\\\text { is determined. }\\n\\\\end{aligned}\\n$$\\n\\nMethod 2: Since the integral is independent of the path, we can choose any path to evaluate it; in particular, we can choose the path consisting of straight lines from $(1,-1,1)$ to $(2,-1,1)$, then to $(2,1,1)$ and then to $(2,1,-1)$. The result is\\n\\n$$\\n\\\\int_{x=1}^{2}(2 x-6) d x+\\\\int_{y=1}^{1}(12-2 y) d y+\\\\int_{z=1}^{-1}\\\\left(12 z^{2}-1\\\\right) d z=15\\n$$\\n\\nwhere the first integral is obtained from the line integral by placing $y=-1, z=1, d y=0, d z=0$; the second integral, by placing $x=2, z=1, d x=0, d z=0$; and the third integral, by placing $x=2, y=1, d x=0, d y=0$.\\n\\n(c) Physically, $\\\\int_{C} \\\\mathbf{F} \\\\cdot d \\\\mathbf{r}$ represents the work done in moving an object from $(1,-1,1)$ to $(2,1,-1)$ along $C$. In a conservative force field, the work done is independent of the path $C$ joining these points.\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " \"10.32. (a) If $x=f(u, v), y=g(u, v)$ defines a transformation which maps a region $\\\\Re$ of the $x y$ plane into a region $\\\\Re^{\\\\prime}$ of the $u v$ plane, prove that\\n\\n$$\\n\\\\iint_{\\\\Re} d x d y=\\\\iint_{\\\\Re^{\\\\prime}}\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| d u d v\\n$$\\n\\n(b) Interpret geometrically the result in (a).\\n\\n(a) If $C$ (assumed to be a simple closed curve) is the boundary of $\\\\Re$, then by Problem 10.8 ,\\n\\n\\n\\\\begin{equation*}\\n\\\\iint_{\\\\Re} d x d y=\\\\frac{1}{2} \\\\oint_{C} x d y-y d x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nUnder the given transformation, the integral on the right of Equation (1) becomes\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{1}{2} \\\\oint_{C^{\\\\prime}} x\\\\left(\\\\frac{\\\\partial y}{\\\\partial u} d u+\\\\frac{\\\\partial y}{\\\\partial v} d v\\\\right)-y\\\\left(\\\\frac{\\\\partial y}{\\\\partial u} d u+\\\\frac{\\\\partial x}{\\\\partial v} d v\\\\right)=\\\\frac{1}{2} \\\\int_{C^{\\\\prime}}\\\\left(x \\\\frac{\\\\partial y}{\\\\partial u}-y \\\\frac{\\\\partial x}{\\\\partial u}\\\\right) d u+\\\\left(x \\\\frac{\\\\partial y}{\\\\partial v}-y \\\\frac{\\\\partial x}{\\\\partial v}\\\\right) d v \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nwhere $C^{\\\\prime}$ is the mapping of $C$ in the $u v$ plane (we suppose the mapping to be such that $C^{\\\\prime}$ is a simple closed curve also).\\n\\nBy Green's theorem, if $\\\\Re^{\\\\prime}$ is the region in the $u v$ plane bounded by $C^{\\\\prime}$, the right side of Equation (2) equals\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{1}{2} \\\\iint_{\\\\Re^{\\\\prime}} \\\\left\\\\lvert\\\\, \\\\frac{\\\\partial}{\\\\partial u}\\\\left(x \\\\frac{\\\\partial y}{\\\\partial v}-y \\\\frac{\\\\partial x}{\\\\partial v}\\\\right)-\\\\frac{\\\\partial}{\\\\partial v}\\\\left(x \\\\frac{\\\\partial y}{\\\\partial u}-y \\\\frac{\\\\partial x}{\\\\partial u}\\\\right) d u d v\\\\right. & =\\\\iint_{\\\\Re^{\\\\prime}}\\\\left|\\\\frac{\\\\partial x}{\\\\partial u} \\\\frac{\\\\partial y}{\\\\partial v}-\\\\frac{\\\\partial x}{\\\\partial v} \\\\frac{\\\\partial y}{\\\\partial u}\\\\right| d u d v \\\\\\\\\\n& =\\\\iint_{\\\\Re^{\\\\prime}}\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| d u d v\\n\\\\end{aligned}\\n$$\\n\\nwhere we have inserted absolute value signs so as to ensure that the result is nonnegative, as is $\\\\iint_{\\\\mathfrak{R}} d x d y$.\\n\\nIn general, we can show (see Problem 10.83) that\\n\\n\\n\\\\begin{equation*}\\n\\\\iint_{\\\\Re} F(x, y) d x d y=\\\\iint_{\\\\Re^{\\\\prime}} F\\\\{f(u, v), g(u, v)\\\\}\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| d u d v \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\n(b) $\\\\iint_{\\\\Re} d x d y$ and $\\\\iint_{\\\\Re^{\\\\prime}}\\\\left|\\\\frac{\\\\partial(x, y)}{\\\\partial(u, v)}\\\\right| d u d v$ represent the area of region $\\\\mathrm{R}$, the first expressed in rectangular coordinates, the second in curvilinear coordinates. See Page 225, and the introduction of the differential element of surface area for an alternative to (a).\\n\",\n",
       " '\\n10.33. Let $\\\\mathbf{F}=\\\\frac{-y \\\\mathbf{i}+x \\\\mathbf{j}}{x^{2}+y^{2}}$. (a) Calculate $\\\\nabla \\\\times \\\\mathbf{F}$. (b) Evaluate $\\\\oint \\\\mathbf{F} \\\\cdot d \\\\mathbf{r}$ around any closed path and explain the results.\\n\\n(a) $\\\\nabla \\\\times \\\\mathbf{F}=\\\\left|\\\\begin{array}{ccc}\\\\mathbf{i} & \\\\mathbf{j} & \\\\mathbf{k} \\\\\\\\ \\\\frac{\\\\partial}{\\\\partial x} & \\\\frac{\\\\partial}{\\\\partial y} & \\\\frac{\\\\partial}{\\\\partial z} \\\\\\\\ \\\\frac{-y}{x^{2}+y^{2}} & \\\\frac{x}{x^{2}+y^{2}} & 0\\\\end{array}\\\\right|=\\\\mathbf{0}$ in any region excluding $(0,0)$.\\n\\n(b) $\\\\oint \\\\mathbf{F} \\\\cdot d \\\\mathbf{r}=\\\\oint_{C} \\\\frac{-y d x=x d y}{x^{2}+y^{2}}$. Let $\\\\mathrm{x}=\\\\rho \\\\cos \\\\phi, \\\\mathrm{y}=\\\\rho \\\\sin \\\\phi$, where $(\\\\rho, \\\\phi)$ are polar coordinates. Then\\n\\n$$\\nd x=-\\\\rho \\\\sin \\\\phi d \\\\phi+d \\\\rho \\\\cos \\\\phi, \\\\quad d y=\\\\rho \\\\cos \\\\phi d \\\\phi+d \\\\rho \\\\sin \\\\phi\\n$$\\n\\nand so\\n\\n$$\\n\\\\frac{-y d x=x d y}{x^{2}+y^{2}}=d \\\\phi=d\\\\left(\\\\operatorname{are} \\\\tan \\\\frac{y}{x}\\\\right)\\n$$\\n\\nFor a closed curve $A B C D A$ [see Figure 10.22 (a)] surrounding the origin, $\\\\phi=0$ at $A$ and $\\\\phi=2 \\\\pi$ after a complete circuit back to $A$. In this case the line integral equals $\\\\int_{0}^{2 \\\\pi}{ }_{0} d \\\\phi=2 \\\\pi$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-282(1)}\\n\\\\end{center}\\n\\n(a)\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-282}\\n\\\\end{center}\\n\\n(b)\\n\\nFigure 10.22\\n\\nFor a closed curve PQRSP [see Figure 10.22(b)] not surrounding the origin, $\\\\phi=\\\\phi_{0}$ at $P$ and $\\\\phi=\\\\phi_{0}$ after a complete circuit back to $P$. In this case the line integral equals $\\\\int_{\\\\phi_{0}}^{\\\\phi_{0}} d \\\\phi=0$.\\n\\nSince $\\\\mathbf{F}=P \\\\mathbf{i}+Q \\\\mathbf{j}, \\\\nabla \\\\times \\\\mathbf{F}=\\\\mathbf{0}$ is equivalent to $\\\\partial P / \\\\partial y=\\\\partial Q / \\\\partial x$, the results would seem to contradict those of Problem 10.11. However, no contradiction exists, since $P=\\\\frac{-y}{x^{2}+y^{2}}$ and $Q=\\\\frac{x}{x^{2}+y^{2}}$ do not have continuous derivatives throughout any region including $(0,0)$, and this was assumed in Problem 10.11.\\n',\n",
       " '\\n10.34. If div $\\\\mathbf{A}$ denotes the divergence of a vector field $\\\\mathbf{A}$ at a point $P$, show that\\n\\n$$\\n\\\\operatorname{div} \\\\mathbf{A}=\\\\lim _{\\\\Delta V \\\\rightarrow 0} \\\\frac{\\\\iint_{\\\\Delta S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S}{\\\\Delta V}\\n$$\\n\\nwhere $\\\\Delta V$ is the volume enclosed by the surface $\\\\Delta S$ and the limit is obtained by shrinking $\\\\Delta V$ to the point $P$.\\n\\nBy the divergence theorem,\\n\\n$$\\n\\\\iiint_{\\\\Delta V} \\\\operatorname{div} \\\\mathbf{A} d V=\\\\iint_{\\\\Delta S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S\\n$$\\n\\nBy the mean value theorem for integrals, the left side can be written\\n\\n$$\\n\\\\overline{\\\\operatorname{div} \\\\mathbf{A}} \\\\iiint_{\\\\Delta V} d V=\\\\overline{\\\\operatorname{div} \\\\mathbf{A}} \\\\Delta V\\n$$\\n\\nwhere $\\\\overline{\\\\operatorname{div} \\\\mathbf{A}}$ is some value intermediate between the maximum and minimum of $\\\\operatorname{div} \\\\mathbf{A}$ throughout $\\\\Delta V$. Then\\n\\n$$\\n\\\\operatorname{div} \\\\mathbf{A}=\\\\frac{\\\\iint_{\\\\Delta S} \\\\mathbf{A} \\\\cdot \\\\mathbf{n} d S}{\\\\Delta V}\\n$$\\n\\nTaking the limit as $\\\\Delta V \\\\rightarrow 0$ such that $P$ is always interior to $\\\\Delta V, \\\\overline{\\\\operatorname{div} \\\\mathbf{A}}$ approaches the value $\\\\operatorname{div} \\\\mathbf{A}$ at point $P$ : hence,\\n\\n$$\\n\\\\operatorname{div} \\\\mathrm{A}=\\\\lim _{\\\\Delta V \\\\rightarrow 0} \\\\frac{\\\\iint_{\\\\Delta S} \\\\mathrm{~A} \\\\cdot \\\\mathrm{n} d S}{\\\\Delta V}\\n$$\\n\\nThis result can be taken as a starting point for defining the divergence of $\\\\mathbf{A}$, and from it all the properties may be derived, including proof of the divergence theorem. We can also use this to extend the concept of divergence to coordinate systems other than rectangular (see Page 170).\\n\\nPhysically, $\\\\left(\\\\iiint_{\\\\Delta S} \\\\mathrm{~A} \\\\cdot \\\\mathrm{n} d S\\\\right) / \\\\Delta V$ represents the flux or net outflow per unit volume of the vector $\\\\mathbf{A}$ from the surface $\\\\Delta S$. If div $\\\\mathbf{A}$ is positive in the neighborhood of a point $P$, it means that the outflow from $P$ is positive, and we call $P$ a source. Similarly, if $\\\\operatorname{div} \\\\mathbf{A}$ is negative in the neighborhood of $P$, the outflow is really an inflow, and $P$ is called a sink. If in a region there are no sources or sinks, then $\\\\operatorname{div} \\\\mathbf{A}=0$, and we call $\\\\mathbf{A}$ a solenoidal vector field.\\n\\n',\n",
       " '11.1. (a) Prove that $\\\\frac{1}{1 \\\\cdot 3}+\\\\frac{1}{3 \\\\cdot 5}+\\\\frac{1}{5 \\\\cdot 7}+\\\\cdots=\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{(2 n-1)(2 n+1)}$ converges and (b) find its sum.\\n\\n$$\\nu_{n}=\\\\frac{1}{(2 n-1)(2 n+1)}=\\\\frac{1}{2}\\\\left(\\\\frac{1}{2 n-1}-\\\\frac{1}{2 n+1}\\\\right)\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nS_{n}=u_{1}+u_{2}+\\\\cdots+u_{n} & =\\\\frac{1}{2}\\\\left(\\\\frac{1}{1}-\\\\frac{1}{3}\\\\right)+\\\\frac{1}{2}\\\\left(\\\\frac{1}{3}-\\\\frac{1}{5}\\\\right)+\\\\cdots+\\\\frac{1}{2}\\\\left(\\\\frac{1}{2 n-1}-\\\\frac{1}{2 n+1}\\\\right) \\\\\\\\\\n& =\\\\frac{1}{2}\\\\left(\\\\frac{1}{1}-\\\\frac{1}{3}+\\\\frac{1}{3}-\\\\frac{1}{5}+\\\\frac{1}{5}-\\\\cdots+\\\\frac{1}{2 n-1}-\\\\frac{1}{2 n+1}\\\\right)=\\\\frac{1}{2}\\\\left(1-\\\\frac{1}{2 n+1}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nSince $\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{2}\\\\left(1-\\\\frac{1}{2 n+1}\\\\right)=\\\\frac{1}{2}$, the series converges and its sum is $1 / 2$.\\n\\nThe series is sometimes called a telescoping series, since the terms of $S_{n}$, other than the first and last, cancel out in pairs.\\n',\n",
       " '\\n11.2. (a) Prove that $\\\\frac{2}{3}+\\\\left(\\\\frac{2}{3}\\\\right)^{2}+\\\\left(\\\\frac{2}{3}\\\\right)^{3}+\\\\cdots=\\\\sum_{n=1}^{\\\\infty}\\\\left(\\\\frac{2}{3}\\\\right)^{n}$ converges and (b) find its sum.\\n\\nThis is a geometric series; therefore, the partial sums are of the form $S_{n}=\\\\frac{a\\\\left(1-r^{n}\\\\right)}{1-r}$. Since $|r|<1$ $S=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}=\\\\frac{a}{1-r}$ and in particular with $r=\\\\frac{2}{3}$ and $a=\\\\frac{2}{3}$, we obtain $S=2$.\\n',\n",
       " '\\n11.3. Prove that the series $\\\\frac{1}{2}+\\\\frac{2}{3}+\\\\frac{3}{4}+\\\\frac{4}{5}+\\\\cdots=\\\\sum_{n=1}^{\\\\infty} \\\\frac{n}{n+1}$ diverges.\\n\\n$\\\\lim _{n \\\\rightarrow \\\\infty} u_{n}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{n}{n+1}=1$. Hence, by Problem 2.26, the series is divergent.\\n',\n",
       " '\\n11.4. Show that the series whose $n$th term is $u_{n}=\\\\sqrt{n+1}-\\\\sqrt{n}$ diverges although $\\\\lim _{x \\\\rightarrow \\\\infty} u_{n}=0$.\\n\\nIt is a fact that $\\\\lim _{x \\\\rightarrow \\\\infty} u_{n}=0$ follows from Problem 2.14(c).\\n\\nNow $S_{n}=u_{1}+\\\\stackrel{\\\\substack{x \\\\rightarrow \\\\infty \\\\\\\\ u_{2}}}{+\\\\cdots+u_{n}}=(\\\\sqrt{2}-\\\\sqrt{1})+(\\\\sqrt{3}-\\\\sqrt{2})+\\\\cdots+((\\\\sqrt{n+1}-\\\\sqrt{n})=\\\\sqrt{n+1}-\\\\sqrt{1}$.\\n\\nThe $S_{n}$ increases without bound and the series diverges.\\n\\nThis problem shows that $\\\\lim _{x \\\\rightarrow \\\\infty}=0$ is a necessary but not sufficient condition for the convergence of $\\\\Sigma u_{n}$\\n\\nSee also Problem 11.6.\\n\\n\\n\\\\section*{Comparison test and quotient test}\\n',\n",
       " '11.5. If $0 \\\\leq u_{n} \\\\leq v_{n}, n=1,2,3, \\\\ldots$ and if $\\\\Sigma v_{n}$ converges, prove that $\\\\Sigma u_{n}$ also converges (i.e., establish the comparison test for convergence).\\n\\nLet $S_{n}=u_{1}+u_{2}+\\\\cdots+u_{n}, T_{n}=v_{1}+v_{2}+\\\\cdots+v_{n}$.\\n\\nSince $\\\\Sigma v_{n}$ converges, $\\\\lim _{n \\\\rightarrow \\\\infty} T_{n}$ exists and equals $T$, say. Also, since $v_{n} \\\\geqq 0, T_{n} \\\\leqq T$.\\n\\nThen $S_{n}=u_{1}+u_{2}+\\\\cdots+u_{n} \\\\leqq v_{1}+v_{2}+\\\\cdots+v_{n} \\\\leqq T$ or $0 \\\\leqq S_{n} \\\\leqq T$\\n\\nThus $S_{n}$ is a bounded monotonic increasing sequence and must have a limit (see Chapter 2); i.e., $\\\\Sigma u_{n}$ converges.\\n',\n",
       " '\\n11.6. Using the comparison test, prove that $1+\\\\frac{1}{2}+\\\\frac{1}{3}+\\\\cdots=\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n}$ diverges.\\n\\nWe have\\n\\n$$\\n\\\\begin{aligned}\\n1 & \\\\geqq \\\\frac{1}{2} \\\\\\\\\\n\\\\frac{1}{2}+\\\\frac{1}{3} & \\\\geqq \\\\frac{1}{4}+\\\\frac{1}{4}=\\\\frac{1}{2} \\\\\\\\\\n\\\\frac{1}{4}+\\\\frac{1}{5}+\\\\frac{1}{6}+\\\\frac{1}{7} & \\\\geqq \\\\frac{1}{8}+\\\\frac{1}{8}+\\\\frac{1}{8}+\\\\frac{1}{8}=\\\\frac{1}{2} \\\\\\\\\\n\\\\frac{1}{8}+\\\\frac{1}{9}+\\\\frac{1}{10}+\\\\cdots+\\\\frac{1}{15} & \\\\geqq \\\\frac{1}{16}+\\\\frac{1}{16}+\\\\frac{1}{16}+\\\\cdots+\\\\frac{1}{16}(8 \\\\text { terms })=\\\\frac{1}{2}\\n\\\\end{aligned}\\n$$\\n\\nand soon. Thus, to any desired number of terms.\\n\\n$$\\n1+\\\\left(\\\\frac{1}{2}+\\\\frac{1}{3}\\\\right)+\\\\left(\\\\frac{1}{4}+\\\\frac{1}{5}+\\\\frac{1}{6}+\\\\frac{1}{7}\\\\right)+\\\\cdots \\\\geqq \\\\frac{1}{2}+\\\\frac{1}{2}+\\\\frac{1}{2}+\\\\cdots\\n$$\\n\\nSince the right-hand side can be made larger than any positive number by choosing enough terms, the given\\n\\nseries diverges.\\\\\\\\\\nBy methods analogous to that used here, we can show that $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{p}}$, where $p$ is a constant, diverges if $p$ $\\\\leqq 1$ and converges if $p>1$. This can also be shown in other ways [see Problem 11.13(a)].\\n',\n",
       " '\\n11.7. Test for convergence or divergence $\\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\ln n}{2 n^{3}-1}$.\\n\\nSince In $n<n$ and $\\\\frac{1}{2 \\\\mathrm{n}^{3}-1} \\\\leqq \\\\frac{1}{n^{3}}$, we have $\\\\frac{\\\\text { In } n}{2 n^{3}-1} \\\\leqq \\\\frac{n}{n^{3}}=\\\\frac{1}{n^{2}}$.\\n\\nThen the given series converges, since $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}}$ converges. 11.8. Let $u_{n}$ and $v_{n}$ be positive. If $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{u_{n}}{v_{n}}=$ constant $A \\\\neq 0$, prove that $\\\\Sigma u_{n}$ converges or diverges according as\\\\\\\\\\n$\\\\Sigma v_{n}$ converges or diverges. By hypothesis, given $\\\\epsilon>0$, we can choose an integer $N$ such that $\\\\left|\\\\frac{u_{n}}{v_{n}}-A\\\\right|<\\\\varepsilon$ for all $n>N$. Then for\\\\\\\\\\n$n=N+1, N+2, \\\\ldots$\\n\\n\\n\\\\begin{equation*}\\n-\\\\varepsilon<f \\\\frac{u_{n}}{v_{n}}-A<\\\\varepsilon \\\\quad \\\\text { or } \\\\quad(A-\\\\varepsilon) v_{n}<u_{n}(A+\\\\varepsilon) v_{n} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSumming from $N+1$ to $\\\\infty$ (more precisely, from $N+1$ to $M$ and then letting $M \\\\rightarrow \\\\infty$ ),\\n\\n\\n\\\\begin{equation*}\\n(A-\\\\varepsilon) \\\\sum_{N+1}^{\\\\infty} v_{n} \\\\leqq \\\\sum_{N+1}^{\\\\infty} u_{n} \\\\leqq(A+\\\\varepsilon) \\\\sum_{N+1}^{\\\\infty} v_{n} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nThere is no loss in generality in assuming $A-\\\\epsilon>0$. Then from the right-hand inequality of Equation (2), $\\\\Sigma u_{n}$ converges when $\\\\Sigma v_{n}$ does. From the left-hand inequality of Equation (2), $\\\\Sigma u_{n}$ diverges when $\\\\Sigma v_{n}$ does. For the cases $A=0$ or $A=\\\\infty$, see Problem 11.66.\\n',\n",
       " \"\\n11.9. Test for convergence: (a) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{4 n^{2}-n+3}{n^{3}+2 n}$, (b) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{n+\\\\sqrt{n}}{2 n^{3}-1}$, and (c) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\ln n}{n^{2}+3}$.\\n\\n(a) For large $n, \\\\frac{4 n^{2}-n+3}{n^{3}+2 n}$ is approximately $\\\\frac{4 n^{2}}{n^{3}}=\\\\frac{4}{n}$. Taking $u_{n}=\\\\frac{4 n^{2}-n+3}{n^{3}+2 n}$ and $v_{n}=\\\\frac{4}{n}$, we have $\\\\lim _{n \\\\rightarrow \\\\infty}=\\\\frac{u_{n}}{v_{n}}=1$.\\n\\nSince $\\\\Sigma v_{n}=4 \\\\Sigma 1 / n$ diverges, $\\\\Sigma u_{n}$ also diverges, by Problem 11.8 .\\n\\nNote that the purpose of considering the behavior of $u_{n}$ for large $n$ is to obtain an appropriate comparison series $v_{n}$. In this case we could just as well have taken $v_{n}=1 / n$.\\n\\nAnother method: $\\\\lim _{n \\\\rightarrow \\\\infty} n\\\\left(\\\\frac{4 n^{2}-n+3}{n^{3}+2 n}\\\\right)=4$. Then by Theorem 1, Page 281, the series converges.\\n\\n(b) For large $n, u_{n}=\\\\frac{n+\\\\sqrt{n}}{2 n^{3}-1}$ is approximately $v_{n}=\\\\frac{n}{2 n^{3}}=\\\\frac{1}{2 n^{2}}$.\\n\\nSince $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{u_{n}}{v_{n}}=1$ and $\\\\sum v_{n}=\\\\frac{1}{2} \\\\sum \\\\frac{1}{n^{2}}$ converges ( $p$ series with $p=2$ ), the given series converges.\\n\\nAnother method: $\\\\lim _{n \\\\rightarrow \\\\infty} n^{2}\\\\left(\\\\frac{n+\\\\sqrt{n}}{2 n^{3}-1}\\\\right)=\\\\frac{1}{2}$. Then by Theorem 1, Page 281, the series converges.\\n\\n(c) $\\\\lim _{n \\\\rightarrow \\\\infty} n^{3 / 2}\\\\left(\\\\frac{\\\\ln n}{n^{2}+3}\\\\right) \\\\leqq \\\\lim _{n \\\\rightarrow \\\\infty} n^{3 / 2}\\\\left(\\\\frac{\\\\ln n}{n^{2}}\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{\\\\ln n}{\\\\sqrt{n}}=0$ (by L'Hospital's rule or otherwise). Then by Theorem 1 with $\\\\mathrm{p}=3 / 2$. the series converges.\\n\\nNote that the method of Problem 11.6(a) yields $\\\\frac{\\\\ln n}{n^{2}+3}<\\\\frac{n}{n^{2}}=\\\\frac{1}{n}$, but nothing can be deduced, since $\\\\Sigma 1 / n$ diverges.\\n\",\n",
       " \"\\n11.10. Examine for convergence: (a) $\\\\sum_{n=1}^{\\\\infty} e^{-n^{2}}$ and (b) $\\\\sum_{n=1}^{\\\\infty} \\\\sin ^{3}\\\\left(\\\\frac{1}{n}\\\\right)$.\\n\\n(a) $\\\\lim _{n \\\\rightarrow \\\\infty} n^{2} e^{-n^{2}}=0$ (by L'Hospital's rule or otherwise). Then by Theorem 1 with $\\\\mathrm{p}=2$, the series converges.\\n\\n(b) For large $\\\\mathrm{n}, \\\\sin (1 / \\\\mathrm{n})$ is approximately $1 / \\\\mathrm{n}$. This leads to consideration of\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} n^{3} \\\\sin ^{3}\\\\left(\\\\frac{1}{n}\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{\\\\sin (1 / n}{1 / n}\\\\right\\\\}^{3}=1\\n$$\\n\\nfrom which we deduce, by Theorem 1 with $p=3$, that the given series converges.\\n\\n\\n\\\\section*{Integral test}\\n\",\n",
       " '11.11. Establish the integral test (see Page 281).\\n\\nWe perform the proof taking $N=1$. Modifications are easily made if $N>1$.\\n\\nFrom the monotonicity of $f(x)$, we have\\n\\n$$\\nu_{n+1}=f(n+1) \\\\leqq f(x) \\\\leqq f(n)=u_{n} \\\\quad n=1,2,3, \\\\ldots\\n$$\\n\\nIntegrating from $x=n$ to $x=n+1$, using Property 7, Page 98,\\n\\n$$\\nu_{n+1} \\\\leqq \\\\int_{n}^{n+1} f(x) d x \\\\leqq u_{n} \\\\quad n=1,2,3 \\\\ldots\\n$$\\n\\nSumming from $n=1$ to $M-1$,\\n\\n\\n\\\\begin{equation*}\\nu_{2}+u_{3}+\\\\cdots+u_{M} \\\\leqq \\\\int_{1}^{M} f(x) d x \\\\leqq u_{1}+u_{2}+\\\\cdots u_{M-1} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf $f(x)$ is strictly decreasing, the equality signs in Equation (1) can be omitted.\\n\\nIf $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{1}^{M} f(x) d x$ exists and is equal to $S$, we see from the left-hand inequality in Equation (1) that $u_{2}+u_{3}+\\\\cdots+u_{M}$ is monotonic increasing and bounded above by $S$, so that $\\\\Sigma u_{n}$ converges.\\n\\nIf $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{1}^{M} f(x) d x$ is unbounded, we see from right-hand inequality in Equation (1) that $\\\\sigma u_{n}$ diverges.\\n\\nThus, the proof is complete.\\n',\n",
       " '\\n11.12. Illustrate geometrically the proof in Problem 11.11.\\n\\nGeometrically, $u_{2}+u_{3}+\\\\cdots+u_{M}$ is the total area of the rectangles shown shaded in Figure 11.3, while $u_{1}+u_{2}+\\\\cdots+u_{M-1}$ is the total area of the rectangles which are shaded and nonshaded.\\n\\nThe area under the curve $y=f(x)$ from $x=1$ to $x=M$ is intermediate in value between the two areas given above, thus illustrating the result (1) of Problem 11.11.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-306}\\n\\\\end{center}\\n\\nFigure 11.3\\n',\n",
       " '\\n11.13. Test for convergence:\\n\\n(a) $\\\\sum_{1}^{\\\\infty} \\\\frac{1}{n^{p}}, p=\\\\mathrm{constant}$\\n\\n(b) $\\\\sum_{1}^{\\\\infty} \\\\frac{n}{n^{2}+1}$\\n\\n(c) $\\\\sum_{2}^{\\\\infty} \\\\frac{1}{n \\\\ln n}$\\n\\n(d) $\\\\sum_{1}^{\\\\infty} n e^{-n^{2}}$\\n\\n(a) Consider $\\\\int_{1}^{M} \\\\frac{d x}{x^{p}}=\\\\int_{1}^{M} x^{-p} d x=\\\\left.\\\\frac{x^{1-p}}{1-p}\\\\right|_{1} ^{M}=\\\\frac{M^{1-p}}{1-p}$, where $p \\\\neq 1$.\\n\\nIf $p<1, \\\\lim _{M \\\\rightarrow \\\\infty} \\\\frac{M^{1-p}-1}{1-p}=\\\\infty$, so that integral, and thus the series, diverges.\\n\\nIf $p>1, \\\\lim _{M \\\\rightarrow \\\\infty} \\\\frac{M^{1-p}-1}{1-p}=\\\\frac{1}{p-1}$, so that the integral, and thus the series, converges.\\n\\nIf $p=1, \\\\quad \\\\int_{1}^{M} \\\\frac{d x}{x^{p}}=\\\\int_{1}^{M} \\\\frac{d x}{x}=\\\\ln M$ and $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\ln M=\\\\infty$, so that the integral, and thus the series, diverges. Thus, the series converges if $p>1$ and diverges if $p \\\\leqq 1$.\\\\\\\\\\n(b) $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{1}^{M} \\\\frac{x d x}{x^{2}+1}=\\\\left.\\\\lim _{M \\\\rightarrow \\\\infty} \\\\frac{1}{2} \\\\ln \\\\left(x^{2}+1\\\\right)\\\\right|_{1} ^{M}=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{1}{2} \\\\ln \\\\left(M^{2}+1\\\\right)-\\\\frac{1}{2}\\\\right\\\\}=\\\\infty$ and the series diverges.\\n\\n(c) $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{1}^{M} \\\\frac{d x}{x \\\\ln x}=\\\\left.\\\\lim _{M \\\\rightarrow \\\\infty} \\\\ln (\\\\ln x)\\\\right|_{2} ^{M}=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\{\\\\ln (\\\\ln M)-\\\\ln (\\\\ln 2)\\\\}=\\\\infty$ and the series diverges.\\n\\n(d) $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{1}^{M} x e^{-x^{2}} d x=\\\\lim _{M \\\\rightarrow \\\\infty}-\\\\left.\\\\frac{1}{2} e^{-x 2}\\\\right|_{1} ^{M}=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\frac{1}{2} e^{-1}-\\\\frac{1}{2} e^{-M^{2}}\\\\right\\\\}=\\\\frac{1}{2} e^{-1}$ and the series converges.\\n\\nNote that when the series converges, the value of the corresponding integral is not (in general) the same as the sum of the series. However, the approximate sum of a series can often be obtained quite accurately by using integrals. See Problem 11.74.\\n',\n",
       " '\\n11.14. Prove that Prove that $\\\\frac{\\\\pi}{4}<\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}+1}<\\\\frac{1}{2}+\\\\frac{\\\\pi}{4}$.\\n\\nFrom Problem 11.11 it follows that\\n\\n$$\\n\\\\lim _{M \\\\rightarrow \\\\infty} \\\\sum_{n=2}^{M} \\\\frac{1}{n^{2}+1}<\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{1}^{M} \\\\frac{d x}{x^{2}+1}<\\\\lim _{M \\\\rightarrow \\\\infty} \\\\sum_{n=1}^{M-1} \\\\frac{1}{n^{2}+1}\\n$$\\n\\ni.e., $\\\\sum_{n=2}^{\\\\infty} \\\\frac{1}{n^{2}+1}<\\\\frac{\\\\pi}{4}<\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}+1}$, from which $\\\\frac{\\\\pi}{4}<\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}+1}$ as required.\\n\\nSince $\\\\sum_{n=2}^{\\\\infty} \\\\frac{1}{n^{2}+1}<\\\\frac{\\\\pi}{4}$, we obtain, on adding $\\\\frac{1}{2}$ to each side, $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}+1}<\\\\frac{1}{2}+\\\\frac{\\\\pi}{4}$.\\n\\nThe required result is therefore proved.\\n\\n\\n\\\\section*{Alternating series}\\n',\n",
       " '11.15. Given the alternating series $a_{1}-a_{2}+a_{3}-a_{4}+\\\\cdots$, where $0 \\\\leq a_{n+1} \\\\leq a_{n}$ and where $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=0$, prove that (a) the series converges and (b) the error made in stopping at any term is not greater than the absolute value of the next term.\\n\\n(a) The sum of the series to $2 \\\\mathrm{M}$ terms is\\n\\n$$\\n\\\\begin{aligned}\\n& S_{2 M}=\\\\left(a_{1}-a_{2}\\\\right)+\\\\left(a_{3}-\\\\left(a_{4}\\\\right)+\\\\cdots+\\\\left(a_{2 M-1}-a_{2 M}\\\\right)\\\\right. \\\\\\\\\\n= & a_{1}-\\\\left(a_{2}-a_{3}\\\\right)-\\\\left(a_{4}-a_{5}\\\\right)-\\\\cdots-\\\\left(a_{2 M-2}-a_{2 M-1}\\\\right)-a_{2 M}\\n\\\\end{aligned}\\n$$\\n\\nSince the quantities in parentheses are nonnegative, we have\\n\\n$$\\nS_{2 M} \\\\geqq 0, \\\\quad S_{2} \\\\leqq S_{4} \\\\leqq S_{6} \\\\leqq S_{8} \\\\leqq \\\\cdots \\\\leqq S_{2 M} \\\\leqq a_{1}\\n$$\\n\\nTherefore, $\\\\left\\\\{S_{2 M}\\\\right\\\\}$ is a bounded monotonic increasing sequence and thus has limit $S$.\\n\\nAlso, $S_{2 M+1}=S_{2 M}+a_{2 M+1}$. Since $\\\\lim _{M \\\\rightarrow \\\\infty} S_{2 M}=S$ and $\\\\lim _{M \\\\rightarrow \\\\infty} a_{2 M+1}=0$ (for, by hypothesis, $\\\\lim _{M \\\\rightarrow \\\\infty}$ $a_{n}=0$ ), it follows that $\\\\lim _{M \\\\rightarrow \\\\infty} S_{2 M+1}=\\\\lim _{M \\\\rightarrow \\\\infty} S_{2 M}+\\\\lim _{M \\\\rightarrow \\\\infty} a_{2 M+1}=S+0=S$.\\n\\nThus, the partial sums of the series approach the limit $S$ and the series converges.\\n\\n(b) The error made in stopping after $2 \\\\mathrm{M}$ terms is\\n\\n$$\\n\\\\left(a_{2 M+1}-a_{2 M+2}\\\\right)+\\\\left(a_{2 M+3}-a_{2 M+4}\\\\right)+\\\\cdots=a_{2 M+1}-\\\\left(a_{2 M+2}-a_{2 M+3}\\\\right)-\\\\cdots\\n$$\\n\\nand is thus nonnegative and less than or equal to $a_{2 M+1}$, the first term which is omitted.\\n\\nSimilarly, the error made in stopping after $2 M+1$ terms is\\n\\n$$\\n-a_{2 M+2}+\\\\left(a_{2 M+3}-a_{2 M+4}\\\\right)+\\\\cdots=-\\\\left(a_{2 M+2}-a_{2 M+3}\\\\right)-\\\\left(a_{2 M+4}-a_{2 M+5}\\\\right)-\\\\cdots\\n$$\\n\\nwhich is nonpositive and greater than $-a_{2 M+2}$.\\n',\n",
       " '\\n11.16. (a) Prove that the series $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n+1}}{2 n-1}$. converges. (b) Find the maximum error made in approximating the sum by the first eight terms and the first nine terms of the series. (c)How many terms of the series are needed in order to obtain an error which does not exceed .001 in absolute value?\\n\\n(a) The series is $1-\\\\frac{1}{3}+\\\\frac{1}{5}-\\\\frac{1}{7}+\\\\frac{1}{9}-\\\\cdots$. If $u_{n}=\\\\frac{(-1)^{n+1}}{2 n-1}$, then $a_{n}=\\\\left|u_{n}\\\\right|=\\\\frac{1}{2 n-1}, a_{n+1}=\\\\left|u_{n+1}\\\\right|=$ $\\\\frac{1}{2 n+1}$. Since $\\\\frac{1}{2 n+1} \\\\leqq \\\\frac{1}{2 n-1}$ and since $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{2 n-1} 0$, it follows by Problem 11.5(a) that the series converges.\\n\\n(b) Use the results of Problem 11.15(b). Then the first eight terms give $1-\\\\frac{1}{3}+\\\\frac{1}{5}-\\\\frac{1}{7}+\\\\frac{1}{9}-\\\\frac{1}{11}+\\\\frac{1}{13}-\\\\frac{1}{15}$, and the error is positive and does not exceed $\\\\frac{1}{17}$.\\n\\nSimilarly, the first nine terms are $1-\\\\frac{1}{3}+\\\\frac{1}{5}-\\\\frac{1}{7}+\\\\frac{1}{9}-\\\\frac{1}{11}+\\\\frac{1}{13}-\\\\frac{1}{15}+\\\\frac{1}{17}$ and the error is negative and greater than or equal to $-\\\\frac{1}{19}$; i.e., the error does not exceed $\\\\frac{1}{19}$ in absolute value.\\n\\n(c) The absolute value of the error made in stopping after $\\\\mathrm{M}$ terms is less than $1 /(2 \\\\mathrm{M}+1)$. To obtain the desired accuracy, we must have $1 /(2 M+1) \\\\leqq .001$, form which $M \\\\geqq 499.5$. Thus, at least 500 terms are needed.\\n\\n\\n\\\\section*{Absolute and conditional convergence}\\n',\n",
       " '11.17. Prove that an absolutely convergent series is convergent.\\n\\nGiven that $\\\\Sigma\\\\left|u_{n}\\\\right|$ converges, we must show that $\\\\Sigma u_{n}$ converges.\\n\\nLet $S_{M}=u_{1}+u_{2}+\\\\cdots+u_{M}$ and $T_{M}=\\\\left|u_{1}\\\\right|+\\\\left|u_{2}\\\\right|+\\\\cdots+\\\\left|u_{M}\\\\right|$. Then\\n\\n$$\\n\\\\begin{aligned}\\nS_{M}+T_{M}= & \\\\left(u_{1}+\\\\left|u_{1}\\\\right|\\\\right)+\\\\left(u_{2}+\\\\left|u_{2}\\\\right|\\\\right)+\\\\cdots+\\\\left(u_{M}+\\\\left|u_{M}\\\\right|\\\\right) \\\\\\\\\\n& \\\\leqq 2\\\\left|u_{1}\\\\right|+2\\\\left|u_{2}\\\\right|+\\\\cdots+2\\\\left|u_{M}\\\\right|\\n\\\\end{aligned}\\n$$\\n\\nSince $\\\\Sigma\\\\left|u_{n}\\\\right|$ converges and since $u_{n}+\\\\left|u_{n}\\\\right| \\\\geqq 0$, for $n=1,2,3, \\\\ldots$, it follows that $S_{M}+T_{M}$ is a bounded monotonic increasing sequence, and so $\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left(S_{M}+T_{M}\\\\right)$ exists.\\n\\nAlso, since $\\\\lim _{M \\\\rightarrow \\\\infty} T_{M}$ exists (since the series is absolutely convergent by hypothesis),\\n\\n$$\\n\\\\lim _{M \\\\rightarrow \\\\infty} S_{M}=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left(S_{M}+T_{M}-T_{M}\\\\right)=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left(S_{M}+T_{M}\\\\right)-\\\\lim _{M \\\\rightarrow \\\\infty} T_{M}\\n$$\\n\\nmust also exist, and the result is proved.\\n',\n",
       " '\\n11.18. Investigate the convergence of the series $\\\\frac{\\\\sin \\\\sqrt{1}}{1^{3 / 2}}-\\\\frac{\\\\sin \\\\sqrt{2}}{2^{3 / 2}}+\\\\frac{\\\\sin \\\\sqrt{3}}{3^{3 / 2}}-\\\\cdots$.\\n\\nSince each term is, in absolute value, less than or equal to the corresponding term of the series $\\\\frac{1}{1^{3 / 2}}+\\\\frac{1}{2^{3 / 2}}+\\\\frac{1}{3^{3 / 2}}+\\\\cdots$. which converges, it follows that the given series is absolutely convergent and, hence, convergent by Problem 11.17.\\n',\n",
       " \"\\n11.19. Examine for convergence and absolute convergence:\\n\\n(a) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1}}{n^{2}+1}$\\\\\\\\\\n(b) $\\\\sum_{n=2}^{\\\\infty} \\\\frac{(-1)^{n-1}}{n \\\\operatorname{In}^{2} n}$\\n\\n(c) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1} 2^{n}}{n^{2}}$\\n\\n(a) The series of absolute values is $\\\\sum_{n=1}^{\\\\infty} \\\\frac{n^{2}}{n^{2}+1}$, which is divergent by Problem 11.13(b). Hence, the given series is not absolutely convergent\\n\\nHowever, if $a_{n}=\\\\left|u_{n}\\\\right|=\\\\frac{n}{n^{2}+1}$ and $a_{n+1}=\\\\left|u_{n+1}\\\\right|=\\\\frac{n+1}{(n+1)^{2}+1}$, then $a_{n+1} \\\\leqq a_{n}$ for all $n \\\\geqq 1$, and\\n\\nalso $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{n}{n^{2}+1}=0$. Hence, by Problem 11.15 the series converges.\\n\\nSince the series converges but is not absolutely convergent, it is conditionally convergent.\\n\\n(b) The series of absolute values is $\\\\sum_{n=2}^{\\\\infty} \\\\frac{1}{n \\\\ln ^{2} n}$. exist.\\n\\nBy the integral test, this series converges or diverges according as $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{2}^{M} \\\\frac{d x}{x \\\\ln ^{2} x}$ exists or does not If $u=\\\\ln x, \\\\int \\\\frac{d x}{x \\\\ln ^{2} x}=\\\\int \\\\frac{d u}{u^{2}}=-\\\\frac{1}{u}+c=-\\\\frac{1}{\\\\ln x}+c$. verges.\\n\\nHence, $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{2}^{M} \\\\frac{d x}{x \\\\ln ^{2} x}=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left(\\\\frac{1}{\\\\ln 2}-\\\\frac{1}{\\\\ln M}\\\\right)=\\\\frac{1}{\\\\ln 2}$, and the integral exists. Thus, the series conThen $\\\\sum_{n=2}^{\\\\infty} \\\\frac{(-1)^{n-1}}{n \\\\ln ^{2} n}$ converges absolutely and thus converges.\\n\\nAnother method: Since $\\\\frac{1}{(n+1) \\\\ln ^{2}(n+1)} \\\\leqq \\\\frac{1}{n \\\\ln ^{2} n}$ and $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{n \\\\ln ^{2} n}=0$, it follows by Problem 11.15(a), that the given alternating series converges. To examine its absolute convergence, we must proceed as\\n\\nbefore.\\\\\\\\\\n(c) Since $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n} \\\\neq 0$ where $u_{n}=\\\\frac{(-1)^{n-1} 2^{n}}{n^{2}}$, the given series cannot be convergent. To show that $\\\\lim _{n \\\\rightarrow \\\\infty} u_{n} \\\\neq 0$, it suffices to show that $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|u_{n}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2 n}{n^{2}} \\\\neq 0$. This can be accomplished by L'Hospital's rule or other methods [see Problem 11.21(b)].\\n\\n\\n\\\\section*{Ratio test}\\n\",\n",
       " '11.20. Establish the ratio test for convergence.\\n\\nConsider first the series $u_{1}+u_{2}+u_{3}+\\\\cdots$ where each term is nonnegative. We must prove that if $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{u_{n+1}}{u_{n}} L<1$, then necessarily $\\\\Sigma u_{n}$ converges.\\n\\nBy hypothesis, we can choose an integer $N$ so large that for all $n \\\\geqq N,\\\\left(u_{n+1} / u_{n}\\\\right)<r$ where $L<r<1$. Then\\n\\n$$\\n\\\\begin{aligned}\\n& u_{N+1}<r u_{N} \\\\\\\\\\n& u_{N+2}<r u_{N+1}<r^{2} u_{N} \\\\\\\\\\n& u_{N+3}<r u_{N+2}<r^{3} u_{N}\\n\\\\end{aligned}\\n$$\\n\\nand so on. By addition,\\n\\n$$\\nu_{N+1}+u_{N+2}+\\\\cdots<u_{N}\\\\left(r+r^{2}+r^{3}+\\\\cdots\\\\right)\\n$$\\n\\nand so the given series converges by the comparison test, since $0<r<1$.\\n\\nIn case the series has terms with mixed signs, we consider $\\\\left|u_{1}\\\\right|+\\\\left|u_{2}\\\\right|\\\\left|u_{3}\\\\right|+\\\\cdots$. By the preceding proof and Problem 11.17, it follows that if $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=L<1$, then $\\\\Sigma u_{n}$ converges (absolutely).\\n\\nSimilarly, we can prove that if $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=L>1$ the series $\\\\Sigma u_{n}$ diverges, while if $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=L=1$ the ratio test fails [see Problem 11.21(c)].\\n',\n",
       " '\\n11.21. Investigate the convergence of\\n\\n(a) $\\\\sum_{n=1}^{\\\\infty} n^{4} e^{-n^{2}}$\\n\\n(b) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1} 2^{n}}{n^{2}}$\\n\\n(c) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1} n}{n^{2}+1}$\\n\\n(a) Here $u_{n}=e^{-n^{2}}$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right| & =\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{(n+1)^{4} e^{-(n+1)^{2}}}{n^{4} e^{-n^{2}}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{(n+1)^{4} e-^{\\\\left(n^{2}+2 n+1\\\\right)}}{n^{4} e^{-n^{2}}} \\\\\\\\\\n& =\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(\\\\frac{n+1}{n}\\\\right)^{4} e^{-2 n-1}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(\\\\frac{n+1}{n}\\\\right)^{4} \\\\lim _{n \\\\rightarrow \\\\infty} e^{-2 n-1}=1 \\\\cdot 0=0\\n\\\\end{aligned}\\n$$\\n\\nSince $0<1$, the series converges.\\n\\n(b) Here $u_{n}=\\\\frac{(-1)^{n-1} 2^{n}}{n^{2}}$. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{(-1)^{n} 2^{n+1}}{(n+1)^{2}} \\\\cdot \\\\frac{n^{2}}{(-1)^{n-1} 2^{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2 n^{2}}{(n+1)^{2}}=2\\n$$\\n\\nSince $s>1$, the series diverges. Compare Problem 11.19(c).\\n\\n(c) Here $u_{n}=\\\\frac{(-1)^{n-1} n}{n^{2}+1}$. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{(-1)^{n}(n+1)}{(n+1)^{2}+1} \\\\cdot \\\\frac{n^{2}+1}{(-1)^{n-1} n}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{(n+1)\\\\left(n^{2}+1\\\\right)}{\\\\left(n^{2}+2 n+2\\\\right)^{n}}=1\\n$$\\n\\nand the ratio test fails. By using other tests [see Problem 11.19(a)], the series is seen to be convergent.\\n\\n\\n\\\\section*{Miscellaneous tests}\\n',\n",
       " '11.22. Test for convergence $1+2 r+r^{2}+2 r^{3}+r^{4}+2 r^{5}+\\\\cdots$ where (a) $r=2 / 3$, (b) $r=-2 / 3$, (c) $r=4 / 3$.\\n\\nHere the ratio test is inapplicable, since $\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=2|r|$ or $\\\\frac{1}{2}|r|$, depending on whether $n$ is odd or even.\\n\\nHowever, using the $n$th root test, we have\\n\\n$$\\n\\\\sqrt[n]{\\\\left|u_{n}\\\\right|}= \\\\begin{cases}\\\\sqrt[n]{2\\\\left|r^{n}\\\\right|}=\\\\sqrt[n]{2|r|} & \\\\text { if } n \\\\text { is odd } \\\\\\\\ \\\\sqrt[n]{\\\\left|r^{n}\\\\right|}=|r| & \\\\text { if } n \\\\text { is even }\\\\end{cases}\\n$$\\n\\nThen $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\sqrt[n]{\\\\left|u_{n}\\\\right|}=|r|\\\\left(\\\\right.$ since $\\\\left.\\\\lim _{n \\\\rightarrow \\\\infty} 2^{1 / n}=1\\\\right)$.\\n\\nThus, if $|r|<1$ the series converges, and if $|r|>1$ the series diverges.\\n\\nHence, the series converges for cases (a) and (b), and diverges in case (c).\\n',\n",
       " \"\\n11.23. Test for convergence $\\\\left(\\\\frac{1}{3}\\\\right)^{2}+\\\\left(\\\\frac{1 \\\\cdot 4}{3 \\\\cdot 6}\\\\right)^{2}+\\\\left(\\\\frac{1 \\\\cdot 4 \\\\cdot 7}{3 \\\\cdot 6 \\\\cdot 9}\\\\right)^{2}+\\\\cdots+\\\\left(\\\\frac{1 \\\\cdot 4 \\\\cdot 7 \\\\ldots(3 n-2)}{3 \\\\cdot 6 \\\\cdot 9 \\\\ldots(3 n)}\\\\right)^{2}+\\\\cdots$.\\n\\nThe ratio test fails, since $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(\\\\frac{3 n+1}{3 n+3}\\\\right)^{2}=1$. However, by Raabe's test,\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} n\\\\left(1-\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty} n\\\\left\\\\{1-\\\\left(\\\\frac{3 n+1}{3 n+3}\\\\right)^{2}\\\\right\\\\}=\\\\frac{4}{3}>1\\n$$\\n\\nand so the series converges.\\n\",\n",
       " \"\\n11.24. Test for convergence $\\\\left(\\\\frac{1}{2}\\\\right)^{2}+\\\\left(\\\\frac{1 \\\\cdot 3}{2 \\\\cdot 4}\\\\right)^{2}+\\\\left(\\\\frac{1 \\\\cdot 3 \\\\cdot 5}{24 t}\\\\right)^{2}+\\\\cdots+\\\\left(\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\ldots(2 n-1)^{2}}{2 \\\\cdot 4 \\\\cdot 6 \\\\ldots(2 n)}\\\\right)+\\\\cdots$.\\n\\nThe ratio test fails, since $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(\\\\frac{2 n+1}{2 n+2}\\\\right)^{2}=1$. Also, Raabe's test fails since\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} n\\\\left(1-\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|\\\\right)=\\\\lim _{n \\\\rightarrow \\\\infty} n\\\\left\\\\{1-\\\\left(\\\\frac{2 n+1}{2 n+2}\\\\right)^{2}\\\\right\\\\}=1\\n$$\\n\\nHowever, using long division,\\n\\n$$\\n\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\left(\\\\frac{2 n+1}{2 n+2}\\\\right)^{2}=1-\\\\frac{1}{n}+\\\\frac{5-4 / n}{4 n^{2}+8 n+4}=1-\\\\frac{1}{n}+\\\\frac{c_{n}}{n^{2}} \\\\quad \\\\text { where }\\\\left|c_{n}\\\\right|<P\\n$$\\n\\nso that the series diverges by Gauss's test.\\n\\n\\n\\\\section*{Series of functions}\\n\",\n",
       " '11.25. For what values of $x$ do the following series converge?\\n\\n(a) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{x^{n-1}}{n \\\\cdot 3^{n}}$\\n\\n(b) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1} x^{2 n-1}}{(2 n-1) !}$\\n\\n(c) $\\\\sum_{n=1}^{\\\\infty} n !(x-a)^{n}$\\n\\n(d) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{n(x-1)^{n}}{2^{n}(3 n-1)}$\\n\\n(a) $u_{n}=\\\\frac{x^{n-1}}{n \\\\cdot 3^{n}}$. Assuming $\\\\mathrm{x} \\\\neq 0$ (if $\\\\mathrm{x}=0$ the series converges), we have\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{x^{n}}{(n+1) \\\\cdot 3^{n+1}} \\\\cdot \\\\frac{n \\\\cdot 3^{n}}{x^{n-1}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{n}{3(n+1)}|x|=\\\\frac{|x|}{3}\\n$$\\n\\nThen the series converges if $\\\\frac{|x|}{3}<1$, and diverges if $\\\\frac{|x|}{3}>1$. If $\\\\frac{|x|}{3}=1$. i.e., $x= \\\\pm 3$, the test fails.\\n\\nIf $x=3$ the series becomes $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{3 n}=\\\\frac{1}{3} \\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n}$, which diverges.\\n\\nIf $x=-3$ the series becomes $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1}}{3 n}=\\\\frac{1}{3} \\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1}}{n}$, which converges.\\n\\nThen the interval of convergence is $-3 \\\\leqq x<3$. The series diverges outside this interval.\\n\\nNote that the series converges absolutely for $-3<x<3$. At $x=-3$ the series converges conditionally.\\n\\n(b) Proceed as in (a) with $u_{n}=\\\\frac{(-1)^{n-1} x^{2 n-1}}{(2 n-1) !}$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right| & =\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{(-1)^{n} x^{2 n+1}}{(2 n+1) !} \\\\cdot \\\\frac{(2 n-1) !}{(-1)^{n-1} x^{2 n-1}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{(2 n-1) !}{(2 n+1) !} x^{2} \\\\\\\\\\n& =\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{(2 n-1) !}{(2 n+1)(2 n)(2 n-1) !} x^{2}=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{x^{2}}{(2 n+1)(2 n)}=0\\n\\\\end{aligned}\\n$$\\n\\nThen the series converges (absolutely) for all $x$, i.e., the interval of (absolute) convergence is $-\\\\infty<x<\\\\infty$.\\n\\n(c) $u_{n}=n !(x-a)^{n}, \\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{(n+1) !(x-a)^{n+1}}{n !(x-a)^{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}(n+1)|x-a|$.\\n\\nThis limit is infinite if $x \\\\neq a$. Then the series converges only for $x=a$.\\n\\n(d) $u_{n}=\\\\frac{n(x-1)^{n}}{2^{n}(3 n-1)}, u_{n+1}=\\\\frac{(n+1)(x-1)^{n+1}}{2^{n+1}(3 n+2)}$. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{(n+1)(3 n-1)(x-1)}{2 n(3 n+2)}\\\\right|=\\\\left|\\\\frac{x-1}{2}\\\\right|=\\\\frac{|x-1|}{2}\\n$$\\n\\nThus, the series converges for $|x-1|<2$ and diverges for $|x-1|>2$.\\n\\nThe test fails for $|x-1|=2$; i.e., $x-1= \\\\pm 2$ or $x=3$ and $x=-1$.\\n\\nFor $x=3$ the series becomes $\\\\sum_{n=1}^{\\\\infty} \\\\frac{n}{3 n-1}$, which diverges, since the $n$th term does not approach zero. zero.\\n\\nFor $x=-1$ the series becomes $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n} n}{3 n-1}$, which also diverges, since the $n$ the term does not approach\\n\\nThen the series converges only for $|x-1|<2$; i.e., $-2<x-1<2$ or $-1<x<3$.\\n',\n",
       " '\\n11.26. For what values of $x$ does (a) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{2 n-1}\\\\left(\\\\frac{x+2}{x-1}\\\\right)^{n}$ and (b) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{(x+n)(x+n-1)}$ converge?\\n\\n(a) $u_{n}=\\\\frac{1}{2 n-1}\\\\left(\\\\frac{x+2}{x-1}\\\\right)^{n}$. Then $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{2 n-1}{2 n+1}\\\\left|\\\\frac{x+2}{x-1}\\\\right|=\\\\left|\\\\frac{x+2}{x-1}\\\\right| \\\\quad$ if $\\\\quad x \\\\neq 1,-2$.\\n\\n\\\\includegraphics[max width=\\\\textwidth, center]{2024_04_03_ffb6ac533fe0a53b3ceeg-312}\\\\\\\\\\n$x=-\\\\frac{1}{2}$.\\n\\nIf $x=1$, the series diverges.\\n\\nIf $x=-2$, the series converges.\\n\\nIf $x-\\\\frac{1}{2}$, the series is $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n}}{2 n-1}$, which converges.\\n\\nThus, the series converges for $\\\\left|\\\\frac{x+2}{x-1}\\\\right|<1, x=-\\\\frac{1}{2}$, and $x=-2$, i.e., for $x \\\\leqq-\\\\frac{1}{2}$.\\\\\\\\\\n(b) The ratio test fails, since $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=1$, where $u_{n}=\\\\frac{1}{(x+n)(x+n-1)}$. However, noting that\\n\\n$$\\n\\\\frac{1}{(x+n)(x+n-1)}=\\\\frac{1}{x+n-1}-\\\\frac{1}{x+n}\\n$$\\n\\nwe see that if $x \\\\neq 0,-1,-2, \\\\ldots,-n$,\\n\\n$$\\n\\\\begin{aligned}\\nS_{n}=u_{1}+u_{2}+\\\\cdots+u_{n}= & \\\\left(\\\\frac{1}{x}-\\\\frac{1}{x+1}\\\\right)+\\\\left(\\\\frac{1}{x+1}-\\\\frac{1}{x+2}\\\\right)+\\\\cdots+\\\\left(\\\\frac{1}{x+n-1}-\\\\frac{1}{x+n}\\\\right) \\\\\\\\\\n= & \\\\frac{1}{x}-\\\\frac{1}{x+n}\\n\\\\end{aligned}\\n$$\\n\\nand $\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}=1 / x$, provided $x \\\\neq 0,-1,-2,-3, \\\\ldots$.\\n\\nThen the series converges for all $x$ except $x=0,-1,-2,-3, \\\\ldots$, and its sum is $1 / x$.\\n\\n\\n\\\\section*{Uniform convergence}\\n',\n",
       " '11.27. Find the domain of convergence of $(1-x)+x(1-x)+x^{2}(1-x)+\\\\cdots$.\\n\\n\\n\\\\section*{Method 1:}\\nSum of first $n$ terms $S_{n}(x)=(1-x)+x(1-x)+x^{2}(1-x)+\\\\cdots+x^{n-1}(1-x)$\\n\\n$$\\n\\\\begin{aligned}\\n& =1-x+x-x^{2}+x^{2}+\\\\cdots+x^{n-1}-x^{n} \\\\\\\\\\n& =1-x^{n}\\n\\\\end{aligned}\\n$$\\n\\nIf $|x|<1, \\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1-x^{n}\\\\right)=1$.\\n\\nIf $|x|>1 . \\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)$ does not exist.\\n\\nIf $x=1, S_{n}(x)=0$ and $\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)=0$.\\n\\nIf $x=-1, S_{n}(x)=1-(-1)^{n}$ and $\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)$ does not exist.\\n\\nThus, the series converges for $|x|<1$ and $x=1$, i.e., for $-1<x \\\\leqq 1$.\\n\\nMethod 2, using the ratio test: The series converges if $x=1$. If $x \\\\neq 1$ and $u_{n}=x^{n-1}(1-x)$, then $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}|x|$.\\n\\nThus, the series converges if $|x|<1$ and diverges if $|x|>1$. The test fails if $|x|=1$. If $x=1$, the series converges; if $x=-1$, the series diverges. Then the series converges for $-1<x \\\\leqq 1$.\\n',\n",
       " '\\n11.28. Investigate the uniform convergence of the series of Problem 11.27 in the interval (a) $-\\\\frac{1}{2}<x<\\\\frac{1}{2}$,\\n\\n(b) $-\\\\frac{1}{2} \\\\leqq x \\\\leqq \\\\frac{1}{2}$, (c) $-.99 \\\\leqq x \\\\leqq .99$, (d) $-1<x<1$, and (e) $0 \\\\leqq x<2$. (a) By Problem 11.27, $S_{n}(x)=1-x^{n}, S(x)=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)=1$ if $-\\\\frac{1}{2}<x<\\\\frac{1}{2}$; thus, the series converges in\\\\\\\\\\nthis interval. We have\\n\\n$$\\n\\\\text { Remainder after } n \\\\text { terms }=R_{n}(x)=S(x)=S_{n}(x)=1-\\\\left(1-x^{n}\\\\right)=x^{n}\\n$$\\n\\nThe series is uniformly convergent in the interval if given any $\\\\epsilon>0$ we can find $N$ dependent on $\\\\epsilon$, but not on $x$, such that $\\\\left|R_{n}(x)\\\\right|<\\\\epsilon$ for all $n>N$. Now\\n\\n$$\\n\\\\left|R_{n}(x)\\\\right|=\\\\left|x^{n}\\\\right|=|x|^{n}<\\\\varepsilon \\\\quad \\\\text { when } \\\\quad n \\\\ln |x|<\\\\ln \\\\varepsilon \\\\quad \\\\text { or } \\\\quad n>\\\\frac{\\\\ln \\\\varepsilon}{\\\\ln |x|}\\n$$\\n\\nsince division by $\\\\ln |x|$ (which is negative, since $|x|<\\\\frac{1}{2}$ ) reverses the sense of the inequality.\\n\\nBut if $|x|<\\\\frac{1}{2}, \\\\ln |x|<\\\\ln \\\\left(\\\\frac{1}{2}\\\\right)$, and $n>\\\\frac{\\\\ln \\\\varepsilon}{\\\\ln |x|}>\\\\frac{\\\\ln \\\\varepsilon}{\\\\ln \\\\left(\\\\frac{1}{2}\\\\right)}=N$. Thus, since $N$ is independent of $x$, the series is uniformly convergent in the interval. (b) In this case $|x| \\\\leqq \\\\frac{1}{2} \\\\cdot \\\\ln |x| \\\\leqq \\\\ln \\\\left(\\\\frac{1}{2}\\\\right)$, and $n>\\\\frac{\\\\ln \\\\varepsilon}{\\\\ln |x|} \\\\geqq \\\\frac{\\\\ln \\\\varepsilon}{\\\\ln \\\\left(\\\\frac{1}{2}\\\\right)}=N$, so that the series is also uniformly\\\\\\\\\\nconvergent in $-\\\\frac{1}{2} \\\\leqq x \\\\leqq \\\\frac{1}{2}$.\\n\\n(c) Reasoning similarly, with $\\\\frac{1}{2}$ replaced by .99 , shows that the series is uniformly convergent in $-.99 \\\\leqq$ $x \\\\leqq 99$.\\n\\n(d) The arguments used here break down in this case, since $\\\\frac{\\\\ln \\\\varepsilon}{\\\\ln |x|}$ can be made larger than any positive number by choosing $|x|$ sufficiently close to 1 . Thus, no $\\\\mathrm{N}$ exists and it follows that the series is not uniformly convergent in $-1<x<1$.\\n\\n(e) Since the series does not even converge at all points in this interval, it cannot converge uniformly in the interval.\\n',\n",
       " '\\n11.29. Discuss the continuity of the sum function $S(x)=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)$ of Problem 11.27 for the interval $0 \\\\leqq x \\\\leqq 1$.\\n\\n$$\\n\\\\text { If } 0 \\\\leqq x<1, S(x)=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1-x^{n}\\\\right)=1\\n$$\\n\\nIf $x=1, S_{n}(x)=0$ and $\\\\mathrm{S}(x)=0$.\\n\\n\\\\includegraphics[max width=\\\\textwidth, center]{2024_04_03_ffb6ac533fe0a53b3ceeg-314}\\\\\\\\\\n$0 \\\\leqq x<1$.\\n\\nIn Problem 11.34 it is shown that if a series is uniformly convergent in an interval, the sum function $S(x)$ must be continuous in the interval. It follows that if the sum function is not continuous in an interval, the series cannot be uniformly convergent. This fact is often used to demonstrate the nonuniform convergence of a series (or sequence).\\n',\n",
       " '\\n11.30. Investigate the uniform convergence of $x^{2}+\\\\frac{x^{2}}{1+x^{2}}+\\\\frac{x^{2}}{\\\\left(1+x^{2}\\\\right)^{2}}+\\\\cdots+\\\\frac{x^{2}}{\\\\left(1+x^{2}\\\\right)^{n}}+\\\\cdots$.\\n\\nSuppose $x \\\\neq 0$. Then the series is a geometric series with ratio $1 /\\\\left(1+x^{2}\\\\right)$ whose sum is (see Problem 2.25).\\n\\n$$\\nS(x)=\\\\frac{x^{2}}{1-1 /\\\\left(1+x^{2}\\\\right)}=1+x^{2}\\n$$\\n\\nIf $x=0$, the sum of the first $n$ terms is $S_{n}(0)=0$; hence, $S(0)=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(0)=0$.\\n\\nSince $\\\\lim _{x \\\\rightarrow 0} S(x)=1 \\\\neq S(0), S(x)$ is discontinuous at $x=0$. Then, by Problem 11.34, the series cannot be uniformly convergent in any interval which includes $x=0$, although it is (absolutely) convergent in any interval. However, it is uniformly convergent in any interval which excludes $x=0$.\\n\\nThis can also be shown directly (see Problem 11.93).\\n\\n\\n\\\\section*{Weierstrass $M$ test}\\n',\n",
       " '11.31. Prove the Weierstrass $M$ test; i.e., if $\\\\left|u_{n}(\\\\mathrm{x})\\\\right| \\\\leq M_{n}, n=1,2,3, \\\\ldots$, where $M_{n}$ are positive constants such that $\\\\Sigma M_{n}$ converges, then $\\\\Sigma u_{n}(\\\\mathrm{x})$ is uniformly (and absolutely) convergent.\\n\\nThe remainder of the series $\\\\Sigma u_{n}(x)$ after $n$ terms is $\\\\left.R_{n}(x)=u_{n+1}(x)+u_{n+2} x\\\\right)+\\\\cdots$. Now\\n\\n$$\\n\\\\left|R_{n}(x)\\\\right|=\\\\left|u_{n+1}(x)+u_{n+2}(x)+\\\\cdots\\\\right| \\\\leqq\\\\left|u_{n+1}(x)\\\\right|+\\\\left|u_{n+2}(x)\\\\right|+\\\\cdots \\\\leqq M_{n+1}+M_{n+2}+\\\\cdots\\n$$\\n\\nBut $M_{n+1}+M_{n+2}+\\\\cdots$ can be made less than $\\\\epsilon$ by choosing $n>N$, since $\\\\Sigma M_{n}$ converges. Since $N$ is clearly independent of $x$, we have $\\\\left|R_{n}(x)\\\\right|<\\\\epsilon$ for $n>N$, and the series is uniformly convergent. The absolute convergence follows at once from the comparison test.\\n',\n",
       " '\\n11.32. Test for uniform convergence: (a) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\cos n x}{n^{4}}$, (b) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{x^{n}}{n^{3 / 2}}$, (c) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\sin x^{n}}{n}$, and (d) $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}+x^{2}}$,\\n\\n(a) $\\\\left|\\\\frac{\\\\cos n x}{n^{4}}\\\\right| \\\\leqq \\\\frac{1}{n^{4}}=M_{n}$. Then, since $\\\\Sigma M$ nn converges (p series with $\\\\mathrm{p}=4>1$ ), the series is uniformly (and absolutely) convergent for all $x$ by the $\\\\mathrm{M}$ test.\\n\\n(b) By the ratio test, the series converges in the interval $-1 \\\\leqq x \\\\leqq 1$; i.e., $|x| \\\\leqq 1$.\\n\\nFor all $x$ in this interval, $\\\\left|\\\\frac{x^{n}}{n^{3 / 2}}\\\\right|=\\\\frac{|x|^{n}}{n^{3 / 2}} \\\\leqq \\\\frac{1}{n^{3 / 2}}$. Choosing $M_{n}=\\\\frac{1}{n^{3 / 2}}$, we see that $\\\\Sigma M_{n}$ converges. Thus, the given series converges uniformly for $-1 \\\\leqq x \\\\leqq 1$ by the $M$ test.\\n\\n(c) $\\\\left|\\\\frac{\\\\sin n x}{n^{4}}\\\\right| \\\\leqq \\\\frac{1}{n}$. However, $\\\\Sigma M_{n}$ where $M_{n}=\\\\frac{1}{n}$ does not converge. The $M$ test cannot be used in this case and we cannot conclude anything about the uniform convergence by this test (see, however, Problem\\n\\n(d) $\\\\left|\\\\frac{1}{n^{2}+x^{2}}\\\\right| \\\\leqq \\\\frac{1}{n^{2}}$, and $\\\\sum \\\\frac{1}{n^{2}}$ converges. Then, by the $\\\\mathrm{M}$ test, the given series converges uniformly for all $x$.\\n',\n",
       " '\\n11.33. If a power series $\\\\Sigma a_{n} x^{n}$ converges for $x=x_{0}$, Prove that it converges. (a) absolutely in the interval $|x| \\\\leqq$ $\\\\left|x_{0}\\\\right|$ and (b) uniformly in the interval $|x| \\\\leqq\\\\left|x_{1}\\\\right|$, where $\\\\left|x_{1}\\\\right|<\\\\left|x_{0}\\\\right|$.\\n\\n(a) Since $\\\\Sigma a_{n} x^{n}{ }_{0}$ converges, $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n} x_{0}^{n}=0$, and so we can make $\\\\left|a_{n} x_{0}^{n}\\\\right|<1$ by choosing $n$ large enough; i.e.,\\n\\n\\n\\\\begin{align*}\\n& \\\\left|a_{n}\\\\right|<\\\\left|a_{n}\\\\right|<\\\\frac{1}{\\\\left|x_{0}\\\\right|^{n}} \\\\text { for } n>N \\\\text {. Then } \\\\\\\\\\n& \\\\qquad \\\\sum_{N+1}^{\\\\infty}\\\\left|a_{n} x^{n}\\\\right|=\\\\sum_{N+1}^{\\\\infty}\\\\left|a_{n}\\\\right||x|^{n}<\\\\sum_{N+1}^{\\\\infty} \\\\frac{|x|^{n}}{\\\\left|x_{0}\\\\right|^{n}} \\\\tag{1}\\n\\\\end{align*}\\n\\n\\nSince the last series in Equation (1) converges for $|x|<\\\\left|x_{0}\\\\right|$, it follows by the comparison test that the first series converges; i.e., the given series is absolutely convergent.\\n\\n(b) Let $M_{n}=\\\\frac{\\\\left|x_{1}\\\\right|^{n}}{\\\\left|x_{0}\\\\right|^{n}}$. Then $\\\\Sigma M_{n}$ converges, since $\\\\left|x_{1}\\\\right|<\\\\left|x_{0}\\\\right|$. As in (a), $\\\\left|a_{n} x^{n}\\\\right|<M_{n}$ for $|x| \\\\leqq\\\\left|x_{1}\\\\right|$, so that by the Weierstrass $M$ test, $\\\\Sigma a_{n} x^{n}$ is uniformly convergent.\\n\\nIt follows that a power series is uniformly convergent in any interval within its interval of convergence.\\n\\n\\n\\\\section*{Theorems on uniform convergence}\\n\\\\subsection*{11.34. Prove Theorem 6, Page 284.}\\nWe must show that $S(x)$ is continuous in $[a, b]$.\\n\\nNow $S(x)=S_{n}(x)+R_{n}(x)$, so that $S(x+h)=S_{n}(x+h)+R_{n}(x+h)$ and thus,\\n\\n\\n\\\\begin{equation*}\\n\\\\left.S(x+h)-S(x)=S_{n}(x)+h\\\\right)-S_{n}(x)+R_{n}(x+h)-R_{n}(\\\\mathrm{x}) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere we choose $h$ so that both $x$ and $x+h$ lie in $[a, b]$ (if $x=b$, for example, this will require $h<0$ ).\\n\\nSince $S_{n}(x)$ is a sum of a finite number of continuous functions, it must also be continuous. Then, given $\\\\epsilon>0$, we can find $\\\\delta$ so that\\n\\n\\n\\\\begin{equation*}\\n\\\\left|S_{n}(x+h)-S_{n}(x)\\\\right|<\\\\epsilon / 3 \\\\text { whenever }|h|<\\\\delta \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSince the series, by hypothesis, is uniformly convergent, we can choose $N$ so that\\n\\n\\n\\\\begin{equation*}\\n\\\\left|R_{n}(x)\\\\right|<\\\\varepsilon / 3 \\\\text { and }|| R_{n}(x+h) \\\\mid<\\\\varepsilon / 3 \\\\text { for } n>N \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nThen from Equations (1), (2), and (3),\\n\\n$$\\n\\\\left.|S(x+h)-S(x)| \\\\leqq \\\\mid S_{n}(x)+h\\\\right)-S_{n}(x)|+| R_{n}(x+h)|+| R_{n}(x) \\\\mid<\\\\epsilon\\n$$\\n\\nfor $|h|<\\\\delta$, and so the continuity is established.\\n\\n\\\\subsection*{11.35. Prove Theorem 7, Page 285.}\\nIf a function is continuous in $[a, b]$, its integral exists. Then, since $S(x), S_{n}(x)$ and $R_{n}(x)$ are continuous,\\n\\n$$\\n\\\\int_{a}^{a} S(x) \\\\int_{a}^{b} S_{n}(x) d x+\\\\int_{a}^{b} R_{n}(x) d x\\n$$\\n\\nTo prove the theorem we must show that\\n\\n$$\\n\\\\left|\\\\int_{a}^{b} S(x) d x-\\\\int_{a}^{b} S_{n}(x) d x\\\\right|=\\\\left|\\\\int_{a}^{b} R_{n}(x) d x\\\\right|\\n$$\\n\\ncan be made arbitrarily small by choosing $n$ large enough. This, however, follows at once, since by the uniform convergence of the series we can make $\\\\left|R_{n}(x)\\\\right|<\\\\epsilon /(b-a)$ for $n>N$ independent of $x$ in $[a, b]$, and so\\n\\n$$\\n\\\\left|\\\\int_{a}^{b} R_{n}(x) d x\\\\right| \\\\leqq \\\\int_{a}^{b}\\\\left|R_{n}(x)\\\\right| d x<\\\\int_{a}^{b} \\\\frac{\\\\varepsilon}{b-a} d x=\\\\varepsilon\\n$$\\n\\nThis is equivalent to the statements\\n\\n$$\\n\\\\int_{a}^{b} S(x) d x=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{a}^{b} S_{n}(x) d x \\\\quad \\\\text { or } \\\\quad \\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{a}^{b} S_{n}(x) d x=\\\\int_{a}^{b}\\\\left\\\\{\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)\\\\right\\\\} d x\\n$$\\n',\n",
       " '\\n11.36. Prove Theorem 8, Page 285.\\n\\nLet $g(x)=\\\\sum_{n=1}^{\\\\infty} u_{n}^{\\\\prime}(x)$. Since, by hypothesis, this series converges uniformly in $[a, b]$, we can integrate term by term (by Problem 11.35) to obtain\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{a}^{x} g(x) d x=\\\\sum_{n=1}^{\\\\infty} \\\\int_{a}^{x} u_{n}^{\\\\prime}(x) d x & =\\\\sum_{n=1}^{\\\\infty}\\\\left\\\\{u_{n}(x)-u_{n}(a)\\\\right\\\\} \\\\\\\\\\n& =\\\\sum_{n=1}^{\\\\infty} u_{n}(x)-\\\\sum_{n=1}^{\\\\infty} u_{n}(a)=S(x)-S(a)\\n\\\\end{aligned}\\n$$\\n\\nbecause, by hypothesis, $\\\\sum_{n=1}^{\\\\infty} u_{n}(x)$ converges to $S(x)$ in $[a, b]$. theorem.\\n\\nDifferentiating both sides of $\\\\int_{0}^{x} g(x) d x=S(x)-S(a)$ then shows that $g(x)=S^{\\\\prime}(x)$, which proves the\\n',\n",
       " '\\n11.37. Let $S_{n}(\\\\mathrm{x})=n x e^{-n x 2}, n=1,2,3, \\\\ldots, 0 \\\\leqq x \\\\leqq 1$. (a) Determine whether $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{0}^{1} S_{n}(x) d x=\\\\int_{0}^{1} \\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x) d x$.\\\\\\\\\\n(b) Explain the result in (a).\\n\\n(a) $\\\\int_{0}^{1} S_{n}(x) d x=\\\\int_{0}^{1} n x e^{-n x^{2}} d x=-\\\\left.\\\\frac{1}{2} e^{-n x^{2}}\\\\right|_{0} ^{1}=\\\\frac{1}{2}\\\\left(1-e^{-n}\\\\right)$. Then\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{0}^{1} S_{n}(x) d x=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{1}{2}\\\\left(1-e^{-n}\\\\right)=\\\\frac{1}{2}\\n$$\\n\\n$S(x)=\\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x)=\\\\lim _{n \\\\rightarrow \\\\infty} n x e^{-n x^{2}}=0$. whether $x=0$ or $<x \\\\leqq 1 . \\\\quad$ Then.\\n\\n$$\\n\\\\int_{0}^{1} S(x) d x=0\\n$$\\n\\nIt follows that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{0}^{1} S_{n}(x) d x \\\\neq \\\\int_{0}^{1} \\\\lim _{n \\\\rightarrow \\\\infty} S_{n}(x) d x$; i.e., the limit cannot be taken under the integral sign.\\n\\n(b) The reason for the result in (a) is that although the sequence $\\\\operatorname{Sn}(\\\\mathrm{x})$ converges to 0 . it does not converge uniformly to 0 . To show this, observe that the function $n x e^{-n x^{2}}$ has a maximum at $x=1 / \\\\sqrt{2 n}$ (by the usual rules of elementary calculus), the value of this maximum being $\\\\sqrt{\\\\frac{1}{2} n} e^{-1 / 2}$. Hence, as $\\\\mathrm{n} \\\\rightarrow \\\\infty$, $\\\\operatorname{Sn}(\\\\mathrm{x})$ cannot be made arbitrarily small for all $\\\\mathrm{x}$ and so cannot converge uniformly to 0 .\\n',\n",
       " '\\n11.38. Let $f(x)=\\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\sin n x}{n^{3}}$. Prove that $\\\\int_{0}^{\\\\pi} f(x) d x=2 \\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{(2 n-1)^{4}}$.\\n\\nWe have $\\\\left|\\\\frac{\\\\sin n x}{n^{3}}\\\\right| \\\\leqq \\\\frac{1}{n^{3}}$. Then, by the Weierstrass $M$ test, the series is uniformly convergent for all $x$, in particular $0 \\\\leqq x \\\\leqq \\\\pi$, and can be integrated term by term. Thus,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{\\\\pi} f(x) d x & =\\\\int_{0}^{\\\\pi}\\\\left(\\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\sin n x}{n^{3}}\\\\right) d x \\\\sum_{n=1}^{\\\\infty} \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin n x}{n^{3}} d x \\\\\\\\\\n& =\\\\sum_{n=1}^{\\\\infty} \\\\frac{1-\\\\cos n \\\\pi}{n^{4}}=2\\\\left(\\\\frac{1}{1^{4}}+\\\\frac{1}{3^{4}}+\\\\frac{1}{5^{4}}+\\\\cdots\\\\right)=2 \\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{(2 n-1)^{4}}\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Power series}\\n',\n",
       " '11.39. Prove that both the power series $\\\\sum_{n=0}^{\\\\infty} a_{n} x^{n}$ and the corresponding series of derivatives $\\\\sum_{n=0}^{\\\\infty} n a_{n} x^{n-1}$ have\\\\\\\\\\nthe same radius of convergence.\\n\\nLet $R>0$ be the radius of convergence of $\\\\Sigma a_{n} x^{n}$. Let $0<\\\\left|x_{0}\\\\right|<R$. Then, as in Problem 11.33, we can choose $N$ as that ||$a_{n} \\\\left\\\\lvert\\\\,<\\\\frac{1}{\\\\left|x_{0}\\\\right|^{n}}\\\\right.$ for $n>N$.\\n\\nThus, the terms of the series $\\\\Sigma\\\\left|n a_{n} x^{n-1}\\\\right|=\\\\Sigma n\\\\left|a_{n}\\\\right||x|^{n-1}$ can for $n>N$ be made less than corresponding terms of the series $\\\\sum n \\\\frac{|x|^{n-1}}{\\\\left|x_{0}\\\\right|^{n}}$, which converges, by the ratio test, for $|x|<\\\\left|x_{0}\\\\right|<R$.\\n\\nHence, $\\\\Sigma n a_{n} x^{n-1}$ converges absolutely for all points $x_{0}$ (no matter how close $\\\\left|x_{0}\\\\right|$ is to $R$ ).\\n\\nIf, however, $|x|>R, \\\\lim _{n \\\\rightarrow \\\\infty} a_{n} x^{n} \\\\neq 0$ and thus $\\\\lim _{n \\\\rightarrow \\\\infty} n a_{n} x^{n-1} \\\\neq 0$, so that $\\\\Sigma n a_{n} x^{n-1}$ does not converge.\\n\\nThus, $R$ is the radius of convergence of $\\\\sum n a_{n} x^{n-1}$.\\n\\nNote that the series of derivatives may or may not converge for values of $x$ such that $|x|=R$.\\n',\n",
       " '\\n11.40. Illustrate Problem 11.39 by using the series $\\\\sum_{n=1}^{\\\\infty} \\\\frac{x^{n}}{n^{2} \\\\cdot 3^{n}}$.\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{x^{n+1}}{(n+1)^{2} \\\\cdot 3^{n+1}} \\\\cdot \\\\frac{n^{2} \\\\cdot 3 n}{x^{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{n^{2}}{3(n+1)^{2}}|x|=\\\\frac{|x|}{3}\\n$$\\n\\nso that the series converges for $|x|<3$. At $x= \\\\pm 3$ the series also converges, so that the interval of convergence is $-3 \\\\leqq x \\\\leqq 3$.\\n\\nThe series of derivatives is\\n\\n$$\\n\\\\sum_{n=1}^{\\\\infty} \\\\frac{n x^{n-1}}{n^{2} \\\\cdot 3 n}=\\\\sum_{n=1}^{\\\\infty} \\\\frac{x^{n-1}}{n \\\\cdot 3 n}\\n$$\\n\\nBy Problem 11.25(a), this has the interval of convergence $-3 \\\\leqq x<3$.\\n\\nThe two series have the same radius of convergence, i.e., $R=3$, although they do not have the same interval of convergence.\\n\\nNote that the result of Problem 11.39 can also be proved by the ratio test if this test is applicable. The proof given there, however, applies even when the test is not applicable, as in the series in Problem 11.22.\\n',\n",
       " '\\n11.41. Prove that in any interval within its interval of convergence, a power series (a) represents a continuous function, say, $\\\\mathrm{f}(\\\\mathrm{x})$; (b) can be integrated term by term to yield the integral of $\\\\mathrm{f}(\\\\mathrm{x})$; and (c) can be differentiated term by term to yield the derivative of $f(x)$.\\n\\nWe consider the power series $\\\\Sigma a_{n} x^{n}$, although analogous results hold for $\\\\Sigma a_{n}(x-a)^{n}$.\\n\\n(a) This follows from Problem 11.33 and 11.34, and the fact that each term anxn of the series is continuous.\\n\\n(b) This follows from Problems 11.33 and 11.35, and the fact that each term anxn of the series is continuous and thus integrable.\\n\\n(c) From Problem 11.39, the series of derivatives of a power series always converges within the interval of convergence of the original power series and therefore is uniformly convergent within this interval. Thus, the required result follows from Problems 11.33 and 11.36.\\n\\nIf a power series converges at one (or both) endpoints of the interval of convergence, it is possible to establish (a) and (b) to include the endpoint (or endpoints). See Problem 11.42.\\n',\n",
       " \"\\n11.42. Prove Abel's theorem that if a power series converges at an endpoint of its interval of convergence, then the interval of uniform convergence includes this endpoint.\\n\\nFor simplicity in the proof, we assume the power series to be $\\\\sum_{k=0}^{\\\\infty} a_{k} x^{k}$ with the endpoint of its interval of convergence at $x=1$, so that the series surely converges for $0 \\\\leqq x \\\\leqq 1$. Then we must show that the series converges uniformly in this interval.\\n\\nLet\\n\\n$$\\nR_{n}(x)=a_{n} x^{n}+a_{n+1} x^{n+1}+a_{n+2} x^{n+2}+\\\\cdots, \\\\quad R_{n}=a_{n}+a a_{n+2}+\\\\cdots\\n$$\\n\\nTo prove the required result we must show that given any $\\\\epsilon>0$, we can find $N$ such that $\\\\mid R_{n \\\\text { all } n>N}$, where $N$ is independent of the particular $x$ in $0 \\\\leqq x \\\\leqq 1$.\\n\\nNow\\n\\n$$\\n\\\\begin{aligned}\\nR_{n}(x) & =\\\\left(R_{n}-R_{n+1}\\\\right) x^{n}+\\\\left(R_{n+1}-R_{n+2}\\\\right) x^{n+1}+\\\\left(R_{n+2}-R_{n+3}\\\\right) x^{n+2}+\\\\cdots \\\\\\\\\\n& =R_{n} x^{n}+R_{n+1}\\\\left(x^{n+1}-x^{n}\\\\right)+R_{n+2}\\\\left(x^{n+2}-x^{n+1}\\\\right)+\\\\cdots \\\\\\\\\\n& =x^{n}\\\\left\\\\{R_{n}-(1-x)\\\\left(R_{n+1}+R_{n+2} x+R_{n+3} x^{2}+\\\\cdots\\\\right)\\\\right\\\\}\\n\\\\end{aligned}\\n$$\\n\\nHence, for $0 \\\\leqq x<1$,\\n\\n\\n\\\\begin{equation*}\\n\\\\left|R_{n}(x)\\\\right| \\\\leqq\\\\left|R_{n}\\\\right|+(1-x)\\\\left(\\\\left|R_{n+1}\\\\right|+\\\\left|R_{n+2}\\\\right| x+\\\\left|R_{n}\\\\right| R n+3 \\\\mid x^{2}+\\\\cdots\\\\right) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSince $\\\\Sigma a_{k}$ converges by hypothesis, it follows that given $\\\\epsilon>0$, we can choose $N$ such that $\\\\left|R_{k}\\\\right|<\\\\epsilon / 2$ for all $k \\\\geqq n$. Then for $n>N$ we have, from Equation (1),\\n\\n\\n\\\\begin{equation*}\\n\\\\left|R_{n}(x)\\\\right| \\\\leqq \\\\frac{\\\\epsilon}{2}+(1-x)\\\\left(\\\\frac{\\\\epsilon}{2}+\\\\frac{\\\\epsilon}{2} x+\\\\frac{\\\\epsilon}{2} x^{2}+\\\\cdots\\\\right)=\\\\frac{\\\\epsilon}{2}+\\\\frac{\\\\epsilon}{2}=\\\\in \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nsince $(1-x)\\\\left(1+x+x^{2}+x^{3}+\\\\ldots\\\\right)=1$ (if $0 \\\\leq x<1$ )\\n\\nAlso, for $x=1,\\\\left|R_{n}(x)\\\\right|=\\\\left|R_{n}\\\\right|<\\\\epsilon$ for $n>N$.\\n\\nThus, $\\\\left|R_{n}(x)\\\\right|<\\\\epsilon$ for all $n>N$, where $N$ is independent of the value of $x$ in $0 \\\\leqq x \\\\leqq 1$, and the required result follows.\\n\\nExtensions to other power series are easily made.\\n\",\n",
       " \"\\n11.43. Prove Abel's limit theorem (see Page 286).\\n\\nAs in Problem 11.42, assume the power series to be $\\\\sum_{k=1}^{\\\\infty} a_{k} x^{k}$, convergent for $0 \\\\leqq x \\\\leqq 1$.\\n\\nThen we must show that $\\\\lim _{x \\\\rightarrow 1-} \\\\sum_{k=0}^{\\\\infty} a_{k} x^{k}=\\\\sum_{k=0}^{\\\\infty} a_{k}$.\\n\\nThis follows at once from Problem 11.42, which shows that $\\\\Sigma a_{k} x^{k}$ is uniformly convergent for $0 \\\\leqq x \\\\leqq 1$, and from Problem 11.34, which shows that $\\\\sum a_{k} x^{k}$ is continuous at $x=1$.\\n\\nExtensions to other power series are easily made.\\n\",\n",
       " '\\n11.44. (a) Prove that $\\\\tan ^{-1} x=x-\\\\frac{x^{3}}{3}+\\\\frac{x^{5}}{5}-\\\\frac{x^{7}}{7}+\\\\cdots$ where the series is uniformly convergent in $-1 \\\\leqq x \\\\leqq 1$.\\n\\n(b) Prove that $\\\\frac{\\\\pi}{4}=1-\\\\frac{1}{3}+\\\\frac{1}{5}-\\\\frac{1}{7}+\\\\cdots$\\n\\n(a) By Problem 2.25, with $\\\\mathrm{r}=-\\\\mathrm{x} 2$ and $\\\\mathrm{a}=1$, we have\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{1}{1+x^{2}}=1-x^{2}+x^{4}-x^{6}+\\\\cdots-1<x<1 \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIntegrating from 0 to $x$, where $-1<x<1$, yields\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{x} \\\\frac{d x}{1+x^{2}}=\\\\tan ^{-1} x=x-\\\\frac{x^{3}}{3}+\\\\frac{x^{5}}{5}-\\\\frac{x^{7}}{7}+\\\\cdots \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nusing Problems 11.33 and 11.35 .\\n\\nSince the series on the right of Equation (2) converges for $x= \\\\pm 1$, it follows by Problem 11.42 that the series is uniformly convergent in $-1 \\\\leqq x \\\\leqq 1$ and represents $\\\\tan ^{-1} x$ in this interval\\n\\n(b) By Problem 11.43 and (a), we have\\n\\n$$\\n\\\\lim _{x \\\\rightarrow 1-} \\\\tan ^{-1} x=\\\\lim _{x \\\\rightarrow 1-}\\\\left(x-\\\\frac{x^{3}}{3}+\\\\frac{x^{5}}{5}-\\\\frac{x^{7}}{7}+\\\\cdots\\\\right) \\\\text { or } \\\\frac{\\\\pi}{4}=1-\\\\frac{1}{3}+\\\\frac{1}{5}-\\\\frac{1}{7}+\\\\cdots\\n$$\\n',\n",
       " '\\n11.45. Evaluate $\\\\int_{0}^{1} \\\\frac{1-e^{-x 2}}{x^{2}} d x$ to three-decimal-place accuracy.\\n\\nWe have $e^{u} 1+u+\\\\frac{u^{2}}{2 !}+\\\\frac{u^{3}}{3 !}+\\\\frac{u^{4}}{4 !}+\\\\frac{u^{5}}{5 !}+\\\\cdots, \\\\quad-\\\\infty<u<\\\\infty$.\\n\\nThen, if $u=-x^{2}, e^{-x^{2}}=1-x^{2}+\\\\frac{x^{4}}{2 !}-\\\\frac{x^{6}}{3 !}+\\\\frac{x^{8}}{3 !}=\\\\frac{x^{10}}{5 !}+\\\\cdots, \\\\quad-\\\\infty<x<\\\\infty$.\\n\\nThus, $\\\\frac{1-e^{-x^{2}}}{x^{2}}=1-\\\\frac{x^{2}}{2 !}+\\\\frac{x^{4}}{3 !}-\\\\frac{x^{6}}{4 !}+\\\\frac{x^{8}}{5 !}-\\\\cdots$.\\n\\nSince the series converges for all $x$ and so, in particular, converges uniformly for $0 \\\\leqq x \\\\leqq 1$, we can integrate term by term to obtain\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{1} \\\\frac{1-e^{-x^{2}}}{x^{2}} d x & =x-\\\\frac{x^{3}}{3 \\\\cdot 2 !}+\\\\frac{x^{5}}{5 \\\\cdot 3 !}-\\\\frac{x^{7}}{7 \\\\cdot 4 !}+\\\\frac{x^{9}}{9 \\\\cdot 5 !}-\\\\left.\\\\cdots\\\\right|_{0} ^{1} \\\\\\\\\\n& =1-\\\\frac{1}{3 \\\\cdot 2 !}+\\\\frac{1}{5 \\\\cdot 3 !}-\\\\frac{1}{7 \\\\cdot 4 !}+\\\\frac{1}{9 \\\\cdot 5 !}-\\\\cdots \\\\\\\\\\n& =1-0.16666+0.03333-0.00595+0.00092-\\\\cdots=0.862\\n\\\\end{aligned}\\n$$\\n\\nNote that the error made in adding the first four terms of the alternating series is less than the fifth term, i.e., less than 0.001 (see Problem 11.15).\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " \"11.46. Prove that $y=J_{p}$ (x) defined by Equation (16), Page 287, satisfies Bessel's differential equation:\\n\\n$$\\nx^{2} y \\\\cdot+x y^{\\\\prime}+\\\\left(x^{2}-p^{2}\\\\right) y=0\\n$$\\n\\nThe series for $J_{p}(x)$ converges for all $x$ [see Problem 11.10 (a)]. Since a power series can be differentiated term by term within its interval of convergence, we have for all $x$,\\n\\n$$\\n\\\\begin{aligned}\\n& y=\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n} x^{p+2 n}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\n& y^{\\\\prime}=\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n}(p+2 n) x^{p+2 n-1}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\n& y^{\\\\prime \\\\prime}=\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n}(p+2 n)(p+2 n-1) x^{p+2 n-2}}{2^{p+2 n} n !(n+p) !}\\n\\\\end{aligned}\\n$$\\n\\nThen,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\left(x^{2}-p^{2}\\\\right) y & =\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n} x^{p+2 n+2}}{2^{p+2 n} n !(n+p) !}-\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n} p^{2} x^{p+2 n}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\nx y^{\\\\prime} & =\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n}(p+2 n) x^{p+2 n}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\ny^{\\\\prime \\\\prime} & =\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n}(p+2 n)(p+2 n-1) x^{p+2 n}}{2^{p+2 n} n !(n+p) !}\\n\\\\end{aligned}\\n$$\\n\\nAdding,\\n\\n$$\\n\\\\begin{aligned}\\nx^{2} y^{\\\\prime \\\\prime}+x y^{\\\\prime}+\\\\left(x^{2}-p^{2}\\\\right) y & =\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n} x^{p+2 n+2}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\n& +\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n}\\\\left[-p^{2}+(p+2 n)+(p+2 n)(p+2 n-1)\\\\right] x^{p+2 n}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\n& =\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n} x^{p+2 n+2}}{2^{p+2 n} n !(n+p) !}+\\\\sum_{n=0}^{\\\\infty} \\\\frac{(-1)^{n}[4 n(n+p)] x^{p+2 n}}{2^{p+2 n} n !(n+p) !} \\\\\\\\\\n& =\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n} 4 x^{p+2 n}}{2^{p+2 n-2}(n-1) !(n-1+p) !}+\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n} 4 x^{p+2 n}}{2^{p+2 n}(n-1) !(n+p-1) !} \\\\\\\\\\n& =-\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n} 4 x^{p+2 n}}{2^{p+2 n}(n-1) !(n+1-p) !}+\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n} 4 x^{p+2 n}}{2^{p+2 n}(n-1) !(n+p-1) !} \\\\\\\\\\n& =0\\n\\\\end{aligned}\\n$$\\n\",\n",
       " '\\n11.47. Test for convergence the complex power series $\\\\sum_{n=1}^{\\\\infty} \\\\frac{z^{n-1}}{n^{3} \\\\cdot 3^{n-1}}$.\\n\\nSince $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{u_{n+1}}{u_{n}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left|\\\\frac{z_{n}}{(n+1)^{3} \\\\cdot 3^{n}} \\\\cdot \\\\frac{n^{3} \\\\cdot 3^{n-1}}{z^{n-1}}\\\\right|=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\frac{n^{3}}{3(n+1)^{3}}|z|=\\\\frac{|z|}{3}$, the series converges for $\\\\frac{|z|}{3}<1$, i.e., $|z|<3$, and diverges for $|z|>3$.\\\\\\\\\\nFor $|z|=3$, the series of absolute values is $\\\\sum_{n=1}^{\\\\infty} \\\\frac{|z|^{n-1}}{n^{3} \\\\cdot 3^{n-1}}=\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{3}}$, so that the series is absolutely con-\\\\\\\\\\nvergent and thus convergent for $|z|=3$.\\n\\nThus, the series converges within and on the circle $|z|=3$.\\n',\n",
       " \"\\n11.48. Assuming the power series for $e^{x}$ holds for complex numbers, show that $e^{i x}=\\\\cos x+i \\\\sin x$.\\n\\nLetting $z=i x$ in $e^{2}=1+z+\\\\frac{z^{2}}{2 !}+\\\\frac{z^{3}}{3 !}+\\\\cdots$, we have\\n\\n$$\\n\\\\begin{aligned}\\ne^{i x} & =1+i x+\\\\frac{i^{2} x^{2}}{2 !}+\\\\frac{i^{3} x^{3}}{3 !}+\\\\cdots=\\\\left(1-\\\\frac{x^{2}}{2 !}+\\\\frac{x^{4}}{4 !}-\\\\cdots\\\\right)+i\\\\left(x-\\\\frac{x^{3}}{3 !}+\\\\frac{x^{5}}{5 !}-\\\\cdots\\\\right) x \\\\\\\\\\n& =\\\\cos x+i \\\\sin x\\n\\\\end{aligned}\\n$$\\n\\nSimilarly, $e^{-i x}=\\\\cos x-i \\\\sin x$. The results are called Euler's identities.\\n\",\n",
       " \"\\n11.49. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1+\\\\frac{1}{2}+\\\\frac{1}{3}+\\\\frac{1}{4}+\\\\cdots+\\\\frac{1}{n}-\\\\operatorname{In} n\\\\right)$ exists.\\n\\nLetting $f(x)=1 / x$ in Equation (1), Problem 11.11, we find\\n\\n$$\\n\\\\frac{1}{2}+\\\\frac{1}{3}+\\\\frac{1}{4}+\\\\cdots+\\\\frac{1}{M} \\\\leqq \\\\ln M \\\\leqq 1+\\\\frac{1}{2}+\\\\frac{1}{3}+\\\\frac{1}{4}+\\\\cdots+\\\\frac{1}{M-1}\\n$$\\n\\nfrom which, on replacing $M$ by $n$, we have\\n\\n$$\\n\\\\frac{1}{n} \\\\leqq 1+\\\\frac{1}{2}+\\\\frac{1}{3}+\\\\frac{1}{4}+\\\\cdots+\\\\frac{1}{n}-\\\\operatorname{In} n \\\\leqq 1\\n$$\\n\\nThus, the sequence $S_{n}=1+\\\\frac{1}{2}+\\\\frac{1}{3}+\\\\frac{1}{4}+\\\\cdots+\\\\frac{1}{n}-\\\\ln n$ is bounded by 0 and 1 .\\n\\nConsider $S_{n+1}-S_{n}=\\\\frac{1}{n+1}-\\\\ln \\\\left(\\\\frac{n+1}{n}\\\\right)$. By integrating the inequality $\\\\frac{1}{n+1} \\\\leqq \\\\frac{1}{x} \\\\leqq \\\\frac{1}{n}$ with respect to $x$ from $n$ to $n+1$, we have\\n\\n$$\\n\\\\frac{1}{n+1} \\\\leqq \\\\ln \\\\left(\\\\frac{n+1}{n}\\\\right) \\\\leqq \\\\frac{1}{n} \\\\quad \\\\text { or } \\\\quad \\\\frac{1}{n+1}-\\\\frac{1}{n} \\\\leqq \\\\frac{1}{n+1}-\\\\ln \\\\left(\\\\frac{n+1}{n}\\\\right) \\\\leqq 0\\n$$\\n\\ni.e., $S_{n+1}-S_{n} \\\\leqq 0$, so that $S_{n}$ is monotonic decreasing.\\n\\nSince $S_{n} \\\\overline{\\\\bar{i}}$ bounded and monotonic decreasing, it has a limit. This limit, denoted by $\\\\gamma$, is equal to $0.577215 \\\\ldots$. and is called Euler's constant. It is not yet known whether $\\\\gamma$ is rational or not.\\n\",\n",
       " '\\n11.50. Prove that the infinite product $\\\\prod_{k=1}^{\\\\infty}\\\\left(1+u_{k}\\\\right)$, converges $\\\\sum_{k=1}^{\\\\infty} u_{k}$ converges.\\n\\nAccording to the Taylor series for $e^{x}$ (Page 289), $1+x \\\\leqq e^{\\\\mathrm{x}}$ for $x>0$, so that\\n\\n$$\\nP_{n}=\\\\prod_{k=1}^{n}\\\\left(1+u_{k}\\\\right)=\\\\left(1+u_{1}\\\\right)\\\\left(1+u_{2}\\\\right) \\\\cdots\\\\left(1+u_{n}\\\\right) \\\\leqq e^{u_{1}} \\\\cdot e^{u_{2}} \\\\cdots e^{u_{n}}=e^{u_{1}+u_{2}+\\\\cdots u_{n}}\\n$$\\n\\nSince $u_{1}+u_{2}+\\\\cdots$ converges, it follows that $P_{n}$ is a bounded monotonic increasing sequence and so has a limit, thus proving the required result.\\n',\n",
       " '\\n11.51. Prove that the series $1-1+1-1+1-1+\\\\cdots$ is $C-1$ summable to $1 / 2$.\\n\\nThe sequence of partial sums is $1,0,1,0,1,0, \\\\ldots$.\\n\\nThen $S_{1}=1, \\\\frac{S_{1}+S_{2}}{2}=\\\\frac{1+0}{2}=\\\\frac{1}{2}, \\\\frac{S_{1}+S_{2}+S_{3}}{3}=\\\\frac{1+0+1}{3}=\\\\frac{2}{3}, \\\\cdots$.\\n\\nContinuing in this manner, we obtain the sequence $1 . \\\\frac{1}{2}, \\\\frac{2}{3}, \\\\frac{1}{2}, \\\\frac{3}{5}, \\\\frac{1}{2}, \\\\ldots$, the $n$th term being $T_{n}=\\\\left\\\\{\\\\begin{array}{ll}1 / 2 & \\\\text { if } n \\\\text { is even } \\\\\\\\ n /(2 n-1) & \\\\text { if } n \\\\text { is odd }\\\\end{array}\\\\right.$. Thus, $\\\\lim _{n \\\\rightarrow \\\\infty} T_{n}=\\\\frac{1}{2}$ and the required result follows.\\n',\n",
       " \"\\n11.52. (a) If $f^{(n+1)}(\\\\mathrm{x})$ is continuous in $[a, b]$ prove that for $c$ in $[a, b], f(x)=f(c)+f^{\\\\prime}(c)(x-c)+$ $\\\\frac{1}{2 !} f^{\\\\prime \\\\prime}(c)(x-c)^{2}+\\\\cdots+\\\\frac{1}{n !} f^{(n)}(c)(x-c)^{n}+\\\\frac{1}{n !} \\\\int_{c}^{x}(x-1)^{n} f^{(n+1)}(t) d t$. (b) Obtain the Lagrange and Cauchy forms of the remainder in Taylor's formula. (See Page 290.)\\n\\nThe proof of (a) is made using mathematical induction. (See Chapter 1.) The result holds for $n=0$, since\\n\\n$$\\nf(x)=f(c)+\\\\int_{c}^{x} f^{\\\\prime}(t) d t=f(c)+f(x)-f(c)\\n$$\\n\\nWe make the induction assumption that it holds for $n=k$ and then use integration by parts with\\n\\n$$\\nd v=\\\\frac{(x-t)^{k}}{k !} d t \\\\text { and } u=f^{k+1}(t)\\n$$\\n\\nThen\\n\\n$$\\nv=-\\\\frac{(x-t)^{k+1}}{(k+1) !} \\\\text { and } d u=f^{k+2}(t) d t\\n$$\\n\\nThus,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{1}{k !} \\\\int_{C}^{x}(x-t)^{k} f^{(k+1)}(t) d t & =-\\\\left.\\\\frac{f^{k+1}(x-t)^{k+1}}{(k+1) !}\\\\right|_{C} ^{x}+\\\\frac{1}{(k+1) !} \\\\int_{C}^{x}(x-t)^{k+1} f^{(k+2)}(t) d t \\\\\\\\\\n& =-\\\\frac{f^{k+1}(x-t)^{k+1}}{(k+1) !}+\\\\frac{1}{(k+1) !} \\\\int_{C}^{x}(x-t)^{k+1} f^{(k+2)}(t) d t\\n\\\\end{aligned}\\n$$\\n\\nHaving demonstrated that the result holds for $k+1$, we conclude that it holds for all positive integers.\\n\\nTo obtain the Lagrange form of the remainder $R_{n}$, consider the form\\n\\n$$\\nf(x)=f(c)+f^{\\\\prime}(c)(x-c)+\\\\frac{1}{2 !} f^{n}(c)(x-c)^{2}+\\\\cdots+\\\\frac{K}{n !}(x-c)^{n}\\n$$\\n\\nThis is the Taylor polynomial $P_{n-1}(x)$ plus $\\\\frac{K}{n !}(x-c)^{n}$. Also, it could be looked upon as $P_{n}$ except that in the last term, $f^{(n)}$ (c) is replaced by a number $K$ such that for fixed $c$ and $x$ the representation of $f(x)$ is exact. Now define a new function\\n\\n$$\\n\\\\Phi(t)=f(t)-f(x)+\\\\sum_{j=1}^{n-1} f^{(j)}(t) \\\\frac{(x-t)^{j}}{j !}+\\\\frac{K(x-t)^{n}}{n !}\\n$$\\n\\nThe function $\\\\Phi$ satisfies the hypothesis of Rolle's Theorem in that $\\\\Phi(c)=\\\\Phi(x)=0$, the function is continuous on the interval bound by $c$ and $x$, and $\\\\Phi^{\\\\prime}$ exists at each point of the interval. Therefore, there exists $\\\\xi$ in the interval such that $\\\\Phi^{\\\\prime}(\\\\xi)=0$. We proceed to compute $\\\\Phi^{\\\\prime}$ and set it equal to zero.\\n\\n$$\\n\\\\Phi^{\\\\prime}(t)=f^{\\\\prime}(t)+\\\\sum_{j=1}^{n-1} f^{(j+1)}(t) \\\\frac{(x-t)^{j}}{j !}-\\\\sum_{j=1}^{n-1} f^{(j)}(t) \\\\frac{(x-t)^{j-1}}{(j-1) !}-\\\\frac{K(x-t)^{n-1}}{(n-1) !}\\n$$\\n\\nThis reduces to\\n\\n$$\\n\\\\Phi^{\\\\prime}(t)=\\\\frac{f^{(n)}(t)}{(n-1) !}(x-t)^{n-1}-\\\\frac{K}{(n-1) !}(x-t)^{n-1}\\n$$\\n\\nAccording to hypothesis, for each $n$ there is $\\\\xi_{n}$ such that\\n\\n$$\\n\\\\Phi\\\\left(\\\\xi_{n}\\\\right)=0\\n$$\\n\\nThus,\\n\\n$$\\nK=f^{(n)}\\\\left(\\\\xi_{n}\\\\right)\\n$$\\n\\nand the Lagrange remainder is\\n\\n$$\\nR_{n-1}=\\\\frac{f^{(n)}\\\\left(\\\\xi_{n}\\\\right)}{n !}(x-c)^{n}\\n$$\\n\\nor, equivalently,\\n\\n$$\\nR_{n}=\\\\frac{1}{(n+1) !} f^{(n+1)}\\\\left(\\\\xi_{n+1}\\\\right)(x-c)^{n+1}\\n$$\\n\\nThe Cauchy form of the remainder follows immediately by applying the mean value theorem for integrals. (See Page 287.)\\n\",\n",
       " \"\\n11.53. Extend Taylor's theorem to functions of two variables $x$ and $y$.\\n\\nDefine $F(t)=f\\\\left(x_{0}+h t, y_{0}+k t\\\\right)$; then, applying Taylor's theorem for one variable (about $t=0$ ),\\n\\n$$\\nF(t)=F(0)+F^{\\\\prime}(0)+\\\\frac{1}{2 !} F^{\\\\prime \\\\prime}(0) t^{2}+\\\\cdots+\\\\frac{1}{n !} F^{(n)}(0) t^{n}+\\\\frac{1}{(n+1) !} F^{(n+1)}(\\\\theta) t^{n+1}, 0<\\\\theta<t\\n$$\\n\\nNow let $t=1$\\n\\n$F(1)=f\\\\left(x_{0}+h, y_{0}+k\\\\right)=F(0)+F^{\\\\prime}(0)+\\\\frac{1}{2 !} F^{\\\\prime \\\\prime}(0)+\\\\cdots+\\\\frac{1}{n !} F^{(n)}(0)+\\\\frac{1}{(n+1) !} F^{(n+1)}(\\\\theta)$\\n\\nWhen the derivatives $F^{\\\\prime}(t), \\\\ldots, F^{(n)}(t), F^{(n+1)}(\\\\theta)$ are computed and substituted into the previous expression, the two-variable version of Taylor's formula results. (See Page 290, where this form and notational details can be found.)\\n\",\n",
       " \"\\n11.54. Expand $x^{2}+3 y-2$ in powers of $x-1$ and $y+2$. Use Taylor's formula. with $h=x-x_{0}, k=y-y_{0}$, where $x_{0}=$ 1 and $y_{0}=-2$.\\n\\n$$\\nx^{2}+3 y-2=-10-4(x-1)+4(y+2)-2(x-1)^{2}+2(x-1)(y+2)+(x-1)^{2}(y+2) \\\\text { (Check this algebraically.) }\\n$$\\n\",\n",
       " \"\\n11.55. Prove that $\\\\ln \\\\frac{x+y}{2}=\\\\frac{x+y-2}{2+\\\\theta(x+y-2)}, 0<\\\\theta 1, x>0, y>0$. (Hint: Use Taylor's formula with the linear term as the remainder.)\\n\",\n",
       " '\\n11.56. Expand $f(x, y)=\\\\sin x y$ in powers of $x-1$ and $y-\\\\frac{\\\\pi}{2}$ to second-degree terms.\\n\\n$$\\n1-\\\\frac{1}{8} \\\\pi^{2}(x-1)^{2}-\\\\frac{\\\\pi}{2}(x-1)\\\\left(y-\\\\frac{\\\\pi}{2}\\\\right)-\\\\left(y-\\\\frac{\\\\pi}{2}\\\\right)^{2}\\n$$\\n\\n',\n",
       " \"12.1. Classify according to the type of improper integral:\\\\\\\\\\n(a) $\\\\int_{-1}^{1} \\\\frac{d x}{\\\\sqrt[3]{x}(x+1)}$\\\\\\\\\\n(c) $\\\\int_{3}^{10} \\\\frac{x d x}{(x-2)^{2}}$\\\\\\\\\\n(e) $\\\\int_{0}^{\\\\pi} \\\\frac{1-\\\\cos x}{x^{2}} d x$\\\\\\\\\\n(b) $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{1+\\\\tan x}$\\\\\\\\\\n(d) $\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{x^{2} d x}{x^{4}+x^{2}+1}$\\n\\n(a) Second kind (integrand is unbounded at $x=0$ and $x=-1$ ).\\n\\n(b) Third kind (integration limit is infinite and integrand is unbounded where $\\\\tan x=-1$ ).\\n\\n(c) This is a proper integral (integrand becomes unbounded at $x=2$, but this is outside the range of integration $3 \\\\leqq x \\\\leqq 10$ ).\\n\\n(d) First kind (integration limits are infinite but integrand is bounded).\\n\\n(e) This is a proper integral (since $\\\\lim _{x \\\\rightarrow 0+} \\\\frac{1-\\\\cos x}{x^{2}}=\\\\frac{1}{2}$ by applying L' Hospital's rule).\\n\",\n",
       " '\\n12.2. Show how to transform the improper integral of the second kind, $\\\\int_{t}^{2} \\\\frac{d x}{\\\\sqrt{x(2-x)}}$, into (a) an improper\\\\\\\\\\nintegral of the first kind, (b) a proper integral.\\n\\n(a) Consider $\\\\int_{t}^{2-\\\\epsilon} \\\\frac{d x}{\\\\sqrt{x(2-x)}}$, where $0<\\\\epsilon<1$, say. Let $2-x=\\\\frac{1}{y}$. Then the integral becomes $\\\\int_{1}^{1 / \\\\epsilon} \\\\frac{d y}{y \\\\sqrt{2 y-1}}$. As $\\\\epsilon \\\\rightarrow 0+$, we see that consideration of the given integral is equivalent to consideration $\\\\int_{1}^{\\\\infty} \\\\frac{d y}{y \\\\sqrt{2 y-1}}$, which is an improper integral of the first kind.\\n\\n(b) Letting $2-x=v 2$ in the integral of (a), it becomes $2 \\\\int_{\\\\sqrt{\\\\epsilon}}^{1} \\\\frac{d v}{\\\\sqrt{v^{2}+2}}$. We are thus led to consideration of $2 \\\\int_{0}^{1} \\\\frac{d v}{\\\\sqrt{v^{2}+1}}$, which is a proper integral.\\n\\nFrom this, we see that an improper integral of the first kind may be transformed into an improper integral of the second kind, and conversely (actually this can always be done).\\n\\nWe also see that an improper integral may be transformed into a proper integral (this can only sometimes be done).\\n\\n\\n\\\\section*{Improper integrals of the first kind}\\n',\n",
       " '12.3. Prove the comparison test (Page 326) for convergence of improper integrals of the first kind.\\n\\nSince $0 \\\\leqq f(x) \\\\leqq g(x)$ for $x \\\\varepsilon a$, we have, using Property 7, Page 98,\\n\\n$$\\n0 \\\\leqq \\\\int_{a}^{b} f(x) d x \\\\leqq \\\\int_{a}^{b} g(x) d x \\\\leqq \\\\int_{\\\\alpha}^{\\\\infty} g(x) d x\\n$$\\n\\nBut, by hypothesis, the last integral exists. Thus, $\\\\lim _{b \\\\rightarrow \\\\infty} \\\\int_{a}^{b} f(x) d x$ exists, and, hence, $\\\\int_{\\\\alpha}^{\\\\infty} f(x) d x$ converges.\\n',\n",
       " '\\n12.4. Prove the quotient test (a) on Page 326 .\\n\\nBy hypothesis, $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{f(x)}{g(x)}=A>0$. Then, given any $\\\\epsilon>0$, we can find $N$ such that $\\\\left|\\\\frac{f(x)}{g(x)}-A\\\\right|<\\\\epsilon$ when $x \\\\varepsilon N$. Thus, for $x \\\\varepsilon N$, we have\\n\\n$$\\nA-\\\\in \\\\leq \\\\frac{f(x)}{g(x)} \\\\leqq A+\\\\in \\\\quad \\\\text { or } \\\\quad(A-\\\\in) g(x) \\\\leqq f(x) \\\\leqq(A+\\\\in) g(x)\\n$$\\n\\nThen\\n\\n\\n\\\\begin{equation*}\\n(A-\\\\in) \\\\int_{N}^{b} g(x) d x \\\\leqq \\\\int_{N}^{b} f(x) d x \\\\leqq(A+\\\\in) \\\\int_{N}^{b} g(x) d x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nThere is no loss of generality in choosing $A-\\\\epsilon>0$.\\n\\nIf $\\\\int_{a}^{\\\\infty} g(x) d x$ converges, then by the inequality on the right of Equation (1),\\n\\n$\\\\lim _{b \\\\rightarrow \\\\infty} \\\\int_{N}^{b} f(x) d x$ exists, and so $\\\\int_{a}^{\\\\infty} f(x) d x$ converges\\n\\nIf $\\\\int_{a}^{\\\\infty} g(x) d x$ diverges, then by the inequality on the left of Equation (1), $\\\\lim _{b \\\\rightarrow \\\\infty} \\\\int_{N}^{b} f(x) d x=\\\\infty$, and so $\\\\int_{a}^{\\\\infty} f(x) d x$ diverges.\\n\\nFor the cases where $A=0$ and $A=\\\\infty$, see Problem 12.41.\\n\\nAs seen in this and Problem 12.3, there is, in general, a marked similarity between proofs for infinite series and improper integrals.\\n',\n",
       " '\\n12.5. Test for convergence: (a) $\\\\int_{1}^{\\\\infty} \\\\frac{x d x}{3 x^{4}+5 x^{2}+1}$ and (b) $\\\\int_{2}^{\\\\infty} \\\\frac{x^{2}-1}{\\\\sqrt{x^{6}+16}} d x$.\\n\\n(a) Method 1: For large $x$, the integrand is approximately $x / 3 \\\\times 4=1 / 3 \\\\times 3$.\\n\\nSince $\\\\frac{x}{3 x^{4}+5 x^{2}+1} \\\\leqq \\\\frac{1}{3 x^{3}}$ and $\\\\frac{1}{3} \\\\int_{t}^{\\\\infty} \\\\frac{d x}{x^{3}}$ converges ( $p$ integral with $p=3$ ), it follows by the comparison test that $\\\\int_{1}^{\\\\infty} \\\\frac{x d x}{3 x^{4}+5 x^{2}+1}$ also converges.\\n\\nNote that the purpose of examining the integrand for large $x$ is to obtain a suitable comparison integral.\\n\\nMethod 2: Let $f(x)=\\\\frac{x}{3 x^{4}+5 x^{2}+1}, g(x)=\\\\frac{1}{x^{3}}$. Since $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{f(x)}{3}$, and $\\\\int_{1}^{\\\\infty} g(x) d x$ converges,\\n\\n$\\\\int_{1}^{\\\\infty} f(x) d x$ also converges by the quotient test. Note that in the comparison function $g(x)$, we have discarded the factor $\\\\frac{1}{3}$. However, it could just as well\\\\\\\\\\nhave been included.\\n\\n$\\\\begin{aligned} & \\\\text { Method 3: } \\\\\\\\ & \\\\text { converges. }\\\\end{aligned} \\\\lim _{x \\\\rightarrow \\\\infty} x^{3}\\\\left(\\\\frac{x}{3 x^{4}+5 x^{2}+1}\\\\right)=\\\\frac{1}{3}$. Hence, by Theorem 1, Page 324, the required integral\\n\\n(b) Method 1: For large $\\\\mathrm{x}$, the integrand is approximately $x^{2} / x^{6}=1 / x$\\n\\nFor $x \\\\geq 2, \\\\frac{x^{2}-1}{\\\\sqrt{x^{6}+1}} \\\\geq \\\\frac{1}{2} . \\\\frac{1}{x}$. Since $\\\\frac{1}{2} \\\\int_{2}^{\\\\infty} \\\\frac{d x}{x}$ diverges, $\\\\int_{2}^{\\\\infty} \\\\frac{x^{2}-1}{\\\\sqrt{x^{6}+16}} d x$ also diverges.\\n\\nMethod 2: Let $f(x)=\\\\frac{x^{2}-1}{\\\\sqrt{\\\\mathrm{x}^{6}-16}}, g(x)=\\\\frac{1}{x}$. Then, since $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\frac{f(x)}{g(x)}=1$ and $\\\\int_{2}^{\\\\infty} g(x) d x$ diverges,\\n\\n$\\\\int_{2}^{\\\\infty} f(x) d x$ also diverges.\\n\\nMethod 3: Since $\\\\lim _{x \\\\rightarrow \\\\infty} x\\\\left(\\\\frac{x^{2}-1}{\\\\sqrt{x^{6}+16}}\\\\right)=1$, the required integral diverges by Theorem 1, Page 324.\\n\\nNote that Method 1 may (and often does) require us to obtain a suitable inequality factor (in this case, $\\\\frac{1}{2}$ or any positive constant less than $\\\\frac{1}{2}$ ) before the comparison test can be applied. Methods 2 and 3, however, do not require this.\\n',\n",
       " \"\\n12.6. Prove that $\\\\int_{0}^{\\\\infty} e^{-x^{2}} d x$ converges.\\n\\n$\\\\lim _{x \\\\rightarrow \\\\infty} x^{2} e^{-x^{2}}=0$ (by L'Hospital's rule or otherwise). Then, by Theorem 1, with $A=0, p=2$, the given integral converges. Compare Problem 11.10(a).\\n\",\n",
       " '\\n12.7. Examine for convergence: (a) $\\\\int_{1}^{\\\\infty} \\\\frac{\\\\ln x}{x+a} d x$, where a is a positive constant and (b) $\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x$.\\n\\n(a) $\\\\lim _{x \\\\rightarrow \\\\infty} x \\\\cdot \\\\frac{\\\\ln x}{x+a}=\\\\infty$. Hence, by Theorem 1, Page 324, with $\\\\mathrm{A}=\\\\infty, \\\\mathrm{p}=1$, the given integral diverges.\\n\\n(b) $\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\int_{0}^{\\\\pi} \\\\frac{1-\\\\cos x}{x^{2}} d x+\\\\int_{\\\\pi}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x$.\\n\\nThe first integral on the right converges [see Problem 12.1(e)].\\n\\nSince $\\\\lim _{x \\\\rightarrow \\\\infty} x^{3 / 2}\\\\left(\\\\frac{1-\\\\cos x}{x^{2}}\\\\right)=0$, the second integral on the right converges by Theorem 1, Page 324, with $A=0$ and $p=3 / 2$.\\n\\nThus, the given integral converges.\\n',\n",
       " '\\n12.8. Test for convergence: (a) $\\\\int_{-\\\\infty}^{-1} \\\\frac{e^{x}}{x} d x$ and (b) $\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{x^{3}+x^{2}}{x^{6}+1} d x$.\\n\\n(a) Let $\\\\mathrm{x}=-\\\\mathrm{y}$. Then the integral becomes $-\\\\int_{1}^{\\\\infty} \\\\frac{e^{-y}}{y} d y$.\\n\\nMethod 1: $\\\\quad \\\\frac{e^{-y}}{y} \\\\leqq e^{-y}$ for $\\\\leqq 1$. Then, since $\\\\int_{1}^{\\\\infty} \\\\mathrm{e}^{-y} d y$ converges, $\\\\int_{1}^{\\\\infty} \\\\frac{e^{-y}}{y} d y$ converges; hence, the given integral converges.\\n\\nMethod 2: $\\\\lim _{x \\\\rightarrow \\\\infty} y^{2}\\\\left(\\\\frac{e^{-y}}{y}\\\\right)=\\\\lim _{y \\\\rightarrow \\\\infty} y e^{-y}=0$. Then the given integral converges by Theorem 1, Page 324, with $A=0$ and $p=2$.\\n\\n(b) Write the given integral as $\\\\int_{-\\\\infty}^{0} \\\\frac{x^{3}+x^{2}}{x^{6}+1} d x+\\\\int_{0}^{\\\\infty} \\\\frac{x^{3}+x^{2}}{x^{6}+1} d x$. Letting $x=-y$ in the first integral, it becomes $-\\\\int_{0}^{\\\\infty} \\\\frac{y^{3}-y^{2}}{y^{6}+1} d y$. Since $\\\\lim _{y \\\\rightarrow \\\\infty} y^{3}\\\\left(\\\\frac{y^{3}-y^{2}}{y^{6}+1}\\\\right)=1$, this integral converges.\\n\\nSince $\\\\lim _{x \\\\rightarrow \\\\infty} x^{3}\\\\left(\\\\frac{x^{3}+x^{2}}{x^{6}+1}\\\\right)=1$, the second integral converges.\\n\\nThus, the given integral converges.\\n\\n\\n\\\\section*{Absolute and conditional convergence for improper integrals of the first kind}\\n',\n",
       " '12.9. Prove that $\\\\int_{\\\\alpha}^{\\\\infty} f(x) d x$ converges if $\\\\int_{0}^{\\\\infty}|f(x)| d x$ converges; i.e., an absolutely convergent integral is\\\\\\\\\\nconvergent.\\n\\nWe have $-|f(x)| \\\\leqq f(x) \\\\leqq|f(x)|$; i.e., $0 \\\\leqq f(x)+|f(x)| 2|f(x)|$. Then\\n\\n$$\\n0 \\\\leqq \\\\int_{a}^{b}[f(x) \\\\leqq+\\\\mid f(x)] d x \\\\leqq 2 \\\\int_{a}^{b}|f(x)| d x\\n$$\\n\\nIf $\\\\int_{\\\\alpha}^{\\\\infty}|f(x)| d x$ converges, it follows that $\\\\left.\\\\int_{\\\\alpha}^{\\\\infty}|f(x)+| f(x) \\\\mid\\\\right] d x$ converges. Hence, by subtracting $\\\\int_{\\\\alpha}^{\\\\infty}|f(x)| d x$, which converges, we see that $\\\\int_{\\\\alpha}^{\\\\infty} f(x) d x$ converges.\\n',\n",
       " '\\n12.10. Prove that $\\\\int_{t}^{\\\\infty} \\\\frac{\\\\cos x}{x^{2}} d x$ converges.\\n\\nMethod 1: $\\\\left|\\\\frac{\\\\cos x}{x^{2}}\\\\right| \\\\leqq \\\\frac{1}{x^{2}}$ for $x \\\\geqq 1$. Then by the comparison test, since $\\\\int_{t}^{\\\\infty} \\\\frac{d x}{x^{2}}$ converges, it follows that $\\\\int_{t}^{\\\\infty}\\\\left|\\\\frac{\\\\cos x}{x^{2}}\\\\right| d x$ converges; $\\\\int_{t}^{\\\\infty}\\\\left|\\\\frac{\\\\cos x}{x^{2}}\\\\right| d x$ converges, i.e., $\\\\int_{t}^{\\\\infty} \\\\frac{\\\\cos x}{x^{2}}$ converges absolutely, and so converges by Problem 12.9.\\n\\nMethod 2: Since $\\\\lim _{x \\\\rightarrow \\\\infty} x^{3 / 2}\\\\left|\\\\frac{\\\\cos x}{e^{2}}\\\\right|=\\\\lim _{x \\\\rightarrow \\\\infty}\\\\left|\\\\frac{\\\\cos x}{x^{1 / 2}}\\\\right|=0$ it follows from Theorem 1, Page 324, with $A=0$ and $p=3 / 2$. that $\\\\int_{t}^{\\\\infty}\\\\left|\\\\frac{\\\\cos x}{x^{2}}\\\\right| d x$ converges, and, hence, $\\\\int_{t}^{\\\\infty} \\\\frac{\\\\cos x}{x^{2}} d x$ converges (absolutely).\\n',\n",
       " '\\n12.11. Prove that $\\\\int_{t}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x$ converges.\\n\\nSince $\\\\int_{0}^{1} \\\\frac{\\\\sin x}{x} d x$ converges $\\\\left(\\\\right.$ because $\\\\frac{\\\\sin x}{x}$ is continuous in $0<x \\\\leqq 1$ and $\\\\lim _{x \\\\rightarrow 0+} \\\\frac{\\\\sin x}{x}=1$ ), we need only show that $\\\\int_{1}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x$ converges.\\n\\nMethod 1: Integration by parts yields\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{t}^{M} \\\\frac{\\\\sin x}{x} d x=-\\\\left.\\\\frac{\\\\cos x}{x}\\\\right|_{1} ^{M}+\\\\int_{t}^{M} \\\\frac{\\\\cos x}{x^{2}} d x=\\\\cos 1-\\\\frac{\\\\cos M}{M}+\\\\int_{t}^{M} \\\\frac{\\\\cos x}{x^{2}} d x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nor, on taking the limit on both sides of Equation (1) as $M \\\\rightarrow \\\\infty$ and using the fact that $\\\\lim _{M \\\\rightarrow \\\\infty} \\\\frac{\\\\cos M}{M}=0$,\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{1}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x=\\\\cos 1+\\\\int_{1}^{\\\\infty} \\\\frac{\\\\cos x}{x^{2}} d x \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSince the integral on the right of Equation (2) converges by Problem 12.10, the required result follows. The technique of integration by parts to establish convergence is often useful in practice.\\n\\nMethod 2:\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x & =\\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin x}{x} d x+\\\\int_{\\\\pi}^{2 \\\\pi} \\\\frac{\\\\sin x}{x} d x+\\\\ldots+\\\\int_{n \\\\pi}^{(n+1) \\\\pi} \\\\frac{\\\\sin x}{x} d x+\\\\ldots \\\\\\\\\\n& =\\\\sum_{n=0}^{\\\\infty} \\\\int_{n \\\\pi}^{(n+1) \\\\pi} \\\\frac{\\\\sin x}{x} d x\\n\\\\end{aligned}\\n$$\\n\\nLetting $x=v+n \\\\pi$, the summation becomes\\n\\n$$\\n\\\\sum_{n=0}^{\\\\infty}(-1)^{n} \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{n+n \\\\pi} d v \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v} d v+\\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+\\\\pi} d v+\\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+2 \\\\pi} d v-\\\\ldots\\n$$\\n\\nThis is an alternating series. Since $\\\\frac{1}{v+n \\\\pi} \\\\leqq \\\\frac{1}{v+(n+1) \\\\pi}$ and $\\\\sin v \\\\geqq 0$ in $[0, \\\\pi]$, it follows that\\n\\n$$\\n\\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+n \\\\pi} d v \\\\leqq \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+(n+1) \\\\pi} d v\\n$$\\n\\nAlso,\\n\\n$$\\n\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+n \\\\pi} d v \\\\leq \\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{0}^{\\\\pi} \\\\frac{d v}{n \\\\pi}=0\\n$$\\n\\nThus, each term of the alternating series is, in absolute value, less than or equal to the preceding term, and the $n$th term approaches zero as $n \\\\rightarrow \\\\infty$. Hence, by the alternating series test (Page 281), the series and, thus, the integral converge.\\n',\n",
       " '\\n12.12. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x$ converges conditionally.\\n\\nSince, by Problem 12.11, the given integral converges, we must show that it is not absolutely convergent; i.e., $\\\\int_{0}^{\\\\infty}\\\\left|\\\\frac{\\\\sin x}{x}\\\\right| d x$ diverges. diverges.\\n\\nAs in Problem 12.11, Method 2, we have\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{\\\\infty}\\\\left|\\\\frac{\\\\sin x}{x}\\\\right| d x=\\\\sum_{n=0}^{\\\\infty} \\\\int_{n \\\\pi}^{(n+1) \\\\pi}\\\\left|\\\\frac{\\\\sin x}{x}\\\\right| d x=\\\\sum_{n=0}^{\\\\infty} \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+n \\\\pi} d v \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nNow $\\\\frac{1}{v+n \\\\pi} \\\\geq \\\\frac{1}{(n+1) \\\\pi}$ for $0 \\\\leqq v \\\\leqq \\\\pi$. Hence,\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin v}{v+n \\\\pi} d v \\\\geq \\\\frac{1}{(n+1) \\\\pi} \\\\int_{9}^{\\\\pi} \\\\sin v d v=\\\\frac{2}{(n+1) \\\\pi} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSince $\\\\sum_{n=0}^{\\\\infty} \\\\frac{2}{(n+1) \\\\pi}$ diverges, the series on the right of Equation (1) diverges by the comparison test.\\n\\nHence, $\\\\int_{0}^{\\\\infty}\\\\left|\\\\frac{\\\\sin x}{x}\\\\right| d x$ diverges and the required result follows.\\n\\n\\n\\\\section*{Improper integrals of the second kind, cauchy principal value}\\n',\n",
       " '12.13. (a) Prove that $\\\\int_{-1}^{7} \\\\frac{d x}{\\\\sqrt[3]{x+1}}$ converges and (b) find its value.\\n\\nThe integrand is unbounded at $x=-1$. Then we define the integral as\\n\\n$$\\n\\\\lim _{\\\\in \\\\rightarrow 0+} \\\\int_{-1+\\\\in}^{7} \\\\frac{d x}{\\\\sqrt[3]{x+1}}=\\\\left.\\\\lim _{\\\\epsilon \\\\rightarrow 0+} \\\\frac{(x+1)^{2 / 3}}{2 / 3}\\\\right|_{-1+\\\\epsilon} ^{7}=\\\\lim _{\\\\epsilon \\\\rightarrow 0+}\\\\left(6-\\\\frac{3}{2} \\\\epsilon^{2 / 3}\\\\right)=6\\n$$\\n\\nThis shows that the integral converges to 6 .\\n',\n",
       " '\\n12.14. Determine whether $\\\\int_{-1}^{5} \\\\frac{d x}{(x-1)^{3}}$ converges (a) in the usual sense and (b) in the Cauchy principal value sense.\\n\\n(a) By definition,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{-1}^{5} \\\\frac{d x}{(x-1)^{3}} & =\\\\lim _{\\\\epsilon_{1} \\\\rightarrow 0+} \\\\int_{-1}^{1-\\\\epsilon_{1}} \\\\frac{d x}{(x-1)^{3}}+\\\\lim _{\\\\epsilon_{2} \\\\rightarrow 0+} \\\\int_{1+\\\\epsilon_{2}}^{5} \\\\frac{d x}{(x-1)^{3}} \\\\\\\\\\n& =\\\\lim _{\\\\epsilon_{1} \\\\rightarrow 0+}\\\\left(\\\\frac{1}{8}-\\\\frac{1}{2 \\\\epsilon_{1}^{2}}\\\\right)+\\\\lim _{\\\\epsilon_{2} \\\\rightarrow 0+}\\\\left(\\\\frac{1}{2 \\\\epsilon_{2}^{2}}-\\\\frac{1}{32}\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nand, since the limits do not exist, the integral does not converge in the usual sense.\\n\\n(b) Since\\n\\n$$\\n\\\\lim _{\\\\epsilon \\\\rightarrow 0+}\\\\left\\\\{\\\\int_{-1}^{1-\\\\epsilon} \\\\frac{d x}{(x-1)^{3}}+\\\\int_{1+\\\\epsilon}^{5} \\\\frac{d x}{(x-1)^{3}}\\\\right\\\\}=\\\\lim _{\\\\epsilon \\\\rightarrow 0+}\\\\left\\\\{\\\\frac{1}{8}-\\\\frac{1}{2 \\\\epsilon^{2}}+\\\\frac{1}{2 \\\\epsilon^{2}}-\\\\frac{1}{32}\\\\right\\\\}=\\\\frac{3}{32}\\n$$\\n\\nthe integral exists in the Cauchy principal value sense. The principal value is $3 / 32$.\\n',\n",
       " '\\n12.15. Investigate the convergence of:\\\\\\\\\\n(a) $\\\\int_{2}^{3} \\\\frac{d x}{x^{2}\\\\left(x^{3}-8\\\\right)^{2 / 3}}$\\\\\\\\\\n(c) $\\\\int_{1}^{5} \\\\frac{d x}{\\\\sqrt{(5-x)(x-1)}}$\\\\\\\\\\n(e) $\\\\int_{0}^{\\\\pi / 2} \\\\frac{d x}{(\\\\cos x)^{1 / n}}, n>1$\\\\\\\\\\n(b) $\\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin x}{x^{3}} d x$\\\\\\\\\\n(d) $\\\\int_{-1}^{1} \\\\frac{2^{\\\\sin ^{-1} x}}{1-x} d x$\\n\\n(a) $\\\\lim _{x \\\\rightarrow 2+}(x-2)^{2 / 3} \\\\cdot \\\\frac{1}{x^{2}\\\\left(x^{3}-8\\\\right)^{2 / 3}}=\\\\lim _{x \\\\rightarrow 2+} \\\\frac{1}{x^{2}}\\\\left(\\\\frac{1}{x^{2}+2 x+4}\\\\right)^{2 / 3}=\\\\frac{1}{8 \\\\sqrt[3]{18}}$. Hence, the integral converges by Theorem 3(i), Page 326.\\n\\n(b) $\\\\lim _{x \\\\rightarrow 0+} x^{2} \\\\cdot \\\\frac{\\\\sin x}{x^{3}}=1$. Hence, the integral diverges by Theorem 3(ii) on Page 326.\\n\\n(c) Write the integral as $\\\\int_{1}^{3} \\\\frac{d x}{\\\\sqrt{(5-x)(x-1)}}+\\\\int_{3}^{5} \\\\frac{d x}{\\\\sqrt{(5-x)(x-1)}}$.\\n\\nSince $\\\\lim _{x \\\\rightarrow 1+}(x-1)^{1 / 2} \\\\cdot \\\\frac{1}{\\\\sqrt{(5-x)(x-1)}}=\\\\frac{1}{2}$, the first integral converges.\\n\\nSince $\\\\lim _{x \\\\rightarrow 5-}(5-x)^{1 / 2} \\\\cdot \\\\frac{1}{\\\\sqrt{(5-x)(x-1)}}=\\\\frac{1}{2}$, the second integral converges.\\n\\nThus, the given integral converges.\\n\\n(d) $\\\\lim _{x \\\\rightarrow 1-}(1-x) \\\\cdot \\\\frac{2^{\\\\sin ^{-1} x}}{1-x}=2^{\\\\pi / 2}$. Hence, the integral diverges.\\n\\nAnother method: $\\\\quad \\\\frac{2^{\\\\sin ^{-1} x}}{1-x} \\\\geqq \\\\frac{2^{-\\\\pi / 2}}{1-x}$, and $\\\\int_{-1}^{1} \\\\frac{d x}{1-x}$ diverges. Hence, the given integral diverges.\\n\\n(e) $\\\\lim _{x \\\\rightarrow 1 / 2 \\\\pi-}(\\\\pi / 2-x)^{1 / n} \\\\cdot \\\\frac{1}{(\\\\cos x)^{1 / n}}=\\\\lim _{x \\\\rightarrow 1 / 2 \\\\pi-}\\\\left(\\\\frac{\\\\pi / 2-x}{\\\\cos x}\\\\right)^{1 / n}=1$. Hence, the integral converges.\\n',\n",
       " '\\n12.16. If $m$ and $n$ are real numbers, prove that $\\\\int_{0}^{1} x^{m-1}(1-x)^{n-1} d x$ (a) converges if $m>0$ and $n>0$ simultaneously and (b) diverges otherwise.\\n\\n(a) For $m \\\\geqq 1$ and $n \\\\geqq 1$ simultaneously, the integral converges, since the integrand is continuous in $0 \\\\leqq x$ $\\\\leq 1$. Write the integral as\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{1 / 2} x^{m-1}(1-x)^{n-1} d x+\\\\int_{1 / 2}^{1} x^{m-1}(1-x)^{n-1} d x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf $0<m<1$ and $0<n<1$, the first integral converges, since $\\\\lim _{x \\\\rightarrow 0}{ }^{+} x^{1-m} \\\\cdot x^{m-1}(1-x)^{n-1}=1$, using Theorem 3(i), Page 326, with $p=1-m$ and $a=0$.\\n\\nSimilarly, the second integral converges, since $\\\\left.\\\\lim _{x \\\\rightarrow 1-}(1-x)^{1-n} \\\\cdot x\\\\right)^{n-1}(1-x)^{n-1}=1$, using 4(i), Page 326, with $p=1-n$ and $b=1$.\\n\\nThus, the given integral converges if $m>0$ and $n>0$ simultaneously.\\n\\n(b) If $m \\\\leqq 0, \\\\lim _{x \\\\rightarrow 0+} x \\\\cdot x^{m-1}(1-x)^{n-1}=\\\\infty$. Hence, the first integral in Equation (1) diverges, regardless of the value of $n$, by Theorem 3(ii), Page 326, with $p=1$ and $a=0$. lows.\\n\\nSimilarly, the second integral diverges if $n \\\\leqq 0$, regardless of the value of $m$, and the required result fol-\\n\\nSome interesting properties of the given integral, called the beta integral or beta function, are considered in Chapter 15.\\n',\n",
       " '\\n12.17. Prove that $\\\\int_{0}^{\\\\pi} \\\\frac{1}{x} \\\\sin \\\\frac{1}{x} d x$ converges conditionally.\\n\\nLetting $x=1 / y$, the integral becomes $\\\\int_{1 / \\\\pi}^{\\\\infty} \\\\frac{\\\\sin y}{y} d y$ and the required result follows from Problem 12.12.\\n\\n\\n\\\\section*{Improper integrals of the third kind}\\n',\n",
       " \"12.18. If $n$ is a real number, prove that $\\\\int_{0}^{\\\\infty} x^{n-1} e^{-x} d x$ (a) converges if $n>0$ and (b) diverges if $n \\\\leqq 0$.\\n\\nWrite the integral as\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{1} x^{n-1} e^{-x} d x+\\\\int_{1}^{\\\\infty} x^{n-1} e^{-x} d x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\n(a) If $n \\\\geqq 1$, the first integral in Equation (1) converges, since the integrand is continuous in $0 \\\\leqq x \\\\leqq 1$.\\n\\nIf $0<n<1$, the first integral in Equation (1) is an improper integral of the second kind at $x=0$. Since $\\\\lim _{x \\\\rightarrow 0^{+}} x^{1-n} \\\\cdot x^{n-1} e^{-x}=1$, the integral converges by Theorem 3(i), Page 326, with $p=1-n$ and $a=0$.\\n\\nThus, the first integral converges for $n>0$.\\n\\nIf $n>0$, the second integral in Equation (1) is an improper integral of the first kind. Since $\\\\lim _{x \\\\rightarrow \\\\infty} x^{2} \\\\cdot x^{n-1}$ $e^{-x}=0$ (by L'Hospital's rule or otherwise), this integral converges by Theorem 1(i), Page 324, with $p=2$.\\n\\nThus, the second integral also converges for $n>0$, and so the given integral converges for $n>0$.\\n\\n(b) If $\\\\mathrm{n} \\\\leqq 0$, the first integral of Equation (1) diverges, since $\\\\lim _{x \\\\rightarrow 0+} x \\\\cdot x^{n-1} e^{-x}=\\\\infty$ [Theorem 3(ii), Page 326].\\n\\nIf $n \\\\leqq 0$, the second integral of Equation (1) converges, since $\\\\lim _{x \\\\rightarrow \\\\infty} \\\\cdot x^{n-1} e^{-x}=0$ [Theorem 1(i), Page 324].\\n\\nSince the first integral in Equation (1) diverges while the second integral converges, their sum also diverges; i.e., the given integral diverges if $n \\\\leqq 0$.\\n\\nSome interesting properties of the given integral, called the gamma function, are considered in Chapter 15 .\\n\\n\\n\\\\section*{Uniform convergence of improper integrals}\\n\",\n",
       " '12.19. (a) Evaluate $\\\\phi(\\\\alpha)=\\\\int_{0}^{\\\\infty} \\\\alpha e^{-\\\\alpha x} d x$ for $\\\\alpha>0$. (b) Prove that the integral in (a) converges uniformly to 1 for $\\\\alpha$ $\\\\epsilon \\\\alpha 1>0$. (c) Explain why the integral does not converge uniformly to 1 for $\\\\alpha>0$.\\n\\n(a) $\\\\phi(\\\\alpha)=\\\\lim _{b \\\\rightarrow \\\\infty} \\\\int_{a}^{b} \\\\alpha e^{-a e} d x=\\\\lim _{b \\\\rightarrow \\\\infty}-\\\\left.e^{-\\\\alpha x}\\\\right|_{x=0} ^{b}=\\\\lim _{b \\\\rightarrow \\\\infty} 1-e^{-a b}=1$ if $\\\\alpha>0$\\n\\nThus, the integral converges to 1 for all $\\\\alpha>0$.\\n\\n(b) Method 1, using definition: The integral converges uniformly to 1 in $\\\\alpha \\\\varepsilon \\\\alpha_{1}>0$ if for each $\\\\epsilon>0$ we can find $N$, depending on $\\\\epsilon$ but not on $\\\\alpha$, such that $\\\\left|1-\\\\int_{0}^{u} \\\\alpha e^{-\\\\alpha x} d x\\\\right|<\\\\in$ for all $u>N$.\\n\\nSince $\\\\left|1-\\\\int_{0}^{u} \\\\alpha e^{-\\\\alpha x} d x\\\\right|=\\\\left|1-\\\\left(1-e^{-\\\\alpha u}\\\\right)\\\\right|=e^{-a u}<e^{-\\\\alpha_{1} u}<\\\\in$ for $u>\\\\frac{1}{\\\\alpha_{1}} \\\\ln \\\\frac{1}{\\\\in}=N$, the result follows.\\n\\nMethod 2, using the Weierstrass $M$ test: Since $\\\\lim _{x \\\\rightarrow \\\\infty} x^{2} \\\\cdot \\\\alpha e^{-\\\\alpha x}=0$ for $\\\\alpha \\\\alpha_{1}>0$, we can choose $\\\\left|\\\\alpha e^{-\\\\alpha x}\\\\right|<\\\\frac{1}{x^{2}}$ for sufficiently large $x$-say, $x \\\\geqq x_{0}$. Taking $M(x)=\\\\frac{1}{x^{2}}$ and noting that $\\\\int_{x_{0}}^{\\\\infty} \\\\frac{d x}{x^{2}}$ converges, it follows that the given integral is uniformly convergent to 1 for $\\\\alpha \\\\varepsilon \\\\alpha_{1}>0$.\\n\\n(c) As $\\\\alpha 1 \\\\rightarrow 0$, the number $\\\\mathrm{N}$ in the first method of (b) increases without limit, so that the integral cannot be uniformly convergent for $\\\\alpha>0$.\\n',\n",
       " '\\n12.20. If $\\\\phi(\\\\alpha)=\\\\int_{0}^{\\\\infty} f(x, \\\\alpha) d x$ is uniformly convergent for $\\\\alpha_{1} \\\\leqq \\\\alpha \\\\leqq \\\\alpha_{2}$, prove that $\\\\phi(\\\\alpha)$ is continuous this interval.\\n\\nLet $\\\\phi(\\\\boldsymbol{\\\\alpha})=\\\\int_{u}^{u} f(x, \\\\alpha) d x+R(u, \\\\boldsymbol{\\\\alpha})$, where $\\\\mathrm{R}(u, \\\\boldsymbol{\\\\alpha})=\\\\int_{u}^{\\\\infty} f(x, \\\\boldsymbol{\\\\alpha}) d x$.\\n\\nThen $\\\\phi(\\\\alpha+h)=\\\\int_{u}^{u} f(x, \\\\alpha+h) d x+R(u, \\\\alpha+h)$ and so\\n\\n$$\\n\\\\phi(\\\\alpha+h)-\\\\phi(\\\\alpha)=\\\\int_{u}^{u}\\\\{f(x, \\\\alpha+h)-f(x, \\\\alpha)\\\\} d x+R(u, \\\\alpha+h)-R(u, \\\\alpha)\\n$$\\n\\nThus,\\n\\n\\n\\\\begin{equation*}\\n|\\\\phi(\\\\alpha+h)-\\\\phi(\\\\alpha)| \\\\leqq \\\\int_{a}^{u}|f(x, \\\\alpha+h)-f(x, \\\\alpha)| d x+\\\\mid R(u, \\\\alpha+h|+| R(u, \\\\alpha) \\\\mid \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nSince the integral is uniformly convergent in $(\\\\alpha)_{1} \\\\leq(\\\\alpha) \\\\leq \\\\alpha_{2}$, we can, for find $N$ independent of $(\\\\alpha)$ such that for $(u)>N$,\\n\\n\\n\\\\begin{equation*}\\n|R(u, \\\\alpha+h)|<\\\\epsilon / 3,|R(u, \\\\alpha)|<\\\\epsilon / 3 \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSince $f(x, \\\\alpha)$ is continuous, we can find $\\\\delta>0$ corresponding to each $\\\\epsilon>0$ such that\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{a}^{v}|f(x, \\\\alpha+h)-f(x, \\\\alpha)| d x<\\\\in / 3 \\\\quad \\\\text { for }|h|<\\\\delta \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nUsing Equations (2) and (3) in (1), we see that $|\\\\phi(\\\\alpha+h)-\\\\phi(\\\\alpha)|<\\\\epsilon$ for $|(h)|<\\\\delta$, so that $\\\\phi(\\\\alpha)$ is continuous.\\n\\nNote that in this proof we assume that both $\\\\alpha$ and $\\\\alpha+h$ are in the interval $\\\\alpha_{1} \\\\leq \\\\alpha \\\\leq \\\\alpha_{2}$. Thus, if $\\\\alpha=\\\\alpha_{1}$, for example, $h>0$ and right-hand continuity is assumed.\\n\\nAlso note the analogy of this proof with that for infinite series.\\n\\nOther properties of uniformly convergent integrals can be proved similarly.\\n',\n",
       " '\\n12.21. (a) Show that $\\\\lim _{\\\\alpha \\\\rightarrow 0+} \\\\int_{0}^{\\\\infty} \\\\alpha e^{-\\\\alpha x} d x \\\\neq \\\\int_{0}^{\\\\infty}\\\\left(\\\\lim _{\\\\alpha \\\\rightarrow 0+} \\\\alpha e^{-\\\\alpha x}\\\\right) d x$ and (b) explain the result in (a).\\n\\n(a) $\\\\lim _{\\\\alpha \\\\rightarrow 0+} \\\\int_{0}^{\\\\infty} \\\\alpha e^{-\\\\alpha x} d x=\\\\lim _{\\\\alpha \\\\rightarrow 0+}=1$ by Problem 12.19(a).\\n\\n$\\\\int_{0}^{\\\\infty}\\\\left(\\\\lim _{\\\\alpha \\\\rightarrow 0+} \\\\alpha e^{-\\\\alpha x}\\\\right) d x=\\\\int_{0}^{\\\\infty} 0 d x=0$. Thus, the required result follows.\\n\\n(b) Since $\\\\phi(\\\\alpha)=\\\\int_{0}^{\\\\infty} \\\\alpha e^{-\\\\alpha x} d x$ is not uniformly convergent for $\\\\alpha \\\\geqq 0$ (see Problem 12.19), there is no guarantee that $\\\\phi(\\\\alpha)$ will be continuous for $\\\\alpha \\\\geqq 0$. Thus, $\\\\lim _{\\\\alpha \\\\rightarrow 0+} \\\\phi(\\\\alpha)$ may not be equal to $\\\\phi(0)$.\\n',\n",
       " '\\n12.22. (a) Prove that $\\\\int_{0}^{\\\\infty} e^{-\\\\alpha x} \\\\cos r x d x=\\\\frac{\\\\alpha}{\\\\alpha^{2}+r^{2}}$ for $\\\\alpha>0$ and any real value of $r$. (b) Prove that the integral in\\n\\n(a) converges uniformly and absolutely for $a \\\\leqq \\\\alpha \\\\leqq b$, where $0<a<b$ and any $\\\\mathrm{r}$.\\n\\n(a) From integration formula 34, Page 103, we have\\n\\n$$\\n\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} e^{-\\\\alpha x} \\\\cos r x d x=\\\\left.\\\\lim _{M \\\\rightarrow \\\\infty} \\\\frac{e^{-\\\\alpha x}(r \\\\sin r x-\\\\alpha \\\\cos r x)}{\\\\alpha^{2}+r^{2}}\\\\right|_{0} ^{M}=\\\\frac{\\\\alpha}{\\\\alpha^{2}+r^{2}}\\n$$\\n\\n(b) This follows at once from the Weierstrass $M$ test for integrals, by noting that $\\\\left|e^{-\\\\alpha x} \\\\cos r x\\\\right| \\\\leqq e^{-\\\\alpha x}$ and $\\\\int_{0}^{\\\\infty} e^{-\\\\alpha x} d x$ converges.\\n\\n\\n\\\\section*{Evaluation of definite integrals}\\n',\n",
       " '12.23. Prove that $\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\sin x d x=\\\\frac{\\\\pi}{2} \\\\ln 2$.\\n\\nThe given integral converges [Problem 12.42(f)]. Letting $x=\\\\pi / 2-y$,\\n\\n$$\\nI=\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\sin x d x=\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\cos y d y=\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\cos x d x\\n$$\\n\\nThen\\n\\n\\n\\\\begin{align*}\\n2 I & =\\\\int_{0}^{\\\\pi / 2}(\\\\ln \\\\sin x+\\\\ln \\\\cos x) d x=\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\left(\\\\frac{\\\\sin 2 x}{2}\\\\right) d x  \\\\tag{1}\\\\\\\\\\n& =\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\sin 2 x d x-\\\\int_{0}^{\\\\pi / 2} \\\\ln 2 d x=\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\sin 2 x d x-\\\\frac{\\\\pi}{2} \\\\ln 2\\n\\\\end{align*}\\n\\n\\nLetting $2 x=v$,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{02}^{\\\\pi / 2} \\\\ln \\\\sin 2 x d x & =\\\\frac{1}{2} \\\\int_{0}^{\\\\pi} \\\\ln \\\\sin v d v=\\\\frac{1}{2}\\\\left\\\\{\\\\int_{0}^{\\\\pi / 2} \\\\ln \\\\sin v d v\\\\right\\\\} \\\\\\\\\\n& \\\\left.=\\\\frac{1}{2}(I+I)=I \\\\quad \\\\text { (letting } v=\\\\pi-\\\\text { in the last integral }\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nHence, Equation $(l)$ becomes $2 I=I \\\\frac{\\\\pi}{2} \\\\ln$ on $I=-\\\\frac{\\\\pi}{2} \\\\ln 2$.\\n',\n",
       " '\\n12.24. Prove that $\\\\int_{0}^{\\\\pi} x \\\\ln \\\\sin x d x=-\\\\frac{\\\\pi^{2}}{2} \\\\ln 2$.\\n\\nLet $x=\\\\pi-y$. Then, using the results in the preceding problem,\\n\\n$$\\n\\\\begin{aligned}\\nJ=\\\\int_{0}^{\\\\pi} x \\\\ln \\\\sin x d x & =\\\\int_{0}^{\\\\pi}(\\\\pi-u) \\\\ln \\\\sin u d u=\\\\int_{0}^{\\\\pi}(\\\\pi-x) \\\\ln \\\\sin x d x \\\\\\\\\\n& =\\\\pi \\\\int_{0}^{\\\\pi} \\\\ln \\\\sin x d x-\\\\int_{0}^{\\\\pi} x \\\\ln \\\\sin x d x \\\\\\\\\\n& =-\\\\pi^{2} \\\\ln 2-J\\n\\\\end{aligned}\\n$$\\n\\nor $\\\\quad J=-\\\\frac{\\\\pi^{2}}{2} \\\\ln 2$.\\n',\n",
       " '\\n12.25. (a) Prove that $\\\\phi(\\\\alpha)=\\\\int_{0}^{\\\\infty} \\\\frac{d x}{x^{2+\\\\alpha}}$ is uniformly convergent for $\\\\alpha \\\\geqq 1$. (b) Show that $\\\\phi(\\\\alpha)=\\\\frac{\\\\pi}{2 \\\\sqrt{\\\\alpha}}$.\\n\\n(c) Evaluate $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+1\\\\right)^{2}}$. (d) Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+1\\\\right)^{n+1}}=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{2 n} \\\\theta d \\\\theta=\\\\frac{1.3 .5 \\\\cdots(2 n-1)}{2.4 .6 \\\\cdots(2 n)} \\\\frac{\\\\pi}{2}$.\\n\\n(a) The result follows from the Weierstrass test, since $\\\\frac{1}{x^{2}+\\\\alpha} \\\\leqq \\\\frac{1}{x^{2}+1}$ for $a \\\\geqq 1$ and $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{x^{2}+1}$ converges.\\n\\n(b) $\\\\phi(\\\\alpha)=\\\\lim _{b \\\\rightarrow \\\\infty} \\\\int_{0}^{b} \\\\frac{d x}{x^{2}+\\\\alpha}=\\\\left.\\\\lim _{b \\\\rightarrow \\\\infty} \\\\frac{1}{\\\\sqrt{\\\\alpha}} \\\\tan ^{-1} \\\\frac{x}{\\\\sqrt{\\\\alpha}}\\\\right|_{0} ^{b}=\\\\lim _{b \\\\rightarrow \\\\infty} \\\\frac{1}{\\\\sqrt{\\\\alpha}} \\\\tan ^{-1} \\\\frac{b}{\\\\sqrt{\\\\alpha}}=\\\\frac{\\\\pi}{2 \\\\sqrt{\\\\alpha}}$\\\\\\\\\\n(c) From (b), $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{x^{2}+\\\\alpha}=\\\\frac{\\\\pi}{2 \\\\sqrt{\\\\alpha}}$. Differentiating both sides with respect to $\\\\alpha$, we have\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\partial}{\\\\partial \\\\alpha}\\\\left(\\\\frac{1}{x^{2}+\\\\alpha}\\\\right) d x=-\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+\\\\alpha\\\\right)^{2}}=\\\\frac{\\\\pi}{4} \\\\alpha^{-3 / 2}\\n$$\\n\\nthe result being justified by Theorem 8 , Page 328, since $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+\\\\alpha\\\\right)^{2}}$ is uniformly convergent for $\\\\alpha \\\\geqq 1$ (because $\\\\frac{1}{\\\\left(x^{2}+\\\\alpha\\\\right)^{2}} \\\\leq \\\\frac{1}{\\\\left(x^{2}+1\\\\right)^{2}}$ and $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+1\\\\right)^{2}}$ converges ).\\n\\nTaking the limit as $\\\\alpha \\\\rightarrow 1+$, using Theorem 6, Page 328, we find $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+1\\\\right)^{2}}=\\\\frac{\\\\pi}{4}$.\\n\\n(d) Differentiating both sides of $\\\\int_{0}^{\\\\infty} \\\\frac{d x}{x^{2}+\\\\alpha}=\\\\frac{\\\\pi}{2} \\\\alpha^{-1 / 2} n$ times, we find\\n\\n$$\\n(-1)(-2) \\\\cdots(-n) \\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+\\\\alpha\\\\right)^{n+1}}=\\\\left(-\\\\frac{1}{2}\\\\right)\\\\left(-\\\\frac{3}{2}\\\\right)\\\\left(-\\\\frac{5}{2}\\\\right) \\\\cdots\\\\left(-\\\\frac{2 n-1}{2}\\\\right) \\\\frac{\\\\pi}{2} \\\\alpha^{-(2 n-1,2)}\\n$$\\n\\nwhere justification proceeds as in (c). Letting $\\\\alpha \\\\rightarrow 1+$, we find\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{d x}{\\\\left(x^{2}+1\\\\right)^{n+1}}=\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(2 n-1)}{2^{n} n !} \\\\frac{\\\\pi}{2}=\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(2 n-1)}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots(2 n)} \\\\frac{\\\\pi}{2}\\n$$\\n\\nSubstituting $x=\\\\tan \\\\theta$, the integral becomes $\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{2 n} \\\\theta d \\\\theta$ and the required result is obtained.\\n',\n",
       " '\\n12.26. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{e^{-a x}-e^{b x}}{x \\\\sec r x} d x=\\\\frac{1}{2} \\\\ln \\\\frac{b^{2}+r^{2}}{a^{2}+e^{2}}$ where $a, b>0$.\\n\\nFrom Problem 12.22 and Theorem 7, Page 328, we have\\n\\n$$\\n\\\\int_{x=0}^{\\\\infty}\\\\left\\\\{\\\\int_{\\\\alpha=a}^{b} e^{-\\\\alpha x} \\\\cos r x d \\\\alpha\\\\right\\\\} d x=\\\\int_{\\\\alpha=a}^{b}\\\\left\\\\{\\\\int_{x=0}^{\\\\infty} e^{-\\\\alpha x} \\\\cos r x d x\\\\right\\\\} d \\\\alpha\\n$$\\n\\nor\\n\\n$$\\n\\\\left.\\\\int_{x=0}^{\\\\infty} \\\\frac{e^{\\\\alpha x} \\\\cos r x}{-x}\\\\right|_{\\\\alpha=a} ^{b} d x=\\\\int_{\\\\alpha=a}^{b} \\\\frac{\\\\alpha}{\\\\alpha^{2}+r^{2}} d \\\\alpha\\n$$\\n\\ni.e.,\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{e^{-a x}-e^{-b x}}{x \\\\sec r x} d x=\\\\frac{1}{2} \\\\ln \\\\frac{b^{2}+r^{2}}{a^{2}+r^{2}}\\n$$\\n',\n",
       " '\\n12.27. Prove that $\\\\int_{0}^{\\\\infty} e^{\\\\alpha x} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\tan ^{-1} \\\\frac{1}{\\\\alpha}-\\\\frac{\\\\alpha}{2} \\\\ln \\\\left(\\\\alpha^{2}+1\\\\right), \\\\alpha>0$.\\n\\nBy Problem 12.22 and Theorem 7, Page 328, we have\\n\\nor\\n\\n$$\\n\\\\int_{0}^{r}\\\\left\\\\{\\\\int_{0}^{\\\\infty} e^{-\\\\alpha x} \\\\cos r x d x\\\\right\\\\} d r=\\\\int_{0}^{\\\\infty}\\\\left\\\\{\\\\int_{0}^{r} e^{-a x} \\\\cos r x d r\\\\right\\\\} d x\\n$$\\n\\n$$\\n\\\\int_{0}^{\\\\infty} e^{-a x} \\\\frac{\\\\sin r x}{x} d x=\\\\int_{0}^{r} \\\\frac{\\\\alpha}{\\\\alpha^{2}+r^{2}}=\\\\tan ^{-1} \\\\frac{r}{\\\\alpha}\\n$$\\n\\nIntegrating again with respect to $r$ from 0 to $r$ yields\\n\\n$$\\n\\\\int_{0}^{\\\\infty} e^{-a x} \\\\frac{1-\\\\cos r x}{x^{2}} d x=\\\\int_{0}^{r} \\\\tan ^{-1} \\\\frac{r}{\\\\alpha} d r=r \\\\tan ^{-1} \\\\frac{r}{\\\\alpha}-\\\\frac{\\\\alpha}{2} \\\\ln \\\\left(\\\\alpha^{2}+r^{2}\\\\right)\\n$$\\n\\nusing integration by parts. The required result follows on letting $r=1$.\\n',\n",
       " '\\n12.28. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\frac{\\\\pi}{2}$.\\n\\nSince $e^{-a x} \\\\frac{1-\\\\cos x}{x^{2}} \\\\leqq \\\\frac{1-\\\\cos x}{x^{2}}$ for $\\\\alpha \\\\geqq 0, x \\\\geqq 0$ and $\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x$ converges [see Problem 12.7(b)], it follows by the Weierstrass test that $\\\\int_{0}^{\\\\infty} e^{\\\\alpha x} \\\\frac{1-\\\\cos x}{x^{2}} d x$ is uniformly convergent and represents a continuous function of $\\\\alpha$ for $\\\\alpha \\\\geqq 0$ (Theorem 6, Page 328). Then, letting $\\\\alpha \\\\rightarrow 0+$, using Problem 12.27, we have\\n\\n$$\\n\\\\lim _{\\\\alpha \\\\rightarrow 0} \\\\int_{0}^{\\\\infty} e^{-\\\\alpha x} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\lim _{\\\\alpha \\\\rightarrow 0}\\\\left\\\\{\\\\tan ^{-1} \\\\frac{1}{\\\\alpha}-\\\\frac{\\\\alpha}{2} \\\\ln \\\\left(\\\\alpha^{2}+1\\\\right)\\\\right\\\\}=\\\\frac{\\\\pi}{2}\\n$$\\n',\n",
       " '\\n12.29. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin x}{x}=\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} x}{x^{2}} d x=\\\\frac{\\\\pi}{2}$.\\n\\nIntegrating by parts, we have\\n\\n$$\\n\\\\int_{\\\\epsilon}^{M} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\left.\\\\left(-\\\\frac{1}{x}\\\\right)(1-\\\\cos x)\\\\right|_{\\\\epsilon} ^{M}+\\\\int_{\\\\epsilon}^{M} \\\\frac{\\\\sin x}{x} d x=\\\\frac{1-\\\\cos \\\\epsilon}{\\\\epsilon}-\\\\frac{1-\\\\cos M}{M}+\\\\int_{\\\\epsilon}^{M} \\\\frac{\\\\sin x}{x} d x\\n$$\\n\\nTaking the limit as $\\\\epsilon \\\\rightarrow 0+$ and $M \\\\rightarrow \\\\infty$ shows that\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x=\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x} d x=\\\\frac{\\\\pi}{2}\\n$$\\n\\nSince $\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x=2 \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2}(x / 2)}{x^{2}} d x=\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} u}{u^{2}} d u$ on letting $\\\\mathrm{u}=x / 2$, we also have $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} x}{x^{2}} d x=\\\\frac{\\\\pi}{2}$.\\n',\n",
       " '\\n12.30. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{3} x}{x} d x=\\\\frac{\\\\pi}{4}$.\\n\\n$$\\n\\\\begin{aligned}\\n\\\\sin ^{3} x & =\\\\left(\\\\frac{e^{i x}-e^{-i x}}{2 i}\\\\right)^{2}=\\\\frac{\\\\left(e^{i x}\\\\right)^{3}-3\\\\left(e^{i x}\\\\right)^{2}\\\\left(e^{-i x}\\\\right)+3\\\\left(e^{i x}\\\\right)\\\\left(e^{i x}\\\\right)^{2}-\\\\left(e^{-i x}\\\\right)^{3}}{(2 i)^{3}} \\\\\\\\\\n& =-\\\\frac{1}{4}\\\\left(\\\\frac{e^{-3 i x}-e^{-3 i x}}{2 i}\\\\right)+\\\\frac{3}{4}\\\\left(\\\\frac{e^{i x}-e^{-i x}}{2 i}\\\\right)=-\\\\frac{1}{4} \\\\sin 3 x+\\\\frac{3}{4} \\\\sin x\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{3} x}{x} d x & =\\\\frac{3}{4} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x-\\\\frac{1}{4} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin 3 x}{x} d x=\\\\frac{3}{4} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin x}{x} d x-\\\\frac{1}{4} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin u}{u} d u \\\\\\\\\\n& =\\\\frac{3}{4}\\\\left(\\\\frac{\\\\pi}{2}\\\\right)-\\\\frac{1}{4}\\\\left(\\\\frac{\\\\pi}{2}\\\\right)=\\\\frac{\\\\pi}{4}\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '12.31. Prove that $\\\\int_{0}^{\\\\infty} e^{-x^{2}} d x=\\\\sqrt{\\\\pi} / 2$.\\n\\nBy Problem 12.6, the integral converges. Let $I_{M}=\\\\int_{0}^{M} e^{-x^{2}} d x=\\\\int_{0}^{M} e^{-y^{2}} d y$ and let $\\\\lim _{M \\\\rightarrow \\\\infty} I_{M}=I$, the required value of the integral. Then\\n\\n$$\\n\\\\begin{aligned}\\nI_{M}^{2} & =\\\\left(\\\\int_{0}^{M} e^{-x^{2}} d x\\\\right)\\\\left(\\\\int_{0}^{M} e^{-x^{2}} d y\\\\right) \\\\\\\\\\n& =\\\\int_{0}^{M} \\\\int_{0}^{M} e^{-\\\\left(x^{2}+y^{2}\\\\right)} d x d y \\\\\\\\\\n& =\\\\iint_{M}^{-\\\\left(x^{2}+y^{2}\\\\right)} d x d y\\n\\\\end{aligned}\\n$$\\n\\nwhere $\\\\Re_{M}$ is the square $O A C E$ of side $M$ (see Figure 12.3). Since the integrand is positive, we have\\n\\n\\n\\\\begin{equation*}\\n\\\\iint_{M} e^{-\\\\left(x^{2}+y^{2}\\\\right)} d x d y \\\\leqq I_{M}^{2} \\\\leqq \\\\iint_{M} e^{-\\\\left(x^{2}+y^{2}\\\\right)} d x d y \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere $\\\\Re_{1}$ and $\\\\Re_{2}$ are the regions in the first quadrant bounded by the circles having radii $M$ and $M \\\\sqrt{2}$, respectively.\\n\\nUsing polar coordinates, we have, from Equation (1),\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{p=0}^{M} e^{-\\\\rho^{2}} \\\\rho d \\\\rho d \\\\phi \\\\leqq I_{M}^{2} \\\\leqq \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\pi=0}^{M \\\\sqrt{2}} e^{-\\\\rho^{2}} \\\\rho d \\\\rho d \\\\phi \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nor\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\pi}{4}\\\\left(1-e^{M^{2}}\\\\right) \\\\leqq I_{M}^{2} \\\\leqq \\\\frac{\\\\pi}{4}\\\\left(1-e^{-2 M^{2}}\\\\right) \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nThen, taking the limit as $M \\\\rightarrow \\\\infty$ in Equation (3), we find $\\\\lim _{M \\\\rightarrow \\\\infty} I^{2}{ }_{M}=I^{2}=\\\\pi / 4$ and $I=\\\\sqrt{\\\\pi} / 2$\\n',\n",
       " '\\n12.32. Evaluate $\\\\int_{0}^{\\\\infty} e^{-x^{2}} \\\\cos \\\\alpha x d x$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-352}\\n\\\\end{center}\\n\\nFigure 12.3\\n\\nLet $I(\\\\alpha)=\\\\int_{0}^{\\\\infty} e^{-x^{2}} \\\\cos \\\\alpha x d x$. Then, using integration by parts and appropriate limiting procedures.\\n\\n$$\\n\\\\frac{d t}{d \\\\alpha}=\\\\int_{0}^{\\\\infty}-x e^{-x^{2}} \\\\sin \\\\alpha x d x=\\\\left.\\\\frac{1}{2} e^{-x^{2}} \\\\sin \\\\alpha x\\\\right|_{0} ^{\\\\infty}-\\\\frac{1}{2} \\\\alpha \\\\int_{0}^{\\\\infty} e^{-x^{2}} \\\\cos \\\\alpha x d x=-\\\\frac{\\\\alpha}{2} I\\n$$\\n\\nThe differentiation under the integral sign is justified by Theorem 8, Page 328, and the fact that $\\\\int_{0}^{\\\\infty} x e^{-x^{2}} \\\\sin$ $\\\\alpha x d x$ is uniformly convergent for all $\\\\alpha$ (since by the Weierstrass test, $\\\\left|x e^{-x_{2}} \\\\sin \\\\alpha x\\\\right| \\\\leqq x e^{-x_{2}}$ and $\\\\int_{0}^{\\\\infty} x e^{-x^{2}} d x$ converges).\\n\\nFrom Problem 12.31 and the uniform convergence, and thus continuity, of the given integral (since $l e^{-x 2}$ $\\\\cos \\\\alpha x \\\\mid \\\\leqq e^{-x 2}$ and $\\\\int_{0}^{\\\\infty} e^{-x 2} d x$ converges, so that that Weierstrass test applies), we have $I(0)=$ $\\\\lim _{\\\\alpha \\\\rightarrow 0} I(\\\\alpha)=\\\\frac{1}{2} \\\\sqrt{\\\\pi}$.\\n\\nSolving $\\\\frac{d I}{d \\\\alpha}=-\\\\frac{\\\\alpha}{2} I$ subject to $I(0)=\\\\frac{\\\\sqrt{\\\\pi}}{2}$, we find $I(\\\\alpha)=\\\\frac{\\\\sqrt{\\\\pi}}{2} e^{-\\\\alpha^{2} / 4}$\\n',\n",
       " '\\n12.33. (a) Prove that $I(\\\\alpha)=\\\\int_{0}^{\\\\infty} e^{-(x-\\\\alpha / x)^{2}} d x=\\\\frac{\\\\sqrt{\\\\pi}}{2}$. (b) Evaluate $\\\\int_{0}^{\\\\infty} \\\\mathrm{e}^{-\\\\left(x^{2}+x^{-2}\\\\right)} d x$.\\n\\n(a) We have $I^{\\\\prime}(\\\\alpha)=2 \\\\int_{0}^{\\\\infty} e^{-(x-\\\\alpha / x)^{2}}\\\\left(1-\\\\alpha / x^{2}\\\\right) d x$\\n\\nThe differentiation is proved valid by observing that the integrand remains bounded as $x \\\\rightarrow 0+$ and that for sufficiently large $x$,\\n\\n$$\\ne^{-(x-\\\\alpha / x) 2}\\\\left(1-\\\\alpha / x^{2}\\\\right)=e^{-x 2}+2 \\\\alpha-\\\\alpha^{2 / x 2}\\\\left(1-\\\\alpha / x^{2}\\\\right) \\\\leqq e^{2 \\\\alpha} e^{-x^{2}}\\n$$\\n\\nso that $I^{\\\\prime}(\\\\alpha)$ converges uniformly for $\\\\alpha \\\\varepsilon 0$ by the Weierstrass test, since $\\\\int_{0}^{\\\\infty} e^{-x^{2}} d x$ converges. Now\\n\\n$$\\nI^{\\\\prime}(\\\\alpha)=2 \\\\int_{0}^{\\\\infty} e^{-(x-\\\\alpha / x)^{2}} d x-2 \\\\alpha \\\\int_{0}^{\\\\infty} \\\\frac{e^{-(x-\\\\alpha / x)^{2}}}{x^{2}} d x=0\\n$$\\n\\nas seen by letting $\\\\alpha / x=y$ in the second integral. Thus, $I(\\\\alpha)=c$, a constant. To determine $c$, let $\\\\alpha \\\\rightarrow 0+$ in the required integral and use Problem 12.31 to obtain $c=\\\\sqrt{\\\\pi} / 2$.\\n\\n(b) From (a), $\\\\int_{0}^{\\\\infty} e^{(x-\\\\alpha / x)^{2}} d x=\\\\int_{0}^{\\\\infty} e^{-\\\\left(x^{2}+\\\\alpha^{2} x^{-2}\\\\right)} d x=e^{2 \\\\alpha} \\\\int_{0}^{\\\\infty} e^{-\\\\left(x^{2}+\\\\alpha^{2} x^{-2}\\\\right)} d x=\\\\frac{\\\\sqrt{\\\\pi}}{2}$.\\n\\nThen $\\\\int_{0}^{\\\\infty} e^{-\\\\left(x^{2}+\\\\alpha^{2} x^{-2}\\\\right)} d x=\\\\frac{\\\\sqrt{\\\\pi}}{2} e^{-2 \\\\alpha}$. Putting $\\\\alpha=1, \\\\int_{0}^{\\\\infty} e^{-\\\\left(x^{2}+x^{-2}\\\\right)} d x=\\\\frac{\\\\sqrt{\\\\pi}}{2} e^{-2}$.\\n',\n",
       " '\\n12.34. Verify the results: (a) $\\\\mathscr{L}\\\\left\\\\{e^{a x}\\\\right\\\\}=\\\\frac{1}{s-\\\\alpha}, s>a$ and (b) $\\\\mathscr{L}\\\\{\\\\cos a z\\\\}=\\\\frac{s}{s^{2}+a^{2}}, s>0$.\\n\\n(a)\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathscr{L}\\\\left\\\\{e^{a x}\\\\right\\\\} & =\\\\int_{0}^{\\\\infty} e^{-s x} e^{a x} d x=\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} e^{-(s-a) x} d x \\\\\\\\\\n& =\\\\lim _{M \\\\rightarrow \\\\infty} \\\\frac{1-e^{-(s-a) M}}{s-a}=\\\\frac{1}{s-a} \\\\quad \\\\text { if } s>a\\n\\\\end{aligned}\\n$$\\n\\n(b) $\\\\mathscr{L}\\\\{\\\\cos a x)=\\\\int_{0}^{\\\\infty} e^{-s x} \\\\cos a x d x=\\\\frac{s}{s^{2}+a^{2}}$ by Problem 12.22 with $\\\\alpha=s, r=a$.\\n\\nAnother method, using complex numbers. From (a), $\\\\mathscr{L}\\\\left\\\\{e^{a x}\\\\right\\\\}=\\\\frac{1}{s-a}$. Replace $a$ by ai. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathscr{L}\\\\left\\\\{e^{a i x}\\\\right\\\\} & =\\\\mathscr{L}\\\\{\\\\cos a x+i \\\\sin a x\\\\}=\\\\mathscr{L}\\\\{\\\\cos a x\\\\}+i \\\\mathscr{L}\\\\{\\\\sin a x\\\\} \\\\\\\\\\n& =\\\\frac{1}{s-a i}=\\\\frac{s+a i}{s^{2}+a^{2}}=\\\\frac{s}{s^{2}+a^{2}}+i \\\\frac{a}{s^{2}+a^{2}}\\n\\\\end{aligned}\\n$$\\n\\nEquating real and imaginary parts:\\n\\n$$\\n\\\\mathscr{L}\\\\{\\\\cos a x\\\\}=\\\\frac{s}{s^{2}+a^{2}}, \\\\mathscr{L}\\\\{\\\\sin a x\\\\}=\\\\frac{a}{s^{2}+a^{2}}\\n$$\\n\\nThis formal method can be justified using the methods in Chapter 16.\\n',\n",
       " '\\n12.35. Prove that (a) $\\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime}(x)\\\\right\\\\}=$ (s) $\\\\mathscr{L}\\\\{Y(x)\\\\}-Y(0)$ and (b) $\\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime \\\\prime}(x)\\\\right\\\\}=s^{2} \\\\mathscr{L}\\\\{Y(x)\\\\}-s Y(0)-Y^{\\\\prime}(0)$ under suitable conditions on $Y(x)$.\\n\\n(a) By definition (and with the aid of integration by parts),\\n\\n$$\\n\\\\begin{aligned}\\n\\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime}(x)\\\\right\\\\} & =\\\\int_{0}^{\\\\infty} e^{-s x} Y^{\\\\prime}(x) d x=\\\\lim _{M \\\\rightarrow 0} \\\\int_{0}^{M} e^{-s x} Y^{\\\\prime}(x) d x \\\\\\\\\\n& =\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\left.e^{-s x} Y(x)\\\\right|_{0} ^{M}+s \\\\int_{0}^{M} e^{-s x} Y(x) d x\\\\right\\\\} \\\\\\\\\\n& =s \\\\int_{0}^{\\\\infty} e^{-s x} Y(x) d x-Y(0)=s \\\\mathscr{L}\\\\{(x)\\\\}-Y(0)\\n\\\\end{aligned}\\n$$\\n\\nassuming that $s$ is such that $\\\\lim _{M \\\\rightarrow \\\\infty} e^{-s M} Y(M)=0$.\\n\\n(b) Let $U(x)=Y^{\\\\prime}(x)$. Then by (a), $\\\\mathscr{L}\\\\left\\\\{U^{\\\\prime}(x)\\\\right\\\\}-U(0)$. Thus,\\n\\n$$\\n\\\\begin{gathered}\\n\\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime}(x)\\\\right\\\\}=s \\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime}(x)\\\\right\\\\}-Y^{\\\\prime}(0)=s[s \\\\mathscr{L}\\\\{Y(x)\\\\}-Y(0)]-Y^{\\\\prime}(0) \\\\\\\\\\n=s^{2} \\\\mathscr{L}\\\\{Y(x)\\\\}-s Y(0)-Y^{\\\\prime}(0)\\n\\\\end{gathered}\\n$$\\n',\n",
       " '\\n12.36. Solve the differential equation $Y^{\\\\prime \\\\prime}(x)+Y(x)=x, Y(0)=0, Y^{\\\\prime}(0)=2$.\\n\\nTake the Laplace transform of both sides of the given differential equation. Then by Problem 12.35.\\n\\n$$\\n\\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime \\\\prime}(x)+Y(x)\\\\right\\\\}=\\\\mathscr{L}\\\\{x\\\\}, \\\\mathscr{L}\\\\left\\\\{Y^{\\\\prime \\\\prime}(x)\\\\right\\\\}+\\\\mathscr{L}\\\\{Y(x)\\\\}=1 / s^{2}\\n$$\\n\\nand so\\n\\n$$\\ns^{2} \\\\mathscr{L}\\\\{Y(x)\\\\}-s \\\\mathscr{L}(0)-Y^{\\\\prime}(0)+\\\\mathscr{L}\\\\{Y(x)\\\\}=1 / s^{2}\\n$$\\n\\nSolving for $\\\\mathscr{L}\\\\{Y(x)\\\\}$ using the given conditions, we find\\n\\n\\n\\\\begin{equation*}\\n\\\\mathscr{L}\\\\{Y(x)\\\\}=\\\\frac{2 s^{2}}{s^{2}\\\\left(s^{2}+1\\\\right)}=\\\\frac{1}{s^{2}}+\\\\frac{1}{s^{2}+1} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nby methods of partial fractions.\\n\\nSince $\\\\frac{1}{s^{2}}=\\\\mathscr{L}\\\\{x\\\\}$ and $\\\\frac{1}{s^{2}+1}=\\\\mathscr{L}\\\\{\\\\sin x\\\\}$, it follows that $\\\\frac{1}{s^{2}}+\\\\frac{1}{s^{2}+1}=\\\\mathscr{L}\\\\{x+\\\\sin x\\\\}$\\n\\nHence, from (1), $\\\\mathscr{L}\\\\{Y(x)\\\\}=\\\\mathscr{L}\\\\{x+\\\\sin x\\\\}$, from which we can conclude that $Y(x)=x+\\\\sin x$, which is, in fact, found to be a solution.\\n\\nAnother method: If $\\\\mathscr{L}\\\\{F(x)\\\\}=f(s)$, we call $f(s)$ the inverse Laplace transform of $F(x)$ and write $f(s)=\\\\mathscr{L}^{-1}$ $\\\\{F(x)\\\\}$.\\n\\nBy Problem 12.78. $\\\\mathscr{L}^{-1}\\\\{f(s)+g(s)\\\\}=\\\\mathscr{L}^{-1}=\\\\mathscr{L}^{-1}\\\\left\\\\{f(s)+\\\\mathscr{L}^{-1}\\\\{g(s)\\\\}\\\\right.$. Then, from Equation (1),\\n\\n$$\\nY(x)=\\\\mathscr{L}^{-1}\\\\left\\\\{\\\\frac{1}{s^{2}}+\\\\frac{1}{s^{2}+1}\\\\right\\\\}=\\\\mathscr{L}^{-1}\\\\left\\\\{\\\\frac{1}{s^{2}}\\\\right\\\\}+\\\\mathscr{L}^{-1}\\\\left\\\\{\\\\frac{1}{s^{2}+1}\\\\right\\\\}=x+\\\\sin\\n$$\\n\\nInverse Laplace transforms can be read from Table 12.1.\\n\\n',\n",
       " '13.1. Graph each of the following functions.\\n\\n(a) $f(x)=\\\\left\\\\{\\\\begin{array}{cc}3 & 0<x<5 \\\\\\\\ -3 & -5<x<0\\\\end{array} \\\\quad\\\\right.$ Period $=10$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-367(1)}\\n\\\\end{center}\\n\\nFigure 13.3\\n\\nSince the period is 10, that portion of the graph in $-5<x<5$ (indicated by heavy lines in Figure 13.3) is extended periodically outside this range (indicated by dashed lines). Note that $f(x)$ is not defined at $x=0,5$, $-5,10,-10,15,-15$, and so on. These values are the discontinuities of $f(x)$.\\n\\n(b) $f(x)=\\\\left\\\\{\\\\begin{array}{cc}\\\\sin x & 0 \\\\leqq x \\\\leqq \\\\pi \\\\\\\\ 0 & \\\\pi<x<2 \\\\pi\\\\end{array}\\\\right.$ Period $=2 \\\\pi$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-367}\\n\\\\end{center}\\n\\nFigure 13.4\\n\\nRefer to Figure 13.4. Note that $f(x)$ is defined for all $x$ and is continuous everywhere.\\n\\n(c) $f(x)=\\\\left\\\\{\\\\begin{array}{ll}0 & 0 \\\\leqq x<2 \\\\\\\\ 1 & 2 \\\\leqq x<4 \\\\\\\\ 0 & 4 \\\\leqq x<6\\\\end{array} \\\\quad\\\\right.$ Period $=6$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-367(2)}\\n\\\\end{center}\\n\\nFig.13.5\\n\\nRefer to Figure 13.5. Note that $f(x)$ is defined for all $x$ and is discontinuous at $x= \\\\pm 2, \\\\pm 4, \\\\pm 8, \\\\pm 10$, $\\\\pm 14, \\\\ldots$.\\n',\n",
       " '\\n13.2. prove $\\\\int_{-L}^{L} \\\\sin \\\\frac{\\\\mathrm{k} \\\\pi \\\\mathrm{x}}{\\\\mathrm{L}} d x=\\\\int_{-L}^{L} \\\\cos \\\\frac{\\\\mathrm{k} \\\\pi \\\\mathrm{x}}{\\\\mathrm{L}} d x=0$ if $k=1,2,3, \\\\ldots$\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\int_{-L}^{L} \\\\sin \\\\frac{\\\\mathrm{k} \\\\pi \\\\mathrm{x}}{\\\\mathrm{L}} d x=-\\\\left.\\\\frac{L}{k \\\\pi} \\\\cos \\\\frac{\\\\mathrm{k \\\\pi x} \\\\mathrm{x}}{\\\\mathrm{L}}\\\\right|_{-L} ^{L}=\\\\frac{L}{k \\\\pi} \\\\cos k \\\\pi+\\\\frac{L}{k \\\\pi} \\\\cos (-k \\\\pi)=0 \\\\\\\\\\n& \\\\int_{-L}^{L} \\\\cos \\\\frac{\\\\mathrm{k} \\\\pi \\\\mathrm{x}}{\\\\mathrm{L}} d x=\\\\left.\\\\frac{L}{k \\\\pi} \\\\sin \\\\frac{k \\\\pi x}{L}\\\\right|_{-L} ^{L}=\\\\frac{L}{k \\\\pi} \\\\sin k \\\\pi-\\\\frac{L}{k \\\\pi} \\\\sin (-k \\\\pi)=0\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n13.3. Prove (a) $\\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\sin \\\\frac{n \\\\pi x}{L} d x= \\\\begin{cases}0 & m \\\\neq n \\\\\\\\ L & m=n\\\\end{cases}$\\n\\n(b) $\\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x=0$\\n\\nwhere $m$ and $n$ can assume any of the values $1,2,3, \\\\ldots$.\\n\\n(a) From trigonometry: $\\\\cos \\\\mathrm{A} \\\\cos \\\\mathrm{B}=\\\\frac{1}{2}\\\\{\\\\cos (\\\\mathrm{A}-\\\\mathrm{B})+\\\\cos (\\\\mathrm{A}+\\\\mathrm{B})\\\\}, \\\\sin \\\\mathrm{A} \\\\sin \\\\mathrm{B}=\\\\frac{1}{2}\\\\{\\\\cos (\\\\mathrm{A}-\\\\mathrm{B})-$ $\\\\cos (\\\\mathrm{A}+\\\\mathrm{B})\\\\}$.\\n\\nThen, if $m \\\\neq n$, by Problem 13.2,\\n\\n$$\\n\\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{2} \\\\int_{-L}^{L}\\\\left\\\\{\\\\cos \\\\frac{(m-x) \\\\pi x}{L}+\\\\cos \\\\frac{(m+n) \\\\pi x}{L}\\\\right\\\\} d x=0\\n$$\\n\\nSimilarly, if $m \\\\neq n$,\\n\\n$$\\n\\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\sin \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{2} \\\\int_{-L}^{L}\\\\left\\\\{\\\\cos \\\\frac{(m-n) \\\\pi x}{L}-\\\\cos \\\\frac{(m+n) \\\\pi x}{L}\\\\right\\\\} d x=0\\n$$\\n\\nIf $m=n$, we have\\n\\n$$\\n\\\\begin{aligned}\\n& \\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{2} \\\\int_{-L}^{L}\\\\left(1+\\\\cos \\\\frac{2 n \\\\pi x}{L}\\\\right) d x=L \\\\\\\\\\n& \\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\sin \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{2} \\\\int_{-L}^{L}\\\\left(1-\\\\cos \\\\frac{2 n \\\\pi x}{L}\\\\right) d x=L\\n\\\\end{aligned}\\n$$\\n\\nNote that if $m=n$ these integrals are equal to $2 L$ and 0 , respectively.\\n\\n(b) We have $\\\\sin A \\\\cos B=1 / 2\\\\{\\\\sin (A-B)+\\\\sin (A+B)\\\\}$. Then by Problem 13.2, if $m \\\\neq n$,\\n\\n$$\\n\\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{2} \\\\int_{-L}^{L}\\\\left\\\\{\\\\sin \\\\frac{(m-n) \\\\pi x}{L}+\\\\sin \\\\frac{(m+n) \\\\pi x}{L}\\\\right\\\\} d x=0\\n$$\\n\\nIf $m=n$,\\n\\n$$\\n\\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{2} \\\\int_{-L}^{L} \\\\sin \\\\frac{2 n \\\\pi x}{L} d x=0\\n$$\\n\\nThe results of (a) and (b) remain valid even when the limits of integration $-L, L$ are replaced by $c, c+2 L$, respectively.\\n',\n",
       " '\\n13.4. If the series $A+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right)$ converges uniformly to $f(\\\\mathrm{x})$ in $(-L, L)$, show that for $n=$\\n\\n$1,2,3, \\\\ldots$, (a) $\\\\quad a_{n}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x$ and (b) $b_{n}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x$, (c) $A=\\\\frac{a_{0}}{2}$.\\n\\n(a) Multiplying\\n\\n\\n\\\\begin{equation*}\\nf(x)=A+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nby $\\\\cos \\\\frac{m \\\\pi x}{L}$ and integrating from $-L$ to $L$, using Problem 13.3, we have\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{-L}^{L} f(x) \\\\cos \\\\frac{m \\\\pi x}{L} d x & =A \\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} d x \\\\\\\\\\n& +\\\\sum_{n=1}^{\\\\infty}\\\\left\\\\{a_{n} \\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x+b_{n} \\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} \\\\sin \\\\frac{n \\\\pi x}{L} d x\\\\right\\\\} \\\\\\\\\\n& =a_{m} L \\\\quad \\\\text { if } m \\\\neq 0\\n\\\\end{aligned}\\n$$\\n\\nThus,\\n\\n$$\\na_{m}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) \\\\cos \\\\frac{m \\\\pi x}{L} d x \\\\quad \\\\text { if } m=1,2,3, \\\\ldots\\n$$\\n\\n(b) Multiplying Equation (1) by $\\\\sin \\\\frac{m \\\\pi x}{L}$ and integrating from $-\\\\mathrm{L}$ to $\\\\mathrm{L}$, using Problem 13.3, we have\\n\\nThus,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{-L}^{L} f(x) \\\\sin \\\\frac{m \\\\pi x}{L} d x= & A \\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} d x \\\\\\\\\\n& +\\\\sum_{n=1}^{\\\\infty}\\\\left\\\\{a_{n} \\\\int_{-L}^{L} \\\\sin \\\\frac{m \\\\pi x}{L} \\\\cos \\\\frac{n \\\\pi x}{L} d x+b_{n} \\\\int_{-L}^{L} \\\\cos \\\\frac{m \\\\pi x}{L} \\\\sin \\\\frac{n \\\\pi x}{L} d x\\\\right\\\\}\\n\\\\end{aligned}\\n$$\\n\\n$$\\n\\\\begin{aligned}\\n& =b_{m} L \\\\\\\\\\nb_{m} & =\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) \\\\sin \\\\frac{m \\\\pi x}{L} d x \\\\text { if } m=1,2,3, \\\\ldots\\n\\\\end{aligned}\\n$$\\n\\n(c) Integrating Equation (1) from $-L$ to $L$, using Problem 13.2, gives\\n\\n$$\\n\\\\int_{-L}^{L} f(x) d x=2 A L \\\\quad \\\\text { or } \\\\quad A=\\\\frac{1}{2 L} \\\\int_{-L}^{L} f(x) d x\\n$$\\n\\nPutting $m=0$ in the result of (a), we find $a_{0}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) d x$ and so $A=\\\\frac{a_{0}}{2}$.\\n\\nThe above results also hold when the integration limits $-L, L$ are replaced by $c, c+2 L$.\\n\\nNote that in (a), (b), and (c), interchange of summation and integration is valid because the series is assumed to converge uniformly to $f(x)$ in $(-L, L)$. Even when this assumption is not warranted, the coefficients $a_{m}$ and $b_{m}$ as obtained are called Fourier coefficients corresponding to $f(x)$, and the corresponding series with these values of $a_{m}$ and $b_{m}$ is called the Fourier series corresponding to $f(x)$. An important problem in this case is to investigate conditions under which this series actually converges to $f(x)$. Sufficient conditions for this convergence are the Dirichlet conditions established in Problems 13.18 through 13.23.\\n',\n",
       " '\\n13.5. (a) Find the Fourier coefficients corresponding to the function\\n\\n$$\\nf(x)=\\\\left\\\\{\\\\begin{array}{cc}\\n0 & -5<x<0 \\\\\\\\\\n3 & 0<x<5\\n\\\\end{array} \\\\quad \\\\text { Period }=10\\\\right.\\n$$\\n\\n(b) Write the corresponding Fourier series.\\n\\n(c) How should $f(x)$ be defined at $x=-5, x=0$, and $x=5$ in order that the Fourier series will converge to $f(x)$ for $-5 \\\\leqq x \\\\leqq 5$ ?\\n\\nThe graph of $f(x)$ is shown in Figure 13.6.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-370}\\n\\\\end{center}\\n\\nFigure 13.6\\n\\n(a) Period $=2 L=10$ and $L=5$. Choose the interval $c$ to $c+2 L$ as -5 to 5 , so that $c=-5$. Then\\n\\n$$\\n\\\\begin{aligned}\\na_{n} & =\\\\frac{1}{L} \\\\int_{c}^{c+2 L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{5} \\\\int_{-5}^{5} f(x) \\\\cos \\\\frac{n \\\\pi x}{5} d x \\\\\\\\\\n& =\\\\frac{1}{5}\\\\left\\\\{\\\\int_{-5}^{0}(0) \\\\cos \\\\frac{n \\\\pi x}{5} d x+\\\\int_{0}^{5}(3) \\\\cos \\\\frac{n \\\\pi x}{5} d x\\\\right\\\\}=\\\\frac{3}{5} \\\\int_{0}^{5} \\\\cos \\\\frac{n \\\\pi x}{5} d x \\\\\\\\\\n& =\\\\left.\\\\frac{3}{5}\\\\left(\\\\frac{5}{n \\\\pi} \\\\sin \\\\frac{n \\\\pi x}{5}\\\\right)\\\\right|_{0} ^{5}=0 \\\\quad \\\\text { if } n \\\\neq 0 \\\\\\\\\\n\\\\text { If } n & =0, a_{n}=a_{0}=\\\\frac{3}{5} \\\\int_{0}^{5} \\\\cos \\\\frac{0 \\\\pi x}{5} d x=\\\\frac{3}{5} \\\\int_{0}^{5} d x=3 . \\\\\\\\\\nb_{n} & =\\\\frac{1}{L} \\\\int_{c}^{c+2 L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{5} \\\\int_{-5}^{5} f(x) \\\\sin \\\\frac{n \\\\pi x}{5} d x \\\\\\\\\\n& =\\\\frac{1}{5}\\\\left\\\\{\\\\int_{-5}^{0}(0) \\\\sin \\\\frac{n \\\\pi x}{5} d x+\\\\int_{0}^{5}(3) \\\\sin \\\\frac{n \\\\pi x}{5} d x\\\\right\\\\}=\\\\frac{3}{5} \\\\int_{0}^{5} \\\\sin \\\\frac{n \\\\pi x}{5} d x \\\\\\\\\\n& =\\\\frac{3}{5}\\\\left(-\\\\frac{5}{n \\\\pi} \\\\cos \\\\frac{n \\\\pi x}{5}\\\\right)_{0}^{5}=\\\\frac{3(1-\\\\cos n \\\\pi)}{n \\\\pi}\\n\\\\end{aligned}\\n$$\\n\\n(b) The corresponding Fourier series is\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right) & =\\\\frac{3}{2}+\\\\sum_{n=1}^{\\\\infty} \\\\frac{3(1-\\\\cos n \\\\pi)}{n \\\\pi} \\\\sin \\\\frac{n \\\\pi x}{5} \\\\\\\\\\n& =\\\\frac{3}{2}+\\\\frac{6}{\\\\pi}\\\\left(\\\\sin \\\\frac{\\\\pi x}{5}+\\\\frac{1}{3} \\\\sin \\\\frac{3 \\\\pi x}{5}+\\\\frac{1}{5} \\\\sin \\\\frac{5 \\\\pi x}{5}+\\\\cdots\\\\right)\\n\\\\end{aligned}\\n$$\\n\\n(c) Since $f(x)$ satisfies the Dirichlet conditions, we can say that the series converges to $f(x)$ at all points of continuity and to $\\\\frac{f(x+0)+f(x-0)}{2}$ at points of discontinuity. At $x=-5,0$, and 5 , which are points of discontinuity, the series converges to $(3+0) / 2=3 / 2$, as seen from the graph. If we redefine $f(x)$ as follows,\\n\\n$$\\nf(x)=\\\\left\\\\{\\\\begin{array}{lc}\\n3 / 2 & x=-5 \\\\\\\\\\n0 & -5<x<0 \\\\\\\\\\n3 / 2 & x=0 \\\\\\\\\\n3 & 0<x<5 \\\\\\\\\\n3 / 2 & x=5\\n\\\\end{array} \\\\quad \\\\text { Period }=10\\\\right.\\n$$\\n\\nthen the series will converge to $f(x)$ for $-5 \\\\leqq x \\\\leqq 5$.\\n',\n",
       " '\\n13.6. Expand $f(x)=x^{2}, 0<x<2 \\\\pi$ in a Fourier series if (a) the period is $2 \\\\pi$ and (b) the period is not specified.\\n\\n(a) The graph of $f(x)$ with period $2 \\\\pi$ is shown in Figure 13.7.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-371}\\n\\\\end{center}\\n\\nFig. 13-7\\n\\nPeriod $=2 L=2 \\\\pi$ and $L=\\\\pi$. Choosing $c=0$, we have\\n\\n$$\\n\\\\begin{aligned}\\na_{n} & =\\\\frac{1}{L} \\\\int_{c}^{c+2 L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{\\\\pi} \\\\int_{0}^{2 \\\\pi} x^{2} \\\\cos n x d x \\\\\\\\\\n& =\\\\left.\\\\frac{1}{\\\\pi}\\\\left\\\\{\\\\left(x^{2}\\\\right)\\\\left(\\\\frac{\\\\sin n x}{n}\\\\right)-(2 x)\\\\left(\\\\frac{-\\\\cos n x}{n^{2}}\\\\right)+2\\\\left(\\\\frac{-\\\\sin n x}{n^{3}}\\\\right)\\\\right\\\\}\\\\right|_{0} ^{2 \\\\pi}=\\\\frac{4}{n^{2}}, \\\\quad n \\\\neq 0\\n\\\\end{aligned}\\n$$\\n\\nIf $n=0, a_{0}=\\\\frac{1}{\\\\pi} \\\\int_{0}^{2 \\\\pi} x^{2} d x=\\\\frac{8 \\\\pi^{2}}{3}$.\\n\\n$$\\n\\\\begin{aligned}\\nb_{n} & =\\\\frac{1}{L} \\\\int_{c}^{c+2 L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{\\\\pi} \\\\int_{0}^{2 \\\\pi} x^{2} \\\\sin n x d x \\\\\\\\\\n& ==\\\\left.\\\\frac{1}{\\\\pi}\\\\left\\\\{\\\\left(x^{2}\\\\right)\\\\left(\\\\frac{\\\\sin n x}{n}\\\\right)-(2 x)\\\\left(\\\\frac{-\\\\cos n x}{n^{2}}\\\\right)+2\\\\left(\\\\frac{-\\\\sin n x}{n^{3}}\\\\right)\\\\right\\\\}\\\\right|_{0} ^{2 \\\\pi}\\n\\\\end{aligned}\\n$$\\n\\nThen $f(x)=x^{2}=\\\\frac{4 \\\\pi^{2}}{3}+\\\\sum_{n=1}^{\\\\infty}\\\\left(\\\\frac{4}{n^{2}} \\\\cos n x-\\\\frac{4 \\\\pi}{n} \\\\sin n x\\\\right)$.\\n\\nThis is valid for $0<x<2 \\\\pi$. At $x=0$ and $x=2 \\\\pi$ the series converges to $2 \\\\pi^{2}$.\\n\\n(b) If the period is not specified, the Fourier series cannot be determined uniquely in general.\\n',\n",
       " '\\n13.7. Using the results of Problem 13.6, prove that $\\\\frac{1}{1^{2}}+\\\\frac{1}{2^{2}}+\\\\frac{1}{3^{2}}+\\\\cdots=\\\\frac{\\\\pi^{2}}{6}$.\\n\\nAt $x=0$, the Fourier series of Problem 13.6 reduces to $\\\\frac{4 \\\\pi^{2}}{3}+\\\\sum_{n=1}^{\\\\infty} \\\\frac{4}{n^{2}}$.\\n\\nBy the Dirichlet conditions, the series converges at $x=0$ to $\\\\frac{1}{2}\\\\left(0+4 \\\\pi^{2}\\\\right)=2 \\\\pi^{2}$.\\n\\nThen $\\\\frac{4 \\\\pi^{2}}{3}+\\\\sum_{n=1}^{\\\\infty} \\\\frac{4}{n^{2}}=2 \\\\pi^{2}$, and so $\\\\sum_{n=1}^{\\\\infty} \\\\frac{1}{n^{2}}=\\\\frac{\\\\pi^{2}}{6}$.\\n\\n\\n\\\\section*{Odd and even functions, half range Fourier series}\\n',\n",
       " '13.8. Classify each of the following functions according to whether they are even, odd, or neither even nor odd.\\n\\n(a) $f(x)=\\\\left\\\\{\\\\begin{array}{cc}2 & 0<x<3 \\\\\\\\ -2 & -3<x<0\\\\end{array} \\\\quad\\\\right.$ Period $=6$\\n\\nFrom Figure 13.8, it is seen that $f(-x)=-f(x)$, so that the function is odd.\\n\\n(b) $f(x)=\\\\left\\\\{\\\\begin{array}{cc}\\\\cos x & 0<x<\\\\pi \\\\\\\\ 0 & \\\\pi<x<2 \\\\pi\\\\end{array}\\\\right.$ Period $=2 \\\\pi$\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-372}\\n\\\\end{center}\\n\\nFigure 13.8\\n\\nFrom Figure 13.9, it is seen that the function is neither even nor odd.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-372(1)}\\n\\\\end{center}\\n\\nFigure 13.9\\n\\n(c) $f(x)=x(10-x), 0<x<10 \\\\quad$ Period $=10$\\n\\nFrom Figure 13.10 below the function is seen to be even.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-372(2)}\\n\\\\end{center}\\n\\nFigure 13.10\\n',\n",
       " '\\n13.9. Show that an even function can have no sine terms in its Fourier expansion.\\n\\nMethod 1: No sine terms appear if $b_{n}=0, n=1,2,3, \\\\ldots$ To show this, let us this, let us write\\n\\n\\n\\\\begin{equation*}\\nb_{n}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{L} \\\\int_{-L}^{0} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x+\\\\frac{1}{L} \\\\int_{0}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIf we make the transformation $x=-u$ in the first integral on the right of Equation (1), we obtain\\n\\n\\n\\\\begin{align*}\\n\\\\frac{1}{L} \\\\int_{-L}^{0} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x & =\\\\frac{1}{L} \\\\int_{0}^{L} f(-u) \\\\sin \\\\left(-\\\\frac{n \\\\pi u}{L}\\\\right) d u=-\\\\frac{1}{L} \\\\int_{0}^{L} f(-u) \\\\sin \\\\frac{n \\\\pi u}{L} d u  \\\\tag{2}\\\\\\\\\\n& =-\\\\frac{1}{L} \\\\int_{0}^{L} f(u) \\\\sin \\\\frac{n \\\\pi u}{L} d u=-\\\\frac{1}{L} \\\\int_{0}^{L} f(x) \\\\sin \\\\frac{n \\\\pi u}{L} d x\\n\\\\end{align*}\\n\\n\\nwhere we have used the fact that for an even function $f(-u)=f(u)$ and in the last last step that the dummy variable of integration $u$ can be replaced by any other symbol, in particular, $x$. Thus, from Equation (1), using Equation (2), we have\\n\\n$$\\nb_{n}=-\\\\frac{1}{L} \\\\int_{0}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x+\\\\frac{1}{L} \\\\int_{0}^{L} f(x) \\\\sin \\\\frac{n \\\\pi u}{L} d x=0\\n$$\\n\\nMethod 2: Assume\\n\\n$$\\nf(x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right)\\n$$\\n\\nThen\\n\\n$$\\nf(-x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}-b_{N} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right)\\n$$\\n\\nIf $f(x)$ is even, $f(-x)=f(x)$. Hence,\\n\\n$$\\n\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}-b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right)\\n$$\\n\\nand so\\n\\n$$\\n\\\\sum_{n=1}^{\\\\infty} b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}=0, \\\\text { i.e., } f(x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty} a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}\\n$$\\n\\nand no sine terms appear.\\n\\nIn a similar manner, we can show that an odd function has no cosine terms (or constant term) in its Fourier expansion.\\n',\n",
       " '\\n13.10. If $f(\\\\mathrm{x})$ is even, show that (a) $a_{n}=\\\\frac{2}{L} \\\\int_{0}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x$, and (b) $b_{n}=0$.\\n\\n(a) $\\\\quad a_{n}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{L} \\\\int_{-L}^{0} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x+\\\\frac{1}{L} \\\\int_{0}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x$\\n\\nLetting $x=-u$,\\n\\n$$\\n\\\\frac{1}{L} \\\\int_{-L}^{0} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{1}{L} \\\\int_{0}^{L} f(-u) \\\\cos \\\\left(\\\\frac{-n \\\\pi x}{L}\\\\right) d u=\\\\frac{1}{L} \\\\int_{0}^{L} f(u) \\\\cos \\\\frac{n \\\\pi x}{L} d u\\n$$\\n\\nsince, by definition of an even function, $f(-u)=f(u)$. Then\\n\\n$$\\na_{n}=\\\\frac{1}{L} \\\\int_{0}^{L} f(u) \\\\cos \\\\frac{n \\\\pi u}{L} d u+\\\\frac{1}{L} \\\\int_{0}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{2}{L} \\\\int_{0}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x\\n$$\\n\\n(b) This follows by Method 1 of Problem 13.9.\\n',\n",
       " '\\n13.11. Expand $f(\\\\mathrm{x})=\\\\sin x, 0<x<\\\\pi$, in a Fourier cosine series.\\n\\nA Fourier series consisting of cosine terms alone is obtained only for an even function. Hence, we extend the definition of $f(x)$ so that it becomes even (dashed part of Figure 13.11). With this extension, $f(x)$ is then defined in an interval of length $2 \\\\pi$. Taking the period as $2 \\\\pi$, we have $2 L=2 \\\\pi$ so that $L=\\\\pi$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-373}\\n\\\\end{center}\\n\\nFigure 13.11\\n\\nBy Problem 13.10, $b_{n}=0$ and\\n\\n$$\\na_{n}=\\\\frac{2}{L} \\\\int_{0}^{L} f(x) \\\\cos \\\\frac{n \\\\pi u}{L} d x=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\pi} \\\\sin x \\\\cos n x d x\\n$$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\pi}\\\\{\\\\sin (x+n x)+\\\\sin (x-n x)\\\\}=\\\\left.\\\\frac{1}{\\\\pi}\\\\left\\\\{-\\\\frac{\\\\cos (n+1) x}{n+1}+\\\\frac{\\\\cos (n-1) x}{n-1}\\\\right\\\\}\\\\right|_{0} ^{\\\\pi} \\\\\\\\\\n& =\\\\frac{1}{\\\\pi}\\\\left\\\\{\\\\frac{1-\\\\cos (n+1) \\\\pi}{n+1}+\\\\frac{\\\\cos (n-1) \\\\pi-1}{n-1}\\\\right\\\\}=\\\\frac{1}{\\\\pi}\\\\left\\\\{\\\\frac{1+\\\\cos n \\\\pi}{n+1}+\\\\frac{1+\\\\cos n \\\\pi}{n-1}\\\\right\\\\} \\\\\\\\\\n& =\\\\frac{-2(1+\\\\cos n \\\\pi)}{\\\\pi\\\\left(n^{2}-1\\\\right)} \\\\text { if } n \\\\neq 1 .\\n\\\\end{aligned}\\n$$\\n\\nFor $n=1$,\\n\\n$$\\nn=1, \\\\quad a_{1}=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\pi} \\\\sin x \\\\cos x d x=\\\\left.\\\\frac{2}{\\\\pi} \\\\frac{\\\\sin ^{2} x}{2}\\\\right|_{0} ^{\\\\pi}=0\\n$$\\n\\nFor $n=0$,\\n\\n$$\\nn=0, \\\\quad a_{0}=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\pi} \\\\sin x d x=\\\\left.\\\\frac{2}{\\\\pi}(-\\\\cos x)\\\\right|_{0} ^{\\\\pi}=\\\\frac{4}{\\\\pi}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nf(x) & =\\\\frac{2}{\\\\pi}-\\\\frac{2}{\\\\pi} \\\\sum_{n=2}^{\\\\infty} \\\\frac{(1+\\\\cos n \\\\pi)}{n^{2}-1} \\\\cos n x \\\\\\\\\\n& =\\\\frac{2}{\\\\pi}-\\\\frac{4}{\\\\pi}\\\\left(\\\\frac{\\\\cos 2 x}{2^{2}-1}+\\\\frac{\\\\cos 4 x}{4^{2}-1}+\\\\frac{\\\\cos 6 x}{6^{2}-1}+\\\\cdots\\\\right)\\n\\\\end{aligned}\\n$$\\n',\n",
       " \"\\n13.12. Expand $f(\\\\mathrm{x})=x, 0<x<2$, in a half range (a) sine series and (b) cosine series.\\n\\n(a) Extend the definition of the given function to that of the odd function of period 4 shown in Figure 13.12. This is sometimes called the odd extension of $f(x)$. Then $2 L=4, L=2$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-374}\\n\\\\end{center}\\n\\nFigure 13.12\\n\\nThus, $a_{n}=0$ and\\n\\n$$\\n\\\\begin{aligned}\\nb_{n} & =\\\\frac{2}{L} \\\\int_{0}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x=\\\\frac{2}{2} \\\\int_{0}^{2} x \\\\sin \\\\frac{n \\\\pi x}{2} d x \\\\\\\\\\n& =\\\\left.\\\\left\\\\{(x)\\\\left(\\\\frac{-2}{n \\\\pi} \\\\cos \\\\frac{n \\\\pi x}{2}\\\\right)-(1)\\\\left(\\\\frac{-4}{n^{2} \\\\pi^{2}} \\\\sin \\\\frac{n \\\\pi x}{2}\\\\right)\\\\right\\\\}\\\\right|_{0} ^{2}=\\\\frac{-4}{n \\\\pi} \\\\cos n \\\\pi \\\\cdot\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nf(x) & =\\\\sum_{n=1}^{\\\\infty} \\\\frac{-4}{n \\\\pi} \\\\cos n \\\\pi \\\\sin \\\\frac{n \\\\pi x}{2} \\\\\\\\\\n& =\\\\frac{4}{\\\\pi}\\\\left(\\\\sin \\\\frac{\\\\pi x}{2}-\\\\frac{1}{2} \\\\sin \\\\frac{2 \\\\pi x}{2}+\\\\frac{1}{3} \\\\sin \\\\frac{3 \\\\pi x}{2}-\\\\cdots\\\\right)\\n\\\\end{aligned}\\n$$\\n\\n(b) Extend the definition of $f(x)$ to that of the even function of period 4 shown in Figure 13.13. This is the even extension of $f(x)$. Then $2 L=4, L=2$.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-375}\\n\\\\end{center}\\n\\nFigure 13.13\\n\\nThus, $b_{n}=0$,\\n\\n$$\\n\\\\begin{aligned}\\na_{n} & =\\\\frac{2}{L} \\\\int_{0}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=\\\\frac{2}{2} \\\\int_{0}^{2} x \\\\cos \\\\frac{n \\\\pi x}{2} d x \\\\\\\\\\n& =\\\\left.\\\\left\\\\{(x)\\\\left(\\\\frac{2}{\\\\pi} \\\\sin \\\\frac{n \\\\pi x}{2}\\\\right)-(1)\\\\left(\\\\frac{-4}{n^{2} \\\\pi^{2}} \\\\cos \\\\frac{n \\\\pi x}{2}\\\\right)\\\\right)\\\\right|_{0} ^{2} \\\\\\\\\\n& =\\\\frac{4}{n^{2} \\\\pi^{2}}(\\\\cos n \\\\pi-1) \\\\quad \\\\text { If } \\\\mathrm{n} \\\\neq 0\\n\\\\end{aligned}\\n$$\\n\\n$$\\n\\\\text { If } n=0, a_{0}=\\\\int_{0}^{2} x d x=2\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nf(x) & =1+\\\\sum_{n=1}^{\\\\infty} \\\\frac{4}{n^{2} \\\\pi^{2}}(\\\\cos n \\\\pi-1) \\\\cos \\\\frac{n \\\\pi x}{2} \\\\\\\\\\n& =1-\\\\frac{8}{\\\\pi^{2}}\\\\left(\\\\cos \\\\frac{n x}{2}+\\\\frac{1}{3^{2}} \\\\cos \\\\frac{3 \\\\pi x}{2}=\\\\frac{1}{5^{2}} \\\\cos \\\\frac{5 \\\\pi x}{2}+\\\\cdots\\\\right)\\n\\\\end{aligned}\\n$$\\n\\nIt should be noted that the given function $f(x)=x, 0<x<2$ is represented equally well by the two different series in (a) and (b).\\n\\n\\n\\\\section*{Parseval's identity}\\n\",\n",
       " \"13.13. Assuming that the Fourier series corresponding to $f(x)$ converges uniformly to $f(x)$ in $(-L, L)$, prove Parseval's identity\\n\\n$$\\n\\\\frac{1}{L} \\\\int_{-L}^{L}\\\\{f(x)\\\\}^{2} d x=\\\\frac{a_{0}^{2}}{2}+\\\\sum\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right)\\n$$\\n\\nwhere the integral is assumed to exist.\\n\\nIf $f(x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right)$, then multiplying by $f(x)$ and integrating term by term from $-L$ to $L$ (which is justified since the series is uniformly convergent), we obtain\\n\\n\\n\\\\begin{align*}\\n\\\\int_{-L}^{L}\\\\{f(x)\\\\}^{2} d x & =\\\\frac{a_{0}}{2} \\\\int_{-L}^{L} f(x) d x+\\\\sum_{n=1}^{\\\\infty}\\\\left\\\\{a_{n} \\\\int_{-L}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x+b_{n} \\\\int_{-L}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x\\\\right\\\\} \\\\\\\\\\n& =\\\\frac{a_{0}^{2}}{2} L+L \\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right) \\\\tag{1}\\n\\\\end{align*}\\n\\n\\nwhere we have used the results\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{-L}^{L} f(x) \\\\cos \\\\frac{n \\\\pi x}{L} d x=L a_{n}, \\\\quad \\\\int_{-L}^{L} f(x) \\\\sin \\\\frac{n \\\\pi x}{L} d x=L b_{n}, \\\\quad \\\\int_{-L}^{L} f(x) d x=L a_{0} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nobtained from the Fourier coefficients.\\n\\nThe required result follows on dividing both sides of Equation (1) by $L$. Parseval's identity is valid under less restrictive conditions than that imposed here.\\n\",\n",
       " \"\\n13.14. (a) Write Parseval's identity corresponding to the Fourier series of Problem 13.12(b). (b) Determine from (a) the sum $\\\\mathrm{S}$ of the series $\\\\frac{1}{1^{4}}+\\\\frac{1}{2^{4}}+\\\\frac{1}{3^{4}}+\\\\cdots+\\\\frac{1}{n^{4}}+\\\\cdots$\\n\\n(a) Here $L=2, a_{0}=2, a_{n}=\\\\frac{4}{n^{2} \\\\pi^{2}}(\\\\cos n \\\\pi-1), n \\\\neq 0, b_{n}=0$.\\n\\nThen Parseval's identity becomes\\n\\n$$\\n\\\\frac{1}{2} \\\\int_{-2}^{2}\\\\{f(x)\\\\}^{2} d x=\\\\frac{1}{2} \\\\int_{-2}^{2} x^{2} d x=\\\\frac{(2)^{2}}{2}+\\\\sum_{n=1}^{\\\\infty} \\\\frac{16}{n^{4} \\\\pi^{4}}(\\\\cos n \\\\pi-1)^{2}\\n$$\\n\\nor\\n\\n$$\\n\\\\frac{8}{3}=2+\\\\frac{64}{\\\\pi^{4}}\\\\left(\\\\frac{1}{1^{4}}+\\\\frac{1}{3^{4}}+\\\\frac{1}{5^{4}}+\\\\cdots\\\\right) \\\\text {. ie., } \\\\frac{1}{1^{4}}+\\\\frac{1}{3^{4}}+\\\\frac{1}{5^{4}}+\\\\cdots=\\\\frac{\\\\pi^{4}}{96}\\n$$\\n\\n(b) $S=, \\\\frac{1}{1^{4}}+\\\\frac{1}{2^{4}}+\\\\frac{1}{3^{4}}+\\\\cdots=\\\\left(\\\\frac{1}{1^{4}}+\\\\frac{1}{3^{4}}+\\\\frac{1}{5^{4}}+\\\\cdots\\\\right)+\\\\left(\\\\frac{1}{2^{4}}+\\\\frac{1}{4^{4}}+\\\\frac{1}{6^{4}}+\\\\cdots\\\\right)$\\n\\n$$\\n\\\\begin{aligned}\\n& =\\\\left(\\\\frac{1}{1^{4}}+\\\\frac{1}{3^{4}}+\\\\frac{1}{5^{4}}+\\\\cdots\\\\right)+\\\\frac{1}{2^{4}}\\\\left(\\\\frac{1}{1^{4}}+\\\\frac{1}{2^{4}}+\\\\frac{1}{3^{4}}+\\\\cdots\\\\right) \\\\\\\\\\n& =\\\\frac{\\\\pi^{4}}{96}+\\\\frac{S}{16}, \\\\quad \\\\text { from which } S=\\\\frac{\\\\pi^{4}}{90}\\n\\\\end{aligned}\\n$$\\n\",\n",
       " \"\\n13.15. Prove that for all positive integers $M$,\\n\\n$$\\n\\\\frac{a_{0}^{2}}{2}+\\\\sum_{n=1}^{M}\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right) \\\\leqq \\\\frac{1}{L} \\\\int_{-L}^{L}\\\\{f(x)\\\\}^{2} d x\\n$$\\n\\nwhere $a_{n}$ and $b_{n}$ are the Fourier coefficients corresponding to $f(x)$, and $f(x)$ is assumed piecewise continuous in $(-L, L)$.\\n\\nLet\\n\\n\\n\\\\begin{equation*}\\nS_{M}(x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{M}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nFor $M=1,2,3, \\\\ldots$, this is the sequence of partial sums of the Fourier series corresponding to $f(x)$.\\n\\nWe have\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{-L}^{L}\\\\left\\\\{f(x)-S_{M}(x)\\\\right\\\\}^{2} d x \\\\geq 0 \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nsince the integrand is nonnegative. Expanding the integrand, we obtain\\n\\n\\n\\\\begin{equation*}\\n2 \\\\int_{-L}^{L} f(x) S_{M}(x) d x-\\\\int_{-L}^{L} S_{M}^{2}(x) d x \\\\leqq \\\\int_{-L}^{L}\\\\{f(x)\\\\}^{2} d x \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nMultiplying both sides of Equation (1) by $2 f(x)$ and integrating from $-L$ to $L$, using Equations (2) of Problem 13.13, gives\\n\\n\\n\\\\begin{equation*}\\n2 \\\\int_{-L}^{L} f(x) S_{M}(x) d x=2 L\\\\left\\\\{\\\\frac{a_{0}^{2}}{2}+\\\\sum_{n=1}^{M}\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right)\\\\right\\\\} \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nAlso, squaring Equation (1) and integrating from $-L$ to $L$, using Problem 13.3, we find\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{-L}^{L} S_{M}^{2}(x) d x=2 L\\\\left\\\\{\\\\frac{a^{2} o}{2}+\\\\sum_{n=1}^{M}\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right)\\\\right\\\\} \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nSubstitution of Equations (4) and (5) into Equation (3) and dividing by $L$ yields the required result.\\n\\nTaking the limit as $M \\\\rightarrow \\\\infty$, we obtain Bessel's inequality\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{a_{0}^{2}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right) \\\\leqq \\\\frac{1}{L} \\\\int_{-L}^{L}\\\\{f(x)\\\\}^{2} d x \\\\tag{6}\\n\\\\end{equation*}\\n\\n\\nIf the equality holds, we have Parseval's identity (Problem 13.13).\\n\\nWe can think of $S_{M}(x)$ as representing an approximation to $f(x)$, while the left-hand side of Equation (2), divided by $2 L$, represents the mean square error of the approximation. Parseval's identity indicates that as $M \\\\rightarrow \\\\infty$, the mean square error approaches zero, while Bessels' inequality indicates the possibility that this mean square error does not approach zero.\\n\\nThe results are connected with the idea of completeness of an orthonormal set. If, for example, we were to leave out one or more terms in a Fourier series ( $\\\\cos 4 \\\\pi x / L$, for example), we could never get the mean square error to approach zero no matter how many terms we took. For an analogy with three-dimensional vectors, see Problem 13.60.\\n\\n\\n\\\\section*{Differentiation and integration of Fourier series}\\n\",\n",
       " '13.16. (a) Find a Fourier series for $f(x)=x^{2}, 0<x<2$, by integrating the series of Problem 13.12(a). (b) Use (a) to evaluate the series $\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1}}{n^{2}}$.\\n\\n(a) From Problem 13.12(a).\\n\\n\\n\\\\begin{equation*}\\nx=\\\\frac{4}{\\\\pi}\\\\left(\\\\sin \\\\frac{\\\\pi x}{2}-\\\\frac{1}{2} \\\\sin \\\\frac{2 \\\\pi x}{2}+\\\\frac{1}{3} \\\\sin \\\\frac{3 \\\\pi x}{2}-\\\\cdots\\\\right) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nIntegrating both sides from 0 to $x$ (applying the theorem of Page 352) and multiplying by 2, we find\\n\\n\\n\\\\begin{equation*}\\nx^{2}=C=\\\\frac{16}{\\\\pi^{2}}\\\\left(\\\\cos \\\\frac{\\\\pi x}{2}-\\\\frac{1}{2^{2}} \\\\cos \\\\frac{2 \\\\pi x}{2}+\\\\frac{1}{3^{2}} \\\\cos \\\\frac{3 \\\\pi x}{2}-\\\\cdots\\\\right) \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nwhere $x^{2}=C=\\\\frac{16}{\\\\pi^{2}}\\\\left(1-\\\\frac{1}{2^{2}}+\\\\frac{1}{3^{2}}-\\\\frac{1}{4^{2}}+\\\\cdots\\\\right)$\\n\\n(b) To determine $\\\\mathrm{C}$ in another way, note that Equation (2) represents the Fourier cosine series for $x^{2}$ in $0<x$ $<2$. Then, since $L=2$ in this case,\\n\\n$$\\nC=\\\\frac{a_{0}}{2}=\\\\frac{1}{L} \\\\int_{0}^{L} f(x)=\\\\frac{1}{2} \\\\int_{0}^{2} x^{2} d x=\\\\frac{4}{3}\\n$$\\n\\nThen, from the value of $C$ in (a), we have\\n\\n$$\\n\\\\sum_{n=1}^{\\\\infty} \\\\frac{(-1)^{n-1}}{n^{2}}=1-\\\\frac{1}{2^{2}}+\\\\frac{1}{3^{2}}-\\\\frac{1}{4^{2}}+\\\\cdots=\\\\frac{\\\\pi^{2}}{16} \\\\cdot \\\\frac{4}{3}=\\\\frac{\\\\pi^{2}}{12}\\n$$\\n',\n",
       " '\\n13.17. Show that term-by-term differentiation of the series in Problem 13.12(a) is not valid.\\n\\nTerm-by-term differentiation yields $2\\\\left(\\\\cos \\\\frac{\\\\pi x}{2}-\\\\cos \\\\frac{2 \\\\pi x}{2}+\\\\cos \\\\frac{3 \\\\pi x}{2}-\\\\cdots\\\\right)$. Since the $n$th term of this series does not approach 0 , the series does not converge for any value of $x$.\\n\\n\\n\\\\section*{Convergence of Fourier series}\\n',\n",
       " '13.18. Prove that\\n\\n(a) $\\\\frac{1}{2}+\\\\cos t+\\\\cos 2 t+\\\\cdots+\\\\cos M t=\\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t}$\\n\\n(b) $\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\pi} \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t=\\\\frac{1}{2}, \\\\quad \\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{0} \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t=\\\\frac{1}{2}$\\\\\\\\\\n(a) We have $\\\\cos n t \\\\sin \\\\frac{1}{2} t=\\\\frac{1}{2}\\\\left\\\\{\\\\sin \\\\left(n+\\\\frac{1}{2}\\\\right) t-\\\\sin \\\\left(n-\\\\frac{1}{2}\\\\right) t\\\\right\\\\}$.\\n\\nThen, summing from $n=1$ to $M$,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\sin \\\\frac{1}{2} t\\\\{\\\\cos t+\\\\cos 2 t+\\\\cdots+\\\\cos M t\\\\} .= & \\\\left(\\\\sin \\\\frac{3}{2} t-\\\\sin \\\\frac{1}{2} t\\\\right)+\\\\left(\\\\sin \\\\frac{5}{2} t-\\\\sin \\\\frac{3}{2} t\\\\right) \\\\\\\\\\n& +\\\\cdots+\\\\left(\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t-\\\\sin \\\\left(M-\\\\sin \\\\frac{1}{2} t\\\\right)\\\\right. \\\\\\\\\\n= & \\\\frac{1}{2}\\\\left\\\\{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t-\\\\sin \\\\frac{1}{2} t\\\\right\\\\}\\n\\\\end{aligned}\\n$$\\n\\nOn dividing by $\\\\sin \\\\frac{1}{2} t$ and adding $\\\\frac{1}{2}$, the required result follows.\\n\\n(b) Integrating the result in (a) from $-\\\\pi$ to 0 and 0 to $\\\\pi$, respectively, gives the required results, since the integrals of all the cosine terms are zero.\\n',\n",
       " \"\\n13.19. Prove that $\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{-\\\\pi}^{\\\\pi} f(x) \\\\sin n x d x=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\int_{-\\\\pi}^{\\\\pi} f(x) \\\\cos n x d x=0$ if $f(x)$ is piecewise continuous.\\n\\nThis follows at once from Problem 13.15, since if the series $\\\\frac{a_{0}^{2}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n}^{2}+b_{n}^{2}\\\\right)$ is convergent,\\\\\\\\\\n$a=\\\\lim b=0$. $\\\\lim _{n \\\\rightarrow \\\\infty} a_{n}=\\\\lim _{n \\\\rightarrow \\\\infty} b_{n}=0$.\\n\\nThe result is sometimes called Riemann's theorem.\\n\",\n",
       " '\\n13.20. Prove that $\\\\lim _{m \\\\rightarrow \\\\infty} \\\\int_{-\\\\pi}^{\\\\pi} f(x) \\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) x d x=0$ if $f(x)$ is piecewise continuous.\\n\\nWe have\\n\\n$$\\n\\\\int_{-\\\\pi}^{\\\\pi} f(x) \\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) x d x=\\\\int_{-\\\\pi}^{\\\\pi}\\\\left\\\\{f(x) \\\\sin \\\\frac{1}{2} x\\\\right\\\\} \\\\cos M x d x+\\\\int_{-\\\\pi}^{\\\\pi}\\\\left\\\\{f(x) \\\\cos \\\\frac{1}{2} x\\\\right\\\\} \\\\sin M x d x\\n$$\\n\\nThen the required result follows at once by using the result of Problem 13.19, with $f(x)$ replaced by $f(x) \\\\sin \\\\frac{1}{2}$ $x$ and $f(x) \\\\cos \\\\frac{1}{2} x$, respectively, which are piecewise continuous if $f(x)$ is.\\n\\nThe result can also be proved when the integration limits are $a$ and $b$ instead of $-\\\\pi$ and $\\\\pi$.\\n',\n",
       " '\\n13.21. Assuming that $L=\\\\pi$, i.e., that the Fourier series corresponding to $f(\\\\mathrm{x})$ has period $2 L=2 \\\\pi$, show that\\n\\n$$\\nS_{M}(x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{M}\\\\left(a_{n} \\\\cos n x+b_{n} \\\\sin n x\\\\right)=\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(t+x) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t\\n$$\\n\\nUsing the formulas for the Fourier coefficients with $L=\\\\pi$, we have\\n\\n$$\\n\\\\begin{aligned}\\na_{n} \\\\cos n x+b_{n} \\\\sin n x & =\\\\left(\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u) \\\\cos n u d u\\\\right) \\\\cos n x+\\\\left(\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u) \\\\sin n u d u\\\\right) \\\\sin n x \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u)(\\\\cos n u \\\\cos n x+\\\\sin n u \\\\sin n x) d u \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u) \\\\cos n(u-x) d u\\n\\\\end{aligned}\\n$$\\n\\nAlso,\\n\\n$$\\n\\\\frac{a_{o}}{2}=\\\\frac{1}{2 \\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u) d u\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\nS_{M}(x) & =\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{M}\\\\left(a_{n} \\\\cos n x+b_{n} \\\\sin n x\\\\right) \\\\\\\\\\n& =\\\\frac{1}{2 \\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u) d u+\\\\frac{1}{\\\\pi} \\\\sum_{n=1}^{M} \\\\int_{-\\\\pi}^{\\\\pi} f(u) \\\\cos n(u-x) d u \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u)\\\\left\\\\{\\\\frac{1}{2}+\\\\sum_{n=1}^{M} \\\\cos n(u-x)\\\\right\\\\} d u \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{\\\\pi} f(u) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right)(u-x)}{2 \\\\sin \\\\frac{1}{2}(u-x)} d u\\n\\\\end{aligned}\\n$$\\n\\nusing Problem 13.18. Letting $u-x=t$, we have\\n\\n$$\\nS_{M}(x)=\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi-x}^{\\\\pi-x} f(t+x) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t\\n$$\\n\\nSince the integrand has period $2 \\\\pi$, we can replace the interval $-\\\\pi-x, \\\\pi-x$ by any other interval of length $2 \\\\pi$, in particular, $-\\\\pi, \\\\pi$. Thus, we obtain the required result.\\n',\n",
       " '\\n13.22.\\n\\nProve that\\n\\n$$\\n\\\\begin{aligned}\\nS_{M}(x)-\\\\left(\\\\frac{(f(x+0)+f(x-0))}{2}\\\\right)= & \\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{0}\\\\left(\\\\frac{(f(t+x)-f(x-0))}{2 \\\\sin \\\\frac{1}{2} t}\\\\right) \\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t d t \\\\\\\\\\n& +\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\pi}\\\\left(\\\\frac{(f(t+x)-f(x+0))}{2 \\\\sin \\\\frac{1}{2} t}\\\\right) \\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t d t\\n\\\\end{aligned}\\n$$\\n\\nFrom Problem 13.21,\\n\\n\\n\\\\begin{equation*}\\nS_{M}(x)=\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{0} f(t+x) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t+\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\pi} f(t+x) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nMultiplying the integrals of Problem 13.18(b) by $f(x-0)$ and $f(x+0)$, respectively,\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{f(x+0)+f(x-0)}{2}=\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{0} f(x-0) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t+\\\\frac{1}{\\\\pi} \\\\int_{-\\\\pi}^{0} f(x+0) \\\\frac{\\\\sin \\\\left(M+\\\\frac{1}{2}\\\\right) t}{2 \\\\sin \\\\frac{1}{2} t} d t \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSubtracting Equation (2) from Equation (1) yields the required result.\\n',\n",
       " '\\n13.23. If $f(\\\\mathrm{x})$ and $f^{\\\\prime}(x)$ are piecewise continuous in $(-\\\\pi, \\\\pi)$, prove that\\n\\n$$\\n\\\\lim _{M \\\\rightarrow \\\\infty} S_{M}(x)=\\\\frac{f(x+0)+f(x-0)}{2}\\n$$\\n\\ntinuous.\\n\\nThe function $\\\\frac{f(t+x)-f(x+0)}{2 \\\\sin \\\\frac{1}{2} t}$ is piecewise continuous in $0<t \\\\leqq \\\\pi$ because $f(x)$ is piecewise con-\\\\\\\\\\nous.\\n\\nAlso, $\\\\lim _{t \\\\rightarrow 0+} \\\\frac{f(t+x)-f(x+0)}{2 \\\\sin \\\\frac{1}{2} t}=\\\\lim _{t \\\\rightarrow 0+} \\\\frac{f(t+x)-f(x+0)}{t} \\\\cdot \\\\frac{t}{2 \\\\sin \\\\frac{1}{2} t}=\\\\lim _{t \\\\rightarrow 0+} \\\\frac{f(t+x)-f(x+0)}{t}$ exists, since, by hypothesis, $f^{\\\\prime}(x)$ is piecewise continuous so that the right-hand derivative of $f(x)$ at each $x$ exists.\\n\\nThus, $\\\\frac{f(t+x)-f(x-0)}{2 \\\\sin \\\\frac{1}{2} t}$ is piecewise continuous in $0 \\\\leqq t \\\\leqq \\\\pi$.\\n\\nSimilarly, $\\\\frac{f(t+x)-f(x-0)}{2 \\\\sin \\\\frac{1}{2} t}$ is piecewise continuous in $-\\\\pi \\\\leqq t \\\\leqq 0$.\\n\\nThen, from Problems 13.20 and 13.22, we have\\n\\n$$\\n\\\\lim _{M \\\\rightarrow \\\\infty} S_{M}(x)-\\\\left\\\\{\\\\frac{f(x+0)-f(x-0)}{2}\\\\right\\\\}=0 \\\\quad \\\\text { or } \\\\quad \\\\lim _{M \\\\rightarrow \\\\infty} S_{M}(x)=\\\\left\\\\{\\\\frac{f(x+0)+f(x-0)}{2}\\\\right\\\\}\\n$$\\n\\n\\n\\\\section*{Boundary value problems}\\n',\n",
       " '13.24. Find a solution $U(x, t)$ of the boundary value problem\\n\\n$$\\n\\\\begin{array}{ll}\\n\\\\frac{\\\\partial U}{\\\\partial t}=3 \\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}} & t>0,0<x<2 \\\\\\\\\\nU(0, t)=0, U(2, t)=0 & t>0 \\\\\\\\\\nU(x, 0)=x & 0<x<2\\n\\\\end{array}\\n$$\\n\\nA method commonly employed in practice is to assume the existence of a solution of the partial differential equation having the particular form $U(x, t)=X(x) T(t)$, where $X(x)$ and $T(t)$ are functions of $x$ and $t$, respectively, which we shall try to determine. For this reason, the method is often called the method of separation of variables.\\n\\nSubstitution in the differential equation yields\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\partial U}{\\\\partial t}(X T)=3 \\\\frac{\\\\partial^{2}}{\\\\partial x^{2}}(X T) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nor\\n\\n\\n\\\\begin{equation*}\\nX \\\\frac{d T}{d t}=3 T \\\\frac{d^{2} X}{d x^{2}} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nwhere we have written $X$ and $T$ in place of $X(x)$ and $T(t)$.\\n\\nEquation (2) can be written as\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{1}{3 T} \\\\frac{d T}{d t}=\\\\frac{1}{X} \\\\frac{d^{2} X}{d x^{2}} \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nSince one side depends only on $t$ and the other only on $x$, and since $x$ and $t$ are independent variables, it is clear that each side must be a constant $c$.\\n\\nIn Problem 13.47 we see that if $c \\\\geq 0$, a solution satisfying the given boundary conditions cannot exist.\\n\\nLet us thus assume that $c$ is a negative constant, which we write as $-\\\\lambda^{2}$. Then, from Equation (3), we obtain two ordinary differentiation equations\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{d T}{d t}+3 \\\\lambda^{2} T=0, \\\\quad \\\\frac{d^{2} X}{d x^{2}}+\\\\lambda^{2} X=0 \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nwhose solutions are, respectively,\\n\\n\\n\\\\begin{equation*}\\nT=C_{1} e^{-3 \\\\lambda^{2} t}, \\\\quad X=A_{1} \\\\cos \\\\lambda x+B_{1} \\\\sin \\\\lambda x \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nA solution is given by the product of $X$ and $T$, which can be written\\n\\n\\n\\\\begin{equation*}\\nU(x, t)=e^{-3 \\\\lambda^{2} t}(A \\\\cos \\\\lambda x+B \\\\sin \\\\lambda x) \\\\tag{6}\\n\\\\end{equation*}\\n\\n\\nwhere $A$ and $B$ are constants.\\n\\nWe now seek to determine $A$ and $B$ so that Equation (6) satisfies the given boundary conditions. To satisfy the condition $U(0, t)=0$, we must have\\n\\n\\n\\\\begin{equation*}\\ne^{-s \\\\lambda^{2} t}(A)=0 \\\\quad \\\\text { or } \\\\quad A=0 \\\\tag{7}\\n\\\\end{equation*}\\n\\n\\nso that Equation (6) becomes\\n\\n\\n\\\\begin{equation*}\\nU(x, t)=B e^{-3 \\\\lambda^{2} t} \\\\sin \\\\lambda x \\\\tag{8}\\n\\\\end{equation*}\\n\\n\\nTo satisfy the condition $U(2, t)=0$, we must then have\\n\\n\\n\\\\begin{equation*}\\nB e^{-s \\\\lambda^{2} t} \\\\sin 2 \\\\lambda=0 \\\\tag{9}\\n\\\\end{equation*}\\n\\n\\nSince $B=0$ makes the solution (8) identically zero, we avoid this choice and instead take\\n\\n\\n\\\\begin{equation*}\\n\\\\sin 2 \\\\lambda=0, \\\\quad \\\\text { i.e., } \\\\quad 2 \\\\lambda=m \\\\pi \\\\quad \\\\text { or } \\\\quad \\\\lambda=\\\\frac{m \\\\pi}{2} \\\\tag{10}\\n\\\\end{equation*}\\n\\n\\nwhere $m=0, \\\\pm 1, \\\\pm 2, \\\\ldots$.\\n\\nSubstitution in Equation (8) now shows that a solution satisfying the first two boundary conditions is\\n\\n\\n\\\\begin{equation*}\\nU(x, t)=B_{m} e^{-3 m^{2} \\\\pi^{2} t / 4} \\\\sin \\\\frac{m \\\\pi x}{2} \\\\tag{11}\\n\\\\end{equation*}\\n\\n\\nwhere we have replaced $B$ by $B_{m}$, indicating that different constants can be used for different values of $m$.\\n\\nIf we now attempt to satisfy the last boundary condition $U(x, 0)=x, 0<x<2$, we find it to be impossible using Equation (11). However, upon recognizing the fact that sums of solutions having the form (11) are also solutions (called the principle of superposition), we are led to the possible solution\\n\\n\\n\\\\begin{equation*}\\nU(x, t)=\\\\sum_{m=1}^{\\\\infty} B_{m} e^{-3 m^{2} \\\\pi^{2} t / 4} \\\\sin \\\\frac{m \\\\pi x}{2} \\\\tag{12}\\n\\\\end{equation*}\\n\\n\\nFrom the condition $U(x, 0)=x, 0<x<2$, we see, on placing $t=0$, that Equation (12) becomes\\n\\n\\n\\\\begin{equation*}\\nx=\\\\sum_{m=1}^{\\\\infty} B_{m} \\\\sin \\\\frac{m \\\\pi x}{2} \\\\quad 0<x<2 \\\\tag{13}\\n\\\\end{equation*}\\n\\n\\nThis, however, is equivalent to the problem of expanding the function $f(x)=x$ for $0<x<2$ into a sine series. The solution to this is given in Problem 13.12(a), from which we see that $B_{m}=\\\\frac{-4}{m \\\\pi} \\\\cos m \\\\pi$ so that\\\\\\\\\\nEquation (12) becomes\\n\\n\\n\\\\begin{equation*}\\nU(x, t)=\\\\sum_{m=1}^{\\\\infty}\\\\left(-\\\\frac{4}{m \\\\pi} \\\\cos m \\\\pi\\\\right) e^{-3 m^{2} \\\\pi^{2} t / 4} \\\\sin \\\\frac{m \\\\pi x}{2} \\\\tag{14}\\n\\\\end{equation*}\\n\\n\\nwhich is a formal solution. To check that Equation (14) is actually a solution, we must show that it satisfies the partial differential equation and the boundary conditions. The proof consists in justification of term-by-term differentiation and use of limiting procedures for infinite series and may be accomplished by methods of Chapter 11.\\n\\nThe boundary value problem considered here has an interpretation in the theory of heat conduction. The equation $\\\\frac{\\\\partial U}{\\\\partial t}=k \\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}}$ is the equation for heat conduction in a thin rod or wire located on the $x$ axis between $x=0$ and $x=L$ if the surface of the wire is insulated so that heat cannot enter or escape. $U(x, t)$ is the temperature at any place $x$ in the rod at time $t$. The constant $k=K / s p$ (where $K$ is the thermal conductivity, $s$ is the specific heat, and $\\\\rho$ is the density of the conducting material) is called the diffusivity. The boundary conditions $U(0, t)=0$ and $U(L, t)=0$ indicate that the end temperatures of the rod are kept at zero units for all time $t>0$, while $U(x, 0)$ indicates the initial temperature at any point $x$ of the rod. In this problem the length of the rod is $L=2$ units, while the diffusivity is $k=3$ units.\\n\\n\\n\\\\section*{Orthogonal functions}\\n',\n",
       " '13.25. (a) Show that the set of functions\\n\\n$$\\n1, \\\\sin \\\\frac{\\\\pi x}{L}, \\\\cos \\\\frac{\\\\pi x}{L}, \\\\sin \\\\frac{2 \\\\pi x}{L}, \\\\cos \\\\frac{2 \\\\pi x}{L}, \\\\sin \\\\frac{3 \\\\pi x}{L}, \\\\cos \\\\frac{3 \\\\pi x}{L}, \\\\ldots\\n$$\\n\\nforms an orthogonal set in the interval $(-L, L)$.\\n\\n(b) Determine the corresponding normalizing constants for the set in (a) so that the set is orthonormal in $(-L, L)$.\\n\\n(a) This follows at once from the results of Problems 13.2 and 13.3.\\n\\n(b) By Problem 13.3,\\n\\n$$\\n\\\\int_{-L}^{L} \\\\sin ^{2} \\\\frac{m \\\\pi x}{L} d x=L, \\\\quad \\\\int_{-L}^{L} \\\\cos ^{2} \\\\frac{m \\\\pi x}{L} d x=L\\n$$\\n\\nThen\\n\\n$$\\n\\\\int_{-L}^{L}\\\\left(\\\\sqrt{\\\\frac{1}{L}} \\\\sin \\\\frac{m \\\\pi x}{L}\\\\right)^{2} d x=1 \\\\quad \\\\int_{-L}^{L}\\\\left(\\\\sqrt{\\\\frac{1}{L}} \\\\cos \\\\frac{m \\\\pi x}{L}\\\\right)^{2} d x=1\\n$$\\n\\nAlso,\\n\\n$$\\n\\\\int_{-L}^{L}(1)^{2} d x=2 L \\\\quad \\\\text { or } \\\\quad \\\\int_{-L}^{L}\\\\left(\\\\frac{1}{\\\\sqrt{2 L}}\\\\right)^{2} d x=1\\n$$\\n\\nThus, the required orthonormal set is given by\\n\\n$$\\n\\\\frac{1}{\\\\sqrt{2 L}}, \\\\frac{1}{\\\\sqrt{L}} \\\\sin \\\\frac{\\\\pi x}{L}, \\\\frac{1}{\\\\sqrt{L}} \\\\cos \\\\frac{\\\\pi x}{L}, \\\\frac{1}{\\\\sqrt{L}} \\\\sin \\\\frac{2 \\\\pi x}{L}, \\\\frac{1}{\\\\sqrt{L}} \\\\cos \\\\frac{2 \\\\pi x}{L}, \\\\ldots\\n$$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '13.26. Find a Fourier series for $f(\\\\mathrm{x})=\\\\cos \\\\alpha x,-\\\\pi \\\\leqq x \\\\leqq \\\\pi$, where $\\\\alpha \\\\neq 0, \\\\pm 1, \\\\pm 2, \\\\pm 3, \\\\ldots$\\n\\nWe shall take the period as $2 \\\\pi$ so that $2 L=2 \\\\pi, L=\\\\pi$. Since the function is even, $b_{n}=0$ and\\n\\n$$\\n\\\\begin{aligned}\\na_{n} & =\\\\frac{2}{L} \\\\int_{0}^{L} f(x) \\\\cos n x d x=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\pi} \\\\cos \\\\alpha x \\\\cos n x d x \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\pi}\\\\{\\\\cos (\\\\alpha-n) x+\\\\cos (\\\\alpha+n) x\\\\} d x \\\\\\\\\\n& =\\\\frac{1}{\\\\pi}\\\\left\\\\{\\\\frac{\\\\sin (\\\\alpha-n) \\\\pi}{\\\\alpha-n}+\\\\frac{\\\\sin (\\\\alpha+n) \\\\pi}{\\\\alpha+n}+\\\\cdots\\\\right\\\\}=\\\\frac{2 \\\\alpha \\\\sin \\\\alpha \\\\pi \\\\cos n \\\\pi}{\\\\pi\\\\left(\\\\alpha^{2}-n^{2}\\\\right)} \\\\\\\\\\n\\\\alpha_{0} & =\\\\frac{2 \\\\sin \\\\alpha \\\\pi}{\\\\alpha \\\\pi}\\n\\\\end{aligned}\\n$$\\n\\nThen\\n\\n$$\\n\\\\begin{aligned}\\n\\\\cos \\\\alpha x & =\\\\frac{\\\\sin \\\\alpha \\\\pi}{\\\\alpha \\\\pi}+\\\\frac{2 \\\\alpha \\\\sin \\\\alpha \\\\pi}{\\\\pi} \\\\sum_{n=1}^{\\\\infty} \\\\frac{\\\\cos n \\\\pi}{\\\\alpha^{2}-2^{2}} \\\\cos n x \\\\\\\\\\n& =\\\\frac{\\\\sin \\\\alpha \\\\pi}{\\\\pi}\\\\left(\\\\frac{1}{\\\\alpha}-\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-1^{2}} \\\\cos x+\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-2^{2}} \\\\cos 2 x-\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-3^{2}} \\\\cos 3 x+\\\\cdots\\\\right)\\n\\\\end{aligned}\\n$$\\n',\n",
       " \"\\n13.27. Prove that $\\\\sin x=x\\\\left(1-\\\\frac{x^{2}}{\\\\pi^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{(2 \\\\pi)^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{(3 \\\\pi)^{2}}\\\\right) \\\\ldots$\\n\\nLet $x=\\\\pi$ in the Fourier series obtained in Problem 13.26. Then\\n\\n$$\\n\\\\cos \\\\alpha=\\\\frac{\\\\sin \\\\alpha \\\\pi}{\\\\pi}\\\\left(\\\\frac{1}{\\\\alpha}+\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-1^{2}}+\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-2^{2}}+\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-3^{2}}+\\\\cdots\\\\right)\\n$$\\n\\nor\\n\\n\\n\\\\begin{equation*}\\n\\\\pi \\\\cot \\\\alpha \\\\pi-\\\\frac{1}{\\\\alpha}=\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-1^{2}}+\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-2^{2}}+\\\\frac{2 \\\\alpha}{\\\\alpha^{2}-3^{2}}+\\\\cdots \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nThis result is of interest since it represents an expansion of the contangent into partial fractions.\\n\\nBy the Weierstrass $M$ test, the series on the right of Equation (1) converges uniformly for $0 \\\\leqq|\\\\alpha| \\\\leqq|x|<1$ and the left-hand side of (1) approaches zero as $\\\\alpha \\\\rightarrow 0$, as is seen by using L'Hospital's rule. Thus, we can integrate both sides of (1) from 0 to $x$ to obtain\\n\\n$$\\n\\\\int_{0}^{x}\\\\left(\\\\pi \\\\cot \\\\alpha \\\\pi-\\\\frac{1}{\\\\alpha}\\\\right) d \\\\alpha=\\\\int_{0}^{x} \\\\frac{2 \\\\alpha}{\\\\alpha^{2}-1} d \\\\alpha+\\\\int_{0}^{x} \\\\frac{2 \\\\alpha}{\\\\alpha^{2}-2^{2}} d \\\\alpha+\\\\cdots\\n$$\\n\\nor\\n\\n$$\\n\\\\left.\\\\ln \\\\left(\\\\frac{\\\\sin \\\\alpha \\\\pi}{\\\\alpha \\\\pi}\\\\right)\\\\right|_{0} ^{x}=\\\\ln \\\\left(1-\\\\frac{x^{2}}{1^{2}}\\\\right)+\\\\ln \\\\left(1-\\\\frac{x^{2}}{2^{2}}\\\\right)+\\\\cdots\\n$$\\n\\ni.e.,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\ln \\\\left(\\\\frac{\\\\sin \\\\pi}{\\\\pi x}\\\\right) & \\\\left.=\\\\lim _{n \\\\rightarrow \\\\infty} \\\\ln \\\\left(1-\\\\frac{x^{2}}{1^{2}}\\\\right)+\\\\ln \\\\left(1-\\\\frac{x^{2}}{2^{2}}\\\\right) \\\\right\\\\rvert\\\\,+\\\\cdots+\\\\ln \\\\left(1-\\\\frac{x^{2}}{n^{2}}\\\\right) \\\\\\\\\\n= & \\\\lim _{n \\\\rightarrow \\\\infty} \\\\ln \\\\left\\\\{\\\\left(1-\\\\frac{x^{2}}{1^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{2^{2}}\\\\right) \\\\cdots\\\\left(1-\\\\frac{x^{2}}{n^{2}}\\\\right)\\\\right\\\\} \\\\\\\\\\n= & \\\\ln \\\\left\\\\{\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1-\\\\frac{x^{2}}{1^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{2^{2}}\\\\right) \\\\cdots\\\\left(1-\\\\frac{x^{2}}{n^{2}}\\\\right)\\\\right\\\\}\\n\\\\end{aligned}\\n$$\\n\\nso that\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{\\\\sin \\\\pi}{\\\\pi x}=\\\\lim _{n \\\\rightarrow \\\\infty}\\\\left(1-\\\\frac{x^{2}}{1^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{2^{2}}\\\\right) \\\\cdots\\\\left(1-\\\\frac{x^{2}}{n^{2}}\\\\right)=\\\\left(1-\\\\frac{x^{2}}{1^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{2^{2}}\\\\right) \\\\ldots \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nReplacing $x$ by $x / \\\\pi$, we obtain\\n\\n\\n\\\\begin{equation*}\\n\\\\sin x=x\\\\left(1-\\\\frac{x^{2}}{\\\\pi^{2}}\\\\right)\\\\left(1-\\\\frac{x^{2}}{(2 \\\\pi)^{2}}\\\\right) \\\\cdots \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\ncalled the infinite product for $\\\\sin x$, which can be shown valid for all $x$. The result is of interest since it corresponds to a factorization of $\\\\sin x$ in a manner analogous to factorization of a polynomial.\\n\",\n",
       " \"\\n13.28. Prove that $\\\\frac{\\\\pi}{2}=\\\\frac{2 \\\\cdot 2 \\\\cdot 4 \\\\cdot 4 \\\\cdot 6 \\\\cdot 6 \\\\cdot 8 \\\\cdot 8 \\\\cdots}{1 \\\\cdot 3 \\\\cdot 3 \\\\cdot 5 \\\\cdot 5 \\\\cdot 7 \\\\cdot 7 \\\\cdot 9 \\\\ldots}$.\\n\\nLet $x=1 / 2$ in Equation (2) of Problem 13.27. Then,\\n\\n$$\\n\\\\frac{2}{\\\\pi}=\\\\left(1-\\\\frac{1}{2^{2}}\\\\right)\\\\left(1-\\\\frac{1}{4^{2}}\\\\right)\\\\left(1-\\\\frac{1}{6^{2}}\\\\right) \\\\cdots=\\\\left(\\\\frac{1}{2} \\\\cdot \\\\frac{3}{2}\\\\right)\\\\left(\\\\frac{3}{4} \\\\cdot \\\\frac{5}{4}\\\\right)\\\\left(\\\\frac{5}{6} \\\\cdot \\\\frac{7}{6}\\\\right) \\\\cdots\\n$$\\n\\nTaking reciprocals of both sides, we obtain the required result, which is often called Wallis's product.\\n\\n\",\n",
       " '14.1. (a) Find the Fourier transform of $f(x)=\\\\left\\\\{\\\\begin{array}{ll}1 & |x|<a \\\\\\\\ 0 & |x|>a\\\\end{array}\\\\right.$. (b) Graph $f(\\\\mathrm{x})$ and its Fourier transform for $a=3$.\\n\\n(a) The Fourier transform of $f(\\\\mathrm{x})$ is\\n\\n$$\\n\\\\begin{aligned}\\nF(\\\\alpha) & =\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} f(u) e^{i \\\\alpha u} d u=\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-a}^{a}(1) e^{i \\\\alpha u} d u=\\\\left.\\\\frac{1}{2 \\\\sqrt{\\\\pi}} \\\\frac{e^{i \\\\alpha u}}{i \\\\alpha}\\\\right|_{-a} ^{a} \\\\\\\\\\n& =\\\\frac{1}{\\\\sqrt{2 \\\\pi}}\\\\left(\\\\frac{e^{i \\\\alpha a}-e^{-i \\\\alpha a}}{i \\\\alpha}\\\\right)=\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\frac{\\\\sin \\\\alpha a}{\\\\alpha}, \\\\quad \\\\alpha \\\\neq 0\\n\\\\end{aligned}\\n$$\\n\\nFor $\\\\alpha=0$, we obtain $F(\\\\alpha)=\\\\sqrt{2 / \\\\pi} a$.\\n\\n(b) The graphs of $f(\\\\mathrm{x})$ and $F(\\\\alpha)$ for $a=3$ are shown in Figures 14.1, and 14.2, respectively.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-391(1)}\\n\\\\end{center}\\n\\nFigure 14.1\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-391}\\n\\\\end{center}\\n\\nFigure 14.2\\n',\n",
       " \"\\n14.2. (a) Use the result of Problem 14.1 to evaluate $\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha a \\\\cos \\\\alpha x}{\\\\alpha} d \\\\alpha$. (b) Deduce the value of $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin u}{u} d u$. (a) From Fourier's integral theorem, if\\n\\n$$\\nF(\\\\alpha)=\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} f(u) e^{i \\\\alpha u} d u \\\\quad \\\\text { then } \\\\quad f(x)=\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} F(\\\\alpha) e^{-i \\\\alpha x} d \\\\alpha\\n$$\\n\\nThen, from Problem 14.1,\\n\\n\\\\[\\n\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} \\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\frac{\\\\sin \\\\alpha a}{\\\\alpha} e^{-i a x} d x= \\\\begin{cases}1 & |x|<a  \\\\tag{1}\\\\\\\\ 1 / 2 & |x|=a \\\\\\\\ 0 & |x|>a\\\\end{cases}\\n\\\\]\\n\\nThe left side of Equation (1) is equal to\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{1}{\\\\pi} \\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha a \\\\cos \\\\alpha x}{\\\\alpha} d \\\\alpha-\\\\frac{i}{\\\\pi} \\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha a \\\\sin \\\\alpha x}{\\\\alpha} d \\\\alpha \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nThe integrand in the second integral of Equation (2) is odd, and so the integral is zero. Then from Equations (1) and (2), we have\\n\\n\\\\[\\n\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha a \\\\cos \\\\alpha x}{\\\\alpha} d \\\\alpha= \\\\begin{cases}\\\\pi & |x|<a  \\\\tag{3}\\\\\\\\ \\\\pi / 2 & |x|=a \\\\\\\\ 0 & |x|>a\\\\end{cases}\\n\\\\]\\n\\nAlternative solution: Since the function $f$ in Problem 14.1 is an even function, the result follows immediately from the Fourier cosine transform (9).\\\\\\\\\\n(b) If $x=0$ and $a=1$ in the result of (a), we have\\n\\n$$\\n\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha}{\\\\alpha} d \\\\alpha=\\\\pi \\\\quad \\\\text { or } \\\\quad \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha}{\\\\alpha} d \\\\alpha=\\\\frac{\\\\pi}{2}\\n$$\\n\\nsince the integrand is even.\\n\",\n",
       " '\\n14.3. If $f(x)$ is an even function, show that (a) $F(\\\\alpha)=\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\int_{0}^{\\\\infty} f(u) \\\\cos \\\\alpha u d u$ and\\n\\n(b) $f(x)=\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\int_{0}^{\\\\infty} F(\\\\alpha) \\\\cos \\\\alpha x d \\\\alpha$\\n\\nWe have\\n\\n$F(\\\\alpha)=\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} f(u) e^{i a u} d u=\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha u d u+\\\\frac{i}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\sin \\\\alpha u d u$\\n\\n(a) If $f(u)$ is even, $f(u) \\\\cos \\\\lambda u$ is even and $f(u) \\\\sin \\\\lambda u$ is odd. Then the second integral on the right of Equation (1) is zero, and the result can be written\\n\\n$$\\nF(\\\\alpha)=\\\\frac{2}{\\\\sqrt{2 \\\\pi}} \\\\int_{0}^{\\\\infty} f(u) \\\\cos \\\\alpha u d u=\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\int_{0}^{\\\\infty} f(u) \\\\cos \\\\alpha u d u\\n$$\\n\\n(b) From (a), $F(-\\\\alpha)=F(\\\\alpha)$ so that $F(\\\\alpha)$ is an even function. Then, by using a proof exactly analogous to that in (a), the required result follows.\\n\\nA similar result holds for odd functions and can be obtained by replacing the cosine by the sine.\\n',\n",
       " '\\n14.4. Solve the integral equation $\\\\int_{0}^{\\\\infty} f(x) \\\\cos \\\\alpha x d x=\\\\left\\\\{\\\\begin{array}{cr}1-\\\\alpha & 0 \\\\leqq \\\\alpha \\\\leqq 1 \\\\\\\\ 0 & \\\\alpha>1\\\\end{array}\\\\right.$.\\n\\nLet $\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\int_{0}^{\\\\infty} f(x) \\\\cos \\\\alpha x d x=F(\\\\alpha)$ and choose $F(\\\\alpha)=\\\\left\\\\{\\\\begin{array}{cc}\\\\sqrt{2 / \\\\pi}(1-\\\\alpha) & 0<\\\\alpha<1 \\\\\\\\ 0 & \\\\alpha>1\\\\end{array}\\\\right.$ Then, by Problem 14.3,\\n\\n$$\\n\\\\begin{aligned}\\nf(x) & =\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\int_{0}^{\\\\infty} F(\\\\alpha) \\\\cos \\\\alpha x d \\\\alpha=\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\int_{0}^{1} \\\\sqrt{\\\\frac{2}{\\\\pi}}(1-\\\\alpha) \\\\cos \\\\alpha x d \\\\alpha \\\\\\\\\\n& =\\\\frac{2}{\\\\pi} \\\\int_{0}^{1}(1-\\\\alpha) \\\\cos \\\\alpha x d \\\\alpha=\\\\frac{2(1-\\\\cos x)}{\\\\pi x^{2}}\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n14.5. Use Problem 14.4 to show that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} u}{u^{2}} d u=\\\\frac{\\\\pi}{2}$.\\n\\nAs obtained in Problem 14.4,\\n\\n$$\\n\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} \\\\cos \\\\alpha x d x=\\\\left\\\\{\\\\begin{array}{rr}\\n1-\\\\alpha & 0 \\\\leqq \\\\alpha \\\\leqq 1 \\\\\\\\\\n0 & \\\\alpha>1\\n\\\\end{array}\\\\right.\\n$$\\n\\nTaking the limit as $\\\\alpha \\\\rightarrow 0+$, we find\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{1-\\\\cos x}{x^{2}} d x=\\\\frac{\\\\pi}{2}\\n$$\\n\\nBut this integral can be written as $\\\\int_{0}^{\\\\infty} \\\\frac{2 \\\\sin ^{2}(x / 2)}{x^{2}} d x$, which becomes $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} u}{u^{2}} d u$ on letting $x=2 u$, so\\\\\\\\\\nthat the required result follows.\\n',\n",
       " \"\\n14.6. Show that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos \\\\alpha x}{a^{2}+1} d \\\\alpha=\\\\frac{\\\\pi}{2} e^{-x}, x \\\\geqq 0$.\\n\\nLet $f(x)=e^{-x}$ in the Fourier integral theorem\\n\\n$$\\nf(x)=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\infty} \\\\cos \\\\alpha x d \\\\alpha \\\\int_{0}^{\\\\infty} f(u) \\\\cos \\\\lambda u d u\\n$$\\n\\nThen\\n\\n$$\\n\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\infty} \\\\cos \\\\alpha x d \\\\alpha \\\\int_{0}^{\\\\infty} e^{-u} \\\\cos \\\\alpha u d u=e^{-x}\\n$$\\n\\nBut by Problem 12.22, we have $\\\\int_{0}^{\\\\infty} e^{-u} \\\\cos \\\\alpha u d u=\\\\frac{1}{\\\\alpha^{2}+1}$. Then\\n\\n$$\\n\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos \\\\alpha x}{\\\\alpha^{2}+1} d \\\\alpha=e^{-x} \\\\quad \\\\text { or } \\\\quad \\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos \\\\alpha x}{a^{2}+1} d \\\\alpha=\\\\frac{\\\\pi}{2} e^{-x}\\n$$\\n\\n\\n\\\\section*{Parseval's identity}\\n\",\n",
       " \"14.7. Verify Parseval's identity for Fourier integrals for the Fourier transforms of Problem 14.1.\\n\\nWe must show that\\n\\n$$\\n\\\\int_{-\\\\infty}^{\\\\infty}\\\\{f(x)\\\\}^{2} d x=\\\\int_{-\\\\infty}^{\\\\infty}\\\\{F(\\\\alpha)\\\\}^{2} d \\\\alpha\\n$$\\n\\nwhere\\n\\n$$\\nf(x)=\\\\left\\\\{\\\\begin{array}{ll}\\n1 & |x|<a \\\\\\\\\\n0 & |x|<a\\n\\\\end{array} \\\\text { and } F(\\\\alpha)=\\\\sqrt{\\\\frac{2}{\\\\pi}} \\\\frac{\\\\sin \\\\alpha a}{\\\\alpha}\\\\right.\\n$$\\n\\nThis is equivalent to\\n\\n$$\\n\\\\int_{-a}^{a}(1)^{2} d x=\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{2}{\\\\pi} \\\\frac{\\\\sin ^{2} \\\\alpha a}{\\\\alpha^{2}} d \\\\alpha\\n$$\\n\\nor\\n\\n$$\\n\\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{\\\\sin ^{2} \\\\alpha a}{\\\\alpha^{2}} d \\\\alpha=2 \\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} \\\\alpha a}{a^{2}} d \\\\alpha=\\\\pi a\\n$$\\n\\ni.e.,\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} \\\\alpha a}{\\\\alpha^{2}} d \\\\alpha=\\\\frac{\\\\pi a}{2}\\n$$\\n\\nBy letting $\\\\alpha a=u$ and using Problem 14.5, it is seen that this is correct. The method can also be used to find $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin ^{2} u}{u^{2}} d u$ directly.\\n\\n\\n\\\\section*{Proof of the Fourier integral theorem}\\n\",\n",
       " \"14.8. Present a heuristic demonstration of Fourier's integral theorem by use of a limiting form of Fourier series.\\n\\nLet\\n\\n\\n\\\\begin{equation*}\\nf(x)=\\\\frac{a_{0}}{2}+\\\\sum_{n=1}^{\\\\infty}\\\\left(a_{n} \\\\cos \\\\frac{n \\\\pi x}{L}+b_{n} \\\\sin \\\\frac{n \\\\pi x}{L}\\\\right) \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere\\n\\n$$\\na_{n}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(u) \\\\cos \\\\frac{n \\\\pi u}{L} d u \\\\text { and } b_{n}=\\\\frac{1}{L} \\\\int_{-L}^{L} f(u) \\\\sin \\\\frac{n \\\\pi u}{L} d u\\n$$\\n\\nThen, by substitution (see Problem 13.21),\\n\\n\\n\\\\begin{equation*}\\nf(x)=\\\\frac{1}{2 L} \\\\int_{-L}^{L} f(u) d u+\\\\frac{1}{L} \\\\sum_{n=1}^{\\\\infty} f(u) \\\\cos \\\\frac{n \\\\pi}{L}(u-x) d u \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nIf we assume that $\\\\int_{-\\\\infty}^{\\\\infty}|f(u)| d u$ converges, the first term on the right of Equation (2) approaches zero as $L \\\\rightarrow \\\\infty$, while the remaining part appears to approach\\n\\n\\n\\\\begin{equation*}\\n\\\\lim _{L \\\\rightarrow \\\\infty} \\\\frac{1}{L} \\\\sum_{n=1}^{\\\\infty} \\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\frac{n \\\\pi}{L}(u-x) d u \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nThis last step is not rigorous and makes the demonstration heuristic.\\n\\nCalling $\\\\Delta \\\\alpha=\\\\pi / L$, Equation (3) can be written\\n\\n\\n\\\\begin{equation*}\\nf(x)=\\\\lim _{\\\\Delta \\\\alpha \\\\rightarrow 0} \\\\sum_{n=1}^{\\\\infty} \\\\Delta \\\\alpha F(n \\\\Delta \\\\alpha) \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nwhere we have written\\n\\n\\n\\\\begin{equation*}\\nF(\\\\alpha)=\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\infty} f(u) \\\\cos \\\\alpha(u-x) d u \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nBut the limit (4) is equal to\\n\\n$$\\nf(x)=\\\\int_{0}^{\\\\infty} F(\\\\alpha) d \\\\alpha=\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\infty} d \\\\alpha \\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha(u-x) d u\\n$$\\n\\nwhich is Fourier's integral formula.\\n\\nThis demonstration serves only to provide a possible result. To be rigorous, we start with the integral\\n\\n$$\\n1 / \\\\pi \\\\int_{0}^{\\\\infty} d \\\\alpha \\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha(u-x) d x\\n$$\\n\\nand examine the convergence. This method is considered in Problems 14.9 through 14.12.\\n\",\n",
       " '\\n14.9. Prove that\\n\\n(a) $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{0}^{L} \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\frac{\\\\pi}{2}$,\\n\\n(b) $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{-L}^{0} \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\frac{\\\\pi}{2}$.\\n\\n(a) Let $\\\\alpha v=y$. Then $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{0}^{L} \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{0}^{\\\\alpha L} \\\\frac{\\\\sin y}{y} d y=\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin y}{y} d y=\\\\frac{\\\\pi}{2}$. by Problem 12.29.\\n\\n(b) Let $\\\\alpha v=-y$. Then $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{-L}^{0} \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\lim _{x \\\\rightarrow \\\\infty} \\\\int_{0}^{\\\\alpha L} \\\\frac{\\\\sin y}{y} d y=\\\\frac{\\\\pi}{2}$.\\n',\n",
       " \"\\n14.10. Riemann's theorem states that if $F(\\\\mathrm{x})$ is piecewise continuous in $(a, b)$, then\\n\\n$$\\n\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{a}^{b} F(x) \\\\sin \\\\alpha x d x=0\\n$$\\n\\nwith a similar result for the cosine (see Problem 14.32). Use this to prove that\\n\\n(a) $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{0}^{L} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\frac{\\\\pi}{2} f(x+0)$\\n\\n(b) $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{-L}^{0} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\frac{\\\\pi}{2} f(x-0)$\\n\\nwhere $f(x)$ and $f^{\\\\prime}(x)$ are assumed piecewise continuous in $(0, L)$ and $(-L, 0)$, respectively.\\n\\n(a) Using Problem 14.9(a), it is seen that a proof of the given result amounts to proving that\\n\\n$$\\n\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{0}^{L}\\\\{f(x+v)-f(x+0)\\\\} \\\\frac{\\\\sin \\\\alpha v}{v} d v=0\\n$$\\n\\nThis follows at once from Riemann's theorem, because $F(v)=\\\\frac{f(x+v)-f(x+0)}{v}$ is piecewise continuous in $(0, L)$, since $\\\\lim _{n \\\\rightarrow 0+} F(v)$ exists and $f(x)$ is piecewise continuous.\\n\\n(b) A proof of this is analogous to that in (a) if we make use of Problem 14.9(b).\\n\",\n",
       " '\\n14.11. If $f(\\\\mathrm{x})$ satisfies the additional condition that $\\\\int_{-\\\\infty}^{\\\\infty}|f(x)| d x$ converges, prove that\\n\\n(a) $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{0}^{\\\\infty} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\frac{\\\\pi}{2} f(x+0)\\\\left(\\\\right.$ b) $\\\\lim _{\\\\alpha \\\\rightarrow \\\\infty} \\\\int_{-\\\\infty}^{0} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\frac{\\\\pi}{2} f(x-0)$\\n\\nWe have\\n\\n\\n\\\\begin{align*}\\n& \\\\int_{0}^{\\\\infty} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\int_{0}^{L} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v+\\\\int_{L}^{\\\\infty} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v  \\\\tag{1}\\\\\\\\\\n& \\\\int_{0}^{\\\\infty} f(x+0) \\\\frac{\\\\sin \\\\alpha v}{v} d v=\\\\int_{0}^{L} f(x+0) \\\\frac{\\\\sin \\\\alpha v}{v} d v+\\\\int_{L}^{\\\\infty} f(x+0) \\\\frac{\\\\sin \\\\alpha v}{v} d v \\\\tag{2}\\n\\\\end{align*}\\n\\n\\nSubtracting,\\n\\n\\n\\\\begin{align*}\\n\\\\int_{0}^{\\\\infty}\\\\{f(x+v)-f(x+0)\\\\} \\\\frac{\\\\sin \\\\alpha v}{v} d v= & \\\\int_{0}^{L}\\\\{f(x+v)-f(x+0)\\\\} \\\\frac{\\\\sin \\\\alpha v}{v} d v \\\\\\\\\\n& +\\\\int_{L}^{\\\\infty} f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v} d v-\\\\int_{L}^{\\\\infty} f(x+0) \\\\frac{\\\\sin \\\\alpha v}{v} d v \\\\tag{3}\\n\\\\end{align*}\\n\\n\\nDenoting the integrals in Equation (3) by $I, I_{1}, I_{2}$, and $I_{3}$, respectively, we have $I=I_{1}+I_{2}+I_{3}$ so that\\n\\n\\n\\\\begin{equation*}\\n|I| \\\\leqq\\\\left|I_{1}\\\\right|+\\\\left|I_{2}\\\\right|+\\\\left|I_{3}\\\\right| \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nNow\\n\\n$$\\n\\\\left|I_{2}\\\\right| \\\\leqq \\\\int_{L}^{\\\\infty}\\\\left|f(x+v) \\\\frac{\\\\sin \\\\alpha v}{v}\\\\right| d v \\\\leqq \\\\frac{1}{L} \\\\int_{L}^{\\\\infty}|f(x+v)| d v\\n$$\\n\\nAlso,\\n\\n$$\\n\\\\left|I_{3}\\\\right| \\\\leqq|f(x+0)|\\\\left|\\\\int_{L}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha v}{v} d v\\\\right|\\n$$\\n\\nSince both $\\\\left.\\\\int_{0}^{\\\\infty} \\\\mid f(x)\\\\right\\\\} d x$ and $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\sin \\\\alpha v}{v} d v$ converge, we can choose $L$ so large that $\\\\left|I_{2}\\\\right| \\\\leqq \\\\epsilon / 3,\\\\left|I_{3}\\\\right|$ $\\\\leqq \\\\epsilon / 3$. Also, we can choose $\\\\alpha$ so large that $\\\\left|I_{1}\\\\right| \\\\leqq \\\\epsilon / 3$. Then from Equation (4) we have $|I|<\\\\epsilon$ for $\\\\alpha$ and $\\\\bar{L}$ sufficiently large so that the required result follows.\\n\\nThis result follows by reasoning exactly analogous to that in (a).\\n',\n",
       " \"\\n14.12. Prove Fourier's integral formula where $f(\\\\mathrm{x})$ satisfies the conditions stated on Page 377.\\n\\nWe must prove that $\\\\lim _{L \\\\rightarrow \\\\infty} \\\\frac{1}{\\\\pi} \\\\int_{\\\\alpha=0}^{L} \\\\int_{u=-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha(x-u) d u d \\\\alpha=\\\\frac{f(x+0)+f(x-0)}{2}$.\\n\\nSince $\\\\left|\\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha(x-u) d u\\\\right| \\\\leqq \\\\int_{-\\\\infty}^{\\\\infty}|f(u)| d u$, which converges, it follows by the Weierstrass test that $\\\\int_{-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha(x-u) d u$ converges absolutely and uniformly for all $\\\\alpha$. Thus, we can reverse the order of integration to obtain\\n\\n$$\\n\\\\begin{aligned}\\n\\\\frac{1}{\\\\pi} \\\\int_{\\\\alpha=0}^{L} d \\\\alpha \\\\int_{u=-\\\\infty}^{\\\\infty} f(u) \\\\cos \\\\alpha(x-u) d u & =\\\\frac{1}{\\\\pi} \\\\int_{u=-\\\\infty}^{\\\\infty} f(u) d u \\\\int_{\\\\alpha=0}^{L} \\\\cos \\\\alpha(x-u) d \\\\alpha \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{u=-\\\\infty}^{\\\\infty} f(u) \\\\frac{\\\\sin L(u-x)}{u-x} d u \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{u=-\\\\infty}^{\\\\infty} f(x+v) \\\\frac{\\\\sin L v}{v} d v \\\\\\\\\\n& =\\\\frac{1}{\\\\pi} \\\\int_{-\\\\infty}^{0} f(x+v) \\\\frac{\\\\sin L v}{v} d v+\\\\frac{1}{\\\\pi} \\\\int_{0}^{\\\\infty} f(x+v) \\\\frac{\\\\sin L v}{v} d v\\n\\\\end{aligned}\\n$$\\n\\nwhere we have let $u=x+v$.\\\\\\\\\\nLetting $L \\\\rightarrow \\\\infty$, we see by Problem 14.11 that the given integral converges to $\\\\frac{f(x)+0)+f(x-0)}{2}$ as\\\\\\\\\\nrequired. required.\\n\\n\\n\\\\section*{Miscellaneous problems}\\n\",\n",
       " \"14.13. Solve $\\\\frac{\\\\partial U}{\\\\partial t}=\\\\frac{\\\\partial^{2} U}{\\\\partial x^{2}}$, subject to the conditions $U(0, t)=0, U(x, 0)=\\\\left\\\\{\\\\begin{array}{rr}1 & 0<x<1 \\\\\\\\ 0 & x \\\\geqq 1\\\\end{array}, U(x, 1)\\\\right.$ is bounded where $x>0, t>0$.\\n\\nWe proceed as in Problem 13.24. A solution satisfying the partial differential equation and the first boundary condition is given by $B e^{-\\\\lambda 2} t \\\\sin \\\\lambda x$. Unlike Problem 13.24, the boundary conditions do not prescribe the specific values for $\\\\lambda$, so we must assume that all values of $\\\\lambda$ are possible. By analogy with that problem, we sum over all possible values of $\\\\lambda$, which corresponds to an integration in this case, and are led to the possible solution\\n\\n\\n\\\\begin{equation*}\\nU(x, 1)=\\\\int_{0}^{\\\\infty} B(\\\\lambda) e^{-\\\\lambda^{2} t} \\\\sin \\\\lambda x d \\\\lambda \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere $B(\\\\lambda)$ is undetermined. By the second condition, we have\\n\\n\\\\[\\n\\\\int_{0}^{\\\\infty} B(\\\\lambda) \\\\sin \\\\lambda x d \\\\lambda=\\\\left\\\\{\\\\begin{array}{rr}\\n1 & 0<x<1  \\\\tag{2}\\\\\\\\\\n0 & x \\\\geqq 1\\n\\\\end{array}=f(x)\\\\right.\\n\\\\]\\n\\nfrom which we have, by Fourier's integral formula,\\n\\n\\n\\\\begin{equation*}\\nB(\\\\lambda)=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\infty} f(x) \\\\sin \\\\lambda x d x=\\\\frac{2}{\\\\pi} \\\\int_{0}^{1} \\\\sin \\\\lambda x d x=\\\\frac{2(1-\\\\cos \\\\lambda)}{\\\\pi \\\\lambda} \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nso that, at least formally, the solution is given by\\n\\n\\n\\\\begin{equation*}\\nU(x, 1)=\\\\frac{2}{\\\\pi} \\\\int_{0}^{\\\\infty}\\\\left(\\\\frac{1-\\\\cos \\\\lambda}{\\\\lambda}\\\\right) e^{-\\\\lambda^{2} t} \\\\sin \\\\lambda x d x \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nSee Problem 14.26.\\n\",\n",
       " '\\n14.14. Show that $e^{-x 2} / 2$ is its own Fourier transform.\\n\\nSince $e^{-x 2} / 2$ is even, its Fourier transform is given by $\\\\sqrt{2 / \\\\pi}=\\\\int_{0}^{\\\\infty} e^{-x^{2} / 2} \\\\cos x \\\\alpha d x$.\\n\\nLetting $x=\\\\sqrt{2 u}$ and using Problem 12.32, the integral becomes\\n\\n$$\\n\\\\frac{2}{\\\\sqrt{\\\\pi}} \\\\int_{0}^{\\\\infty} e^{-u^{2}} \\\\cos (\\\\alpha \\\\sqrt{2} u) d u=\\\\frac{2}{\\\\sqrt{\\\\pi}} \\\\cdot \\\\frac{\\\\sqrt{\\\\pi}}{2} e^{-\\\\alpha^{2} / 2}\\n$$\\n\\nwhich proves the required result.\\n',\n",
       " '\\n14.15. Solve the integral equation\\n\\n$$\\ny(x)=g(x)+\\\\int_{-\\\\infty}^{\\\\infty} y(u) r(x-u) d u\\n$$\\n\\nwhere $g(x)$ and $r(x)$ are given.\\n\\nSuppose that the Fourier transforms of $y(x), g(x)$, and $r(x)$ exist, and denote them by $Y(\\\\alpha), G(\\\\alpha)$, and $R(\\\\alpha)$, respectively. Then, taking the Fourier transform of both sides of the given integral equation, we have, by the convolution theorem,\\n\\n$$\\nY(\\\\alpha)=G(\\\\alpha)+\\\\sqrt{2 \\\\pi} Y(\\\\alpha) R(\\\\alpha) \\\\quad \\\\text { or } \\\\quad Y(\\\\alpha)=\\\\frac{G(\\\\alpha)}{1-\\\\sqrt{2 \\\\pi} R(\\\\alpha)}\\n$$\\n\\nThen\\n\\n$$\\ny(x)=\\\\mathscr{F}^{-1}\\\\left\\\\{\\\\frac{G(\\\\alpha)}{1-\\\\sqrt{2 \\\\pi} R(\\\\alpha)}\\\\right\\\\}=\\\\frac{1}{\\\\sqrt{2 \\\\pi}} \\\\int_{-\\\\infty}^{\\\\infty} \\\\frac{G(\\\\alpha)}{1-\\\\sqrt{2 \\\\pi} R(\\\\alpha)} e^{-i \\\\alpha x} d \\\\alpha\\n$$\\n\\nassuming this integral exists.\\n\\n',\n",
       " '15.1. $\\\\quad$ Prove (a) $\\\\Gamma(x+1)=x \\\\Gamma(\\\\mathrm{x}), x>0$ and (b) $\\\\Gamma(n+1)=n !, n=1,2,3, \\\\ldots$\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Gamma(v+1) & =\\\\int_{0}^{\\\\infty} x^{v} e^{-x} d x=\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} x^{v} e^{-x} d x \\\\\\\\\\n& =\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\left.\\\\left(x^{v}\\\\right)\\\\left(-e^{-x}\\\\right)\\\\right|_{0} ^{M}-\\\\int_{0}^{M}\\\\left(-e^{-x}\\\\right)\\\\left(v x^{v-1}\\\\right) d x\\\\right\\\\} \\\\\\\\\\n& =\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{-M^{v} e^{-M}+v \\\\int_{0}^{M} x^{v-1} e^{-x} d x\\\\right\\\\}=v \\\\Gamma(v) \\\\quad \\\\text { if } v>0\\n\\\\end{aligned}\\n$$\\n\\n(a)\\n\\n(b) $\\\\Gamma(1)=\\\\int_{0}^{\\\\infty} e^{-x} d x=\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} e^{-x} d x=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left(1-e^{-M}\\\\right)=1$.\\n\\nPut $n=1,2,3, \\\\ldots$ in $\\\\Gamma(n+1)=n \\\\Gamma(n)$. Then\\n\\n$$\\n\\\\Gamma(2)=1 \\\\Gamma(1)=1, \\\\Gamma(3)=2 \\\\Gamma(2)=2 \\\\cdot 1=2 ! \\\\Gamma(4)=3 \\\\Gamma(3)=3 \\\\cdot 2 !=3 !\\n$$\\n\\nIn general, $\\\\Gamma(n+1)=n$ ! if $n$ is a positive integer.\\n',\n",
       " '\\n15.2. Evaluate each of the following:\\n\\n(a) $\\\\frac{\\\\Gamma(6)}{2 \\\\Gamma(3)}=\\\\frac{5 !}{2 \\\\cdot 2 !}=\\\\frac{5 \\\\cdot 4 \\\\cdot 3 \\\\cdot 2}{2 \\\\cdot 2}=30$\\n\\n(b) $\\\\frac{\\\\Gamma\\\\left(\\\\frac{5}{2}\\\\right)}{\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}=\\\\frac{\\\\frac{3}{2} \\\\Gamma\\\\left(\\\\frac{3}{2}\\\\right)}{\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}=\\\\frac{\\\\frac{3}{2} \\\\cdot \\\\frac{1}{2} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}=\\\\frac{3}{4}$\\n\\n(c) $\\\\frac{\\\\Gamma(3) \\\\Gamma(2.5)}{\\\\Gamma(5.5)}=\\\\frac{2 !(1.5)(0.5) \\\\Gamma(0.5)}{(4.5)(3.5)(2.5)(1.5)(0.5) \\\\Gamma(0.5)}=\\\\frac{16}{315}$\\n\\n(d) $\\\\frac{6 \\\\Gamma\\\\left(\\\\frac{8}{3}\\\\right)}{5 \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)}=\\\\frac{6\\\\left(\\\\frac{5}{3}\\\\right)\\\\left(\\\\frac{2}{3}\\\\right) \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)}{5 \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)}=\\\\frac{4}{3}$\\n',\n",
       " '\\n15.3. Evaluate each integral.\\n\\n(a) $\\\\int_{0}^{\\\\infty} x^{3} e^{-x} d x=\\\\Gamma(4)=3 !=6$\\n\\n(b) $\\\\int_{0}^{\\\\infty} x^{6} e^{-2 x} d x$\\n\\nLet $2 x=7$. Then the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty}\\\\left(\\\\frac{y}{2}\\\\right)^{6} e^{-y} \\\\frac{d y}{2}=\\\\frac{1}{2^{7}} \\\\int_{0}^{\\\\infty} y^{6} e^{-y} d y=\\\\frac{\\\\Gamma(7)}{2^{7}}=\\\\frac{6 !}{2^{7}}=\\\\frac{45}{8}\\n$$\\n',\n",
       " '\\n15.4. Prove that $\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=\\\\sqrt{\\\\pi}$.\\n\\n$$\\n\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=\\\\int_{0}^{\\\\infty} x^{-1 / 2} e^{-x} d x\\n$$\\n\\nLetting $x=u^{2}$ this integral becomes\\n\\n$$\\n2 \\\\int_{0}^{\\\\infty} e^{-u^{2}} d u=2\\\\left(\\\\frac{\\\\sqrt{\\\\pi}}{2}\\\\right)=\\\\sqrt{\\\\pi}\\n$$\\n\\nusing Problem 12.31. This result also is described in Equation (11a, b) on Page 391.\\n',\n",
       " '\\n15.5. Evaluate each integral.\\n\\n(a) $\\\\int_{0}^{\\\\infty} \\\\sqrt{y} e^{-y^{2}} d y$.\\n\\nLetting $y^{3}=x$, the intergral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\sqrt{x^{1 / 3}} e^{-x} \\\\cdot \\\\frac{1}{3} x^{-2 / 3} d x=\\\\frac{1}{3} \\\\int_{0}^{\\\\infty} x^{-1 / 2} e^{-x} d x=\\\\frac{1}{3} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=\\\\frac{\\\\sqrt{\\\\pi}}{3}\\n$$\\n\\n(b)\\n\\n$\\\\int_{0}^{\\\\infty} 3^{-4 x^{2}} d x=\\\\int_{0}^{\\\\infty}\\\\left(e^{\\\\operatorname{In} 3}\\\\right)^{\\\\left(-4 x^{2}\\\\right)} d z=\\\\int_{0}^{\\\\infty}\\\\left(e^{-(4 \\\\ln 3) z^{2}} d z\\\\right.$\\n\\nLetting $(4 \\\\ln 3) z^{2}=x$, the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\mathrm{e}^{-x} d\\\\left(\\\\frac{x^{1 / 2}}{\\\\sqrt{4 \\\\ln 3}}\\\\right)=\\\\frac{1}{2 \\\\sqrt{4 \\\\ln 3}} \\\\int_{0}^{\\\\infty} x^{-1 / 2} e^{-x} d x=\\\\frac{\\\\Gamma(1 / 2)}{2 \\\\sqrt{4 \\\\ln 3}}=\\\\frac{\\\\sqrt{\\\\pi}}{4 \\\\sqrt{\\\\ln 3}}\\n$$\\n\\n(c) $\\\\int_{0}^{1} \\\\frac{d x}{\\\\sqrt{-\\\\ln x}}$.\\n\\nLet $-\\\\ln \\\\mathrm{x}=\\\\mathrm{u}$. Then $\\\\mathrm{x}=\\\\mathrm{e}-\\\\mathrm{u}$. When $\\\\mathrm{x}=1, \\\\mathrm{u}=0$; when $\\\\mathrm{x}=0, \\\\mathrm{u}=\\\\infty$. The integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{e^{-u}}{\\\\sqrt{u}} d u=\\\\int_{0}^{\\\\infty} u^{-1 / 2} e^{-u} d u=\\\\Gamma(1 / 2)=\\\\sqrt{\\\\pi}\\n$$\\n',\n",
       " '\\n15.6. Evaluate $\\\\int_{0}^{\\\\infty} x^{m} e^{-a x^{n}} d x$, where $m, n$, and $a$ are positive constants.\\n\\nLetting $a x^{n}=y$, the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty}\\\\left\\\\{\\\\left(\\\\frac{y}{a}\\\\right)^{1 / n}\\\\right\\\\}^{m} e^{-y} d\\\\left\\\\{\\\\left(\\\\frac{y}{a}\\\\right)^{1 / n}\\\\right\\\\}=\\\\frac{1}{n a^{(m+1) / n}} \\\\int_{0}^{\\\\infty} y^{(m+1) / n-1} e^{-y} d y=\\\\frac{1}{n a^{(m+1) / n}} \\\\Gamma\\\\left(\\\\frac{m+1}{n}\\\\right)\\n$$\\n',\n",
       " '\\n15.7. Evaluate (a) (a) $\\\\Gamma(-1 / 2)$ (b) $(-5 / 2)$\\n\\nWe use the generalization to negative values defined by $\\\\Gamma(x)=\\\\frac{\\\\Gamma(x+1)}{x}$.\\n\\n(a) Letting $x=-\\\\frac{1}{2}, \\\\quad \\\\Gamma(-1 / 2)=\\\\frac{\\\\Gamma(1 / 2)}{-1 / 2}=-2 \\\\sqrt{\\\\pi}$.\\n\\n(b) Letting $x=-3 / 2, \\\\quad \\\\Gamma(-3 / 2)=\\\\frac{\\\\Gamma(-1 / 2)}{-3 / 2}=\\\\frac{-2 \\\\sqrt{\\\\pi}}{-3 / 2}=\\\\frac{4 \\\\sqrt{\\\\pi}}{3}$, using (a)\\n\\nThen $\\\\Gamma(-5 / 2)=\\\\frac{\\\\Gamma(-3 / 2)}{-5 / 2}=-\\\\frac{8}{15} \\\\sqrt{\\\\pi}$.\\n',\n",
       " '\\n15.8. Prove that $\\\\int_{0}^{1} x^{m}(\\\\ln x)^{n} d x=\\\\frac{(-1)^{n} n !}{(m+1)^{n+1}}$, where $n$ is a positive integer and $m>-1$.\\n\\nLetting $x=e^{-y}$, the integral becomes $(-1)^{n} \\\\int_{0}^{\\\\infty} y^{n} e^{-(m+1) y} d y$. If $(m+1) y=u$, this last integral becomes\\n\\n$$\\n(-1)^{n} \\\\int_{0}^{\\\\infty} \\\\frac{u^{n}}{(m+1)^{n}} e^{-u} \\\\frac{d u}{m+1}=\\\\frac{(-1)^{n}}{(m+1)^{n+1}} \\\\int_{0}^{\\\\infty} u^{n} e^{-u} d u=\\\\frac{(-1)^{n}}{(m+1)^{n+1}} \\\\Gamma(n+1)=\\\\frac{(-1)^{n} n !}{(m+1)^{n+1}}\\n$$\\n\\nCompare with Problem 8.50.\\n',\n",
       " \"\\n15.9. A particle is attracted toward a fixed point $O$ with a force inversely proportional to its instantaneous distance from $O$. If the particle is released from rest, find the time for it to reach $O$\\n\\nAt time $t=0$, let the particle be located on the $x$ axis at $x=a>0$ and let $O$ be the origin. Then, by Newton's law,\\n\\n\\n\\\\begin{equation*}\\nm \\\\frac{d^{2} x}{d t^{2}}=-\\\\frac{k}{x} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere $m$ is the mass of the particle and $k>0$ is a constant of proportionality. comes\\n\\nLet $\\\\frac{d x}{d t}=v$, the velocity of the particle. Then $\\\\frac{d^{2} x}{d t^{2}}=\\\\frac{d v}{d t}=\\\\frac{d v}{d x} \\\\cdot \\\\frac{d x}{d t}=v \\\\cdot \\\\frac{d v}{d x}$ and Equation (1) be-\\n\\n\\n\\\\begin{equation*}\\nm v \\\\frac{d v}{d x}=-\\\\frac{k}{x} \\\\quad \\\\text { or } \\\\quad \\\\frac{m v^{2}}{2}=-k \\\\ln x+c \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nupon integrating. Since $v=0$ at $x=a$, we find $c=k \\\\ln a$. Then\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{m v^{2}}{2}=k \\\\ln \\\\frac{a}{x} \\\\quad \\\\text { or } \\\\quad v=\\\\frac{d x}{d t}=-\\\\sqrt{\\\\frac{2 k}{m}} \\\\sqrt{\\\\ln \\\\frac{a}{x}} \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nwhere the negative sign is chosen, since $x$ is decreasing as $t$ increases. We thus find that the time $T$ taken for the particle to go from $x=a$ to $x=0$ is given by\\n\\n\\n\\\\begin{equation*}\\nT=\\\\sqrt{\\\\frac{m}{2 k}} \\\\int_{0}^{a} \\\\frac{d x}{\\\\sqrt{\\\\ln a / x}} \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nLetting $\\\\ln a / x=u$ or $x=a e^{-u}$, this becomes\\n\\n$$\\nT=a \\\\sqrt{\\\\frac{m}{2 k}} \\\\int_{0}^{\\\\infty} u^{-1 / 2} e^{-u} d u=a \\\\sqrt{\\\\frac{m}{2 k}} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=a \\\\sqrt{\\\\frac{\\\\pi m}{2 k}}\\n$$\\n\\n\\n\\\\section*{The Beta Function}\\n\",\n",
       " '15.10. Prove that (a) $B(u, v)=B(v, u)$ and (b) $B(u, v)=2 \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 u-1} \\\\theta \\\\cos ^{2 v-1} \\\\theta d \\\\theta$.\\n\\n(a) Using the transformation $\\\\mathrm{x}=1-\\\\mathrm{y}$, we have\\n\\n$$\\nB(u, v)=\\\\int_{0}^{1} x^{u-1}(1-x)^{v-1} d x=\\\\int_{0}^{1}(1-y)^{u-1} y^{v-1} d y=\\\\int_{0}^{1} y^{v-1}(1-y)^{u-1} d y=B(v, u)\\n$$\\n\\n(b) Using the transformation $\\\\mathrm{x}=\\\\sin ^{2} \\\\theta$, we have\\n\\n$$\\n\\\\begin{aligned}\\nB(u, v) & =\\\\int_{0}^{1} x^{u-1}(1-x)^{v-1} d x=\\\\int_{0}^{\\\\pi / 2}\\\\left(\\\\sin ^{2} \\\\theta\\\\right)^{u-1}\\\\left(\\\\cos ^{2} \\\\theta\\\\right)^{v-1} 2 \\\\sin \\\\theta \\\\cos \\\\theta d \\\\theta \\\\\\\\\\n& =2 \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 u-1} \\\\theta \\\\cos ^{2 x-1} \\\\theta d \\\\theta\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n15.11. Prove that $B(u, v)=\\\\frac{\\\\Gamma(u) \\\\Gamma(v)}{\\\\Gamma(u+v)} \\\\quad u, v>0$.\\n\\nLetting $z^{2}=x^{2}$, we have $\\\\Gamma(u)=\\\\int_{0}^{\\\\infty} z^{u-1} e^{-z} d x=2 \\\\int_{0}^{\\\\infty} x^{2 u-1} e^{-x^{2}} d x$.\\n\\nSimilarly, $\\\\Gamma(v)=2 \\\\int_{0}^{\\\\infty} y^{2 v-1} e^{-y^{2}} d y$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Gamma(u) \\\\Gamma(v) & =4\\\\left(\\\\int_{0}^{\\\\infty} x^{2 u-1} e^{-x^{2}} d x\\\\right)\\\\left(\\\\int_{0}^{\\\\infty} y^{2 v-1} e^{-y^{2}} d y\\\\right) \\\\\\\\\\n& =4 \\\\int_{0}^{\\\\infty} \\\\int_{0}^{\\\\infty} x^{2 u-1} y^{2 v-1} e^{-\\\\left(x^{2}+y^{2}\\\\right)} d x d y\\n\\\\end{aligned}\\n$$\\n\\nTransforming to polar coordinates, $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Gamma(u) \\\\Gamma(v) & =4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{\\\\infty} \\\\rho^{2}(u+v)-1 e^{-\\\\rho^{2}} \\\\cos ^{2 u-1} \\\\phi \\\\sin ^{2 v-1} \\\\phi d \\\\rho d \\\\phi \\\\\\\\\\n& =4\\\\left(\\\\int_{p=0}^{\\\\infty} p^{2(u+v)-1} e^{-p^{2}} d p\\\\right)\\\\left(\\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\cos ^{2 u-1} \\\\phi \\\\sin ^{2 v-1} \\\\phi d \\\\phi\\\\right) \\\\\\\\\\n& =2 \\\\Gamma(u+v) \\\\int_{0}^{\\\\pi / 2} \\\\cos ^{2 u-1} \\\\phi \\\\sin ^{2 v-1} \\\\phi d \\\\phi=\\\\Gamma(u+v) B(v, u) \\\\\\\\\\n& =\\\\Gamma(u+v) B(u, v)\\n\\\\end{aligned}\\n$$\\n\\nusing the results of Problem 15.10. Hence, the required result follows.\\n\\nThis argument can be made rigorous by using a limiting procedure as in Problem 12.31.\\n',\n",
       " '\\n15.12. Evaluate each of the following integrals.\\n\\n(a) $\\\\int_{0}^{1} x^{4}(1-x)^{3} d x=B(5,4)=\\\\frac{\\\\Gamma(5) \\\\Gamma(4)}{\\\\Gamma(9)}=\\\\frac{4 ! 3 !}{8 !}=\\\\frac{1}{280}$\\n\\n(b) $\\\\int_{0}^{2} \\\\frac{x^{2} d x}{\\\\sqrt{2-x}}$\\n\\nLetting $\\\\mathrm{x}=2 \\\\mathrm{v}$, the integral becomes\\n\\n$4 \\\\sqrt{2} \\\\int_{0}^{1} \\\\frac{v^{2}}{\\\\sqrt{1-v}} d v=4 \\\\sqrt{2} \\\\int_{0}^{1} v^{2}(1-v)^{-1 / 2} d v=4 \\\\sqrt{2} B\\\\left(3, \\\\frac{1}{2}\\\\right)=\\\\frac{4 \\\\sqrt{2 \\\\Gamma(3) \\\\Gamma(1 / 2)}}{\\\\Gamma(7 / 2)}=\\\\frac{64 \\\\sqrt{2}}{15}$\\n\\n(c) $\\\\int_{0}^{a} y^{4} \\\\sqrt{a^{2}-y^{2}} d y$\\n\\nLetting $y^{2}=a^{2} x$ or $y=\\\\sqrt{x}$, the integral becomes\\n\\n$$\\na^{6} \\\\int_{0}^{1} x^{3 / 2}(1-x)^{1 / 2} d x=a^{6} B(5 / 2,3 / 2)=\\\\frac{a^{6} \\\\Gamma(5 / 2) \\\\Gamma(3 / 2)}{\\\\Gamma(4)}=\\\\frac{\\\\pi a^{6}}{16}\\n$$\\n',\n",
       " '\\n15.13. Show that $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 u-1} \\\\theta \\\\cos ^{2 v-1} \\\\theta d \\\\theta=\\\\frac{\\\\Gamma(u) \\\\Gamma(v)}{2 \\\\Gamma(u+v)} \\\\quad u, v>0$.\\n\\nThis follows at once from Problems 15.10 and 15.11 .\\n',\n",
       " '\\n15.14. Evaluate (a) $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{6} \\\\theta d \\\\theta$, (b) $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{4} \\\\theta \\\\cos ^{5} \\\\theta d \\\\theta$, and (c) $\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{4} \\\\theta d \\\\theta$.\\n\\n(a) Let $2 u-1=6,2 v-1=0$, i.e., $u=7 / 2, v=1 / 2$, in Problem 15.13. Then the required integral has the value $\\\\frac{\\\\Gamma(7 / 2) \\\\Gamma(1 / 2)}{2 \\\\Gamma(4)}=\\\\frac{5 \\\\pi}{32}$.\\n\\n(b) Letting $2 \\\\mathrm{u}-1=4,2 v-1=5$, the required integral has the value $\\\\frac{\\\\Gamma(5 / 2) \\\\Gamma(3)}{2 \\\\Gamma(11 / 2)}=\\\\frac{8}{315}$.\\n\\n(c) The given integral $=2 \\\\int_{0}^{\\\\pi / 2} \\\\cos ^{4} \\\\theta d \\\\theta$. Thus, letting $2 u-1=0,2 v-1=4$ in Problem 15.13, the value is $\\\\frac{2 \\\\Gamma(1 / 2) \\\\Gamma(5 / 2)}{2 \\\\Gamma(3)}=\\\\frac{3 \\\\pi}{8}$.\\n',\n",
       " '\\n15.15. Prove $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{p} \\\\theta d \\\\theta=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{p} \\\\theta d \\\\theta=(a) \\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(p-1)}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots p} \\\\frac{\\\\pi}{2}$ if $p$ is an even positive integer and\\n\\n(b) $\\\\frac{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots(p-1)}{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots p}$ if $\\\\mathrm{p}$ is an odd positive integer.\\n\\nFrom Problem 15.13, with $2 u-1=p, 2 v-1=0$, we have\\n\\n$$\\n\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{p} \\\\theta d \\\\theta=\\\\frac{\\\\Gamma\\\\left[\\\\frac{1}{2}(p+1) \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)\\\\right.}{2 \\\\Gamma\\\\left[\\\\frac{1}{2}(p+2)\\\\right]}\\n$$\\n\\n(a) If $p=2 r$, the integral equals\\n\\n$\\\\frac{\\\\Gamma(r+1) \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{2 \\\\Gamma(r+1)}=\\\\frac{\\\\left(r-\\\\frac{1}{2}\\\\right)\\\\left(r-\\\\frac{3}{2}\\\\right) \\\\cdots \\\\frac{1}{2} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right) \\\\cdot \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{2 r(r-1)}=\\\\frac{(2 r-1)(2 r-3) \\\\cdots 1}{2 r(2 r-2) \\\\cdots 2} \\\\frac{\\\\pi}{2}=\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(2 r-1)}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots 2 r} \\\\frac{\\\\pi}{2}$\\n\\n(b) If $\\\\mathrm{p}=2 \\\\mathrm{r}+1$, the integral equals\\n\\n$$\\n\\\\frac{\\\\Gamma(r+1) \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{2 \\\\Gamma\\\\left(r+\\\\frac{3}{2}\\\\right)}=\\\\frac{r(r-1) \\\\cdots 1 \\\\cdot \\\\sqrt{\\\\pi}}{2\\\\left(r+\\\\frac{1}{2}\\\\right)\\\\left(r-\\\\frac{1}{2}\\\\right) \\\\cdots \\\\frac{1}{2} \\\\sqrt{\\\\pi}}=\\\\frac{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots 2 r}{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(2 r+1)}\\n$$\\n\\nIn both cases, $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{p} \\\\theta d \\\\theta=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{p} \\\\theta d \\\\theta$, as seen by letting $\\\\theta=\\\\pi / 2-\\\\phi$.\\n',\n",
       " '\\n15.16. Evaluate (a) $\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{6} \\\\theta d \\\\theta$, (b) $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{3} \\\\theta \\\\cos ^{2} \\\\theta d \\\\theta$, and (c) $\\\\int_{0}^{2 \\\\pi} \\\\sin ^{8} \\\\theta d \\\\theta$.\\n\\n(a) From Problem 15.15, the integral equals $\\\\frac{1 \\\\cdot 3 \\\\cdot 5}{2 \\\\cdot 4 \\\\cdot 6}=\\\\frac{5 \\\\pi}{32}$ [compare Problem 15.14(a)].\\n\\n(b) The integral equals\\n\\n$$\\n\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{3} \\\\theta\\\\left(1-\\\\sin ^{2} \\\\theta\\\\right) d \\\\theta=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{3} \\\\theta d \\\\theta-\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{5} \\\\theta d \\\\theta=\\\\frac{2}{1 \\\\cdot 3}-\\\\frac{2 \\\\cdot 4}{1 \\\\cdot 3 \\\\cdot 5}=\\\\frac{2}{15}\\n$$\\n\\nThe method of Problem 15.14(b) can also be used.\\n\\n(c) The given integral equals $4 \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{8} \\\\theta d \\\\theta=4\\\\left(\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdot 7}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdot 8} \\\\frac{\\\\pi}{2}\\\\right)=\\\\frac{35 \\\\pi}{64}$.\\n',\n",
       " '\\n15.17. Given $\\\\int_{0}^{\\\\infty} \\\\frac{x^{p-1}}{1+x} d x=\\\\frac{\\\\pi}{\\\\sin p \\\\pi}$, show that $\\\\Gamma(p) \\\\Gamma(1-p)=\\\\frac{\\\\pi}{\\\\sin p \\\\pi}$, where $0<p<1$.\\n\\nLetting $\\\\frac{x}{1+x}=y$ or $x=\\\\frac{y}{1-y}$, the given integral becomes\\n\\n$$\\n\\\\int_{0}^{1} y^{p-1}(1-y)^{-p} d y=B(p, 1-p)=\\\\Gamma(p) \\\\Gamma(1-p)\\n$$\\n\\nand the result follows.\\n',\n",
       " '\\n15.18. Evaluate $\\\\int_{0}^{\\\\infty} \\\\frac{d y}{1+y^{4}}$.\\n\\nLet $y^{4}=x$. Then the integral becomes $\\\\frac{1}{4} \\\\int_{0}^{\\\\infty} \\\\frac{x^{-3 / 4}}{1+x} d x=\\\\frac{\\\\pi}{4 \\\\sin (\\\\pi / 4)}=\\\\frac{\\\\pi \\\\sqrt{2}}{4}$ by Problem 15.17, with $p=\\\\frac{1}{4}$. The result can also be obtained by letting $y^{2}=\\\\tan \\\\theta$.\\n',\n",
       " \"\\n15.19. Show that $\\\\int_{0}^{2} x \\\\sqrt[3]{8-x^{3}} d x=\\\\frac{16 \\\\pi}{9 \\\\sqrt{3}}$.\\n\\nLetting $x^{3}-8 y$ or $x=2 y^{1 / 3}$, the integral becomes\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{1} 2 y^{1 / 3} \\\\sqrt{8(1-y)} \\\\cdot \\\\frac{2}{3} y^{-2 / 3} d y & =\\\\frac{8}{3} \\\\int_{0}^{1} y^{-1 / 3}(1-y)^{1 / 3} d y=\\\\frac{8}{3} B\\\\left(\\\\frac{2}{3}, \\\\frac{4}{3}\\\\right) \\\\\\\\\\n& =\\\\frac{8}{3} \\\\frac{\\\\Gamma\\\\left(\\\\frac{2}{3} \\\\Gamma \\\\frac{4}{3}\\\\right)}{\\\\Gamma(2)}=\\\\frac{8}{9} \\\\Gamma\\\\left(\\\\frac{1}{3}\\\\right) \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)=\\\\frac{8}{9} \\\\cdot \\\\frac{\\\\pi}{\\\\sin \\\\pi / 3}=\\\\frac{16 \\\\pi}{9 \\\\sqrt{3}}\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Stirling's formula}\\n\",\n",
       " '15.20. Show that for large positive integers $n, n !=\\\\sqrt{2 \\\\pi n} n^{n} e^{-n}$ approximately.\\n\\nBy definition, $\\\\Gamma(z)=\\\\int_{0}^{\\\\infty} t^{z-1} e^{-t} d t$. Let $l f z=x+1$, then\\n\\n\\n\\\\begin{equation*}\\n\\\\Gamma(x+1)=\\\\int_{0}^{\\\\infty} t^{x} e^{-t} d t=\\\\int_{0}^{\\\\infty} e^{-t+\\\\operatorname{In} t^{x}} d t=\\\\int_{0}^{\\\\infty} e^{-t+x \\\\operatorname{In} t} d t \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nFor a fixed value of $x$ the function $x, \\\\ln t-t$ has a relative maximum for $t=x$ (as is demonstrated by elementary ideas of calculus). The substitution $t=x+y$ yields\\n\\n\\n\\\\begin{equation*}\\n\\\\Gamma(x+1)=e^{-x} \\\\int_{-x}^{\\\\infty} e^{x \\\\operatorname{In}(\\\\mathrm{x}+\\\\mathrm{y})-\\\\mathrm{y}} d y=x^{x} e^{-x} \\\\int_{-x}^{\\\\infty} e^{x \\\\operatorname{In}\\\\left(1+\\\\frac{\\\\mathrm{y}}{\\\\mathrm{x}}\\\\right)-y} d y \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nTo this point the analysis has been rigorous. The following formal steps can be made rigorous by incorporating appropriate limiting procedures; however, because of the difficulty of the proofs, they have been omitted.\\n\\nIn Equation (2) introduce the logarithmic expansion\\n\\n\\n\\\\begin{equation*}\\n\\\\ln \\\\left(1+\\\\frac{y}{x}\\\\right)=\\\\frac{y}{x}-\\\\frac{y^{2}}{2 x^{2}}+\\\\frac{y^{3}}{3 x^{3}}-+\\\\cdots \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nand also let\\n\\n$$\\ny=\\\\sqrt{x} v, \\\\quad d y=\\\\sqrt{x} d v\\n$$\\n\\nThen\\n\\n\\n\\\\begin{equation*}\\n\\\\Gamma(x+1)=x^{x} e^{-x} \\\\sqrt{x} \\\\int_{-x}^{\\\\infty} e^{-v^{2} / 2+\\\\left(v^{3} / 3\\\\right) \\\\sqrt{x-\\\\cdots}} d v \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nFor large values of $x$\\n\\n$$\\n\\\\Gamma(x+1) \\\\approx x^{x} e^{-x} \\\\sqrt{x} \\\\int_{-x}^{\\\\infty} e^{-v^{2} / 2} d v=x^{x} e^{-x} \\\\sqrt{2 \\\\pi x}\\n$$\\n\\nWhen $x$ is replaced by integer values $n$, then the Stirling relation\\n\\n\\n\\\\begin{equation*}\\nn !=\\\\Gamma(x+1) \\\\approx \\\\sqrt{2 \\\\pi x} x^{x} e^{-x} \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nis obtained.\\n\\nIt is of interest that from Equation (4) we can also obtain the result (12) on Page 391. See Problem 15.72.\\n\\n\\n\\\\section*{Dirichlet integrals}\\n',\n",
       " '15.21. Evaluate $I=\\\\iiint_{V} x^{\\\\alpha-1} y^{\\\\beta-1} z^{y-1} d x d y d z$, where $V$ is the region in the first octant bounded by the sphere $x^{2}+y^{2}$ $+z^{2}=1$ and the coordinate planes.\\n\\nLet $x^{2}=u, y^{2}=v, z^{2}=w$. Then\\n\\n\\n\\\\begin{align*}\\nI & =\\\\iiint_{\\\\Re} u^{(\\\\alpha-1) / 2} v^{(\\\\beta-1) / 2} w^{(y-1) / 2} \\\\frac{d u}{2 \\\\sqrt{u}} \\\\frac{d v}{2 \\\\sqrt{v}} \\\\frac{d w}{2 \\\\sqrt{w}}  \\\\tag{1}\\\\\\\\\\n& =\\\\frac{1}{8} \\\\iiint_{\\\\Re} u^{(\\\\alpha / 2)-1} v^{(\\\\beta / 2)-1} w^{(\\\\gamma / 2)-1} d u d v d w\\n\\\\end{align*}\\n\\n\\nwhere $\\\\Re$ is the region in the $u v w$ space bounded by the plane $u+v+w=1$ and the $u v, v w$, and $u w$ planes, as in Figure 15.2. Thus,\\n\\n\\n\\\\begin{align*}\\nI & =\\\\frac{1}{8} \\\\int_{u=0}^{1} \\\\int_{v=0}^{1-u} \\\\int_{w=0}^{1-u-v} u^{(\\\\alpha / 2)-1} v^{(\\\\beta / 2)-1} w^{(y-/ 2)-1} d u d v d w \\\\\\\\\\n& =\\\\frac{1}{4 \\\\gamma} \\\\int_{u=0}^{1} \\\\int_{v=0}^{1-u} u^{(\\\\alpha / 2)-1} v^{(\\\\beta / 2)-1}(1-u-v)^{\\\\gamma / 2} d u d v  \\\\tag{2}\\\\\\\\\\n& =\\\\frac{1}{4 \\\\gamma} \\\\int_{u=0}^{1} u^{(\\\\alpha / 2)-1}\\\\left\\\\{\\\\int_{v=0}^{1-u} v^{(\\\\beta / 2)-1}(1-u-v)^{\\\\gamma / 2} d v\\\\right\\\\} d u\\n\\\\end{align*}\\n\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-410}\\n\\\\end{center}\\n\\nFigure 15.2\\n\\nLetting $v=(1-u) t$, we have\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{v=0}^{1-u} v^{(\\\\beta / 2)-1}(1-u-v)^{\\\\gamma / 2} d v & =(1-u)^{(\\\\beta+\\\\gamma) / 2} \\\\int_{t=0}^{1} t^{(\\\\beta / 2)-1}(1-t)^{\\\\gamma / 2} d t \\\\\\\\\\n& =(1-u)^{(\\\\beta+\\\\gamma) / 2} \\\\frac{\\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2+1)}{\\\\Gamma[(\\\\beta+\\\\gamma) / 2+1]}\\n\\\\end{aligned}\\n$$\\n\\nso that Equation (2) becomes\\n\\n\\n\\\\begin{align*}\\nI & =\\\\frac{1}{4 \\\\gamma} \\\\frac{\\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2+1)}{\\\\Gamma[(\\\\beta+\\\\gamma) / 2+1]} \\\\int_{u=0}^{1} u^{(\\\\alpha / 2)^{-1}}(1-u)^{(\\\\beta+\\\\gamma) / 2} d u \\\\\\\\\\n& =\\\\frac{1}{4 \\\\gamma} \\\\frac{\\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2+1)}{\\\\Gamma[(\\\\beta+\\\\gamma) / 2+1]} \\\\cdot \\\\frac{\\\\Gamma(\\\\alpha / 2) \\\\Gamma(\\\\beta+\\\\gamma) / 2+1)}{\\\\Gamma[(\\\\alpha+\\\\beta+\\\\gamma) / 2+1]}=\\\\frac{\\\\Gamma(\\\\alpha / 2) \\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2)}{8 \\\\Gamma[(\\\\alpha+\\\\beta+) / 2+1]} \\\\tag{3}\\n\\\\end{align*}\\n\\n\\nwhere we have used $(\\\\gamma / 2) \\\\Gamma(\\\\gamma / 2)=\\\\Gamma(\\\\gamma / 2+1)$.\\n\\nThe integral evaluated here is a special case of the Dirichlet integral Equation (20), Page 393. The general case can be evaluated similarly.\\n',\n",
       " '\\n15.22. Find the mass of the region bounded by $x^{2}+y^{2}+z^{2}=a^{2}$ if the density is $\\\\sigma=x^{2} y^{2} z^{2}$.\\n\\nThe required mass $=8 \\\\iiint_{V} x^{2} y^{2} z^{2} d x d y d z$, where $V$ is the region in the first octant bounded by the sphere $x^{2}+y^{2}+z^{2}=a^{2}$ and the coordinate planes.\\n\\nIn the Dirichlet integral, Equation (20), Page 393, let $b=c=a, p=q=r=2$, and $\\\\alpha=\\\\beta=\\\\gamma=3$. Then the required result is\\n\\n$$\\n8 . \\\\frac{a^{3} \\\\cdot a^{3} \\\\cdot a^{3}}{2 \\\\cdot 2 \\\\cdot 2} \\\\frac{\\\\Gamma(3 / 2) \\\\Gamma(3 / 2) \\\\Gamma(3 / 2)}{\\\\Gamma(1+3 / 2+3 / 2+3 / 2)}=\\\\frac{4 \\\\pi s^{9}}{945}\\n$$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '15.23. Show that $\\\\int_{0}^{1} \\\\sqrt{1-x^{4}} d x=\\\\frac{\\\\{\\\\Gamma(1 / 4)\\\\}^{2}}{6 \\\\sqrt{2 \\\\pi}}$.\\n\\nLet $x^{4}=y$. Then the integral becomes\\n\\n$$\\n\\\\frac{1}{4} \\\\int_{0}^{1} y^{-3 / 4}(1-y)^{1 / 2} d y=\\\\frac{1}{4} \\\\frac{\\\\Gamma(1 / 4) \\\\Gamma(3 / 2)}{\\\\Gamma(7 / 4)}=\\\\frac{\\\\sqrt{\\\\pi}}{4} \\\\frac{\\\\{\\\\Gamma(1 / 4)\\\\}^{2}}{\\\\Gamma(1.4) \\\\Gamma(3 / 4)} .\\n$$\\n\\nFrom Problem 15.17, with $p=1 / 4, \\\\Gamma(1 / 4) \\\\Gamma(3 / 4)=\\\\pi \\\\sqrt{2}$, so that the required result follows.\\n',\n",
       " '\\n15.24. Prove the duplication formula $2^{2 p-1} \\\\Gamma(\\\\mathrm{p}) \\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right)=\\\\sqrt{\\\\pi} \\\\Gamma(2 p)$.\\n\\nLet $I=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} x d x, J=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} 2 x d x$.\\n\\nThen $I=\\\\frac{1}{2} B\\\\left(p+\\\\frac{1}{2}, \\\\frac{1}{2}\\\\right)=\\\\frac{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right) \\\\sqrt{\\\\pi}}{2 \\\\Gamma(p+1)}$.\\n\\nLetting $2 x=u$, we find\\n\\n$$\\nJ=\\\\frac{1}{2} \\\\int_{0}^{\\\\pi} \\\\sin ^{2 p} u d u=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} u d u=I\\n$$\\n\\nBut\\n\\n$$\\n\\\\begin{aligned}\\nJ & =\\\\int_{0}^{\\\\pi / 2}(2 \\\\sin x \\\\cos x)^{2 p} d x=2^{2 p} \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} x \\\\cos ^{2 p} x d x \\\\\\\\\\n& =2^{2 p-1} B\\\\left(p+\\\\frac{1}{2}, P+\\\\frac{1}{2}\\\\right)=\\\\frac{2^{2 p-1}\\\\left\\\\{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right)\\\\right\\\\}^{2}}{\\\\Gamma(2 p+1)}\\n\\\\end{aligned}\\n$$\\n\\nThen, since $I=J$,\\n\\n$$\\n\\\\frac{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right) \\\\sqrt{\\\\pi}}{2 p \\\\Gamma(p)}=\\\\frac{2^{2 p-1}\\\\left\\\\{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right)\\\\right\\\\}^{2}}{2 p \\\\Gamma(2 p)}\\n$$\\n\\nand the required result follows. (See Problem 15.74, where the duplication formula is developed for the simpler case of integers.)\\n',\n",
       " '\\n15.25. Show that $\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\phi}{\\\\sqrt{1-\\\\frac{1}{2} \\\\sin ^{2} \\\\phi}}=\\\\frac{\\\\{\\\\Gamma(1 / 4)\\\\}^{2}}{4 \\\\sqrt{\\\\pi}}$.\\n\\nConsider\\n\\n$$\\nI=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{\\\\cos \\\\theta}}=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{-1 / 2} \\\\theta d \\\\theta=\\\\frac{1}{2} B\\\\left(\\\\frac{1}{4}, \\\\frac{1}{2}\\\\right)=\\\\frac{\\\\Gamma\\\\left(\\\\frac{1}{4}\\\\right) \\\\sqrt{\\\\pi}}{2 \\\\Gamma\\\\left(\\\\frac{3}{4}\\\\right)}=\\\\frac{\\\\left\\\\{\\\\Gamma\\\\left(\\\\frac{1}{4}\\\\right)\\\\right\\\\}^{2}}{2 \\\\sqrt{2 \\\\pi}}\\n$$\\n\\nas in Problem 15.23.\\n\\nBut $I=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{\\\\cos \\\\theta}}=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{\\\\cos ^{2} \\\\theta / 2-\\\\sin ^{2} \\\\theta / 2}}=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{1-2 \\\\sin ^{2} \\\\theta / 2}}$. follows.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-411}\\n\\\\end{center}\\n',\n",
       " '\\n15.26. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos x}{x^{p}} d x=\\\\frac{\\\\pi}{2 \\\\Gamma(p) \\\\cos (p \\\\pi / 2)}, 0<p<1$.\\n\\nWe have $\\\\frac{1}{x^{p}}=\\\\frac{1}{\\\\Gamma(p)} \\\\int_{0}^{\\\\infty} u^{p-1} e^{-x u} d u$. Then\\n\\n\\n\\\\begin{align*}\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos x}{x^{p}} d x & =\\\\frac{1}{\\\\Gamma(p)} \\\\int_{0}^{\\\\infty} \\\\int_{0}^{\\\\infty} u^{p-1} e^{-x u} \\\\cos x d u d x  \\\\tag{1}\\\\\\\\\\n& =\\\\frac{1}{\\\\Gamma(p)} \\\\int_{0}^{\\\\infty} \\\\frac{u^{p}}{1+u^{2}} d u\\n\\\\end{align*}\\n\\n\\nwhere we have reversed the order of integration and used Problem 12.22.\\n\\nLetting $u^{2}=v$ in the last integral, we have, by Problem 15.17,\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{\\\\infty} \\\\frac{u^{p}}{1+u^{2}} d u=\\\\frac{1}{2} \\\\int_{0}^{\\\\infty} \\\\frac{v^{(p-1) / 2}}{1+v} d v=\\\\frac{\\\\pi}{2 \\\\sin (p+1) \\\\pi / 2}=\\\\frac{\\\\pi}{2 \\\\cos p \\\\pi / 2} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSubstitution of Equation (2) in Equation (1) yields the required result.\\n',\n",
       " '\\n15.27. Evaluate $\\\\int_{0}^{\\\\infty} \\\\cos x^{2} d x$.\\n\\nLetting $x^{2}=y$, the integral becomes $\\\\frac{1}{2} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos y}{\\\\sqrt{y}} d y=\\\\frac{1}{2}\\\\left(\\\\frac{\\\\pi}{2 \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right) \\\\cos \\\\pi / 4}\\\\right)=\\\\frac{1}{2} \\\\sqrt{\\\\pi / 2}$ by Problem 15.26.\\n\\nThis integral and the corresponding one for the sine [see Problem 15.68(a)] are called Fresnel integrals.\\n\\n']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_solved_problems(latex_content):\n",
    "    # Regex to match section numbers, allowing for whitespace, LaTeX command prefixes, and looking ahead to ensure it's likely a title following.\n",
    "    # Adjust this pattern to fit the specificities of your LaTeX files.\n",
    "    pattern = r'(^|\\\\section|\\\\subsection|\\\\subsubsection)\\s*{?\\s*(\\d+\\.\\d+)(\\.?\\s)(?=\\s*[^%\\\\].*?$)'\n",
    "\n",
    "    # Split the content based on the pattern\n",
    "    sections = []\n",
    "    start = 0\n",
    "\n",
    "    for chapter in latex_content:\n",
    "        if \"solved_problems\" in chapter:\n",
    "            for match in re.finditer(pattern, chapter[\"solved_problems\"], flags=re.MULTILINE):\n",
    "                end = match.start()\n",
    "                if start < end:\n",
    "                    sections.append(chapter[\"solved_problems\"][start:end])\n",
    "                start = end\n",
    "            sections.append(chapter[\"solved_problems\"][start:])  # Add the last section\n",
    "\n",
    "    return sections\n",
    "\n",
    "get_solved_problems(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0be03f5-3fca-4407-99ba-b08e4f955834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supplementary_problems_answers_in_chapters(latex_content):\n",
    "    # Regex to match section numbers, allowing for whitespace, LaTeX command prefixes, and looking ahead to ensure it's likely a title following.\n",
    "    # Adjust this pattern to fit the specificities of your LaTeX files.\n",
    "    pattern = r'(^|\\\\section|\\\\subsection|\\\\subsubsection)\\s*{?\\s*(\\d+\\.\\d+)(\\.?\\s)(?=\\s*[^%\\\\].*?$)'\n",
    "\n",
    "    # Split the content based on the pattern\n",
    "    questions = []\n",
    "    answers = []\n",
    "    start = 0\n",
    "\n",
    "    for chapter in latex_content:\n",
    "        if \"solved_problems\" in chapter:\n",
    "            for match in re.finditer(pattern, chapter[\"supplementary_problems\"], flags=re.MULTILINE):\n",
    "                end = match.start()\n",
    "                if start < end:\n",
    "                    questions.append(chapter[\"supplementary_problems\"][start:end])\n",
    "                start = end\n",
    "            questions.append(chapter[\"supplementary_problems\"][start:])  # Add the last section\n",
    "        if \"answers_to_supplementary_problems\" in chapter:\n",
    "            for match in re.finditer(pattern, chapter[\"answers_to_supplementary_problems\"], flags=re.MULTILINE):\n",
    "                end = match.start()\n",
    "                if start < end:\n",
    "                    answers.append(chapter[\"answers_to_supplementary_problems\"][start:end])\n",
    "                start = end\n",
    "            answers.append(chapter[\"answers_to_supplementary_problems\"][start:])  # Add the last section\n",
    "\n",
    "    sections = []\n",
    "    unsanswered = []\n",
    "    for question in questions:\n",
    "        start_string = question.split(\" \")[0].strip()\n",
    "        found_answer = False\n",
    "        for answer in answers:\n",
    "            if start_string in answer and answer.strip().index(start_string)==0:\n",
    "                sections.append(question+\" SOLUTION:\"+answer)\n",
    "                found_answer = True\n",
    "        if not found_answer:\n",
    "            unsanswered.append(question)\n",
    "        \n",
    "    return sections, unsanswered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fdad28-6a16-46e9-b4ab-973315da31a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 76\n"
     ]
    }
   ],
   "source": [
    "answered, unanswered = get_supplementary_problems_answers_in_chapters(contents)\n",
    "print(len(answered), len(unanswered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5a083d-3e45-48eb-9d3b-cc960198c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "lesson\n",
      "solved_problems\n",
      "supplementary_problems\n"
     ]
    }
   ],
   "source": [
    "for v in contents[0]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f91ccb5-ea04-4067-9f67-f0de724fdcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing section 0\n",
      "-s->\\section*{SOLVED PROBLEMS} 24\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 34\n",
      "-s->\\section*{SOLVED PROBLEMS} 63\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 77\n",
      "-s->\\section*{SOLVED PROBLEMS} 107\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 118\n",
      "-s->\\section*{SOLVED PROBLEMS} 136\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 147\n",
      "-s->\\section*{SOLVED PROBLEMS} 164\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 170\n",
      "-s->\\section*{SOLVED PROBLEMS} 189\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 197\n",
      "-s->\\section*{SOLVED PROBLEMS} 223\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 238\n",
      "-s->\\section*{SOLVED PROBLEMS} 273\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 282\n",
      "-s->\\section*{SOLVED PROBLEMS} 302\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 311\n",
      "-s->\\section*{SOLVED PROBLEMS} 322\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 327\n",
      "-s->\\section*{SOLVED PROBLEMS} 337\n",
      "-a->\\section*{SUPPLEMENTARY PROBLEMS} 343\n",
      "-s->\\section*{SOLVED PROBLEMS} 364\n",
      "28 solved problems separated out\n"
     ]
    }
   ],
   "source": [
    "#for each book separately, go through all functions above, saving the intermediate outputs\n",
    "book_url = \"books/SCHAUM's Outlines - Advanced Calculus, 3rd Edition_2010/2024_04_03_ffb6ac533fe0a53b3ceeg/2024_04_03_ffb6ac533fe0a53b3ceeg.tex\"# Open the file with read permission\n",
    "with open(book_url, 'r') as file:\n",
    "    # Read the contents of the file into a string\n",
    "    file_contents = file.read()\n",
    "\n",
    "contents = get_structured_contents(book_url, file_contents)\n",
    "\n",
    "#Check for this manually before continuing:\n",
    "#contents must:\n",
    "#have consecutive chapter names on the first line\n",
    "#contains lesson, solved_problems, supplementary_problems\n",
    "#the last chapter must contain answers_to_supplementary_problems\n",
    "\n",
    "#create a json file url from the book url\n",
    "json_url = book_url.rsplit('.', 1)[0] + '.json'\n",
    "\n",
    "solved_problems_this_book = get_solved_problems(contents)\n",
    "print(len(solved_problems_this_book),\"solved problems separated out\")\n",
    "\n",
    "#get supplementary problems and their solutions\n",
    "supplementary_problems_this_book, unanswered = get_supplementary_problems_answers_in_chapters(contents)\n",
    "\n",
    "#print(supplementary_problems_this_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d8bca3-6955-443d-a2d3-cbe964988cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\section*{SOLVED PROBLEMS}\\n\\n\\\\section*{The gamma function}\\n',\n",
       " '15.1. $\\\\quad$ Prove (a) $\\\\Gamma(x+1)=x \\\\Gamma(\\\\mathrm{x}), x>0$ and (b) $\\\\Gamma(n+1)=n !, n=1,2,3, \\\\ldots$\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Gamma(v+1) & =\\\\int_{0}^{\\\\infty} x^{v} e^{-x} d x=\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} x^{v} e^{-x} d x \\\\\\\\\\n& =\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{\\\\left.\\\\left(x^{v}\\\\right)\\\\left(-e^{-x}\\\\right)\\\\right|_{0} ^{M}-\\\\int_{0}^{M}\\\\left(-e^{-x}\\\\right)\\\\left(v x^{v-1}\\\\right) d x\\\\right\\\\} \\\\\\\\\\n& =\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left\\\\{-M^{v} e^{-M}+v \\\\int_{0}^{M} x^{v-1} e^{-x} d x\\\\right\\\\}=v \\\\Gamma(v) \\\\quad \\\\text { if } v>0\\n\\\\end{aligned}\\n$$\\n\\n(a)\\n\\n(b) $\\\\Gamma(1)=\\\\int_{0}^{\\\\infty} e^{-x} d x=\\\\lim _{M \\\\rightarrow \\\\infty} \\\\int_{0}^{M} e^{-x} d x=\\\\lim _{M \\\\rightarrow \\\\infty}\\\\left(1-e^{-M}\\\\right)=1$.\\n\\nPut $n=1,2,3, \\\\ldots$ in $\\\\Gamma(n+1)=n \\\\Gamma(n)$. Then\\n\\n$$\\n\\\\Gamma(2)=1 \\\\Gamma(1)=1, \\\\Gamma(3)=2 \\\\Gamma(2)=2 \\\\cdot 1=2 ! \\\\Gamma(4)=3 \\\\Gamma(3)=3 \\\\cdot 2 !=3 !\\n$$\\n\\nIn general, $\\\\Gamma(n+1)=n$ ! if $n$ is a positive integer.\\n',\n",
       " '\\n15.2. Evaluate each of the following:\\n\\n(a) $\\\\frac{\\\\Gamma(6)}{2 \\\\Gamma(3)}=\\\\frac{5 !}{2 \\\\cdot 2 !}=\\\\frac{5 \\\\cdot 4 \\\\cdot 3 \\\\cdot 2}{2 \\\\cdot 2}=30$\\n\\n(b) $\\\\frac{\\\\Gamma\\\\left(\\\\frac{5}{2}\\\\right)}{\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}=\\\\frac{\\\\frac{3}{2} \\\\Gamma\\\\left(\\\\frac{3}{2}\\\\right)}{\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}=\\\\frac{\\\\frac{3}{2} \\\\cdot \\\\frac{1}{2} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}=\\\\frac{3}{4}$\\n\\n(c) $\\\\frac{\\\\Gamma(3) \\\\Gamma(2.5)}{\\\\Gamma(5.5)}=\\\\frac{2 !(1.5)(0.5) \\\\Gamma(0.5)}{(4.5)(3.5)(2.5)(1.5)(0.5) \\\\Gamma(0.5)}=\\\\frac{16}{315}$\\n\\n(d) $\\\\frac{6 \\\\Gamma\\\\left(\\\\frac{8}{3}\\\\right)}{5 \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)}=\\\\frac{6\\\\left(\\\\frac{5}{3}\\\\right)\\\\left(\\\\frac{2}{3}\\\\right) \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)}{5 \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)}=\\\\frac{4}{3}$\\n',\n",
       " '\\n15.3. Evaluate each integral.\\n\\n(a) $\\\\int_{0}^{\\\\infty} x^{3} e^{-x} d x=\\\\Gamma(4)=3 !=6$\\n\\n(b) $\\\\int_{0}^{\\\\infty} x^{6} e^{-2 x} d x$\\n\\nLet $2 x=7$. Then the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty}\\\\left(\\\\frac{y}{2}\\\\right)^{6} e^{-y} \\\\frac{d y}{2}=\\\\frac{1}{2^{7}} \\\\int_{0}^{\\\\infty} y^{6} e^{-y} d y=\\\\frac{\\\\Gamma(7)}{2^{7}}=\\\\frac{6 !}{2^{7}}=\\\\frac{45}{8}\\n$$\\n',\n",
       " '\\n15.4. Prove that $\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=\\\\sqrt{\\\\pi}$.\\n\\n$$\\n\\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=\\\\int_{0}^{\\\\infty} x^{-1 / 2} e^{-x} d x\\n$$\\n\\nLetting $x=u^{2}$ this integral becomes\\n\\n$$\\n2 \\\\int_{0}^{\\\\infty} e^{-u^{2}} d u=2\\\\left(\\\\frac{\\\\sqrt{\\\\pi}}{2}\\\\right)=\\\\sqrt{\\\\pi}\\n$$\\n\\nusing Problem 12.31. This result also is described in Equation (11a, b) on Page 391.\\n',\n",
       " '\\n15.5. Evaluate each integral.\\n\\n(a) $\\\\int_{0}^{\\\\infty} \\\\sqrt{y} e^{-y^{2}} d y$.\\n\\nLetting $y^{3}=x$, the intergral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\sqrt{x^{1 / 3}} e^{-x} \\\\cdot \\\\frac{1}{3} x^{-2 / 3} d x=\\\\frac{1}{3} \\\\int_{0}^{\\\\infty} x^{-1 / 2} e^{-x} d x=\\\\frac{1}{3} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=\\\\frac{\\\\sqrt{\\\\pi}}{3}\\n$$\\n\\n(b)\\n\\n$\\\\int_{0}^{\\\\infty} 3^{-4 x^{2}} d x=\\\\int_{0}^{\\\\infty}\\\\left(e^{\\\\operatorname{In} 3}\\\\right)^{\\\\left(-4 x^{2}\\\\right)} d z=\\\\int_{0}^{\\\\infty}\\\\left(e^{-(4 \\\\ln 3) z^{2}} d z\\\\right.$\\n\\nLetting $(4 \\\\ln 3) z^{2}=x$, the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\mathrm{e}^{-x} d\\\\left(\\\\frac{x^{1 / 2}}{\\\\sqrt{4 \\\\ln 3}}\\\\right)=\\\\frac{1}{2 \\\\sqrt{4 \\\\ln 3}} \\\\int_{0}^{\\\\infty} x^{-1 / 2} e^{-x} d x=\\\\frac{\\\\Gamma(1 / 2)}{2 \\\\sqrt{4 \\\\ln 3}}=\\\\frac{\\\\sqrt{\\\\pi}}{4 \\\\sqrt{\\\\ln 3}}\\n$$\\n\\n(c) $\\\\int_{0}^{1} \\\\frac{d x}{\\\\sqrt{-\\\\ln x}}$.\\n\\nLet $-\\\\ln \\\\mathrm{x}=\\\\mathrm{u}$. Then $\\\\mathrm{x}=\\\\mathrm{e}-\\\\mathrm{u}$. When $\\\\mathrm{x}=1, \\\\mathrm{u}=0$; when $\\\\mathrm{x}=0, \\\\mathrm{u}=\\\\infty$. The integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty} \\\\frac{e^{-u}}{\\\\sqrt{u}} d u=\\\\int_{0}^{\\\\infty} u^{-1 / 2} e^{-u} d u=\\\\Gamma(1 / 2)=\\\\sqrt{\\\\pi}\\n$$\\n',\n",
       " '\\n15.6. Evaluate $\\\\int_{0}^{\\\\infty} x^{m} e^{-a x^{n}} d x$, where $m, n$, and $a$ are positive constants.\\n\\nLetting $a x^{n}=y$, the integral becomes\\n\\n$$\\n\\\\int_{0}^{\\\\infty}\\\\left\\\\{\\\\left(\\\\frac{y}{a}\\\\right)^{1 / n}\\\\right\\\\}^{m} e^{-y} d\\\\left\\\\{\\\\left(\\\\frac{y}{a}\\\\right)^{1 / n}\\\\right\\\\}=\\\\frac{1}{n a^{(m+1) / n}} \\\\int_{0}^{\\\\infty} y^{(m+1) / n-1} e^{-y} d y=\\\\frac{1}{n a^{(m+1) / n}} \\\\Gamma\\\\left(\\\\frac{m+1}{n}\\\\right)\\n$$\\n',\n",
       " '\\n15.7. Evaluate (a) (a) $\\\\Gamma(-1 / 2)$ (b) $(-5 / 2)$\\n\\nWe use the generalization to negative values defined by $\\\\Gamma(x)=\\\\frac{\\\\Gamma(x+1)}{x}$.\\n\\n(a) Letting $x=-\\\\frac{1}{2}, \\\\quad \\\\Gamma(-1 / 2)=\\\\frac{\\\\Gamma(1 / 2)}{-1 / 2}=-2 \\\\sqrt{\\\\pi}$.\\n\\n(b) Letting $x=-3 / 2, \\\\quad \\\\Gamma(-3 / 2)=\\\\frac{\\\\Gamma(-1 / 2)}{-3 / 2}=\\\\frac{-2 \\\\sqrt{\\\\pi}}{-3 / 2}=\\\\frac{4 \\\\sqrt{\\\\pi}}{3}$, using (a)\\n\\nThen $\\\\Gamma(-5 / 2)=\\\\frac{\\\\Gamma(-3 / 2)}{-5 / 2}=-\\\\frac{8}{15} \\\\sqrt{\\\\pi}$.\\n',\n",
       " '\\n15.8. Prove that $\\\\int_{0}^{1} x^{m}(\\\\ln x)^{n} d x=\\\\frac{(-1)^{n} n !}{(m+1)^{n+1}}$, where $n$ is a positive integer and $m>-1$.\\n\\nLetting $x=e^{-y}$, the integral becomes $(-1)^{n} \\\\int_{0}^{\\\\infty} y^{n} e^{-(m+1) y} d y$. If $(m+1) y=u$, this last integral becomes\\n\\n$$\\n(-1)^{n} \\\\int_{0}^{\\\\infty} \\\\frac{u^{n}}{(m+1)^{n}} e^{-u} \\\\frac{d u}{m+1}=\\\\frac{(-1)^{n}}{(m+1)^{n+1}} \\\\int_{0}^{\\\\infty} u^{n} e^{-u} d u=\\\\frac{(-1)^{n}}{(m+1)^{n+1}} \\\\Gamma(n+1)=\\\\frac{(-1)^{n} n !}{(m+1)^{n+1}}\\n$$\\n\\nCompare with Problem 8.50.\\n',\n",
       " \"\\n15.9. A particle is attracted toward a fixed point $O$ with a force inversely proportional to its instantaneous distance from $O$. If the particle is released from rest, find the time for it to reach $O$\\n\\nAt time $t=0$, let the particle be located on the $x$ axis at $x=a>0$ and let $O$ be the origin. Then, by Newton's law,\\n\\n\\n\\\\begin{equation*}\\nm \\\\frac{d^{2} x}{d t^{2}}=-\\\\frac{k}{x} \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nwhere $m$ is the mass of the particle and $k>0$ is a constant of proportionality. comes\\n\\nLet $\\\\frac{d x}{d t}=v$, the velocity of the particle. Then $\\\\frac{d^{2} x}{d t^{2}}=\\\\frac{d v}{d t}=\\\\frac{d v}{d x} \\\\cdot \\\\frac{d x}{d t}=v \\\\cdot \\\\frac{d v}{d x}$ and Equation (1) be-\\n\\n\\n\\\\begin{equation*}\\nm v \\\\frac{d v}{d x}=-\\\\frac{k}{x} \\\\quad \\\\text { or } \\\\quad \\\\frac{m v^{2}}{2}=-k \\\\ln x+c \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nupon integrating. Since $v=0$ at $x=a$, we find $c=k \\\\ln a$. Then\\n\\n\\n\\\\begin{equation*}\\n\\\\frac{m v^{2}}{2}=k \\\\ln \\\\frac{a}{x} \\\\quad \\\\text { or } \\\\quad v=\\\\frac{d x}{d t}=-\\\\sqrt{\\\\frac{2 k}{m}} \\\\sqrt{\\\\ln \\\\frac{a}{x}} \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nwhere the negative sign is chosen, since $x$ is decreasing as $t$ increases. We thus find that the time $T$ taken for the particle to go from $x=a$ to $x=0$ is given by\\n\\n\\n\\\\begin{equation*}\\nT=\\\\sqrt{\\\\frac{m}{2 k}} \\\\int_{0}^{a} \\\\frac{d x}{\\\\sqrt{\\\\ln a / x}} \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nLetting $\\\\ln a / x=u$ or $x=a e^{-u}$, this becomes\\n\\n$$\\nT=a \\\\sqrt{\\\\frac{m}{2 k}} \\\\int_{0}^{\\\\infty} u^{-1 / 2} e^{-u} d u=a \\\\sqrt{\\\\frac{m}{2 k}} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)=a \\\\sqrt{\\\\frac{\\\\pi m}{2 k}}\\n$$\\n\\n\\n\\\\section*{The Beta Function}\\n\",\n",
       " '15.10. Prove that (a) $B(u, v)=B(v, u)$ and (b) $B(u, v)=2 \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 u-1} \\\\theta \\\\cos ^{2 v-1} \\\\theta d \\\\theta$.\\n\\n(a) Using the transformation $\\\\mathrm{x}=1-\\\\mathrm{y}$, we have\\n\\n$$\\nB(u, v)=\\\\int_{0}^{1} x^{u-1}(1-x)^{v-1} d x=\\\\int_{0}^{1}(1-y)^{u-1} y^{v-1} d y=\\\\int_{0}^{1} y^{v-1}(1-y)^{u-1} d y=B(v, u)\\n$$\\n\\n(b) Using the transformation $\\\\mathrm{x}=\\\\sin ^{2} \\\\theta$, we have\\n\\n$$\\n\\\\begin{aligned}\\nB(u, v) & =\\\\int_{0}^{1} x^{u-1}(1-x)^{v-1} d x=\\\\int_{0}^{\\\\pi / 2}\\\\left(\\\\sin ^{2} \\\\theta\\\\right)^{u-1}\\\\left(\\\\cos ^{2} \\\\theta\\\\right)^{v-1} 2 \\\\sin \\\\theta \\\\cos \\\\theta d \\\\theta \\\\\\\\\\n& =2 \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 u-1} \\\\theta \\\\cos ^{2 x-1} \\\\theta d \\\\theta\\n\\\\end{aligned}\\n$$\\n',\n",
       " '\\n15.11. Prove that $B(u, v)=\\\\frac{\\\\Gamma(u) \\\\Gamma(v)}{\\\\Gamma(u+v)} \\\\quad u, v>0$.\\n\\nLetting $z^{2}=x^{2}$, we have $\\\\Gamma(u)=\\\\int_{0}^{\\\\infty} z^{u-1} e^{-z} d x=2 \\\\int_{0}^{\\\\infty} x^{2 u-1} e^{-x^{2}} d x$.\\n\\nSimilarly, $\\\\Gamma(v)=2 \\\\int_{0}^{\\\\infty} y^{2 v-1} e^{-y^{2}} d y$. Then\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Gamma(u) \\\\Gamma(v) & =4\\\\left(\\\\int_{0}^{\\\\infty} x^{2 u-1} e^{-x^{2}} d x\\\\right)\\\\left(\\\\int_{0}^{\\\\infty} y^{2 v-1} e^{-y^{2}} d y\\\\right) \\\\\\\\\\n& =4 \\\\int_{0}^{\\\\infty} \\\\int_{0}^{\\\\infty} x^{2 u-1} y^{2 v-1} e^{-\\\\left(x^{2}+y^{2}\\\\right)} d x d y\\n\\\\end{aligned}\\n$$\\n\\nTransforming to polar coordinates, $x=\\\\rho \\\\cos \\\\phi, y=\\\\rho \\\\sin \\\\phi$,\\n\\n$$\\n\\\\begin{aligned}\\n\\\\Gamma(u) \\\\Gamma(v) & =4 \\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\int_{\\\\rho=0}^{\\\\infty} \\\\rho^{2}(u+v)-1 e^{-\\\\rho^{2}} \\\\cos ^{2 u-1} \\\\phi \\\\sin ^{2 v-1} \\\\phi d \\\\rho d \\\\phi \\\\\\\\\\n& =4\\\\left(\\\\int_{p=0}^{\\\\infty} p^{2(u+v)-1} e^{-p^{2}} d p\\\\right)\\\\left(\\\\int_{\\\\phi=0}^{\\\\pi / 2} \\\\cos ^{2 u-1} \\\\phi \\\\sin ^{2 v-1} \\\\phi d \\\\phi\\\\right) \\\\\\\\\\n& =2 \\\\Gamma(u+v) \\\\int_{0}^{\\\\pi / 2} \\\\cos ^{2 u-1} \\\\phi \\\\sin ^{2 v-1} \\\\phi d \\\\phi=\\\\Gamma(u+v) B(v, u) \\\\\\\\\\n& =\\\\Gamma(u+v) B(u, v)\\n\\\\end{aligned}\\n$$\\n\\nusing the results of Problem 15.10. Hence, the required result follows.\\n\\nThis argument can be made rigorous by using a limiting procedure as in Problem 12.31.\\n',\n",
       " '\\n15.12. Evaluate each of the following integrals.\\n\\n(a) $\\\\int_{0}^{1} x^{4}(1-x)^{3} d x=B(5,4)=\\\\frac{\\\\Gamma(5) \\\\Gamma(4)}{\\\\Gamma(9)}=\\\\frac{4 ! 3 !}{8 !}=\\\\frac{1}{280}$\\n\\n(b) $\\\\int_{0}^{2} \\\\frac{x^{2} d x}{\\\\sqrt{2-x}}$\\n\\nLetting $\\\\mathrm{x}=2 \\\\mathrm{v}$, the integral becomes\\n\\n$4 \\\\sqrt{2} \\\\int_{0}^{1} \\\\frac{v^{2}}{\\\\sqrt{1-v}} d v=4 \\\\sqrt{2} \\\\int_{0}^{1} v^{2}(1-v)^{-1 / 2} d v=4 \\\\sqrt{2} B\\\\left(3, \\\\frac{1}{2}\\\\right)=\\\\frac{4 \\\\sqrt{2 \\\\Gamma(3) \\\\Gamma(1 / 2)}}{\\\\Gamma(7 / 2)}=\\\\frac{64 \\\\sqrt{2}}{15}$\\n\\n(c) $\\\\int_{0}^{a} y^{4} \\\\sqrt{a^{2}-y^{2}} d y$\\n\\nLetting $y^{2}=a^{2} x$ or $y=\\\\sqrt{x}$, the integral becomes\\n\\n$$\\na^{6} \\\\int_{0}^{1} x^{3 / 2}(1-x)^{1 / 2} d x=a^{6} B(5 / 2,3 / 2)=\\\\frac{a^{6} \\\\Gamma(5 / 2) \\\\Gamma(3 / 2)}{\\\\Gamma(4)}=\\\\frac{\\\\pi a^{6}}{16}\\n$$\\n',\n",
       " '\\n15.13. Show that $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 u-1} \\\\theta \\\\cos ^{2 v-1} \\\\theta d \\\\theta=\\\\frac{\\\\Gamma(u) \\\\Gamma(v)}{2 \\\\Gamma(u+v)} \\\\quad u, v>0$.\\n\\nThis follows at once from Problems 15.10 and 15.11 .\\n',\n",
       " '\\n15.14. Evaluate (a) $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{6} \\\\theta d \\\\theta$, (b) $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{4} \\\\theta \\\\cos ^{5} \\\\theta d \\\\theta$, and (c) $\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{4} \\\\theta d \\\\theta$.\\n\\n(a) Let $2 u-1=6,2 v-1=0$, i.e., $u=7 / 2, v=1 / 2$, in Problem 15.13. Then the required integral has the value $\\\\frac{\\\\Gamma(7 / 2) \\\\Gamma(1 / 2)}{2 \\\\Gamma(4)}=\\\\frac{5 \\\\pi}{32}$.\\n\\n(b) Letting $2 \\\\mathrm{u}-1=4,2 v-1=5$, the required integral has the value $\\\\frac{\\\\Gamma(5 / 2) \\\\Gamma(3)}{2 \\\\Gamma(11 / 2)}=\\\\frac{8}{315}$.\\n\\n(c) The given integral $=2 \\\\int_{0}^{\\\\pi / 2} \\\\cos ^{4} \\\\theta d \\\\theta$. Thus, letting $2 u-1=0,2 v-1=4$ in Problem 15.13, the value is $\\\\frac{2 \\\\Gamma(1 / 2) \\\\Gamma(5 / 2)}{2 \\\\Gamma(3)}=\\\\frac{3 \\\\pi}{8}$.\\n',\n",
       " '\\n15.15. Prove $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{p} \\\\theta d \\\\theta=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{p} \\\\theta d \\\\theta=(a) \\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(p-1)}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots p} \\\\frac{\\\\pi}{2}$ if $p$ is an even positive integer and\\n\\n(b) $\\\\frac{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots(p-1)}{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots p}$ if $\\\\mathrm{p}$ is an odd positive integer.\\n\\nFrom Problem 15.13, with $2 u-1=p, 2 v-1=0$, we have\\n\\n$$\\n\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{p} \\\\theta d \\\\theta=\\\\frac{\\\\Gamma\\\\left[\\\\frac{1}{2}(p+1) \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)\\\\right.}{2 \\\\Gamma\\\\left[\\\\frac{1}{2}(p+2)\\\\right]}\\n$$\\n\\n(a) If $p=2 r$, the integral equals\\n\\n$\\\\frac{\\\\Gamma(r+1) \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{2 \\\\Gamma(r+1)}=\\\\frac{\\\\left(r-\\\\frac{1}{2}\\\\right)\\\\left(r-\\\\frac{3}{2}\\\\right) \\\\cdots \\\\frac{1}{2} \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right) \\\\cdot \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{2 r(r-1)}=\\\\frac{(2 r-1)(2 r-3) \\\\cdots 1}{2 r(2 r-2) \\\\cdots 2} \\\\frac{\\\\pi}{2}=\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(2 r-1)}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots 2 r} \\\\frac{\\\\pi}{2}$\\n\\n(b) If $\\\\mathrm{p}=2 \\\\mathrm{r}+1$, the integral equals\\n\\n$$\\n\\\\frac{\\\\Gamma(r+1) \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right)}{2 \\\\Gamma\\\\left(r+\\\\frac{3}{2}\\\\right)}=\\\\frac{r(r-1) \\\\cdots 1 \\\\cdot \\\\sqrt{\\\\pi}}{2\\\\left(r+\\\\frac{1}{2}\\\\right)\\\\left(r-\\\\frac{1}{2}\\\\right) \\\\cdots \\\\frac{1}{2} \\\\sqrt{\\\\pi}}=\\\\frac{2 \\\\cdot 4 \\\\cdot 6 \\\\cdots 2 r}{1 \\\\cdot 3 \\\\cdot 5 \\\\cdots(2 r+1)}\\n$$\\n\\nIn both cases, $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{p} \\\\theta d \\\\theta=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{p} \\\\theta d \\\\theta$, as seen by letting $\\\\theta=\\\\pi / 2-\\\\phi$.\\n',\n",
       " '\\n15.16. Evaluate (a) $\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{6} \\\\theta d \\\\theta$, (b) $\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{3} \\\\theta \\\\cos ^{2} \\\\theta d \\\\theta$, and (c) $\\\\int_{0}^{2 \\\\pi} \\\\sin ^{8} \\\\theta d \\\\theta$.\\n\\n(a) From Problem 15.15, the integral equals $\\\\frac{1 \\\\cdot 3 \\\\cdot 5}{2 \\\\cdot 4 \\\\cdot 6}=\\\\frac{5 \\\\pi}{32}$ [compare Problem 15.14(a)].\\n\\n(b) The integral equals\\n\\n$$\\n\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{3} \\\\theta\\\\left(1-\\\\sin ^{2} \\\\theta\\\\right) d \\\\theta=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{3} \\\\theta d \\\\theta-\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{5} \\\\theta d \\\\theta=\\\\frac{2}{1 \\\\cdot 3}-\\\\frac{2 \\\\cdot 4}{1 \\\\cdot 3 \\\\cdot 5}=\\\\frac{2}{15}\\n$$\\n\\nThe method of Problem 15.14(b) can also be used.\\n\\n(c) The given integral equals $4 \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{8} \\\\theta d \\\\theta=4\\\\left(\\\\frac{1 \\\\cdot 3 \\\\cdot 5 \\\\cdot 7}{2 \\\\cdot 4 \\\\cdot 6 \\\\cdot 8} \\\\frac{\\\\pi}{2}\\\\right)=\\\\frac{35 \\\\pi}{64}$.\\n',\n",
       " '\\n15.17. Given $\\\\int_{0}^{\\\\infty} \\\\frac{x^{p-1}}{1+x} d x=\\\\frac{\\\\pi}{\\\\sin p \\\\pi}$, show that $\\\\Gamma(p) \\\\Gamma(1-p)=\\\\frac{\\\\pi}{\\\\sin p \\\\pi}$, where $0<p<1$.\\n\\nLetting $\\\\frac{x}{1+x}=y$ or $x=\\\\frac{y}{1-y}$, the given integral becomes\\n\\n$$\\n\\\\int_{0}^{1} y^{p-1}(1-y)^{-p} d y=B(p, 1-p)=\\\\Gamma(p) \\\\Gamma(1-p)\\n$$\\n\\nand the result follows.\\n',\n",
       " '\\n15.18. Evaluate $\\\\int_{0}^{\\\\infty} \\\\frac{d y}{1+y^{4}}$.\\n\\nLet $y^{4}=x$. Then the integral becomes $\\\\frac{1}{4} \\\\int_{0}^{\\\\infty} \\\\frac{x^{-3 / 4}}{1+x} d x=\\\\frac{\\\\pi}{4 \\\\sin (\\\\pi / 4)}=\\\\frac{\\\\pi \\\\sqrt{2}}{4}$ by Problem 15.17, with $p=\\\\frac{1}{4}$. The result can also be obtained by letting $y^{2}=\\\\tan \\\\theta$.\\n',\n",
       " \"\\n15.19. Show that $\\\\int_{0}^{2} x \\\\sqrt[3]{8-x^{3}} d x=\\\\frac{16 \\\\pi}{9 \\\\sqrt{3}}$.\\n\\nLetting $x^{3}-8 y$ or $x=2 y^{1 / 3}$, the integral becomes\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{0}^{1} 2 y^{1 / 3} \\\\sqrt{8(1-y)} \\\\cdot \\\\frac{2}{3} y^{-2 / 3} d y & =\\\\frac{8}{3} \\\\int_{0}^{1} y^{-1 / 3}(1-y)^{1 / 3} d y=\\\\frac{8}{3} B\\\\left(\\\\frac{2}{3}, \\\\frac{4}{3}\\\\right) \\\\\\\\\\n& =\\\\frac{8}{3} \\\\frac{\\\\Gamma\\\\left(\\\\frac{2}{3} \\\\Gamma \\\\frac{4}{3}\\\\right)}{\\\\Gamma(2)}=\\\\frac{8}{9} \\\\Gamma\\\\left(\\\\frac{1}{3}\\\\right) \\\\Gamma\\\\left(\\\\frac{2}{3}\\\\right)=\\\\frac{8}{9} \\\\cdot \\\\frac{\\\\pi}{\\\\sin \\\\pi / 3}=\\\\frac{16 \\\\pi}{9 \\\\sqrt{3}}\\n\\\\end{aligned}\\n$$\\n\\n\\n\\\\section*{Stirling's formula}\\n\",\n",
       " '15.20. Show that for large positive integers $n, n !=\\\\sqrt{2 \\\\pi n} n^{n} e^{-n}$ approximately.\\n\\nBy definition, $\\\\Gamma(z)=\\\\int_{0}^{\\\\infty} t^{z-1} e^{-t} d t$. Let $l f z=x+1$, then\\n\\n\\n\\\\begin{equation*}\\n\\\\Gamma(x+1)=\\\\int_{0}^{\\\\infty} t^{x} e^{-t} d t=\\\\int_{0}^{\\\\infty} e^{-t+\\\\operatorname{In} t^{x}} d t=\\\\int_{0}^{\\\\infty} e^{-t+x \\\\operatorname{In} t} d t \\\\tag{1}\\n\\\\end{equation*}\\n\\n\\nFor a fixed value of $x$ the function $x, \\\\ln t-t$ has a relative maximum for $t=x$ (as is demonstrated by elementary ideas of calculus). The substitution $t=x+y$ yields\\n\\n\\n\\\\begin{equation*}\\n\\\\Gamma(x+1)=e^{-x} \\\\int_{-x}^{\\\\infty} e^{x \\\\operatorname{In}(\\\\mathrm{x}+\\\\mathrm{y})-\\\\mathrm{y}} d y=x^{x} e^{-x} \\\\int_{-x}^{\\\\infty} e^{x \\\\operatorname{In}\\\\left(1+\\\\frac{\\\\mathrm{y}}{\\\\mathrm{x}}\\\\right)-y} d y \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nTo this point the analysis has been rigorous. The following formal steps can be made rigorous by incorporating appropriate limiting procedures; however, because of the difficulty of the proofs, they have been omitted.\\n\\nIn Equation (2) introduce the logarithmic expansion\\n\\n\\n\\\\begin{equation*}\\n\\\\ln \\\\left(1+\\\\frac{y}{x}\\\\right)=\\\\frac{y}{x}-\\\\frac{y^{2}}{2 x^{2}}+\\\\frac{y^{3}}{3 x^{3}}-+\\\\cdots \\\\tag{3}\\n\\\\end{equation*}\\n\\n\\nand also let\\n\\n$$\\ny=\\\\sqrt{x} v, \\\\quad d y=\\\\sqrt{x} d v\\n$$\\n\\nThen\\n\\n\\n\\\\begin{equation*}\\n\\\\Gamma(x+1)=x^{x} e^{-x} \\\\sqrt{x} \\\\int_{-x}^{\\\\infty} e^{-v^{2} / 2+\\\\left(v^{3} / 3\\\\right) \\\\sqrt{x-\\\\cdots}} d v \\\\tag{4}\\n\\\\end{equation*}\\n\\n\\nFor large values of $x$\\n\\n$$\\n\\\\Gamma(x+1) \\\\approx x^{x} e^{-x} \\\\sqrt{x} \\\\int_{-x}^{\\\\infty} e^{-v^{2} / 2} d v=x^{x} e^{-x} \\\\sqrt{2 \\\\pi x}\\n$$\\n\\nWhen $x$ is replaced by integer values $n$, then the Stirling relation\\n\\n\\n\\\\begin{equation*}\\nn !=\\\\Gamma(x+1) \\\\approx \\\\sqrt{2 \\\\pi x} x^{x} e^{-x} \\\\tag{5}\\n\\\\end{equation*}\\n\\n\\nis obtained.\\n\\nIt is of interest that from Equation (4) we can also obtain the result (12) on Page 391. See Problem 15.72.\\n\\n\\n\\\\section*{Dirichlet integrals}\\n',\n",
       " '15.21. Evaluate $I=\\\\iiint_{V} x^{\\\\alpha-1} y^{\\\\beta-1} z^{y-1} d x d y d z$, where $V$ is the region in the first octant bounded by the sphere $x^{2}+y^{2}$ $+z^{2}=1$ and the coordinate planes.\\n\\nLet $x^{2}=u, y^{2}=v, z^{2}=w$. Then\\n\\n\\n\\\\begin{align*}\\nI & =\\\\iiint_{\\\\Re} u^{(\\\\alpha-1) / 2} v^{(\\\\beta-1) / 2} w^{(y-1) / 2} \\\\frac{d u}{2 \\\\sqrt{u}} \\\\frac{d v}{2 \\\\sqrt{v}} \\\\frac{d w}{2 \\\\sqrt{w}}  \\\\tag{1}\\\\\\\\\\n& =\\\\frac{1}{8} \\\\iiint_{\\\\Re} u^{(\\\\alpha / 2)-1} v^{(\\\\beta / 2)-1} w^{(\\\\gamma / 2)-1} d u d v d w\\n\\\\end{align*}\\n\\n\\nwhere $\\\\Re$ is the region in the $u v w$ space bounded by the plane $u+v+w=1$ and the $u v, v w$, and $u w$ planes, as in Figure 15.2. Thus,\\n\\n\\n\\\\begin{align*}\\nI & =\\\\frac{1}{8} \\\\int_{u=0}^{1} \\\\int_{v=0}^{1-u} \\\\int_{w=0}^{1-u-v} u^{(\\\\alpha / 2)-1} v^{(\\\\beta / 2)-1} w^{(y-/ 2)-1} d u d v d w \\\\\\\\\\n& =\\\\frac{1}{4 \\\\gamma} \\\\int_{u=0}^{1} \\\\int_{v=0}^{1-u} u^{(\\\\alpha / 2)-1} v^{(\\\\beta / 2)-1}(1-u-v)^{\\\\gamma / 2} d u d v  \\\\tag{2}\\\\\\\\\\n& =\\\\frac{1}{4 \\\\gamma} \\\\int_{u=0}^{1} u^{(\\\\alpha / 2)-1}\\\\left\\\\{\\\\int_{v=0}^{1-u} v^{(\\\\beta / 2)-1}(1-u-v)^{\\\\gamma / 2} d v\\\\right\\\\} d u\\n\\\\end{align*}\\n\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-410}\\n\\\\end{center}\\n\\nFigure 15.2\\n\\nLetting $v=(1-u) t$, we have\\n\\n$$\\n\\\\begin{aligned}\\n\\\\int_{v=0}^{1-u} v^{(\\\\beta / 2)-1}(1-u-v)^{\\\\gamma / 2} d v & =(1-u)^{(\\\\beta+\\\\gamma) / 2} \\\\int_{t=0}^{1} t^{(\\\\beta / 2)-1}(1-t)^{\\\\gamma / 2} d t \\\\\\\\\\n& =(1-u)^{(\\\\beta+\\\\gamma) / 2} \\\\frac{\\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2+1)}{\\\\Gamma[(\\\\beta+\\\\gamma) / 2+1]}\\n\\\\end{aligned}\\n$$\\n\\nso that Equation (2) becomes\\n\\n\\n\\\\begin{align*}\\nI & =\\\\frac{1}{4 \\\\gamma} \\\\frac{\\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2+1)}{\\\\Gamma[(\\\\beta+\\\\gamma) / 2+1]} \\\\int_{u=0}^{1} u^{(\\\\alpha / 2)^{-1}}(1-u)^{(\\\\beta+\\\\gamma) / 2} d u \\\\\\\\\\n& =\\\\frac{1}{4 \\\\gamma} \\\\frac{\\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2+1)}{\\\\Gamma[(\\\\beta+\\\\gamma) / 2+1]} \\\\cdot \\\\frac{\\\\Gamma(\\\\alpha / 2) \\\\Gamma(\\\\beta+\\\\gamma) / 2+1)}{\\\\Gamma[(\\\\alpha+\\\\beta+\\\\gamma) / 2+1]}=\\\\frac{\\\\Gamma(\\\\alpha / 2) \\\\Gamma(\\\\beta / 2) \\\\Gamma(\\\\gamma / 2)}{8 \\\\Gamma[(\\\\alpha+\\\\beta+) / 2+1]} \\\\tag{3}\\n\\\\end{align*}\\n\\n\\nwhere we have used $(\\\\gamma / 2) \\\\Gamma(\\\\gamma / 2)=\\\\Gamma(\\\\gamma / 2+1)$.\\n\\nThe integral evaluated here is a special case of the Dirichlet integral Equation (20), Page 393. The general case can be evaluated similarly.\\n',\n",
       " '\\n15.22. Find the mass of the region bounded by $x^{2}+y^{2}+z^{2}=a^{2}$ if the density is $\\\\sigma=x^{2} y^{2} z^{2}$.\\n\\nThe required mass $=8 \\\\iiint_{V} x^{2} y^{2} z^{2} d x d y d z$, where $V$ is the region in the first octant bounded by the sphere $x^{2}+y^{2}+z^{2}=a^{2}$ and the coordinate planes.\\n\\nIn the Dirichlet integral, Equation (20), Page 393, let $b=c=a, p=q=r=2$, and $\\\\alpha=\\\\beta=\\\\gamma=3$. Then the required result is\\n\\n$$\\n8 . \\\\frac{a^{3} \\\\cdot a^{3} \\\\cdot a^{3}}{2 \\\\cdot 2 \\\\cdot 2} \\\\frac{\\\\Gamma(3 / 2) \\\\Gamma(3 / 2) \\\\Gamma(3 / 2)}{\\\\Gamma(1+3 / 2+3 / 2+3 / 2)}=\\\\frac{4 \\\\pi s^{9}}{945}\\n$$\\n\\n\\n\\\\section*{Miscellaneous problems}\\n',\n",
       " '15.23. Show that $\\\\int_{0}^{1} \\\\sqrt{1-x^{4}} d x=\\\\frac{\\\\{\\\\Gamma(1 / 4)\\\\}^{2}}{6 \\\\sqrt{2 \\\\pi}}$.\\n\\nLet $x^{4}=y$. Then the integral becomes\\n\\n$$\\n\\\\frac{1}{4} \\\\int_{0}^{1} y^{-3 / 4}(1-y)^{1 / 2} d y=\\\\frac{1}{4} \\\\frac{\\\\Gamma(1 / 4) \\\\Gamma(3 / 2)}{\\\\Gamma(7 / 4)}=\\\\frac{\\\\sqrt{\\\\pi}}{4} \\\\frac{\\\\{\\\\Gamma(1 / 4)\\\\}^{2}}{\\\\Gamma(1.4) \\\\Gamma(3 / 4)} .\\n$$\\n\\nFrom Problem 15.17, with $p=1 / 4, \\\\Gamma(1 / 4) \\\\Gamma(3 / 4)=\\\\pi \\\\sqrt{2}$, so that the required result follows.\\n',\n",
       " '\\n15.24. Prove the duplication formula $2^{2 p-1} \\\\Gamma(\\\\mathrm{p}) \\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right)=\\\\sqrt{\\\\pi} \\\\Gamma(2 p)$.\\n\\nLet $I=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} x d x, J=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} 2 x d x$.\\n\\nThen $I=\\\\frac{1}{2} B\\\\left(p+\\\\frac{1}{2}, \\\\frac{1}{2}\\\\right)=\\\\frac{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right) \\\\sqrt{\\\\pi}}{2 \\\\Gamma(p+1)}$.\\n\\nLetting $2 x=u$, we find\\n\\n$$\\nJ=\\\\frac{1}{2} \\\\int_{0}^{\\\\pi} \\\\sin ^{2 p} u d u=\\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} u d u=I\\n$$\\n\\nBut\\n\\n$$\\n\\\\begin{aligned}\\nJ & =\\\\int_{0}^{\\\\pi / 2}(2 \\\\sin x \\\\cos x)^{2 p} d x=2^{2 p} \\\\int_{0}^{\\\\pi / 2} \\\\sin ^{2 p} x \\\\cos ^{2 p} x d x \\\\\\\\\\n& =2^{2 p-1} B\\\\left(p+\\\\frac{1}{2}, P+\\\\frac{1}{2}\\\\right)=\\\\frac{2^{2 p-1}\\\\left\\\\{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right)\\\\right\\\\}^{2}}{\\\\Gamma(2 p+1)}\\n\\\\end{aligned}\\n$$\\n\\nThen, since $I=J$,\\n\\n$$\\n\\\\frac{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right) \\\\sqrt{\\\\pi}}{2 p \\\\Gamma(p)}=\\\\frac{2^{2 p-1}\\\\left\\\\{\\\\Gamma\\\\left(p+\\\\frac{1}{2}\\\\right)\\\\right\\\\}^{2}}{2 p \\\\Gamma(2 p)}\\n$$\\n\\nand the required result follows. (See Problem 15.74, where the duplication formula is developed for the simpler case of integers.)\\n',\n",
       " '\\n15.25. Show that $\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\phi}{\\\\sqrt{1-\\\\frac{1}{2} \\\\sin ^{2} \\\\phi}}=\\\\frac{\\\\{\\\\Gamma(1 / 4)\\\\}^{2}}{4 \\\\sqrt{\\\\pi}}$.\\n\\nConsider\\n\\n$$\\nI=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{\\\\cos \\\\theta}}=\\\\int_{0}^{\\\\pi / 2} \\\\cos ^{-1 / 2} \\\\theta d \\\\theta=\\\\frac{1}{2} B\\\\left(\\\\frac{1}{4}, \\\\frac{1}{2}\\\\right)=\\\\frac{\\\\Gamma\\\\left(\\\\frac{1}{4}\\\\right) \\\\sqrt{\\\\pi}}{2 \\\\Gamma\\\\left(\\\\frac{3}{4}\\\\right)}=\\\\frac{\\\\left\\\\{\\\\Gamma\\\\left(\\\\frac{1}{4}\\\\right)\\\\right\\\\}^{2}}{2 \\\\sqrt{2 \\\\pi}}\\n$$\\n\\nas in Problem 15.23.\\n\\nBut $I=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{\\\\cos \\\\theta}}=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{\\\\cos ^{2} \\\\theta / 2-\\\\sin ^{2} \\\\theta / 2}}=\\\\int_{0}^{\\\\pi / 2} \\\\frac{d \\\\theta}{\\\\sqrt{1-2 \\\\sin ^{2} \\\\theta / 2}}$. follows.\\n\\n\\\\begin{center}\\n\\\\includegraphics[max width=\\\\textwidth]{2024_04_03_ffb6ac533fe0a53b3ceeg-411}\\n\\\\end{center}\\n',\n",
       " '\\n15.26. Prove that $\\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos x}{x^{p}} d x=\\\\frac{\\\\pi}{2 \\\\Gamma(p) \\\\cos (p \\\\pi / 2)}, 0<p<1$.\\n\\nWe have $\\\\frac{1}{x^{p}}=\\\\frac{1}{\\\\Gamma(p)} \\\\int_{0}^{\\\\infty} u^{p-1} e^{-x u} d u$. Then\\n\\n\\n\\\\begin{align*}\\n\\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos x}{x^{p}} d x & =\\\\frac{1}{\\\\Gamma(p)} \\\\int_{0}^{\\\\infty} \\\\int_{0}^{\\\\infty} u^{p-1} e^{-x u} \\\\cos x d u d x  \\\\tag{1}\\\\\\\\\\n& =\\\\frac{1}{\\\\Gamma(p)} \\\\int_{0}^{\\\\infty} \\\\frac{u^{p}}{1+u^{2}} d u\\n\\\\end{align*}\\n\\n\\nwhere we have reversed the order of integration and used Problem 12.22.\\n\\nLetting $u^{2}=v$ in the last integral, we have, by Problem 15.17,\\n\\n\\n\\\\begin{equation*}\\n\\\\int_{0}^{\\\\infty} \\\\frac{u^{p}}{1+u^{2}} d u=\\\\frac{1}{2} \\\\int_{0}^{\\\\infty} \\\\frac{v^{(p-1) / 2}}{1+v} d v=\\\\frac{\\\\pi}{2 \\\\sin (p+1) \\\\pi / 2}=\\\\frac{\\\\pi}{2 \\\\cos p \\\\pi / 2} \\\\tag{2}\\n\\\\end{equation*}\\n\\n\\nSubstitution of Equation (2) in Equation (1) yields the required result.\\n',\n",
       " '\\n15.27. Evaluate $\\\\int_{0}^{\\\\infty} \\\\cos x^{2} d x$.\\n\\nLetting $x^{2}=y$, the integral becomes $\\\\frac{1}{2} \\\\int_{0}^{\\\\infty} \\\\frac{\\\\cos y}{\\\\sqrt{y}} d y=\\\\frac{1}{2}\\\\left(\\\\frac{\\\\pi}{2 \\\\Gamma\\\\left(\\\\frac{1}{2}\\\\right) \\\\cos \\\\pi / 4}\\\\right)=\\\\frac{1}{2} \\\\sqrt{\\\\pi / 2}$ by Problem 15.26.\\n\\nThis integral and the corresponding one for the sine [see Problem 15.68(a)] are called Fresnel integrals.\\n\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solved_problems_this_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ccd0c273-7ea5-476b-b375-1464670d1260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "print(len(supplementary_problems_this_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a30c0e70-4e8d-4147-a630-3213be81ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_url, 'w') as file:\n",
    "    json.dump([contents, solved_problems_this_book, supplementary_problems_this_book] , file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
